---
title: "第六周练习：回归分析实践"
---

## 练习背景：波士顿房价预测

本练习将使用波士顿房价数据集（Boston），目标是建立回归模型来预测波士顿郊区的房价中位数 (`medv`)。

数据集已经加载在 R 环境中。请使用 `?Boston` 命令查看数据集的详细信息，熟悉各个变量的含义。

## 练习任务

### 任务一：简单线性回归

1.  **问题**：建立一个简单线性回归模型，使用 `rm` (平均房间数) 预测 `medv` (房价中位数)。
    *   **详细步骤**：
        *   使用 `lm()` 函数创建线性回归模型。
        *   在 `lm()` 函数中，设定模型公式为 `medv ~ rm`，明确指出 `rm` 是自变量，`medv` 是因变量。
        *   将创建的模型对象命名为 `simple_lm`，方便后续引用。
        *   使用 `summary(simple_lm)` 函数，请求 R 输出模型摘要报告。
2.  **问题**：解释模型摘要输出中 `rm` 变量的系数估计值。
    *   **详细步骤**：
        *   在 `summary(simple_lm)` 的输出结果中，找到名为 "Coefficients" 的部分。
        *   在 "Coefficients" 部分，找到 `rm` 变量对应的行。
        *   关注 "Estimate" 列，它给出了 `rm` 变量的系数估计值 ($\hat{\beta}_1$)。理解这个数值的含义：当平均房间数 `rm` 增加一个单位时，房价中位数 `medv` 平均会发生怎样的变化？
        *   同时，查看 "Std. Error"、"t value" 和 "Pr(>|t|)" 列。理解标准误差衡量系数估计的精确度，t 值用于检验系数是否显著不为零，而 p 值则给出了显著性检验的概率值。
3.  **问题**：计算模型的 \(R^2\) 值，并解释其含义。
    *   **详细步骤**：
        *   在 `summary(simple_lm)` 的输出结果中，查找 "Multiple R-squared" 的值。
        *   记录下这个 \(R^2\) 值。思考并解释：这个值代表了什么？模型能够解释房价变异的程度是多少？
        *   理解 \(R^2\) 值的范围（0 到 1）以及值越高通常表示模型拟合效果越好的含义。
4.  **问题**：绘制 `rm` 和 `medv` 的散点图，并添加回归线。
    *   **详细步骤**：
        *   使用 `ggplot()` 函数启动 ggplot2 绘图系统，并在其中指定数据集为 `Boston`，通过 `aes(x = rm, y = medv)` 设置 x 轴为 `rm`，y 轴为 `medv`。
        *   使用 `geom_point()` 图层添加散点，展示原始数据点的分布。
        *   使用 `geom_smooth(method = "lm", se = FALSE)` 图层添加线性回归线。设置 `method = "lm"` 指定添加线性回归线，`se = FALSE`  表示不显示回归线周围的置信区间阴影。
        *   使用 `labs()` 函数添加图表标题和坐标轴标签，使图表更易读。

### 任务二：多元线性回归

1.  **问题**：建立一个多元线性回归模型，使用 `rm`、`lstat` (低收入人群比例) 和 `ptratio` (师生比例) 预测 `medv`。
    *   **详细步骤**：
        *   再次使用 `lm()` 函数创建回归模型，但这次使用多元回归公式 `medv ~ rm + lstat + ptratio`，表示使用 `rm`、`lstat` 和 `ptratio` 三个自变量共同预测 `medv`。
        *   将这个多元回归模型命名为 `multi_lm`。
        *   使用 `summary(multi_lm)` 查看新模型的摘要报告。
2.  **问题**：比较简单线性回归和多元线性回归模型的 \(R^2\) 值。多元回归模型的拟合效果是否更好？为什么？
    *   **详细步骤**：
        *   对比 `summary(simple_lm)` 和 `summary(multi_lm)` 输出结果中的 "Multiple R-squared" 值。
        *   观察多元回归模型的 \(R^2\) 值是否比简单线性回归模型更高。
        *   思考并解释：通常情况下，向模型中增加自变量会对 \(R^2\) 值产生什么影响？为什么多元回归模型可能提供更好的拟合效果？
3.  **问题**：解释多元线性回归模型中 `rm`、`lstat` 和 `ptratio` 变量的系数估计值。与简单线性回归中 `rm` 的系数有何不同？
    *   **详细步骤**：
        *   在 `summary(multi_lm)` 的 "Coefficients" 部分，找到 `rm`、`lstat` 和 `ptratio` 各自对应的系数估计值。
        *   理解偏回归系数的概念。例如，对于 `rm` 的系数，其含义是在保持 `lstat` 和 `ptratio` 不变的条件下，`rm` 每增加一个单位，`medv` 的平均变化量。
        *   比较多元回归模型中 `rm` 的系数与之前简单线性回归模型中 `rm` 的系数。思考并解释：为什么同一个变量 `rm` 的系数在不同模型中会有所变化？
4.  **问题**：使用 `vif()` 函数检验多元线性回归模型中是否存在多重共线性问题。
    *   **详细步骤**：
        *   首先，确保加载了 `car` 包，因为 `vif()` 函数来自这个包。
        *   使用 `vif(multi_lm)` 函数，计算多元线性回归模型中各个自变量的方差膨胀因子 (VIF)。
        *   根据 VIF 值判断是否存在多重共线性。通常，VIF 值大于 10 被认为是一个信号，表明可能存在显著的多重共线性问题。

### 任务三：模型评估与诊断

1.  **问题**：计算任务二中多元线性回归模型的均方误差 (MSE) 和均方根误差 (RMSE)。
    *   **详细步骤**：
        *   使用 `augment(multi_lm)` 函数，获取一个包含原始数据、预测值 (`.fitted`) 和残差 (`.resid`) 的增强型数据框。
        *   要手动计算 MSE，首先计算所有残差的平方，然后求这些平方值的平均数。公式为：$\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$，其中 \(y_i\) 是真实值，\(\hat{y}_i\) 是预测值，\(n\) 是样本量。
        *   RMSE 是 MSE 的平方根，计算公式为：$\text{RMSE} = \sqrt{\text{MSE}}$。RMSE 的单位与因变量相同，更易于解释。
        *   或者，为了更方便地计算 MSE 和 RMSE，可以使用 `Metrics` 包中的 `mse()` 和 `rmse()` 函数。你需要提供真实值（`Boston$medv`）和模型的预测值（可以使用 `fitted(multi_lm)` 获取）。
2.  **问题**：绘制多元线性回归模型的残差图 (Residual vs Fitted plot) 和 QQ 图，诊断模型是否满足线性性、同方差性和正态性假设。
    *   **详细步骤**：
        *   使用 `plot(multi_lm, which = 1)` 命令绘制残差图。观察图中残差点是否随机散布在水平 0 线上下，且没有明显的模式（如曲线、喇叭口形）。如果残差呈现一定的模式，可能表明模型不满足线性性或同方差性假设。
        *   使用 `plot(multi_lm, which = 2)` 命令绘制 QQ 图（正态分位数-分位数图）。观察图中残差点是否近似沿一条直线分布。如果残差点偏离直线较远，可能表明模型残差不满足正态性假设。
        *   或者，为了获得更美观且信息更丰富的诊断图，可以使用 `ggfortify` 包的 `autoplot(multi_lm)` 函数，它可以一次性生成包括残差图、QQ 图在内的多种诊断图。
3.  **问题**：如果模型不满足某些假设，你认为可能的原因是什么？你会考虑采取哪些改进措施？
    *   **详细步骤**：
        *   回顾回归分析的四大基本假设：线性性、同方差性、残差独立性、残差正态性。
        *   根据残差图和 QQ 图的诊断结果，判断模型可能违反了哪些假设。例如，残差图呈现漏斗状可能暗示异方差性，QQ 图尾部偏离直线可能暗示残差非正态。
        *   针对可能违反的假设，思考潜在原因。例如，非线性关系可能导致线性性假设不成立，变量量纲或数据生成过程的差异可能导致异方差性。
        *   考虑可以采取的改进措施。例如，对于非线性关系，可以尝试变量转换（如对数变换、平方项）或使用非线性模型；对于异方差性，可以考虑加权最小二乘法或稳健标准误；对于非正态性，如果问题不严重且样本量较大，中心极限定理可能在一定程度上缓解问题，否则可能需要考虑 Box-Cox 变换或非参数方法。

### 任务四：变量选择

1.  **问题**：使用向前逐步回归、向后逐步回归和双向逐步回归方法，基于 AIC 准则，从 Boston 数据集的所有变量中选择最优的预测变量子集，建立回归模型预测 `medv`。比较这三种方法选择的变量有何异同？
    *   **详细步骤**：
        *   首先，构建一个包含 Boston 数据集中所有自变量的完整模型，例如命名为 `full_model`。同时，构建一个仅包含截距项的零模型，例如命名为 `null_model`。
        *   使用 `step()` 函数执行向前逐步回归。以 `null_model` 为起始模型，设定搜索范围为 `full_model` 的公式，指定 `direction = "forward"` 和 `trace = 0`（不显示逐步过程）。将结果模型命名为 `forward_step`。
        *   使用 `step()` 函数执行向后逐步回归。以 `full_model` 为起始模型，指定 `direction = "backward"` 和 `trace = 0`。将结果模型命名为 `backward_step`。
        *   使用 `step()` 函数执行双向逐步回归。以 `null_model` 为起始模型，设定搜索范围为 `full_model` 的公式，指定 `direction = "both"` 和 `trace = 0`。将结果模型命名为 `both_step`。
        *   使用 `coef()` 函数分别提取 `forward_step`、`backward_step` 和 `both_step` 模型的系数，系数非零的变量即为被选入模型的变量。
        *   比较这三种逐步回归方法选出的变量集合，观察它们是否完全一致，或者存在哪些差异。同时，比较这三个模型的 AIC 值，AIC 值越小的模型通常被认为更好。
2.  **问题**：使用 Lasso 回归进行变量选择。通过交叉验证确定最优的 \(\lambda\) 值，并解释 Lasso 如何进行变量选择。
    *   **详细步骤**：
        *   准备 Lasso 回归所需的输入数据：将 Boston 数据集中除 `medv` 列外的所有列转换为矩阵形式，作为自变量矩阵 `x`；将 `medv` 列作为因变量向量 `y`。
        *   使用 `cv.glmnet()` 函数执行交叉验证，以选择最优的 \(\lambda\) 值。设置 `alpha = 1` 以指定 Lasso 回归，`nfolds = 10` 表示进行 10 折交叉验证。将交叉验证的结果命名为 `lasso_cv`。
        *   从 `lasso_cv` 结果中提取最优的 \(\lambda\) 值 (`lambda.min`)。
        *   使用 `glmnet()` 函数，用最优的 \(\lambda\) 值拟合 Lasso 模型。同样设置 `alpha = 1` 和 `lambda = best_lambda`。将拟合的模型命名为 `lasso_model`。
        *   使用 `coef(lasso_model)` 查看 Lasso 模型的系数。Lasso 回归通过 L1 正则化，倾向于将一些不重要变量的系数压缩至 0，从而实现变量选择。系数为 0 的变量即被 Lasso 排除在模型之外。
        *   使用 `plot(lasso_cv)` 绘制交叉验证的结果图，观察 \(\lambda\) 值与交叉验证误差之间的关系，以及最优 \(\lambda\) 值是如何被确定的。
3.  **问题**：比较逐步回归和 Lasso 回归选择的变量子集，以及模型的预测性能 (例如，在测试集上的 RMSE)。哪种方法更适合这个数据集？
    *   **详细步骤**：
        *   首先，将 Boston 数据集划分为训练集和测试集。例如，可以随机抽取 70% 的数据作为训练集，剩余 30% 作为测试集。确保划分过程设置随机种子，以保证结果的可重复性。
        *   在训练集上，分别应用之前得到的逐步回归方法（例如，双向逐步回归得到的 `step_model_train`）和 Lasso 回归方法（`lasso_model_train`）进行模型训练。
        *   使用训练好的逐步回归模型和 Lasso 回归模型，分别对测试集进行房价预测。
        *   计算两种模型在测试集上的 RMSE 值。RMSE 值越小，表明模型在测试集上的预测性能越好。
        *   比较逐步回归和 Lasso 回归选择的变量子集，以及它们在测试集上的 RMSE 值。综合考虑模型的复杂程度（选择的变量数量）和预测性能，判断哪种变量选择方法更适合于当前的波士顿房价数据集。

### 任务五：模型解释与应用

1.  **问题**：选择你认为最优的回归模型（例如，基于任务四的结果），解释模型中各个变量的系数。
    *   **详细步骤**：
        *   回顾任务四的结果，综合考虑变量选择方法、模型复杂度和预测性能等因素，选择你认为在这个数据集上表现最优的回归模型。
        *   如果你选择了逐步回归模型，使用 `summary()` 函数查看模型摘要，重点关注 "Coefficients" 部分，解释模型中每个被选入的变量的系数估计值。解释系数的符号（正负）和大小，以及对应的 p 值，判断变量对房价的影响方向和显著性水平。
        *   如果你选择了 Lasso 回归模型，使用 `coef()` 函数查看模型系数。解释所有非零系数的变量对房价的影响方向和大致程度。由于 Lasso 回归系数经过压缩，可能需要注意系数的实际经济意义。
        *   在解释系数时，务必结合变量的实际含义，用通俗易懂的语言描述每个变量对房价的影响，例如，“在其他条件不变的情况下，每增加一个单位的 XXX 变量，房价平均会增加/减少 YYY 千美元”。
2.  **问题**：假设你想预测一个波士顿郊区房屋的房价，已知其 `rm = 6`，`lstat = 10`，`ptratio = 15`，使用你选择的模型进行预测，并给出预测结果的解释。
    *   **详细步骤**：
        *   创建一个新的数据框，用于存放待预测房屋的特征数据。数据框的列名必须与模型训练时使用的自变量名称一致。例如，创建一个名为 `new_house` 的数据框，包含 `rm`、`lstat` 和 `ptratio` 三列，并填入给定的数值 (rm=6, lstat=10, ptratio=15)。
        *   如果你选择的是逐步回归模型，直接使用 `predict()` 函数，以训练好的模型和 `new_house` 数据框作为输入，进行预测。
        *   如果你选择的是 Lasso 回归模型，由于 `glmnet` 函数需要矩阵形式的输入，你需要先将 `new_house` 数据框转换为矩阵形式，例如 `new_x`，然后再使用 `predict()` 函数进行预测。
        *   获取模型的预测输出后，解释预测结果的含义。例如，说明预测的房价中位数是多少千美元，并简要解释模型是如何基于输入的房屋特征给出预测的。
