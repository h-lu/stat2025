---
title: "第六周：回归分析初步"
---

## 第十一次课：线性回归模型与最小二乘法

### 回归分析概述

**回归分析的目的**：
- 研究因变量与一个或多个自变量之间的关系
- 建立模型进行预测和解释
- 评估变量之间的关联程度和方向

回归分析是商业分析中最常用的分析技术之一，它能够帮助我们回答以下问题：
- 影响销售额的关键因素有哪些？每个因素的影响程度如何？
- 如何根据产品特征预测价格？
- 不同营销投入对业绩的边际贡献是多少？

**回归分析的应用场景**：
- 预测销售额、房价、股票价格等
- 分析影响消费者购买行为的因素
- 评估营销活动的效果
- 识别影响企业绩效的关键指标

**回归分析的类型**：
- **线性回归**：因变量与自变量之间呈线性关系
- **非线性回归**：因变量与自变量之间呈非线性关系
- **简单线性回归**：只有一个自变量
- **多元线性回归**：有多个自变量

**回归分析与其他统计方法的区别**：
- 与相关分析相比：回归不仅描述关系，还建立预测模型
- 与方差分析相比：回归处理连续自变量，方差分析处理分类自变量

**回归分析的基本步骤**：
1. **确定回归模型**：选择合适的回归模型类型
2. **估计模型参数**：使用样本数据估计模型中的未知参数
3. **模型检验**：检验模型的拟合效果和显著性
4. **模型应用**：使用建立的模型进行预测、解释和决策

```{r, eval=FALSE}
# 创建示例数据
set.seed(123)
advertising_data <- data.frame(
  TV = runif(100, 5, 50),
  Radio = runif(100, 1, 30),
  Newspaper = runif(100, 0, 20)
)
# 生成销售额数据，使其与广告投入有一定关系
advertising_data$Sales <- 5 + 0.15 * advertising_data$TV + 
                            0.3 * advertising_data$Radio + 
                            0.1 * advertising_data$Newspaper + 
                            rnorm(100, 0, 2)

# 探索性数据分析
summary(advertising_data)
cor(advertising_data)

# 可视化变量关系
library(ggplot2)
library(gridExtra)

p1 <- ggplot(advertising_data, aes(x = TV, y = Sales)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "电视广告与销售额关系")

p2 <- ggplot(advertising_data, aes(x = Radio, y = Sales)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "广播广告与销售额关系")

p3 <- ggplot(advertising_data, aes(x = Newspaper, y = Sales)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "报纸广告与销售额关系")

grid.arrange(p1, p2, p3, ncol = 2)
```

### 简单线性回归模型

**模型形式**：$y = \beta_0 + \beta_1 x + \epsilon$
- $y$：因变量
- $x$：自变量
- $\beta_0$：截距，当$x=0$时，$y$的期望值
- $\beta_1$：斜率，自变量$x$每增加一个单位，因变量$y$的平均变化量
- $\epsilon$：随机误差项，反映模型无法解释的随机变异

简单线性回归是理解回归分析的基础，它描述了一个自变量和一个因变量之间的线性关系。例如，我们可以建立一个模型来描述广告支出（自变量）与销售额（因变量）之间的关系。

**最小二乘法(OLS)**：

最小二乘法是一种估计回归系数的方法，其目标是找到能使误差平方和最小的回归线。

- 目标：使残差平方和(RSS)最小化
- $\text{RSS} = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 = \sum_{i=1}^{n} (y_i - (\hat{\beta}_0 + \hat{\beta}_1 x_i))^2$
- $\hat{\beta}_0$和$\hat{\beta}_1$是$\beta_0$和$\beta_1$的估计值
- $\hat{y}_i = \hat{\beta}_0 + \hat{\beta}_1 x_i$是因变量$y_i$的预测值

**最小二乘估计的公式**：
- $\hat{\beta}_1 = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^{n}(x_i - \bar{x})^2}$
- $\hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x}$

**回归系数的解释**：
- $\hat{\beta}_0$：当自变量$x$为0时，因变量$y$的预测值（在实际情况中，自变量为0可能没有现实意义）
- $\hat{\beta}_1$：自变量$x$每增加一个单位，因变量$y$的预测值平均增加$\hat{\beta}_1$个单位（边际效应）

**回归模型的评估指标**：

1. **拟合优度 $R^2$**：
   - 表示模型解释的因变量方差比例
   - 取值范围[0,1]，越接近1表示模型拟合越好
   - $R^2 = 1 - \frac{SSE}{SST} = 1 - \frac{\sum(y_i - \hat{y}_i)^2}{\sum(y_i - \bar{y})^2}$

2. **残差标准误差(RSE)**：
   - 衡量因变量实际值偏离预测值的平均程度
   - $RSE = \sqrt{\frac{SSE}{n-2}} = \sqrt{\frac{\sum(y_i - \hat{y}_i)^2}{n-2}}$

**回归模型的假设条件**：
- **线性性**：因变量与自变量之间存在线性关系
- **独立性**：误差项之间相互独立
- **同方差性**：误差项的方差为常数（同质性）
- **正态性**：误差项服从均值为0的正态分布

```{r, eval=FALSE}
# 简单线性回归示例：电视广告与销售额
tv_model <- lm(Sales ~ TV, data = advertising_data)

# 查看回归结果
summary(tv_model)

# 可视化回归线和预测区间
ggplot(advertising_data, aes(x = TV, y = Sales)) +
  geom_point() +
  geom_smooth(method = "lm", level = 0.95) +
  labs(title = "电视广告支出与销售额的简单线性回归",
       x = "电视广告支出（千元）",
       y = "销售额（万元）") +
  theme_minimal()

# 残差分析
par(mfrow = c(2, 2))
plot(tv_model)
```

### R语言实现简单线性回归

**基本函数**：
```{r, eval=FALSE}
# 建立简单线性回归模型
lm_model <- lm(Sales ~ TV, data = advertising_data)

# 查看模型摘要
summary(lm_model)

# 提取回归系数
coef(lm_model)

# 置信区间
confint(lm_model, level = 0.95)

# 模型预测
new_data <- data.frame(TV = c(10, 20, 30, 40))
predict(lm_model, newdata = new_data, interval = "confidence")
predict(lm_model, newdata = new_data, interval = "prediction")

# 残差和拟合值
residuals(lm_model)
fitted(lm_model)

# 回归诊断图
par(mfrow = c(2, 2))
plot(lm_model)
```

**ggplot2进行回归可视化**：
```{r, eval=FALSE}
library(ggplot2)

# 基本散点图和回归线
ggplot(advertising_data, aes(x = TV, y = Sales)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = TRUE) +
  labs(title = "电视广告支出与销售额关系",
       x = "电视广告支出（千元）", 
       y = "销售额（万元）") +
  theme_minimal()

# 回归残差可视化
advertising_data$predicted <- fitted(lm_model)
advertising_data$residuals <- residuals(lm_model)

ggplot(advertising_data, aes(x = predicted, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(title = "残差vs拟合值",
       x = "拟合值", y = "残差") +
  theme_minimal()

# QQ图检验正态性
ggplot(advertising_data, aes(sample = residuals)) +
  stat_qq() +
  stat_qq_line() +
  labs(title = "残差QQ图") +
  theme_minimal()
```

**结果解读**：
- **系数估计值**：截距($\hat{\beta}_0$)和斜率($\hat{\beta}_1$)的估计值
- **标准误差**：系数估计值的标准误差，表示估计的精确度
- **t值**：系数估计值与标准误差的比值，用于检验系数是否显著不为0
- **p值**：系数是否显著不为0的显著性水平
- **R²值**：模型解释的方差比例，衡量拟合优度
- **F统计量**：整个模型的显著性检验

**案例解读**：
```{r, eval=FALSE}
# 假设这是summary(lm_model)的输出结果：
# Coefficients:
#             Estimate Std. Error t value Pr(>|t|)    
# (Intercept)   7.0326     0.4578  15.361  < 2e-16 ***
# TV            0.0475     0.0097   4.897 4.75e-06 ***
# ---
# R-squared: 0.612, Adjusted R-squared: 0.606 
# F-statistic: 23.97 on 1 and 98 DF, p-value: 4.75e-06

# 商业解读：
# 1. 截距7.0326表示当电视广告支出为0时，预期销售额为7.0326万元
# 2. 电视广告系数0.0475表示每增加1千元的电视广告支出，销售额平均增加0.0475万元
# 3. 电视广告变量的p值非常小(<0.0001)，表示电视广告支出对销售额有显著影响
# 4. R²值为0.612，说明模型解释了约61.2%的销售额变异
# 5. 整体模型F检验显著(p<0.0001)，表明模型有统计学意义
```

## 第十二次课：多元线性回归模型

### 多元线性回归模型

**多元线性回归的意义**：
在商业环境中，一个因变量往往受多个因素影响。例如，销售额不仅受电视广告的影响，还可能受广播、报纸、社交媒体等多种营销渠道的影响。多元线性回归能够同时考虑多个自变量的影响，更全面地分析因素间的关系。

**模型形式**：$y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_p x_p + \epsilon$
- $y$：因变量
- $x_1, x_2, \dots, x_p$：$p$个自变量
- $\beta_0$：截距
- $\beta_1, \beta_2, \dots, \beta_p$：偏回归系数，控制其他自变量不变时，每个自变量对因变量的边际影响
- $\epsilon$：随机误差项

**偏回归系数的解释**：
- $\beta_1$表示在其他自变量$x_2, \dots, x_p$保持不变的情况下，自变量$x_1$每增加一个单位，因变量$y$的平均变化量

这个解释非常重要，因为它体现了"控制变量"的思想，即我们能够分离出单个自变量的"净效应"。这在商业分析中尤为有用，例如，我们可以分析在广播广告投入不变的情况下，增加电视广告对销售的边际贡献。

**参数估计**：
- 同样使用最小二乘法(OLS)
- 通过矩阵运算求解：$\hat{\beta} = (X^TX)^{-1}X^Ty$
- 其中$X$是自变量矩阵，$y$是因变量向量

**多元线性回归模型的假设条件**：
- 线性性：因变量与每个自变量之间存在线性关系
- 独立性：观测值之间相互独立
- 同方差性：误差项方差恒定
- 正态性：误差项服从正态分布
- 无多重共线性：自变量之间不存在高度相关性

**多重共线性问题**：
- 定义：自变量之间存在强相关关系
- 后果：回归系数估计不稳定，标准误增大
- 诊断：方差膨胀因子(VIF)
- 处理：变量选择、正则化、主成分分析等

```{r, eval=FALSE}
# 检测多重共线性
library(car)
multi_model <- lm(Sales ~ TV + Radio + Newspaper, data = advertising_data)
vif(multi_model)
# VIF > 10通常表示存在严重多重共线性
```

**模型拟合与检验**：
- **R²**：衡量模型对数据的拟合程度，取值范围[0,1]
- **调整R²**：考虑自变量个数对R²的影响，防止过拟合
- **F检验**：检验模型整体的显著性
- **t检验**：检验每个偏回归系数的显著性

**解释多元回归模型时需注意**：
- 解释系数时必须强调"控制其他变量不变"
- R²会随自变量增加而增加，应关注调整R²
- 显著性水平应解释为"在控制了其他变量后"

### R语言实现多元线性回归

下面我们将使用广告投入数据集建立多元线性回归模型，分析不同广告渠道对销售额的影响：

```{r, eval=FALSE}
# 多元线性回归示例
multi_model <- lm(Sales ~ TV + Radio + Newspaper, data = advertising_data)

# 查看模型摘要
summary(multi_model)

# 方差分析表，展示模型整体显著性
anova(multi_model)

# 检验多重共线性
library(car)
vif(multi_model)
```

**嵌套模型比较**：
```{r, eval=FALSE}
# 构建不同的嵌套模型
model1 <- lm(Sales ~ TV, data = advertising_data)
model2 <- lm(Sales ~ TV + Radio, data = advertising_data)
model3 <- lm(Sales ~ TV + Radio + Newspaper, data = advertising_data)

# 使用anova函数比较嵌套模型
anova(model1, model2, model3)

# 使用AIC比较模型
AIC(model1, model2, model3)
BIC(model1, model2, model3)
```

**偏回归图**：观察单个自变量的边际贡献
```{r, eval=FALSE}
library(car)
avPlots(multi_model)
```

**变量重要性评估**：
```{r, eval=FALSE}
library(relaimpo)
calc.relimp(multi_model, type = "lmg", rela = TRUE)
```

**多元回归的可视化**：
```{r, eval=FALSE}
# 可视化不同渠道的边际效应
library(ggplot2)
library(gridExtra)

# 构建效应图
effect_tv <- ggplot(advertising_data, aes(x = TV, y = Sales)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm") +
  labs(title = "电视广告的边际效应") +
  theme_minimal()

effect_radio <- ggplot(advertising_data, aes(x = Radio, y = Sales)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm") +
  labs(title = "广播广告的边际效应") +
  theme_minimal()

effect_newspaper <- ggplot(advertising_data, aes(x = Newspaper, y = Sales)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm") +
  labs(title = "报纸广告的边际效应") +
  theme_minimal()

grid.arrange(effect_tv, effect_radio, effect_newspaper, ncol = 2)

# 3D可视化（针对两个自变量）
library(plotly)
fit <- lm(Sales ~ TV + Radio, data = advertising_data)

# 创建网格点
grid.lines = 50
x.pred <- seq(min(advertising_data$TV), max(advertising_data$TV), length.out = grid.lines)
y.pred <- seq(min(advertising_data$Radio), max(advertising_data$Radio), length.out = grid.lines)
xy <- expand.grid(TV = x.pred, Radio = y.pred)

# 预测z值
z.pred <- matrix(predict(fit, newdata = xy), 
                nrow = grid.lines, ncol = grid.lines)

# 创建3D图
plot_ly() %>%
  add_trace(data = advertising_data, 
            x = ~TV, y = ~Radio, z = ~Sales,
            type = "scatter3d", mode = "markers",
            marker = list(size = 5, color = "blue", opacity = 0.5)) %>%
  add_surface(x = x.pred, y = y.pred, z = z.pred,
              colorscale = "Viridis", opacity = 0.8) %>%
  layout(title = "销售额与电视、广播广告投入的关系",
         scene = list(xaxis = list(title = "电视广告"),
                     yaxis = list(title = "广播广告"),
                     zaxis = list(title = "销售额")))
```

**变量选择方法**：
当有多个潜在自变量时，我们需要选择一个最佳的变量子集：

```{r, eval=FALSE}
# 向前逐步回归
null_model <- lm(Sales ~ 1, data = advertising_data)
full_model <- lm(Sales ~ ., data = advertising_data)
forward_model <- step(null_model, scope = list(lower = null_model, upper = full_model), 
                    direction = "forward")

# 向后逐步回归
backward_model <- step(full_model, direction = "backward")

# 双向逐步回归（同时考虑增加和删除变量）
stepwise_model <- step(null_model, scope = list(lower = null_model, upper = full_model), 
                     direction = "both")

# 使用Leaps包进行最优子集选择
library(leaps)
subsets <- regsubsets(Sales ~ ., data = advertising_data, nvmax = ncol(advertising_data) - 1)
summary(subsets)
plot(subsets, scale = "r2")
plot(subsets, scale = "adjr2")
plot(subsets, scale = "Cp")
plot(subsets, scale = "bic")
```

**正则化回归**：
处理多重共线性和预防过拟合的现代方法：

```{r, eval=FALSE}
# 岭回归
library(glmnet)
x <- as.matrix(advertising_data[, c("TV", "Radio", "Newspaper")])
y <- advertising_data$Sales
ridge_model <- glmnet(x, y, alpha = 0)
plot(ridge_model, xvar = "lambda", label = TRUE)
cv_ridge <- cv.glmnet(x, y, alpha = 0)
best_lambda <- cv_ridge$lambda.min
ridge_coef <- coef(ridge_model, s = best_lambda)

# Lasso回归
lasso_model <- glmnet(x, y, alpha = 1)
plot(lasso_model, xvar = "lambda", label = TRUE)
cv_lasso <- cv.glmnet(x, y, alpha = 1)
best_lambda <- cv_lasso$lambda.min
lasso_coef <- coef(lasso_model, s = best_lambda)
```

### 回归分析的实际应用案例

**案例1：房价预测模型**

```{r, eval=FALSE}
# 导入波士顿房价数据集
library(MASS)
data(Boston)
head(Boston)

# 变量说明
# medv: 自住房屋的中位数价值（千美元）（因变量）
# rm: 每套住宅的平均房间数
# lstat: 人口中地位较低人群的百分比
# crim: 城镇人均犯罪率
# zn: 占地面积超过2.5万平方英尺的住宅用地比例
# indus: 每个城镇非零售业务的比例
# chas: 查尔斯河虚拟变量（1 = 边界在河边；0 = 否）
# nox: 一氧化氮浓度（千万分之一）
# ...

# 探索性分析
pairs(Boston[, c("medv", "rm", "lstat", "crim", "nox")])
cor(Boston)

# 建立模型
model_all <- lm(medv ~ ., data = Boston)
summary(model_all)

# 变量选择
step_model <- step(model_all, direction = "both")
summary(step_model)

# 最优模型解释与诊断
par(mfrow = c(2, 2))
plot(step_model)

# 预测
new_house <- data.frame(
  rm = 6.5,
  lstat = 10,
  crim = 0.5,
  zn = 50,
  indus = 5,
  chas = 0,
  nox = 0.5,
  age = 50,
  dis = 4,
  rad = 6,
  tax = 400,
  ptratio = 15,
  black = 380,
  chas = 0
)

predict(step_model, newdata = new_house, interval = "prediction")
```

**案例2：销售额预测与营销投资优化**

```{r, eval=FALSE}
# 使用前面的广告数据
# 假设我们有一个额外的数据集，包含不同产品线的广告效果
product_data <- data.frame(
  product = rep(c("A", "B", "C"), each = 30),
  TV = runif(90, 5, 50),
  Radio = runif(90, 1, 30),
  Newspaper = runif(90, 0, 20)
)
# 生成不同的效应模式
product_data$Sales <- 5 + 
  ifelse(product_data$product == "A", 0.2, 
         ifelse(product_data$product == "B", 0.1, 0.05)) * product_data$TV +
  ifelse(product_data$product == "A", 0.15, 
         ifelse(product_data$product == "B", 0.3, 0.1)) * product_data$Radio +
  ifelse(product_data$product == "A", 0.05, 
         ifelse(product_data$product == "B", 0.1, 0.2)) * product_data$Newspaper +
  rnorm(90, 0, 2)

# 分析不同产品线的广告效果
library(ggplot2)
ggplot(product_data, aes(x = TV, y = Sales, color = product)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  facet_wrap(~product) +
  labs(title = "不同产品线的电视广告效果") +
  theme_minimal()

# 为每个产品线建立单独的模型
product_models <- list()
for(p in unique(product_data$product)) {
  subset_data <- product_data[product_data$product == p, ]
  product_models[[p]] <- lm(Sales ~ TV + Radio + Newspaper, data = subset_data)
  print(paste("Product", p, "model:"))
  print(summary(product_models[[p]]))
}

# 互动效应模型（产品与广告渠道的交互）
interaction_model <- lm(Sales ~ product * (TV + Radio + Newspaper), 
                        data = product_data)
summary(interaction_model)

# 营销预算优化：基于边际回报率
# 根据回归系数计算每个渠道的投资回报率，优化预算分配
```

**案例3：市场细分分析**

```{r, eval=FALSE}
# 不同市场细分的回归分析
segment_data <- data.frame(
  customer_segment = rep(c("高收入", "中收入", "低收入"), each = 30),
  price = runif(90, 50, 200),
  promotion = runif(90, 0, 1),
  store_quality = runif(90, 1, 5)
)
# 不同细分市场的消费者对价格和促销的敏感度不同
segment_data$purchase <- 10 +
  ifelse(segment_data$customer_segment == "高收入", -0.01, 
         ifelse(segment_data$customer_segment == "中收入", -0.03, -0.05)) * segment_data$price +
  ifelse(segment_data$customer_segment == "高收入", 1, 
         ifelse(segment_data$customer_segment == "中收入", 2, 3)) * segment_data$promotion +
  0.5 * segment_data$store_quality +
  rnorm(90, 0, 1)

# 分析不同细分市场的价格敏感度
segment_models <- list()
for(s in unique(segment_data$customer_segment)) {
  subset_data <- segment_data[segment_data$customer_segment == s, ]
  segment_models[[s]] <- lm(purchase ~ price + promotion + store_quality, 
                           data = subset_data)
  print(paste("Segment", s, "model:"))
  print(summary(segment_models[[s]]))
}

# 差异化定价策略建议
price_sensitivity <- data.frame(
  segment = names(segment_models),
  price_effect = sapply(segment_models, function(model) coef(model)["price"])
)
print(price_sensitivity)
```

::: {.callout-tip appearance="simple"}
## AI辅助学习建议（第六周）

### 回归分析理解与解释
- **请AI解释回归系数的含义**：要求AI使用通俗易懂的语言解释回归系数的实际意义
- **让AI比较相关分析与回归分析**：理解两者的区别和各自适用场景
- **要求AI解释拟合优度(R²)**：深入理解R²的含义、局限性和在商业分析中的解读方式

### R代码编写与模型构建
- **请AI生成完整的回归分析流程代码**：从数据探索、模型构建到诊断和解释的全流程代码
- **让AI帮助进行变量选择**：生成向前、向后或逐步回归代码，并解释选择逻辑
- **要求AI编写回归结果可视化代码**：创建更专业和直观的回归结果展示图

### 回归模型诊断与优化
- **请AI检查回归模型假设**：生成检验线性性、同方差性、独立性和正态性的代码和解释
- **让AI解释多重共线性问题**：诊断和处理多重共线性的方法
- **要求AI优化模型预测性能**：提供提高模型预测准确性的建议

### 回归分析应用场景
- **请AI推荐适合项目主题的回归应用问题**：根据选择的项目主题获取具体的研究问题建议
- **让AI设计商业分析方案**：设计从数据收集到分析解释的完整方案
- **要求AI解释回归分析在不同行业的应用**：了解回归分析在市场营销、金融、人力资源等领域的典型应用案例
:::

### 参考文献与扩展阅读

1. James, G., Witten, D., Hastie, T., & Tibshirani, R. (2013). An Introduction to Statistical Learning. Springer.
2. Kutner, M. H., Nachtsheim, C. J., Neter, J., & Li, W. (2005). Applied Linear Statistical Models (5th ed.). McGraw-Hill.
3. Fox, J. (2016). Applied Regression Analysis and Generalized Linear Models (3rd ed.). SAGE Publications.
4. Faraway, J. J. (2014). Linear Models with R (2nd ed.). Chapman and Hall/CRC.
5. 李惠莲. (2018). 回归分析在商业决策中的应用. 统计与决策, 34(15), 82-85. 