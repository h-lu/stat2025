{"title":"第八周：承前启后：阶段回顾与多元回归再探","markdown":{"yaml":{"title":"第八周：承前启后：阶段回顾与多元回归再探","execute":{"echo":true,"message":false,"warning":false,"error":false,"cache":false}},"headingText":"1. 欢迎来到第二阶段！","containsRefs":false,"markdown":"\n\n\n本周我们正式进入课程的第二阶段。在深入学习更高级的统计模型之前，我们需要系统地回顾和巩固第一阶段（第 1-7 周）的核心知识，并在此基础上，重新审视和深入理解**多元线性回归 (Multiple Linear Regression, MLR)**。\n\n::: {.callout-note title=\"本周目标\"}\n-   **系统回顾**第一阶段核心内容：数据处理与可视化 (`tidyverse`, `ggplot2`)；描述统计；参数估计（点估计与置信区间）；假设检验逻辑；常用检验方法 (t 检验, ANOVA, 卡方检验)；相关分析；简单线性回归 (SLR) 基础与多元线性回归 (MLR) 初步概念。\n-   **深入理解** MLR 中**偏回归系数**的意义：控制变量与独立效应。\n-   **反复练习**对 `lm()` 输出中 MLR 系数的**业务含义解释**。\n-   区分统计显著性与实际重要性。\n-   回顾线性回归的 **L.I.N.E.** 假设，理解其重要性及违背后果。\n-   （演示）利用 AI 辅助回顾概念、解释 MLR 系数，并**强调验证其准确性**。\n:::\n\n## 2. 阶段一知识回顾 (重点环节)\n\n让我们通过互动问答、知识点串讲和快速练习，快速回顾一下前七周的核心内容。\n\n::: panel-tabset\n### 数据处理与可视化\n\n-   **`tidyverse` 核心包:** `dplyr`, `tidyr`, `readr`, `ggplot2` 等。\n-   **`dplyr` 动词:**\n    -   `select()`: 选择列。\n    -   `filter()`: 筛选行。\n    -   `mutate()`: 创建/修改列。\n    -   `arrange()`: 排序。\n    -   `group_by()` + `summarise()`: 分组汇总 (常用 `n()`, `mean()`, `sd()`, `min()`, `max()`, `n_distinct()`)。\n    -   管道 `%>%`: 连接操作。\n-   **`tidyr` 动词:**\n    -   `pivot_longer()`: 宽数据变长。\n    -   `pivot_wider()`: 长数据变宽。\n    -   `drop_na()`: 删除含 NA 的行。\n    -   `replace_na()`: 替换 NA。\n-   **整洁数据原则:** 每个变量一列，每个观测一行，每种观测一个表。\n-   **`ggplot2` 图形语法:**\n    -   `ggplot(data, aes(x=..., y=..., color=...)) + geom_xxx(...)`\n    -   常用 `geom`: `geom_point`, `geom_line`, `geom_histogram`, `geom_density`, `geom_boxplot`, `geom_violin`, `geom_bar`, `geom_col`, `geom_smooth`。\n    -   定制: `labs()`, `theme_...()`, `coord_flip()`。\n\n**快速练习:** \n\n1. 如何筛选 `mpg` 数据集中 `manufacturer` 为 \"audi\" 且 `year` 为 2008 的车辆？ \n2. 如何计算 `mpg` 数据集中每个 `manufacturer` 的平均城市里程 (`cty`)？ \n3. 如何用 `ggplot2` 绘制 `mpg` 数据集中 `cty` (城市里程) 与 `hwy` (高速里程) 的散点图，并按 `drv` (驱动方式) 区分颜色？\n\n\n### 描述统计与参数估计\n\n-   **描述统计:**\n    -   集中趋势: 均值 (`mean`), 中位数 (`median`)。\n    -   离散趋势: 标准差 (`sd`), 方差 (`var`), IQR (`IQR`), 范围 (`range`)。\n-   **参数估计:**\n    -   点估计: 用样本统计量估计总体参数 (如 $\\bar{x}$ 估计 $\\mu$)。\n    -   区间估计: 置信区间 (CI)。\n-   **置信区间:**\n    -   提供总体参数可能范围的估计，并附带置信水平。\n    -   95% CI 含义：重复抽样构造区间，约 95% 的区间会包含真值。\n    -   解读：我们有 XX% 的信心认为总体参数落在 \\[下限, 上限\\] 之间。\n    -   影响因素：置信水平、样本量、数据变异性。\n\n**快速思考:** \n\n1. 什么时候应该使用中位数而不是均值来描述数据的中心？\n2. 99% 置信区间与 95% 置信区间相比，哪个更宽？为什么？ \n3. 增加样本量会对置信区间的宽度产生什么影响？\n\n### 假设检验逻辑与常用方法\n\n-   **假设检验逻辑:**\n    -   $H_0$ (原假设) vs $H_1$ (备择假设)。\n    -   $\\alpha$ (显著性水平，第一类错误概率)。\n    -   检验统计量。\n    -   P 值 (在 $H_0$ 为真的条件下，观测到当前或更极端结果的概率)。\n    -   决策：P ≤ $\\alpha$ -\\> 拒绝 $H_0$；P \\> $\\alpha$ -\\> 未能拒绝 $H_0$。\n    -   两类错误：Type I ($\\alpha$) vs Type II ($\\beta$)；Power = $1-\\beta$。\n-   **常用检验方法回顾 (见第七周总结):**\n    -   **t 检验 (`t.test`)**: 比较 1 或 2 组均值 (单样本, 双独立样本, 配对样本)。\n    -   **ANOVA (`aov`, `TukeyHSD`)**: 比较 3+ 组均值。\n    -   **卡方检验 (`chisq.test`, `fisher.test`)**: 分析分类变量关联性 (独立性检验) 或分布拟合 (拟合优度检验)。\n    -   **相关检验 (`cor.test`)**: 检验两个连续 (或有序) 变量的相关性是否显著。\n    -   **SLR (`lm`)**: 检验单个自变量对因变量的线性影响是否显著 (看系数的 P 值)。\n\n**快速判断:** \n\n1. 想比较两种不同减肥方法的效果（体重减少量），应使用哪种检验？(假设满足条件) \n2. 想调查某大学男女生对食堂满意度（满意/不满意）是否存在差异，应使用哪种检验？ \n3. 想研究广告投入（连续变量）与产品销量（连续变量）之间是否存在线性关系，应使用哪种分析？ \n4. 想比较三种不同品牌灯泡的平均寿命是否有差异，应使用哪种检验？如果结果显著，下一步该做什么？\n:::\n\n## 3. 多元回归“再认识”：深入理解偏回归系数\n\n我们在第六周初步接触了 MLR。现在，我们要深入理解其核心——**偏回归系数 (Partial Regression Coefficient)**。\n\n-   **回顾模型形式:** $Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_k X_k + \\epsilon$\n-   **偏回归系数** $\\beta_j$ 的意义 (核心！):\n    -   $\\beta_j$ 衡量的是，**在保持模型中所有其他自变量 (**$X_1, ..., X_{j-1}, X_{j+1}, ..., X_k$) 数值不变 (或称“控制住” Control For) 的条件下**，自变量 $X_j$ **每增加一个单位**时，因变量 Y 的**期望**平均变化量。\n    -   它反映了 $X_j$ 对 Y 的**独立效应 (Independent Effect)** 或**调整后效应 (Adjusted Effect)**。\n-   **为何重要？**\n    -   现实世界中变量往往相互关联（存在混淆 Confounding）。如果不控制其他相关变量，我们可能会错误地估计某个变量的真实影响（遗漏变量偏误 Omitted Variable Bias）。\n    -   MLR 通过将多个相关变量纳入模型，可以**分离出**每个自变量在控制了其他变量影响后的**净效应 (Net Effect)**。\n-   **示例：预测汽车高速里程 (hwy)**\n    -   **SLR:** `lm(hwy ~ displ, data = mpg)`\n\n        -   `displ` 的系数 $\\hat{\\beta}_1 \\approx -3.53$。这表示排量每增加 1 升，hwy 平均减少 3.53 MPG，**但这个估计可能混杂了其他与排量相关的因素（如气缸数、车重等）的影响**。\n\n    -   **MLR:** `lm(hwy ~ displ + cyl + drv, data = mpg)` (加入气缸数 `cyl` 和驱动方式 `drv`)\n\n        ```{r}\n        library(tidyverse)\n        mlr_model_mpg <- lm(hwy ~ displ + cyl + drv, data = mpg)\n        summary(mlr_model_mpg)\n        ```\n\n        -   **解读 `displ` 的偏回归系数** $\\hat{\\beta}_{displ} \\approx -1.1245$:\n            -   **在保持气缸数 (cyl) 和驱动方式 (drv) 不变的情况下**，发动机排量 (displ) 每增加 1 升，高速公路里程 (hwy) **平均减少**约 1.12 MPG。\n            -   **对比 SLR:** 这个系数 (-1.1245) 的绝对值小于 SLR 中的系数 (-3.53)。这表明，排量对里程的**部分**负面影响实际上是通过气缸数等其他因素体现的。控制了这些因素后，排量本身的**独立**负面影响变小了。\n        -   **解读 `cyl` 的偏回归系数** $\\hat{\\beta}_{cyl} \\approx -1.4509$:\n            -   **在保持排量 (displ) 和驱动方式 (drv) 不变的情况下**，气缸数 (cyl) 每增加 1 个，高速公路里程 (hwy) **平均减少**约 1.45 MPG。\n        -   **解读分类变量 `drv` (因子):** R 自动进行了虚拟编码 (Dummy Coding)。它选择一个参照组（这里是 `drv = '4'` 四驱），其他组别的系数表示**相对于参照组**的平均差异。\n            -   `drvf` ($\\hat{\\beta}_{drvf} \\approx 5.04$): **在保持排量和气缸数不变的情况下**，前驱 (`drv='f'`) 车辆的平均高速里程比四驱 (`drv='4'`) 车辆**高**约 5.04 MPG (且 P \\< 0.05，差异显著)。\n            -   `drvr` ($\\hat{\\beta}_{drvr} \\approx 4.9$): **在保持排量和气缸数不变的情况下**，后驱 (`drv='r'`) 车辆的平均高速里程比四驱 (`drv='4'`) 车辆**高**约 4.9 MPG (且 P \\< 0.05，差异显著)。\n\n## 4. 统计显著性 vs 实际重要性\n\n-   **统计显著性 (Statistical Significance):** 由 **P 值**决定。P 值 \\< $\\alpha$ 意味着我们有足够证据拒绝 $H_0$（例如，系数不为 0，或组间均值有差异）。它表明观察到的效应**不太可能**仅仅由随机抽样误差引起。\n-   **实际重要性 (Practical Significance / Effect Size):** 指效应的**大小或幅度**在现实世界中是否有意义或值得关注。\n-   **区分:**\n    -   **大样本量**可能导致**非常小**的效应也具有**统计显著性**（P 值很小），但这个效应在实际应用中可能微不足道。\n    -   **小样本量**可能导致**很大**的效应却**不具有**统计显著性（P 值较大），因为证据不足。\n-   **评估实际重要性:**\n    -   **回归系数的大小:** $\\beta_j$ 的值本身有多大？结合业务背景判断这个变化量是否有意义。\n    -   **R²:** 模型解释了多少变异？(虽然 R² 高不代表模型一定好或有因果关系)。\n    -   **置信区间:** 系数的置信区间宽度和位置提供了效应大小不确定性的信息。\n    -   **标准化系数 (Standardized Coefficients, Betas):** (后续可能涉及) 将所有变量标准化后进行回归，得到的系数可以比较不同自变量的相对重要性（因为它们在同一尺度上）。\n    -   **领域知识 (Domain Knowledge):** 结合专业背景判断效应是否重要。\n\n::: {.callout-warning title=\"警惕 P 值崇拜\"}\n不要仅仅根据 P 值 \\< 0.05 就认为结果一定重要。要结合效应大小、置信区间、研究背景和实际影响来综合判断。\n:::\n\n## 5. 回归模型的假设 (L.I.N.E.)\n\n线性回归模型（包括 SLR 和 MLR）的有效性依赖于一些关键假设。如果这些假设严重违背，模型的预测和推断结果可能不可靠。\n\n1.  **线性性 (Linearity):** 因变量 $Y$ 与**每个**自变量 $X_j$ 之间的关系是**线性的**（在控制其他变量后）。\n    -   **检查:** 残差图 (Residuals vs Fitted plot)，残差应该随机散布在 0 附近，没有明显模式（如曲线）。也可以绘制部分残差图 (Partial Residual Plots)。\n    -   **后果:** 如果关系是非线性的，线性模型拟合会很差，预测不准。\n    -   **处理:** 变量变换（如 $\\log(Y)$, $X^2$），加入非线性项，使用非线性模型。\n2.  **独立性 (Independence):** **误差项** $\\epsilon_i$ (或观测值 $Y_i$) 之间相互独立。\n    -   **检查:** 通常根据研究设计判断（如时间序列数据、聚类数据可能违背）。也可以检查残差的自相关性 (Durbin-Watson test)。\n    -   **后果:** 标准误估计偏低，导致 P 值偏小，容易犯第一类错误。\n    -   **处理:** 使用考虑了依赖性的模型（如时间序列模型、多层模型）。\n3.  **正态性 (Normality):** **误差项** $\\epsilon$ 服从**正态分布**。注意：是**误差项**，不是 $Y$ 或 $X$ 本身！\n    -   **检查:** 残差的正态 QQ 图 (Normal Q-Q plot)，点应大致落在直线上；残差的直方图；Shapiro-Wilk 检验。\n    -   **后果:** 在小样本下，系数的置信区间和 P 值可能不准确。但在大样本下（CLT），t 检验和 F 检验对轻微偏离正态性比较稳健。\n    -   **处理:** 变量变换，使用稳健回归方法。\n4.  **等方差性 (Equal Variance / Homoscedasticity):** **误差项** $\\epsilon$ 的方差对于**所有**自变量的取值水平都是**恒定的** ($\\sigma^2$)。\n    -   **检查:** 残差图 (Residuals vs Fitted plot)，点的散布宽度应该大致均匀，没有喇叭形或扇形。也可以用 Breusch-Pagan 检验等。\n    -   **后果:** OLS 估计仍然是无偏的，但标准误和 P 值不准确。\n    -   **处理:** 变量变换（如 $\\log(Y)$），使用加权最小二乘法 (WLS) 或稳健标准误。\n\n::: {.callout-info title=\"L.I.N.E. 助记\"}\n**L**inearity, **I**ndependence, **N**ormality, **E**qual Variance. 这些是经典 OLS 回归的核心假设。我们将在下一周学习如何通过**模型诊断**来检查这些假设。\n:::\n\n## 6. AI 辅助理解与验证\n\nAI 工具可以帮助我们回顾概念和解释结果，但务必谨慎使用。\n\n::: {.callout-tip title=\"AI 辅助演示 (需验证！)\"}\n-   **回顾概念:** \"请解释多元线性回归中偏回归系数的概念\" 或 \"线性回归的假设(LINE)有哪些？\"\n-   **解释 MLR 系数:** (提供 `summary()` 输出) \"请解释这个 R 回归输出中 'displ' 的系数，并考虑模型中的其他变量\"\n-   **比较 SLR 和 MLR 系数:** \"为什么在简单线性回归(hwy \\~ displ)和多元线性回归(hwy \\~ displ + cyl + drv)中，'displ' 的系数会不同？\"\n\n**特别提醒：** AI生成的内容可能存在不准确或不够细致的问题。**请务必结合课堂所学知识和教材内容进行批判性思考和验证。** 切勿直接将AI的解释作为最终答案直接使用。\n:::\n\n## 7. 本周总结与预告\n\n本周我们系统回顾了第一阶段的知识体系，并深入探讨了多元线性回归的核心——偏回归系数的意义和解释，以及统计显著性与实际重要性的区别。我们还重温了线性回归的关键假设 (L.I.N.E.)，为下周的模型诊断打下基础。\n\n**下周预告:** 模型拟合好了，但它可靠吗？下周我们将学习**回归模型诊断**的实战技术，利用各种图形和检验方法来检查 L.I.N.E. 假设是否满足，并识别模型中可能存在的问题（如异常值、强影响点、多重共线性）。","srcMarkdownNoYaml":"\n\n## 1. 欢迎来到第二阶段！\n\n本周我们正式进入课程的第二阶段。在深入学习更高级的统计模型之前，我们需要系统地回顾和巩固第一阶段（第 1-7 周）的核心知识，并在此基础上，重新审视和深入理解**多元线性回归 (Multiple Linear Regression, MLR)**。\n\n::: {.callout-note title=\"本周目标\"}\n-   **系统回顾**第一阶段核心内容：数据处理与可视化 (`tidyverse`, `ggplot2`)；描述统计；参数估计（点估计与置信区间）；假设检验逻辑；常用检验方法 (t 检验, ANOVA, 卡方检验)；相关分析；简单线性回归 (SLR) 基础与多元线性回归 (MLR) 初步概念。\n-   **深入理解** MLR 中**偏回归系数**的意义：控制变量与独立效应。\n-   **反复练习**对 `lm()` 输出中 MLR 系数的**业务含义解释**。\n-   区分统计显著性与实际重要性。\n-   回顾线性回归的 **L.I.N.E.** 假设，理解其重要性及违背后果。\n-   （演示）利用 AI 辅助回顾概念、解释 MLR 系数，并**强调验证其准确性**。\n:::\n\n## 2. 阶段一知识回顾 (重点环节)\n\n让我们通过互动问答、知识点串讲和快速练习，快速回顾一下前七周的核心内容。\n\n::: panel-tabset\n### 数据处理与可视化\n\n-   **`tidyverse` 核心包:** `dplyr`, `tidyr`, `readr`, `ggplot2` 等。\n-   **`dplyr` 动词:**\n    -   `select()`: 选择列。\n    -   `filter()`: 筛选行。\n    -   `mutate()`: 创建/修改列。\n    -   `arrange()`: 排序。\n    -   `group_by()` + `summarise()`: 分组汇总 (常用 `n()`, `mean()`, `sd()`, `min()`, `max()`, `n_distinct()`)。\n    -   管道 `%>%`: 连接操作。\n-   **`tidyr` 动词:**\n    -   `pivot_longer()`: 宽数据变长。\n    -   `pivot_wider()`: 长数据变宽。\n    -   `drop_na()`: 删除含 NA 的行。\n    -   `replace_na()`: 替换 NA。\n-   **整洁数据原则:** 每个变量一列，每个观测一行，每种观测一个表。\n-   **`ggplot2` 图形语法:**\n    -   `ggplot(data, aes(x=..., y=..., color=...)) + geom_xxx(...)`\n    -   常用 `geom`: `geom_point`, `geom_line`, `geom_histogram`, `geom_density`, `geom_boxplot`, `geom_violin`, `geom_bar`, `geom_col`, `geom_smooth`。\n    -   定制: `labs()`, `theme_...()`, `coord_flip()`。\n\n**快速练习:** \n\n1. 如何筛选 `mpg` 数据集中 `manufacturer` 为 \"audi\" 且 `year` 为 2008 的车辆？ \n2. 如何计算 `mpg` 数据集中每个 `manufacturer` 的平均城市里程 (`cty`)？ \n3. 如何用 `ggplot2` 绘制 `mpg` 数据集中 `cty` (城市里程) 与 `hwy` (高速里程) 的散点图，并按 `drv` (驱动方式) 区分颜色？\n\n\n### 描述统计与参数估计\n\n-   **描述统计:**\n    -   集中趋势: 均值 (`mean`), 中位数 (`median`)。\n    -   离散趋势: 标准差 (`sd`), 方差 (`var`), IQR (`IQR`), 范围 (`range`)。\n-   **参数估计:**\n    -   点估计: 用样本统计量估计总体参数 (如 $\\bar{x}$ 估计 $\\mu$)。\n    -   区间估计: 置信区间 (CI)。\n-   **置信区间:**\n    -   提供总体参数可能范围的估计，并附带置信水平。\n    -   95% CI 含义：重复抽样构造区间，约 95% 的区间会包含真值。\n    -   解读：我们有 XX% 的信心认为总体参数落在 \\[下限, 上限\\] 之间。\n    -   影响因素：置信水平、样本量、数据变异性。\n\n**快速思考:** \n\n1. 什么时候应该使用中位数而不是均值来描述数据的中心？\n2. 99% 置信区间与 95% 置信区间相比，哪个更宽？为什么？ \n3. 增加样本量会对置信区间的宽度产生什么影响？\n\n### 假设检验逻辑与常用方法\n\n-   **假设检验逻辑:**\n    -   $H_0$ (原假设) vs $H_1$ (备择假设)。\n    -   $\\alpha$ (显著性水平，第一类错误概率)。\n    -   检验统计量。\n    -   P 值 (在 $H_0$ 为真的条件下，观测到当前或更极端结果的概率)。\n    -   决策：P ≤ $\\alpha$ -\\> 拒绝 $H_0$；P \\> $\\alpha$ -\\> 未能拒绝 $H_0$。\n    -   两类错误：Type I ($\\alpha$) vs Type II ($\\beta$)；Power = $1-\\beta$。\n-   **常用检验方法回顾 (见第七周总结):**\n    -   **t 检验 (`t.test`)**: 比较 1 或 2 组均值 (单样本, 双独立样本, 配对样本)。\n    -   **ANOVA (`aov`, `TukeyHSD`)**: 比较 3+ 组均值。\n    -   **卡方检验 (`chisq.test`, `fisher.test`)**: 分析分类变量关联性 (独立性检验) 或分布拟合 (拟合优度检验)。\n    -   **相关检验 (`cor.test`)**: 检验两个连续 (或有序) 变量的相关性是否显著。\n    -   **SLR (`lm`)**: 检验单个自变量对因变量的线性影响是否显著 (看系数的 P 值)。\n\n**快速判断:** \n\n1. 想比较两种不同减肥方法的效果（体重减少量），应使用哪种检验？(假设满足条件) \n2. 想调查某大学男女生对食堂满意度（满意/不满意）是否存在差异，应使用哪种检验？ \n3. 想研究广告投入（连续变量）与产品销量（连续变量）之间是否存在线性关系，应使用哪种分析？ \n4. 想比较三种不同品牌灯泡的平均寿命是否有差异，应使用哪种检验？如果结果显著，下一步该做什么？\n:::\n\n## 3. 多元回归“再认识”：深入理解偏回归系数\n\n我们在第六周初步接触了 MLR。现在，我们要深入理解其核心——**偏回归系数 (Partial Regression Coefficient)**。\n\n-   **回顾模型形式:** $Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_k X_k + \\epsilon$\n-   **偏回归系数** $\\beta_j$ 的意义 (核心！):\n    -   $\\beta_j$ 衡量的是，**在保持模型中所有其他自变量 (**$X_1, ..., X_{j-1}, X_{j+1}, ..., X_k$) 数值不变 (或称“控制住” Control For) 的条件下**，自变量 $X_j$ **每增加一个单位**时，因变量 Y 的**期望**平均变化量。\n    -   它反映了 $X_j$ 对 Y 的**独立效应 (Independent Effect)** 或**调整后效应 (Adjusted Effect)**。\n-   **为何重要？**\n    -   现实世界中变量往往相互关联（存在混淆 Confounding）。如果不控制其他相关变量，我们可能会错误地估计某个变量的真实影响（遗漏变量偏误 Omitted Variable Bias）。\n    -   MLR 通过将多个相关变量纳入模型，可以**分离出**每个自变量在控制了其他变量影响后的**净效应 (Net Effect)**。\n-   **示例：预测汽车高速里程 (hwy)**\n    -   **SLR:** `lm(hwy ~ displ, data = mpg)`\n\n        -   `displ` 的系数 $\\hat{\\beta}_1 \\approx -3.53$。这表示排量每增加 1 升，hwy 平均减少 3.53 MPG，**但这个估计可能混杂了其他与排量相关的因素（如气缸数、车重等）的影响**。\n\n    -   **MLR:** `lm(hwy ~ displ + cyl + drv, data = mpg)` (加入气缸数 `cyl` 和驱动方式 `drv`)\n\n        ```{r}\n        library(tidyverse)\n        mlr_model_mpg <- lm(hwy ~ displ + cyl + drv, data = mpg)\n        summary(mlr_model_mpg)\n        ```\n\n        -   **解读 `displ` 的偏回归系数** $\\hat{\\beta}_{displ} \\approx -1.1245$:\n            -   **在保持气缸数 (cyl) 和驱动方式 (drv) 不变的情况下**，发动机排量 (displ) 每增加 1 升，高速公路里程 (hwy) **平均减少**约 1.12 MPG。\n            -   **对比 SLR:** 这个系数 (-1.1245) 的绝对值小于 SLR 中的系数 (-3.53)。这表明，排量对里程的**部分**负面影响实际上是通过气缸数等其他因素体现的。控制了这些因素后，排量本身的**独立**负面影响变小了。\n        -   **解读 `cyl` 的偏回归系数** $\\hat{\\beta}_{cyl} \\approx -1.4509$:\n            -   **在保持排量 (displ) 和驱动方式 (drv) 不变的情况下**，气缸数 (cyl) 每增加 1 个，高速公路里程 (hwy) **平均减少**约 1.45 MPG。\n        -   **解读分类变量 `drv` (因子):** R 自动进行了虚拟编码 (Dummy Coding)。它选择一个参照组（这里是 `drv = '4'` 四驱），其他组别的系数表示**相对于参照组**的平均差异。\n            -   `drvf` ($\\hat{\\beta}_{drvf} \\approx 5.04$): **在保持排量和气缸数不变的情况下**，前驱 (`drv='f'`) 车辆的平均高速里程比四驱 (`drv='4'`) 车辆**高**约 5.04 MPG (且 P \\< 0.05，差异显著)。\n            -   `drvr` ($\\hat{\\beta}_{drvr} \\approx 4.9$): **在保持排量和气缸数不变的情况下**，后驱 (`drv='r'`) 车辆的平均高速里程比四驱 (`drv='4'`) 车辆**高**约 4.9 MPG (且 P \\< 0.05，差异显著)。\n\n## 4. 统计显著性 vs 实际重要性\n\n-   **统计显著性 (Statistical Significance):** 由 **P 值**决定。P 值 \\< $\\alpha$ 意味着我们有足够证据拒绝 $H_0$（例如，系数不为 0，或组间均值有差异）。它表明观察到的效应**不太可能**仅仅由随机抽样误差引起。\n-   **实际重要性 (Practical Significance / Effect Size):** 指效应的**大小或幅度**在现实世界中是否有意义或值得关注。\n-   **区分:**\n    -   **大样本量**可能导致**非常小**的效应也具有**统计显著性**（P 值很小），但这个效应在实际应用中可能微不足道。\n    -   **小样本量**可能导致**很大**的效应却**不具有**统计显著性（P 值较大），因为证据不足。\n-   **评估实际重要性:**\n    -   **回归系数的大小:** $\\beta_j$ 的值本身有多大？结合业务背景判断这个变化量是否有意义。\n    -   **R²:** 模型解释了多少变异？(虽然 R² 高不代表模型一定好或有因果关系)。\n    -   **置信区间:** 系数的置信区间宽度和位置提供了效应大小不确定性的信息。\n    -   **标准化系数 (Standardized Coefficients, Betas):** (后续可能涉及) 将所有变量标准化后进行回归，得到的系数可以比较不同自变量的相对重要性（因为它们在同一尺度上）。\n    -   **领域知识 (Domain Knowledge):** 结合专业背景判断效应是否重要。\n\n::: {.callout-warning title=\"警惕 P 值崇拜\"}\n不要仅仅根据 P 值 \\< 0.05 就认为结果一定重要。要结合效应大小、置信区间、研究背景和实际影响来综合判断。\n:::\n\n## 5. 回归模型的假设 (L.I.N.E.)\n\n线性回归模型（包括 SLR 和 MLR）的有效性依赖于一些关键假设。如果这些假设严重违背，模型的预测和推断结果可能不可靠。\n\n1.  **线性性 (Linearity):** 因变量 $Y$ 与**每个**自变量 $X_j$ 之间的关系是**线性的**（在控制其他变量后）。\n    -   **检查:** 残差图 (Residuals vs Fitted plot)，残差应该随机散布在 0 附近，没有明显模式（如曲线）。也可以绘制部分残差图 (Partial Residual Plots)。\n    -   **后果:** 如果关系是非线性的，线性模型拟合会很差，预测不准。\n    -   **处理:** 变量变换（如 $\\log(Y)$, $X^2$），加入非线性项，使用非线性模型。\n2.  **独立性 (Independence):** **误差项** $\\epsilon_i$ (或观测值 $Y_i$) 之间相互独立。\n    -   **检查:** 通常根据研究设计判断（如时间序列数据、聚类数据可能违背）。也可以检查残差的自相关性 (Durbin-Watson test)。\n    -   **后果:** 标准误估计偏低，导致 P 值偏小，容易犯第一类错误。\n    -   **处理:** 使用考虑了依赖性的模型（如时间序列模型、多层模型）。\n3.  **正态性 (Normality):** **误差项** $\\epsilon$ 服从**正态分布**。注意：是**误差项**，不是 $Y$ 或 $X$ 本身！\n    -   **检查:** 残差的正态 QQ 图 (Normal Q-Q plot)，点应大致落在直线上；残差的直方图；Shapiro-Wilk 检验。\n    -   **后果:** 在小样本下，系数的置信区间和 P 值可能不准确。但在大样本下（CLT），t 检验和 F 检验对轻微偏离正态性比较稳健。\n    -   **处理:** 变量变换，使用稳健回归方法。\n4.  **等方差性 (Equal Variance / Homoscedasticity):** **误差项** $\\epsilon$ 的方差对于**所有**自变量的取值水平都是**恒定的** ($\\sigma^2$)。\n    -   **检查:** 残差图 (Residuals vs Fitted plot)，点的散布宽度应该大致均匀，没有喇叭形或扇形。也可以用 Breusch-Pagan 检验等。\n    -   **后果:** OLS 估计仍然是无偏的，但标准误和 P 值不准确。\n    -   **处理:** 变量变换（如 $\\log(Y)$），使用加权最小二乘法 (WLS) 或稳健标准误。\n\n::: {.callout-info title=\"L.I.N.E. 助记\"}\n**L**inearity, **I**ndependence, **N**ormality, **E**qual Variance. 这些是经典 OLS 回归的核心假设。我们将在下一周学习如何通过**模型诊断**来检查这些假设。\n:::\n\n## 6. AI 辅助理解与验证\n\nAI 工具可以帮助我们回顾概念和解释结果，但务必谨慎使用。\n\n::: {.callout-tip title=\"AI 辅助演示 (需验证！)\"}\n-   **回顾概念:** \"请解释多元线性回归中偏回归系数的概念\" 或 \"线性回归的假设(LINE)有哪些？\"\n-   **解释 MLR 系数:** (提供 `summary()` 输出) \"请解释这个 R 回归输出中 'displ' 的系数，并考虑模型中的其他变量\"\n-   **比较 SLR 和 MLR 系数:** \"为什么在简单线性回归(hwy \\~ displ)和多元线性回归(hwy \\~ displ + cyl + drv)中，'displ' 的系数会不同？\"\n\n**特别提醒：** AI生成的内容可能存在不准确或不够细致的问题。**请务必结合课堂所学知识和教材内容进行批判性思考和验证。** 切勿直接将AI的解释作为最终答案直接使用。\n:::\n\n## 7. 本周总结与预告\n\n本周我们系统回顾了第一阶段的知识体系，并深入探讨了多元线性回归的核心——偏回归系数的意义和解释，以及统计显著性与实际重要性的区别。我们还重温了线性回归的关键假设 (L.I.N.E.)，为下周的模型诊断打下基础。\n\n**下周预告:** 模型拟合好了，但它可靠吗？下周我们将学习**回归模型诊断**的实战技术，利用各种图形和检验方法来检查 L.I.N.E. 假设是否满足，并识别模型中可能存在的问题（如异常值、强影响点、多重共线性）。"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":false,"freeze":false,"echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"message":false,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles/custom.css"],"toc":true,"number-sections":false,"include-in-header":[{"text":"<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css\" integrity=\"sha512-1ycn6IcaQQ40/MKBW2W4Rhis/DbILU74C1vSrLJxCq57o941Ym01SwNsOMqvEBFlcgUa6xkm/sYwpb+ilR5gUw==\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\">\n"}],"output-file":"week8_lecture.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","knitr":{"opts_chunk":{"comment":"#>","fig.align":"center","fig.width":8,"fig.height":6,"out.width":"90%","dpi":300,"dev":"ragg_png"}},"theme":"cosmo","callout-appearance":"none","message":false,"title":"第八周：承前启后：阶段回顾与多元回归再探"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}