---
title: "第五周：做出判断：假设检验 (单/双样本) 与 ANOVA 应用"
execute:
  echo: true
  warning: false
  message: false
---

## 1. 假设检验：基于证据做决策

上周我们学习了如何用置信区间来估计总体参数的范围。**假设检验 (Hypothesis Testing)** 是推断统计的另一个核心工具，它提供了一个正式的框架，用于**利用样本数据来判断关于总体的某个断言（假设）是否可信**。

-   **核心思想:** 我们想检验一个关于总体的**原假设 (Null Hypothesis,** $H_0$)。我们收集样本数据，看样本证据**在多大程度上反对** $H_0$。如果证据足够强（即样本结果在 $H_0$ 成立的条件下非常罕见），我们就**拒绝** $H_0$，并接受与之对立的**备择假设 (Alternative Hypothesis,** $H_1$ 或 $H_a$)。

::: {.callout-note title="本周目标"}
-   理解假设检验的基本逻辑：原假设、备择假设、P 值、显著性水平、决策规则。
-   区分并理解两类错误。
-   掌握单样本 t 检验的应用场景、假设、R 实现和结果解读。
-   掌握双独立样本 t 检验的应用场景、假设（特别是方差齐性）、R 实现和结果解读。
-   掌握配对样本 t 检验的应用场景、与独立样本的区别、R 实现和结果解读。
-   理解为何需要方差分析 (ANOVA) 来比较多组均值。
-   掌握单因素 ANOVA 的应用场景、假设、R 实现和结果解读（ANOVA 表）。
-   理解事后检验的必要性，并掌握 Tukey's HSD 的 R 实现和解读。
:::

## 2. 假设检验的逻辑步骤

一个典型的假设检验包含以下步骤：

1.  **陈述假设:**
    -   **原假设 (**$H_0$): 通常是表示“没有效应”、“没有差异”或维持现状的陈述。它包含等号（=, ≤, ≥）。我们总是**假设** $H_0$ 为真开始分析。
        -   例：新药无效 ($μ_{新药} = μ_{安慰剂}$)。
        -   例：产品合格率不低于 95% ($p \ge 0.95$)。
    -   **备择假设 (**$H_1$ 或 $H_a$): 我们希望找到证据支持的陈述，通常是表示“有效应”、“有差异”或我们怀疑的情况。它不包含等号（≠, \<, \>）。
        -   例：新药有效 ($μ_{新药} \ne μ_{安慰剂}$，双侧检验；或 $μ_{新药} > μ_{安慰剂}$，单侧检验)。
        -   例：产品合格率低于 95% ($p < 0.95$)。
2.  **选择显著性水平 (**$\alpha$):
    -   $\alpha$ 是我们愿意承担的**犯第一类错误的概率**（见下文）。
    -   它代表了我们拒绝 $H_0$ 所需的证据强度阈值。
    -   常用值：0.05 (5%)，有时也用 0.01 或 0.10。**需要在分析前确定**。
3.  **计算检验统计量 (Test Statistic)**:
    -   根据样本数据计算一个值，该值衡量了样本结果与 $H_0$ 预期结果之间的差异程度（考虑了抽样变异性）。
    -   不同的检验方法有不同的检验统计量（如 t 值, F 值, $\chi^2$ 值）。
4.  **计算 P 值 (P-value)**:
    -   **核心概念:** P 值是在**假设** $H_0$ 为真的前提下，观察到**当前样本结果或更极端结果**的概率。
    -   P 值越小，表示样本结果在 $H_0$ 下越不可能发生，反对 $H_0$ 的证据越强。
5.  **做出决策:**
    -   将 P 值与显著性水平 $\alpha$ 进行比较：
        -   如果 **P 值 ≤** $\alpha$: 结果具有**统计显著性 (Statistically Significant)**。我们**拒绝** $H_0$，接受 $H_1$。有足够证据反对原假设。
        -   如果 **P 值 \>** $\alpha$: 结果**不具有**统计显著性。我们**未能拒绝 (Fail to Reject)** $H_0$。没有足够证据反对原假设。
    -   **注意:** 未能拒绝 $H_0$ **不等于** 证明 $H_0$ 为真，只是证据不足以推翻它。
6.  **解释结果:** 结合具体问题情境，用通俗语言解释决策的含义。

## 3. 两类错误

在假设检验中，我们可能做出错误的决策：

-   **第一类错误 (Type I Error,** $\alpha$ 错误, 弃真错误):
    -   当 $H_0$ **实际上为真**时，我们却**拒绝**了它。
    -   发生概率为 $\alpha$ (显著性水平)。
    -   后果：错误地认为有效应或差异（例如，认为无效药有效）。
-   **第二类错误 (Type II Error,** $\beta$ 错误, 取伪错误):
    -   当 $H_0$ **实际上为假**（$H_1$ 为真）时，我们却**未能拒绝**它。
    -   发生概率为 $\beta$。
    -   **统计功效 (Power)** = $1 - \beta$，即当 $H_1$ 为真时，正确拒绝 $H_0$ 的概率。
    -   后果：未能发现存在的效应或差异（例如，未能发现有效药物的效果）。

::: {.callout-warning title="错误权衡"}
$\alpha$ 和 $\beta$ 通常是相互制约的。降低 $\alpha$（减少犯第一类错误的风险）通常会增加 $\beta$（增加犯第二类错误的风险），反之亦然。选择 $\alpha$ 需要权衡两类错误的相对严重性。统计功效受样本量、效应大小、$\alpha$ 水平和数据变异性影响。
:::

## 4. 单样本 t 检验 (One-Sample t-test)

-   **目的:** 检验**单个总体的均值** $\mu$ 是否等于某个**已知的特定值** $\mu_0$。

-   **应用场景:**

    -   某品牌矿泉水声称每瓶含钠量为 20mg，检验是否属实？($H_0: \mu = 20$)
    -   某地区去年人均收入为 50000 元，今年是否有显著变化？($H_0: \mu = 50000$)

-   **假设条件:**

    1.  样本是**随机**从总体中抽取的。
    2.  总体分布**近似正态**，或者**样本量足够大**（通常 n ≥ 30，中心极限定理保证样本均值的抽样分布近似正态）。可以通过 QQ 图或 Shapiro-Wilk 检验来检查正态性。

-   **检验统计量 (t 值):** $$ t = \frac{\bar{x} - \mu_0}{s / \sqrt{n}} $$ 其中 $\bar{x}$ 是样本均值，$\mu_0$ 是假设的总体均值， $s$ 是样本标准差， $n$ 是样本量。该统计量服从自由度为 $df = n-1$ 的 t 分布。

-   **R 实现: `t.test()`**

    ```{r}
    library(tidyverse)
    
    # 示例：检验一批灯泡的平均寿命是否显著不等于 1000 小时
    lifespan <- c(980, 1020, 1010, 995, 970, 1035, 1005, 960, 1015, 990)
    sample_mean <- mean(lifespan)
    sample_sd <- sd(lifespan)
    n <- length(lifespan)
    print(paste("Sample Mean:", sample_mean, "Sample SD:", sample_sd, "n:", n))

    # H0: mu = 1000
    # H1: mu != 1000 (双侧检验)
    t_test_result <- t.test(lifespan, mu = 1000)
    print(t_test_result)

    # 访问结果的关键信息
    t_test_result$statistic # t 值
    t_test_result$parameter # 自由度 (df)
    t_test_result$p.value   # P 值
    t_test_result$conf.int  # 总体均值的置信区间 (默认 95%)
    t_test_result$estimate  # 样本均值
    ```

-   **结果解读:**

    -   查看 **P 值**。如果 P 值 \< $\alpha$ (例如 0.05)，则拒绝 $H_0$。
    -   在上面的例子中，如果 P 值 \< 0.05，我们可以说：有统计学证据表明这批灯泡的平均寿命**显著不等于** 1000 小时 (在 $\alpha=0.05$ 水平下)。
    -   查看**置信区间**。如果 $\mu_0$ (这里是 1000) **不包含**在置信区间内，也支持拒绝 $H_0$。置信区间给出了总体均值可能的范围。
    -   **单侧检验:** 如果想检验平均寿命是否**大于** 1000 ($H_1: \mu > 1000$)，使用 `alternative = "greater"`；如果想检验是否**小于** 1000 ($H_1: \mu < 1000$)，使用 `alternative = "less"`。

## 5. 双独立样本 t 检验 (Two-Independent-Samples t-test)

-   **目的:** 比较**两个独立总体**的均值 $\mu_1$ 和 $\mu_2$ 是否相等。

-   **应用场景:**

    -   比较两种不同教学方法下学生的平均成绩是否有差异？($H_0: \mu_1 = \mu_2$)
    -   比较男性和女性的平均工资是否有差异？($H_0: \mu_{male} = \mu_{female}$)

-   **假设条件:**

    1.  两个样本是**独立**随机抽取的。
    2.  两个总体都**近似正态**分布，或者两个样本量都**足够大** (n1 ≥ 30, n2 ≥ 30)。
    3.  **方差齐性 (Homogeneity of Variances):** 两个总体的方差 $\sigma_1^2$ 和 $\sigma_2^2$ 相等。这是传统 Student's t-test 的要求。
        -   **检验方差齐性:** 可以使用 Levene's test 或 F 检验 (`var.test()`)。$H_0$: 方差相等。如果 P 值 \> $\alpha$ (如 0.05)，则不能拒绝方差齐性的假设。
        -   **方差不齐怎么办？** R 中的 `t.test()` 默认使用 **Welch's t-test**，它**不要求方差齐性**，是对自由度进行了调整的 t 检验，通常更推荐使用。

-   **R 实现: `t.test()`** (使用公式语法或分别传入两个向量)

    ```{r}
    # 示例：比较两种肥料对作物产量的影响
    yield_A <- c(25, 28, 22, 30, 26)
    yield_B <- c(32, 35, 29, 38, 31, 33)

    # 1. (可选但推荐) 检查方差齐性
    var_test_result <- var.test(yield_A, yield_B)
    print(var_test_result) # 查看 P 值

    # 2. 执行 t 检验
    # H0: mu_A = mu_B (或 mu_A - mu_B = 0)
    # H1: mu_A != mu_B
    # 默认使用 Welch's t-test (var.equal = FALSE)
    t_test_ind_welch <- t.test(yield_A, yield_B)
    print(t_test_ind_welch)

    # 如果方差齐性检验 P 值很大 (如 > 0.1 或 0.05)，且你坚持使用 Student's t-test
    # t_test_ind_student <- t.test(yield_A, yield_B, var.equal = TRUE)
    # print(t_test_ind_student)

    # 使用公式语法 (数据需要是长格式)
    yield_data <- tibble(
      Yield = c(yield_A, yield_B),
      Fertilizer = factor(rep(c("A", "B"), times = c(length(yield_A), length(yield_B))))
    )
    print(yield_data)
    t.test(Yield ~ Fertilizer, data = yield_data) # 默认 Welch
    # t.test(Yield ~ Fertilizer, data = yield_data, var.equal = TRUE) # Student's
    ```

-   **结果解读:**

    -   同样关注 **P 值**。如果 P 值 \< $\alpha$，拒绝 $H_0$，认为两个总体的均值有显著差异。
    -   查看**置信区间** (针对均值差 $\mu_1 - \mu_2$)。如果区间**不包含 0**，也支持拒绝 $H_0$。区间给出了两个总体均值差异的可能范围。
    -   同样可以进行单侧检验 (`alternative = "greater"` 或 `"less"`)。

## 6. 配对样本 t 检验 (Paired-Samples t-test)

-   **目的:** 比较**同一个对象**在**两种不同条件下**或**两个不同时间点**的均值是否存在差异。本质上是检验**差值的均值**是否等于 0。

-   **应用场景:**

    -   比较同一批患者服药前后的血压平均值是否有变化？
    -   比较同一组学生使用两种不同学习方法后的测试成绩是否有差异？
    -   比较同一块土地使用两种不同肥料的产量是否有差异（需要配对设计）？

-   **与独立样本的区别:** 独立样本是比较**两个不同组**的对象；配对样本是比较**同一组对象**的两次测量。配对设计可以有效控制个体差异。

-   **假设条件:**

    1.  样本是**配对**的。
    2.  配对**差值 (Differences)** 来自的总体**近似正态**分布，或者**配对数量足够大** (n_pairs ≥ 30)。

-   **检验统计量:** 对**差值**进行单样本 t 检验，检验差值的均值 $\mu_d$ 是否等于 0。 $$ t = \frac{\bar{d} - 0}{s_d / \sqrt{n_{pairs}}} $$ 其中 $\bar{d}$ 是差值的样本均值，$s_d$ 是差值的样本标准差，$n_{pairs}$ 是配对数量。自由度 $df = n_{pairs}-1$。

-   **R 实现: `t.test()`** (设置 `paired = TRUE`)

    ```{r}
    # 示例：比较 10 名学生使用新旧两种教学方法后的测试得分
    score_old <- c(75, 82, 68, 79, 88, 72, 90, 85, 77, 81)
    score_new <- c(80, 85, 75, 81, 92, 78, 93, 88, 80, 84)

    # H0: mu_diff = 0 (两种方法得分均值无差异)
    # H1: mu_diff != 0
    t_test_paired <- t.test(score_new, score_old, paired = TRUE)
    print(t_test_paired)

    # 也可以先计算差值，再做单样本 t 检验
    # differences <- score_new - score_old
    # t.test(differences, mu = 0) # 结果与上面相同
    ```

-   **结果解读:**

    -   关注 **P 值**。如果 P 值 \< $\alpha$，拒绝 $H_0$，认为两种条件下或两个时间点的均值存在显著差异。
    -   查看**置信区间** (针对差值的均值 $\mu_d$)。如果区间**不包含 0**，也支持拒绝 $H_0$。区间给出了均值差异的可能范围。
    -   同样可以进行单侧检验。例如，检验新方法是否**优于**旧方法 ($H_1: \mu_d > 0$)，使用 `alternative = "greater"`。

## 7. 单因素方差分析 (One-Way ANOVA)

-   **动机:** 当我们要比较**三个或更多**独立组的均值时，如果两两进行 t 检验，会增加犯第一类错误的概率（多重比较问题）。例如，比较 3 组，需要做 3 次 t 检验，总体 $\alpha$ 会膨胀。ANOVA 提供了一种**一次性**检验所有组均值是否**完全相等**的方法。

-   **目的:** 检验**三个或更多**独立总体的均值是否**全部相等**。

-   **应用场景:**

    -   比较三种不同肥料对作物产量的平均影响是否相同？
    -   比较四种不同教学方法下学生的平均成绩是否都一样？
    -   比较不同地区（≥3个）的平均房价是否相同？

-   **基本思想:** 比较组间变异 (Between-group Variation) 与组内变异 (Within-group Variation)。

    -   如果组间变异**显著大于**组内变异，则说明各组均值之间可能存在显著差异。

-   **假设条件:**

    1.  各样本是**独立**随机抽取的。
    2.  各总体都**近似正态**分布。
    3.  **方差齐性:** 各总体的方差**相等**。这对 ANOVA 比较重要，可以用 Levene's test 检验。

-   **假设陈述:**

    -   $H_0: \mu_1 = \mu_2 = ... = \mu_k$ (所有 k 个总体的均值都相等)
    -   $H_1:$ 至少有一个总体的均值与其他总体不相等 (注意：不是所有均值都不等)。

-   **检验统计量 (F 值):** $$ F = \frac{\text{组间均方 (Mean Square Between, MSB)}}{\text{组内均方 (Mean Square Within, MSW)}} $$

    -   MSB 度量了各样本均值相对于总均值的变异。
    -   MSW 度量了每个样本内部数据的变异（是总体方差的估计）。
    -   F 值服从 F 分布，具有两个自由度：$df_1 = k-1$ (组间自由度) 和 $df_2 = N-k$ (组内自由度)，其中 k 是组数，N 是总样本量。

-   **R 实现: `aov()` (Analysis of Variance)**

    ```{r}
    # 示例：比较三种不同教学方法 (A, B, C) 的学生成绩
    scores_methodA <- c(78, 85, 82, 79, 88)
    scores_methodB <- c(88, 92, 90, 86, 94)
    scores_methodC <- c(72, 78, 75, 80, 70)

    # 准备长格式数据
    anova_data <- tibble(
      Score = c(scores_methodA, scores_methodB, scores_methodC),
      Method = factor(rep(c("A", "B", "C"), each = 5))
    )
    print(anova_data)

    # (可选) 检查方差齐性 (例如使用 car 包的 leveneTest)
    # library(car)
    # leveneTest(Score ~ Method, data = anova_data)

    # 执行 ANOVA
    # H0: mu_A = mu_B = mu_C
    # H1: 至少有一个 mu 不相等
    anova_result <- aov(Score ~ Method, data = anova_data)

    # 查看 ANOVA 表
    summary(anova_result)
    ```

-   **解读 ANOVA 表 (`summary(anova_result)`)** 
    -   `Df`: 自由度 ($k-1$ 和 $N-k$)。
    -   `Sum Sq`: 平方和 (组间 SSb, 组内 SSw)。
    -   `Mean Sq`: 均方 (MSB = SSb/df1, MSW = SSw/df2)。
    -   `F value`: F 统计量 ($F = MSB / MSW$)。
    -   `Pr(>F)`: **P 值**。
    -   **决策:** 查看 P 值。如果 P 值 \< $\alpha$ (如 0.05)，则**拒绝** $H_0$。
    -   **结论:** 在上面的例子中，P 值 (0.000311) 远小于 0.05，因此我们拒绝 $H_0$，认为**至少有一种教学方法的平均成绩与其他方法存在显著差异**。

## 8. 事后检验 (Post-hoc Tests)

-   **为何需要？** ANOVA 检验的 P 值 \< $\alpha$ 只能告诉我们**至少有一组均值不同**，但**不能**告诉我们具体是**哪些组之间**存在差异。

-   **目的:** 在 ANOVA 拒绝 $H_0$ 后，进行两两比较，找出具体哪些组的均值存在显著差异。

-   **常用方法：Tukey's Honest Significant Difference (HSD)**

    -   控制了进行所有可能两两比较时的总体第一类错误率。
    -   计算每对组均值差的置信区间和调整后的 P 值。

-   **R 实现: `TukeyHSD()`** (需要先运行 `aov()`)

    ```{r}
    # 对之前的 anova_result 进行 Tukey HSD 检验
    tukey_result <- TukeyHSD(anova_result)
    print(tukey_result)

    # 绘制置信区间图
    plot(tukey_result)
    ```

-   **解读 `TukeyHSD()` 结果:**
    -   `diff`: 两组样本均值的差。
    -   `lwr`, `upr`: 均值差的 95% 置信区间下限和上限。
    -   `p adj`: 调整后的 P 值 (Adjusted P-value)。
    -   **决策:** 查看 `p adj`。如果 `p adj` \< $\alpha$ (如 0.05)，则认为该对组的均值存在显著差异。
    -   **结论:** 从上面的结果看，方法 B 的平均成绩显著高于方法 A 和方法 C；方法 C 和方法 A 之间没有显著差异 (在 $\alpha=0.05$ 水平下)。
    -   置信区间图：如果区间**不包含 0**，则表示差异显著。

## 9. 项目相关与本周总结

-   **项目任务:**
    -   根据你的项目问题和数据类型，判断是否需要进行 t 检验或 ANOVA。
    -   如果需要比较两组（独立或配对），选择合适的 t 检验，执行并解释结果。
    -   如果需要比较三组或更多组，执行 ANOVA。如果 ANOVA 结果显著，进行 Tukey's HSD 事后检验，并解释具体哪些组之间存在差异。
    -   **注意检查相应检验的假设条件**（特别是正态性和方差齐性），可以在报告中提及检查结果或局限性。
-   **本周回顾:** 本周内容非常关键且密集。我们系统学习了假设检验的完整逻辑，并掌握了应用最广泛的几种检验方法：单样本 t 检验、双独立样本 t 检验、配对样本 t 检验和单因素方差分析 (ANOVA) 及其事后检验。理解每种检验的应用场景、假设条件、R 实现和结果解读至关重要。

**下周预告:** 我们将转向探索变量之间的**关系**，学习相关分析和简单线性回归，了解如何量化和描述两个连续变量之间的线性关联程度。