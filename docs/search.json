[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "统计学与R语言",
    "section": "",
    "text": "欢迎\n这是统计学课程的在线教材。本教材包含了课程大纲和每周的课程内容。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>欢迎</span>"
    ]
  },
  {
    "objectID": "index.html#课程目标",
    "href": "index.html#课程目标",
    "title": "统计学与R语言",
    "section": "课程目标",
    "text": "课程目标\n本课程旨在帮助学生：\n\n掌握统计学的基本概念和方法\n学会使用统计软件进行数据分析\n培养统计思维和实践能力",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>欢迎</span>"
    ]
  },
  {
    "objectID": "index.html#使用说明",
    "href": "index.html#使用说明",
    "title": "统计学与R语言",
    "section": "使用说明",
    "text": "使用说明\n\n左侧导航栏包含课程大纲和每周的课程内容\n代码块可以点击展开/折叠\n每章都有详细的目录导航",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>欢迎</span>"
    ]
  },
  {
    "objectID": "syllbus.html",
    "href": "syllbus.html",
    "title": "课程概述",
    "section": "",
    "text": "课程大纲 (按周次和项目)",
    "crumbs": [
      "课程概述"
    ]
  },
  {
    "objectID": "syllbus.html#课程概述",
    "href": "syllbus.html#课程概述",
    "title": "统计学与R语言",
    "section": "",
    "text": "知识目标\n\n\n\n\n理解统计学的基本概念、原理和方法。\n掌握描述性统计、推断性统计的基本方法。\n熟练运用假设检验、置信区间和回归分析等统计方法解决实际问题。\n熟悉R语言及 tidyverse 生态在统计分析中的应用。\n了解AI辅助统计分析工具的基本使用。\n\n\n\n\n\n\n\n\n\n能力目标\n\n\n\n\n培养学生运用统计思维分析和解决实际经济管理问题的能力。\n提升学生的数据处理、分析和解释能力。\n培养学生使用R语言和 tidyverse 进行高效数据分析和建模的能力。\n培养学生利用AI工具辅助学习和研究的能力。\n提升学生的团队合作、沟通和项目管理能力（通过项目式教学）。\n\n\n\n\n\n\n\n\n\n素质目标\n\n\n\n\n培养学生严谨的科学态度和实事求是的精神。\n培养学生对数据敏感性和批判性思维。\n培养学生终身学习和自主学习的能力，适应数字化时代的需求。\n\n\n\n\n\n\n\n\n\n\n教学方法\n\n\n\n\n课堂讲授 (传统教学 + AI辅助)： 结合传统讲授，利用AI工具（如Cursor, VS Code插件）进行代码演示、实时答疑、个性化辅导等，提升课堂互动性和效率。\n项目式教学： 以小组为单位，围绕实际经管问题开展统计项目，学生在项目实践中学习和应用统计知识。\nR语言 & tidyverse 实践： 强调R语言和 tidyverse 生态的实际操作，通过案例分析、实验练习等方式，让学生掌握 tidyverse 在数据处理、可视化和统计分析中的应用。\nAI辅助学习： 引导学生使用AI工具辅助学习，例如利用AI代码生成、代码解释、错误诊断等功能，提高学习效率和解决问题的能力。\n\n\n\n\n\n\n\n\n\n\n考核方式\n\n\n\n\n课堂参与 (10%)： 出勤、课堂互动、课堂表现\n小组项目3次 (30%)： 包括项目选题、数据收集、统计分析、结果解释和结论。\n最终项目1次 (20%)： 包括项目选题、数据收集、统计分析、结果解释和结论。\n期末考试 (40%)： 闭卷考试，考察学生对统计学基本概念、原理和方法的掌握程度。\n\n\n\n\n\n教材： 推荐使用经典的统计学教材，例如《统计学》（贾俊平）、《商务与经济统计》（David R. Anderson）等，可根据实际情况选择合适的教材。\nR语言 & tidyverse 参考书： 《R for Data Science》（Hadley Wickham & Garrett Grolemund），《R语言实战》（Robert I. Kabacoff）等。\nAI辅助工具参考资料： Cursor, VS Code 插件相关教程和文档。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>统计学与R语言</span>"
    ]
  },
  {
    "objectID": "syllbus.html#课程大纲-按周次和项目",
    "href": "syllbus.html#课程大纲-按周次和项目",
    "title": "课程概述",
    "section": "",
    "text": "项目一：数据探索与初步洞察：以兴趣领域为例 (第1-4周，共16课时)\n\n\n\n\n\n\n项目主题 (学生可选择以下主题之一，或自拟主题经教师批准)\n\n\n\n\n主题一：电影偏好分析\n\n项目目标：通过获取电影数据集（例如IMDb, MovieLens等公开数据集或API），运用描述性统计方法和初步推断方法，分析不同类型电影的特征、用户评分分布、流行趋势等，洞察电影市场和用户偏好。\n\n主题二：音乐流派分析\n\n项目目标：通过获取音乐数据集（例如Spotify API, Last.fm API, 或公开音乐数据集），运用描述性统计方法和初步推断方法，分析不同音乐流派的特征、用户收听习惯、流行趋势等，洞察音乐市场和用户偏好。\n\n主题三：游戏类型分析\n\n项目目标：通过获取游戏数据集（例如Steam API, 游戏数据平台API, 或游戏销售数据集），运用描述性统计方法和初步推断方法，分析不同游戏类型的特征、用户偏好、流行趋势等，洞察游戏市场和用户偏好。\n\n主题四：股票市场分析\n\n项目目标：通过获取股票市场数据集（例如Yahoo Finance API, Tushare API, 或股票交易数据集），运用描述性统计方法和初步推断方法，分析不同股票的特征、价格波动规律、市场趋势等，洞察股票市场和投资机会。\n\n\n学生可以从以上四个主题中选择一个，或者结合自己的兴趣和专业背景，自拟项目主题，并提交给教师审批。鼓励学生发挥创新思维，选择具有实际意义和研究价值的主题。\n\n\n\n第一周 (4课时)\n\n项目启动与统计学导论\n\n课程和项目介绍、项目主题选择、分组\n统计学基本概念、应用领域、R语言和 tidyverse 简介\n数据获取方法入门：公开数据集、API、爬虫初步\nR环境搭建和 tidyverse 安装\n\n\n\n\n第二周 (4课时)\n\n数据获取与R语言数据导入\n\n项目讨论：确定数据来源和获取方案\n公开数据集、API获取实践\nR语言数据导入：readr 包，CSV, TXT等格式\n数据初步查看和理解\n数据类型回顾与数据质量\n描述性统计量：均值、中位数、标准差等\ndplyr 包：数据清洗和预处理初步\n\n\n\n\n第三周 (4课时)\n\n描述性统计：数据探索与可视化\n\ndplyr 、tidyr 包：数据清洗和预处理进阶\nggplot2 包：数据可视化初步，直方图、散点图、箱线图等\ntidyverse 生态：数据处理和可视化的综合应用 #### 第四周 (4课时)\n\n推断性统计初步：参数估计与假设检验\n\n参数估计：点估计、区间估计\n假设检验基本原理与步骤\n单样本t检验、双样本t检验 (独立样本、配对样本)\n项目一检查与汇报准备\n\n\n\n\n\n项目二：XXX (第5-8周，共16课时) (项目主题待定，可根据学生专业和兴趣调整)\n\n第五周 (4课时)\n\n方差分析 (ANOVA)\n\n方差分析原理与应用场景\n单因素方差分析\n多重比较\nR语言实现和案例分析\n\n\n\n\n第六周 (4课时)\n\n回归分析初步\n\n线性回归模型\n最小二乘法\n回归系数的解释和检验\nR语言实现和案例分析\n\n\n\n\n第七周 (4课时)\n\n分类数据分析\n\n卡方检验：拟合优度检验、独立性检验\n相关分析：Pearson相关系数、Spearman相关系数\nR语言实现和案例分析\n\n\n\n\n第八周 (4课时)\n\n项目二中期检查与汇报\n\n项目中期汇报和交流\n非参数检验方法简介 (根据项目进展情况选择性讲解)\n项目二中期总结与后续计划\n\n\n\n\n\n项目三：XXX (第9-12周，共16课时) (项目主题待定，可根据课程进度和学生反馈调整)\n\n第九周 (4课时)\n\n多元回归分析\n\n多元线性回归模型\n模型诊断与改进\n变量选择\nR语言实现和案例分析\n\n\n\n\n第十周 (4课时)\n\nLogistic 回归\n\nLogistic 回归模型原理\n模型评估与解释\nR语言实现和案例分析\n\n\n\n\n第十一周 (4课时)\n\n时间序列分析初步 (或根据学生兴趣选择其他专题)\n\n时间序列基本概念\n平稳性检验\nARIMA模型初步\nR语言实现和案例分析\n\n\n\n\n第十二周 (4课时)\n\n项目三中期检查与汇报\n\n项目中期汇报和交流\n时间序列分析或其他专题深入 (根据学生兴趣和项目进展调整)\n项目三中期总结与后续计划\n\n\n\n\n\n综合项目：XXX (第13-16周，共16课时) (项目主题为综合性经管问题，鼓励学生自主选题)\n\n第十三周 (4课时)\n\n综合项目启动与选题指导\n\n综合项目介绍和要求\n选题原则和方法指导\n小组讨论和选题\n\n\n\n\n第十四周 (4课时)\n\n综合项目数据分析方法指导\n\n针对不同项目选题的数据分析方法建议\nR语言高级数据分析技巧\nAI辅助统计分析工具介绍和使用\n\n\n\n\n第十五周 (4课时)\n\n综合项目中期检查与辅导\n\n小组汇报项目进展，展示初步分析结果\n教师巡回指导，解答学生疑问，提供个性化辅导\n项目报告撰写指导\n\n\n\n\n第十六周 (4课时)\n\n综合项目展示与答辩\n\n各小组进行综合项目展示和答辩\n课程总结与期末考试安排\n优秀综合项目展示",
    "crumbs": [
      "课程概述"
    ]
  },
  {
    "objectID": "syllbus.html#项目式教学说明",
    "href": "syllbus.html#项目式教学说明",
    "title": "课程概述",
    "section": "项目式教学说明",
    "text": "项目式教学说明\n\n\n\n\n\n\n项目分组\n\n\n\n\n建议每组2-3人，鼓励学生自由组队，也可由教师根据情况进行分组。\n\n\n\n\n\n\n\n\n\n项目选题\n\n\n\n\n项目主题为示例，教师可以根据教学目标、学生专业背景和兴趣、以及实际数据可获得性等因素，调整项目主题。鼓励学生结合自身专业和兴趣自主选题。\n\n\n\n\n\n\n\n\n\n项目成果\n\n\n\n\n每个项目小组需要提交项目报告，并在指定时间进行项目展示和答辩。项目报告应包括：项目背景、研究问题、数据来源、研究方法、数据分析过程、结果解释、结论与建议、参考文献、R代码 (使用 tidyverse 风格) 等。\n\n\n\n\n\n\n\n\n\n项目评价\n\n\n\n\n项目评价包括小组互评和教师评价。评价内容包括：项目报告质量、项目展示效果、答辩表现、团队合作、创新性、R代码质量 (包括 tidyverse 的合理使用) 等。",
    "crumbs": [
      "课程概述"
    ]
  },
  {
    "objectID": "syllbus.html#ai辅助教学说明",
    "href": "syllbus.html#ai辅助教学说明",
    "title": "课程概述",
    "section": "AI辅助教学说明",
    "text": "AI辅助教学说明\n\n\n\n\n\n\nAI辅助教学\n\n\n\n\n课堂互动与答疑： 利用AI工具（如Cursor, VS Code插件的AI聊天功能）辅助课堂答疑，快速解答学生在统计概念、R语言代码等方面的问题。\n代码演示与生成： 使用AI工具进行R代码的实时演示和生成，例如，在讲解统计方法时，可以使用AI工具快速生成R代码，并展示运行结果，提高教学效率。\n个性化学习辅导： 鼓励学生使用AI工具进行个性化学习，例如，利用AI的代码解释功能理解代码逻辑，利用AI的代码错误诊断功能解决编程问题。教师也可以利用AI工具分析学生的学习数据，提供个性化辅导建议。\n拓展学习资源： 教师可以利用AI工具搜索和推荐与课程相关的学习资源，例如，公开数据集、API文档、R语言教程、统计学案例分析等，拓展学生的学习视野。",
    "crumbs": [
      "课程概述"
    ]
  },
  {
    "objectID": "week01.html",
    "href": "week01.html",
    "title": "第一周：项目启动与统计学导论",
    "section": "",
    "text": "欢迎来到统计学！\n本周我们将开启统计学之旅！ 第一周是入门周，我们会一起了解本课程的项目式教学模式，探索统计学的奥秘，初步接触强大的R语言和AI辅助工具，并开始为我们的第一个项目做准备。\n本讲义特别说明： 本课程鼓励大家使用现代化的代码编辑器，例如 VS Code 或 Cursor，并结合强大的 AI 插件 来进行 R 语言编程和统计分析。 这些工具能够提供更智能的代码辅助、更高效的开发体验，并更好地与 AI 功能集成。 当然，如果您习惯使用 RStudio，也可以继续使用。 本讲义将重点介绍如何在 VS Code 和 Cursor 中配置和使用 R 语言环境。",
    "crumbs": [
      "课程内容",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>第一周：项目启动与统计学导论</span>"
    ]
  },
  {
    "objectID": "week01.html#第一周项目启动与统计学导论",
    "href": "week01.html#第一周项目启动与统计学导论",
    "title": "统计学讲义 - 第一周：项目启动与统计学导论",
    "section": "",
    "text": "欢迎来到统计学！\n本周我们将开启统计学之旅！ 第一周是入门周，我们会一起了解本课程的项目式教学模式，探索统计学的奥秘，初步接触强大的R语言和AI辅助工具，并开始为我们的第一个项目做准备。\n本讲义特别说明： 本课程鼓励大家使用现代化的代码编辑器，例如 VS Code 或 Cursor，并结合强大的 AI 插件 来进行 R 语言编程和统计分析。 这些工具能够提供更智能的代码辅助、更高效的开发体验，并更好地与 AI 功能集成。 当然，如果您习惯使用 RStudio，也可以继续使用。 本讲义将重点介绍如何在 VS Code 和 Cursor 中配置和使用 R 语言环境。\n\n\n\n\n\n\n本周学习目标\n\n\n\n\n理解课程模式: 了解项目式教学，明确项目要求。\n统计学入门: 深入理解统计学的基本概念和应用。\nR语言初探 (VS Code/Cursor): 初步认识 R 语言在 VS Code 或 Cursor 中的使用。\nAI工具体验 (VS Code/Cursor): 了解 AI 插件在 VS Code 或 Cursor 中辅助统计学习的作用。\n数据获取初步: 掌握基本数据获取方法 (公开数据集、API)。\n环境搭建 (VS Code/Cursor): 完成 VS Code 或 Cursor 中 R 语言环境的搭建和 tidyverse 包的安装。\n\n\n\n\n\n课程和项目介绍\n大家好！很高兴和大家一起学习统计学。\n\n课程概要: 本课程为期16周，共64课时。 我们的目标是让大家不仅掌握统计学的理论知识，更能运用统计方法解决实际的经济管理问题。 考核方式包括平时成绩、项目报告和期末考试。\n项目式教学: 本课程采用项目式教学，这意味着我们将通过一系列实际项目来学习统计学。 项目是驱动力，实践是最好的老师！\n\n项目一：数据探索与初步洞察 (4周) 我们将从大家感兴趣的领域入手，例如电影、音乐、游戏、股票等，选择一个主题进行数据探索和初步分析。\n项目目标: 通过实际操作，学习数据获取、描述性统计和初步推断，培养数据分析的初步能力。\n主题选择: 大家可以选择以下主题，或者自拟主题 (需经老师批准)：\n\n电影偏好分析\n音乐流行趋势分析\n电子游戏市场分析\n股票市场波动分析\n\n小组合作: 我们将以小组 (2-3人) 为单位进行项目。鼓励大家自由组队，发挥团队合作精神。小组内部分工协作，例如数据收集、数据分析、报告撰写、展示汇报等。\n时间安排: 项目一为期四周，期间会有中期检查和汇报，最终进行项目答辩。\n成果要求: 每个小组需要提交项目报告，并在答辩时进行展示。 项目报告需要包含：问题描述、数据来源、研究方法、数据分析过程、结果解释、结论与建议、R代码等。\n评价标准: 项目评价将综合考虑小组互评和教师评价，内容包括项目报告质量、展示效果、答辩表现、团队合作、创新性、R代码质量等。",
    "crumbs": [
      "课程内容",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>统计学讲义 - 第一周：项目启动与统计学导论</span>"
    ]
  },
  {
    "objectID": "week01.html#统计学导论",
    "href": "week01.html#统计学导论",
    "title": "第一周：项目启动与统计学导论",
    "section": "统计学导论",
    "text": "统计学导论\n\n什么是统计学？\n\n什么是统计学？ 统计学是一门从数据中提取信息和知识的科学。 它的目标是：\n\n描述数据: 用简洁明了的方式概括数据的特征。\n推断结论: 从样本数据推断总体特征。\n预测未来: 利用数据模型预测未来的趋势。\n辅助决策: 为决策提供数据支持和科学依据。\n\n统计学的应用领域: 统计学无处不在！ 在经济管理领域，统计学更是应用广泛，例如：\n\n市场调查: 了解消费者需求和市场趋势，例如，通过问卷调查了解消费者对新产品的偏好。\n销售预测: 预测产品销量，制定生产计划和库存管理策略，例如，根据历史销售数据和季节性因素预测下个季度的销售额。\n风险管理: 评估和控制经营风险，例如，利用统计模型评估投资组合的风险，或者预测贷款违约率。\n运营优化: 提高运营效率，降低成本，例如，通过分析生产数据，找出影响生产效率的关键因素，并进行优化。\n人力资源管理: 分析员工绩效，优化人员配置，例如，通过分析员工的绩效数据，评估培训效果，或者预测员工离职率。\n\n统计学与我们的生活息息相关，掌握统计学方法，将为未来的学习和工作打下坚实的基础。\n\n\n\n统计学基本概念\n\n基本概念详解: 理解以下基本概念是学好统计学的基石。\n\n总体 (Population):\n\n\n\n\n\n\n总体 (Population)\n\n\n\n定义： 总体 是我们研究对象的全体，由所有感兴趣的个体组成。 总体是我们希望了解和推断的目标群体。\n关键特征：\n\n完整性： 包含所有研究个体。\n理论性： 在实际研究中，有时总体是理论上的，难以完全观测。\n\n例子：\n\n研究中国大学生的平均身高： 总体是中国所有在校大学生。\n研究某品牌手机的用户满意度： 总体是该品牌手机的所有用户。\n研究某城市所有家庭的收入水平： 总体是该城市所有家庭。\n\n目标总体 vs. 抽样总体 (重要概念):\n\n目标总体 (Target Population): 研究者真正想要研究的总体，例如，所有中国大学生。\n抽样总体 (Sampling Population): 实际抽取样本的总体，是目标总体的可操作部分。 例如，由于时间和经费限制，我们可能只能从中国部分地区的大学生中抽取样本，那么这些被抽样的地区大学生构成的总体就是抽样总体。\n\n理想情况： 抽样总体 尽可能接近 目标总体，以保证研究结果的代表性和推广性。 但实际研究中，抽样总体往往只是目标总体的一部分。 需要注意抽样总体和目标总体的差异，谨慎推广研究结论。\n\n\n个体 (Individual):\n\n\n\n\n\n\n个体 (Individual)\n\n\n\n定义： 个体 是总体中的基本单元，是我们研究的对象。 总体由若干个个体组成。\n关键特征：\n\n不可再分性： 在当前研究问题下，个体是不可再分割的最小单元。\n同质性： 同一总体中的个体，在研究的某些特征上是相似的。\n\n例子 (继续沿用上面的例子):\n\n研究中国大学生的平均身高： 每个大学生 就是一个个体。\n研究某品牌手机的用户满意度： 每个手机用户 就是一个个体。\n研究某城市所有家庭的收入水平： 每个家庭 就是一个个体。\n\n注意： 个体和总体的概念是相对的。 例如，当我们研究 “大学” 这个总体时，每个 “大学” 是一个个体；但当我们研究某个 “大学” 的学生情况时，这个 “大学” 就变成了总体，而每个 “学生” 则变成了个体。 个体和总体的划分取决于研究问题和研究范围。\n\n\n样本 (Sample):\n\n\n\n\n\n\n样本 (Sample)\n\n\n\n定义： 样本 是从总体中抽取的一部分个体的集合。 样本是总体的代表。 我们通过研究样本来推断总体。\n关键特征：\n\n部分性： 样本只是总体的一部分。\n代表性 (重要！): 样本应该尽可能代表总体，反映总体的特征。 只有具有代表性的样本，才能有效地推断总体。\n随机性 (理想情况): 理想的样本是随机抽取的，以减少抽样偏差，提高样本的代表性。\n\n例子 (继续沿用上面的例子):\n\n研究中国大学生的平均身高： 从中国大学生中随机抽取 1000 名大学生，这 1000 名大学生构成一个样本。\n研究某品牌手机的用户满意度： 从该品牌手机用户中随机抽取 500 名用户进行调查，这 500 名用户的回答构成一个样本。\n研究某城市所有家庭的收入水平： 从该城市家庭中随机抽取 200 户家庭进行调查，这 200 户家庭构成一个样本。\n\n样本容量 (Sample Size): 样本中所包含的个体数量。 样本容量的大小会影响样本的代表性和推断的精度。 样本容量越大，通常样本的代表性越好，推断结果越精确，但成本也越高。 如何确定合适的样本容量，是统计学研究中的重要问题。\n抽样 (Sampling): 从总体中抽取样本的过程。 抽样方法的选择直接影响样本的代表性。 常见的抽样方法包括：\n\n简单随机抽样 (Simple Random Sampling): 每个个体被抽取的概率相等，保证了抽样的公平性。\n分层抽样 (Stratified Sampling): 先将总体分层，然后在每层内进行随机抽样，可以提高样本的代表性，尤其适用于总体内部差异较大的情况。\n整群抽样 (Cluster Sampling): 先将总体分成若干群，然后随机抽取若干群，再对抽取的群内的所有个体进行调查，适用于总体分布范围广、调查成本较高的情况。\n系统抽样 (Systematic Sampling): 按照一定的顺序和间隔抽取个体，操作简便，但需要注意周期性偏差。\n方便抽样 (Convenience Sampling): 选择容易接触到的个体作为样本，成本低，但代表性差，结论的推广性受到限制。\n\n在实际研究中，需要根据研究目的、总体特征、研究成本等因素，选择合适的抽样方法，尽可能提高样本的代表性，保证研究结论的可靠性和有效性。\n\n\n变量 (Variable):\n\n\n\n\n\n\n变量 (Variable)\n\n\n\n定义： 变量 是描述个体某种特征的概念。 变量是可变的，不同个体在同一变量上的取值可能不同。 统计研究的核心内容之一就是研究变量及其关系。\n关键特征：\n\n可变性： 变量的取值在不同个体之间是变化的。\n可测量性： 变量的取值是可以测量和记录的。\n多样性： 变量可以是各种各样的，例如，身高、体重、年龄、性别、收入、学历、满意度、偏好等等。\n\n例子 (继续沿用上面的例子):\n\n研究中国大学生的平均身高： 身高 就是一个变量。 每个大学生的身高数值可能不同。\n研究某品牌手机的用户满意度： 用户满意度 就是一个变量。 每个用户对手机的满意程度可能不同。 手机品牌 也可以作为一个变量，不同用户可能使用不同品牌的手机。\n研究某城市所有家庭的收入水平： 家庭年收入 就是一个变量。 不同家庭的年收入数值可能不同。 家庭所在地区 也可以作为一个变量，不同家庭可能居住在城市的不同地区。\n\n变量的类型 (重要！): 根据变量的性质和测量尺度，可以将变量分为不同的类型：\n\n分类变量 (Categorical Variable) / 定性变量 (Qualitative Variable): 描述个体所属类别或属性的变量。 取值为类别，例如，性别 (男/女), 学历 (本科/硕士/博士), 颜色 (红/绿/蓝), 品牌 (苹果/华为/小米) 等。 分类变量的取值没有顺序或数值大小的含义，只能进行分类和计数。 分类变量又可以分为：\n\n名义变量 (Nominal Variable): 类别之间没有顺序关系，例如，性别、颜色、品牌等。\n有序变量 (Ordinal Variable): 类别之间有顺序关系，但间隔不相等，例如，学历 (小学 &lt; 初中 &lt; 高中 &lt; 本科 &lt; 硕士 &lt; 博士), 满意度 (非常满意 &gt; 满意 &gt; 一般 &gt; 不满意 &gt; 非常不满意), 等级 (一级 &gt; 二级 &gt; 三级) 等。\n\n数值变量 (Numerical Variable) / 定量变量 (Quantitative Variable): 描述个体数量特征的变量。 取值为数值，可以进行数学运算，例如，身高 (cm), 体重 (kg), 年龄 (岁), 收入 (元), 考试成绩 (分), 销售额 (万元) 等。 数值变量又可以分为：\n\n离散变量 (Discrete Variable): 取值是有限的或可数的，通常是整数，例如，人口数、汽车数量、考试及格人数、问卷调查的题项数等。\n连续变量 (Continuous Variable): 取值是无限的或不可数的，在一定范围内可以取任意数值，例如，身高、体重、温度、时间、收入、价格等。\n\n\n理解变量的类型对于选择合适的统计分析方法至关重要。 例如，对于分类变量，我们通常计算频数、频率、百分比等；对于数值变量，我们可以计算均值、标准差、相关系数等。\n\n\n数据 (Data):\n\n\n\n\n\n\n数据 (Data)\n\n\n\n定义： 数据 是变量的具体观测值，是记录下来的事实。 数据是统计分析的原材料。\n关键特征：\n\n真实性： 数据应该真实反映客观情况。\n记录性： 数据是记录下来的，可以存储和分析。\n多样性： 数据可以是各种形式的，例如，数值、文本、图像、音频、视频等。 在统计学中，我们主要处理结构化数据 (例如，表格数据、数据库数据)。\n\n例子 (继续沿用上面的例子):\n\n研究中国大学生的平均身高： 收集到的 每个大学生的具体身高数值 (例如，170cm, 175cm, 165cm, …) 就是数据。\n研究某品牌手机的用户满意度： 收集到的 每个用户的满意度评分 (例如，5分, 4分, 3分, …) 就是数据。 以及 用户对满意度评价的具体类别 (例如，满意, 一般, 不满意) 也是数据。\n研究某城市所有家庭的收入水平： 收集到的 每个家庭的具体年收入数值 (例如，10万元, 20万元, 8万元, …) 就是数据。\n\n数据与变量的关系： 数据是变量的具体实现，变量是数据的抽象概括。 数据是变量的取值，变量是数据的名称。 我们通过收集数据来研究变量，通过分析数据来了解变量的规律和特征。\n数据质量 (重要性): 高质量的数据 是得出可靠统计结论的基础。 数据质量问题包括：\n\n数据缺失 (Missing Data): 部分数据缺失，影响分析的完整性和准确性。\n数据错误 (Data Error): 数据记录错误，例如，录入错误、测量误差等。\n数据不一致 (Data Inconsistency): 不同来源的数据不一致，例如，不同部门统计的数据口径不一致。\n数据偏差 (Data Bias): 数据本身存在系统性偏差，例如，抽样偏差、选择偏差等。\n\n在进行统计分析之前，需要对数据进行清洗和预处理，以提高数据质量，保证分析结果的可靠性。\n\n\n\n数据的类型: 根据性质不同，数据可以分为不同的类型 (前面已简要介绍，这里再强调一下)：\n\n分类数据 (Categorical Data) / 定性数据 (Qualitative Data): 描述个体所属类别的数据。\n顺序数据 (Ordinal Data): 可以排序的数据，但数值之间没有确定的间隔。\n数值型数据 (Numerical Data) / 定量数据 (Quantitative Data): 用数值表示的数据，可以进行数学运算。 又分为离散型和连续型。\n\n度量尺度: 数据的度量尺度决定了可以进行的统计分析类型 (前面已简要介绍，这里再强调一下)：\n\n定类尺度 (Nominal Scale): 只能进行分类，类别之间没有顺序。\n定序尺度 (Ordinal Scale): 可以排序，类别之间有顺序，但间隔不确定。\n定距尺度 (Interval Scale): 可以进行加减运算，数值之间间隔相等，但没有绝对零点。\n定比尺度 (Ratio Scale): 可以进行加减乘除运算，数值之间间隔相等，有绝对零点。\n\n理解数据类型和度量尺度 至关重要，这将直接影响我们选择合适的统计方法和解释分析结果。 在后续的学习中，我们会不断强调数据类型和度量尺度的重要性。\n\n\n\nR语言、tidyverse 和 AI 辅助工具简介 (VS Code/Cursor)\n\nR 语言: 统计分析的利器！ 在 VS Code 和 Cursor 中，我们可以通过安装相应的扩展来支持 R 语言。\n\nR 语言的特点:\n\n开源免费: 任何人都可以免费使用和修改 R 语言。\n强大的统计分析功能: R 语言拥有丰富的统计分析包，几乎涵盖了所有统计分析方法。\n优秀的数据可视化能力: R 语言的 ggplot2 包是数据可视化的标杆。\n活跃的社区: R 语言拥有庞大而活跃的社区，可以方便地获取帮助和资源。\n跨平台性: R 语言可以运行在 Windows, macOS, Linux 等多种操作系统上。\n\nR 语言的应用领域: 统计学、数据科学、机器学习、生物信息学、金融分析、社会科学等。\n在 VS Code 和 Cursor 中使用 R 语言: 通过安装 R 扩展 (R Extension for VS Code)，我们可以方便地在 VS Code 和 Cursor 中进行 R 语言编程。 R 扩展提供了代码高亮、代码补全、代码格式化、代码调试、R 终端集成等功能，极大地提升了 R 语言开发效率。\n在 VS Code 中配置 R 语言环境:\n\n安装 R 软件: 首先需要在您的计算机上安装 R 软件。 请访问 R 官网 https://www.r-project.org/，根据您的操作系统下载并安装 R 软件。 安装完成后，在命令行或终端中输入 R --version，如果能正确显示 R 版本信息，则说明 R 软件安装成功。\n安装 VS Code R 扩展: 打开 VS Code，点击左侧的 “扩展” 图标 (或按下 Ctrl+Shift+X)，在搜索框中输入 “R”，找到 “R Extension for VS Code” 扩展，点击 “安装” 按钮进行安装。 安装完成后，点击 “重新加载” 按钮重启 VS Code。\n配置 R 路径: VS Code R 扩展需要知道 R 软件的安装路径。 在 VS Code 中，按下 Ctrl+Shift+P (或 Cmd+Shift+P 在 macOS 上) 打开命令面板，输入 “R: Set R Path”，选择 “R: Set R Path” 命令。 然后，在弹出的输入框中输入 R 软件的安装路径。 如果您不确定 R 软件的安装路径，可以在 R 终端中输入 R.home() 命令获取 R 的安装路径。 通常情况下，Windows 上的 R 安装路径类似于 C:\\Program Files\\R\\R-4.3.0，macOS 上的 R 安装路径类似于 /Library/Frameworks/R.framework/Resources，Linux 上的 R 安装路径可能是 /usr/bin/R 或 /usr/local/bin/R。 请根据您的实际安装路径进行配置。\n安装 languageserver 包: languageserver 包是 R 语言的语言服务器协议 (LSP) 实现，为 VS Code R 扩展提供代码智能提示、代码补全、代码诊断等功能。 在 R 终端中输入 install.packages(\"languageserver\") 命令安装 languageserver 包。\n创建 R 文件并运行代码: 在 VS Code 中，创建一个新的文件，将文件后缀名保存为 .R，例如 hello.R。 在 hello.R 文件中输入 R 代码，例如 print(\"Hello, R in VS Code!\")。 按下 Ctrl+Shift+P，输入 “R: Run R code”，选择 “R: Run R code” 命令，即可在 VS Code 的 R 终端中运行 R 代码。 您也可以选中要运行的 R 代码，然后右键点击，选择 “Run Selection in R Terminal” 运行选中的代码。\n\n在 Cursor 中配置 R 语言环境:\nCursor 编辑器与 VS Code 高度兼容，可以直接使用 VS Code 的扩展。 因此，在 Cursor 中配置 R 语言环境的步骤与 VS Code 类似：\n\n安装 R 软件: (同 VS Code 配置步骤 1)\n安装 VS Code R 扩展: 打开 Cursor，点击左侧的 “扩展” 图标 (或按下 Ctrl+Shift+X)，在搜索框中输入 “R”，找到 “R Extension for VS Code” 扩展，点击 “安装” 按钮进行安装。 安装完成后，点击 “重新加载” 按钮重启 Cursor。\n配置 R 路径: (同 VS Code 配置步骤 3) 在 Cursor 中，按下 Ctrl+Shift+P (或 Cmd+Shift+P 在 macOS 上) 打开命令面板，输入 “R: Set R Path”，选择 “R: Set R Path” 命令，配置 R 软件的安装路径。\n安装 languageserver 包: (同 VS Code 配置步骤 4) 在 R 终端中输入 install.packages(\"languageserver\") 命令安装 languageserver 包。\n创建 R 文件并运行代码: (同 VS Code 配置步骤 5) 在 Cursor 中，创建一个新的 R 文件 (后缀名为 .R)，输入 R 代码，使用 “R: Run R code” 或 “Run Selection in R Terminal” 命令运行 R 代码。\n\n完成以上步骤后，您就可以在 VS Code 或 Cursor 中愉快地进行 R 语言编程了！\n\ntidyverse: R 语言的现代数据科学工具集！ tidyverse 是由 Hadley Wickham 等开发的 R 包集合，旨在提供一套一致、简洁、高效的数据科学工具。 tidyverse 包的核心理念是 “数据整理 (Data Wrangling) -&gt; 数据可视化 (Data Visualization) -&gt; 数据建模 (Data Modeling)” 的数据分析流程。\n\ntidyverse 核心包:\n\ndplyr: 用于数据清洗和数据转换，提供了一系列简洁高效的数据操作函数，例如 filter() (筛选行), select() (选择列), mutate() (创建新列), group_by() (分组), summarise() (汇总) 等。 dplyr 的语法简洁易懂，易于学习和使用。\nggplot2: 用于数据可视化，基于 “图形语法 (Grammar of Graphics)” 理论，可以绘制各种精美、灵活、可定制的统计图形。 ggplot2 是 R 语言数据可视化的标杆，也是数据科学领域最流行的可视化工具之一。\ntidyr: 用于数据整理，主要用于处理 “整洁数据 (Tidy Data)”，将数据整理成适合分析的规范格式。 tidyr 提供了 pivot_longer() (长数据转换), pivot_wider() (宽数据转换), separate() (分离列), unite() (合并列) 等函数。\nreadr: 用于数据导入，提供快速、可靠的数据读取函数，可以读取 CSV, TSV, FWV 等多种格式的数据文件。 readr 默认使用 UTF-8 编码，可以有效避免中文乱码问题。\npurrr: 用于函数式编程，提供了一系列函数式编程工具，可以简化循环操作，提高代码效率和可读性。\nstringr: 用于字符串处理，提供了一系列简洁易用的字符串操作函数，可以方便地进行字符串的匹配、替换、提取等操作。\nforcats: 用于因子 (分类变量) 处理，提供了一系列因子操作函数，可以方便地调整因子水平的顺序、合并因子水平等。\n\ntidyverse 的优势:\n\n一致的语法风格: tidyverse 包的函数命名和语法风格高度一致，易于学习和记忆。\n链式操作 (管道操作符 %&gt;%): tidyverse 广泛使用管道操作符 %&gt;%，可以将多个操作连接起来，形成清晰的数据处理流程，提高代码可读性。\n高效的数据处理能力: tidyverse 包底层使用 C++ 编写，具有高效的数据处理能力，可以处理大规模数据集。\n与 R 语言生态系统良好集成: tidyverse 与 R 语言的其他包和工具良好集成，可以方便地进行扩展和应用。\n\n安装 tidyverse: 在 R 终端中输入 install.packages(\"tidyverse\") 即可安装 tidyverse 包及其依赖包。 安装完成后，使用 library(tidyverse) 加载 tidyverse 包。\n\nAI 辅助工具 (VS Code/Cursor 插件): AI 正在改变编程方式！ 在 VS Code 和 Cursor 中，我们可以使用各种 AI 插件来辅助 R 语言编程和统计分析。\n\nAI 插件的类型: 代码自动补全、代码生成、代码解释、代码重构、AI 聊天等。\n常用的 AI 插件: GitHub Copilot, Cursor AI, Codeium, Tabnine 等。\nAI 插件在统计学习中的作用: 提高编程效率、辅助代码学习、解答 R 语言问题、辅助数据分析和模型构建等。\nGitHub Copilot (VS Code/Cursor 插件) 使用示例:\n\n安装 GitHub Copilot 插件: 在 VS Code 或 Cursor 中，点击左侧的 “扩展” 图标，搜索 “GitHub Copilot”，找到 “GitHub Copilot” 扩展，点击 “安装” 按钮进行安装。 安装完成后，需要登录您的 GitHub 账号并订阅 GitHub Copilot 服务 (通常提供免费试用期)。\n代码自动补全: 在 R 代码编辑器中输入代码时，GitHub Copilot 会根据上下文自动给出代码建议。 例如，当您输入 library( 时，Copilot 会自动提示 R 包的名称列表；当您定义一个函数时，Copilot 会根据函数名和参数自动生成函数体代码。 您可以使用 Tab 键接受 Copilot 的建议，或者继续输入自己的代码。\n代码生成: 您可以让 GitHub Copilot 根据自然语言描述生成 R 代码。 例如，您可以输入注释 # generate a scatter plot of mpg and wt from mtcars dataset using ggplot2，然后按下 Enter 键，Copilot 可能会自动生成相应的 R 代码。 您也可以选中一段注释，然后按下 Ctrl+I (或 Cmd+I 在 macOS 上) 快捷键，让 Copilot 根据注释生成代码。\n代码解释: 您可以选中一段 R 代码，然后右键点击，选择 “Copilot: Explain”，让 Copilot 解释选中的代码的功能和作用。 Copilot 会在侧边栏中显示代码解释。\n\nCursor AI (Cursor 内置功能) 使用示例:\n\n代码生成: 在 Cursor 中，您可以按下 Ctrl+Shift+L (或 Cmd+Shift+L 在 macOS 上) 快捷键，打开 Cursor AI 的 “Generate” 功能。 在弹出的输入框中输入自然语言描述，例如 “用 R 语言读取 CSV 文件并计算均值”，然后点击 “Generate” 按钮，Cursor AI 会自动生成相应的 R 代码。\n代码解释: 在 Cursor 中，您可以选中一段 R 代码，然后按下 Ctrl+Shift+E (或 Cmd+Shift+E 在 macOS 上) 快捷键，打开 Cursor AI 的 “Explain” 功能。 Cursor AI 会在编辑器中以注释的形式解释选中的代码。\nAI 聊天: 在 Cursor 中，您可以按下 Ctrl+Shift+C (或 Cmd+Shift+C 在 macOS 上) 快捷键，打开 Cursor AI 的 “Chat” 功能。 在聊天框中，您可以向 AI 提问 R 语言相关的问题，例如 “如何用 R 语言安装包？”，“dplyr::filter() 函数怎么用？” 等。 Cursor AI 会根据您的问题给出解答和代码示例。\n\n其他 AI 插件的使用方法类似，您可以参考插件的官方文档或使用说明，探索和掌握各种 AI 插件的功能，充分利用 AI 技术来辅助 R 语言学习和编程。\n\n\n\n\n数据获取方法入门\n\n数据来源的重要性: 数据是统计分析的基础，高质量的数据是得出可靠结论的前提。\n\n数据来源的类型: 一手数据 (Primary Data) 和 二手数据 (Secondary Data)。\n数据获取方法: 调查、实验、观察、文献检索、网络爬虫等。\n本课程主要关注二手数据，重点介绍公开数据集和公开 API 的获取方法。\n\n公开数据集:\n\n什么是公开数据集？ 公开数据集是指可以免费获取和自由使用的数据集。 这些数据集通常由政府机构、研究机构、企业或个人发布，旨在促进数据共享和科学研究。\n常见的公开数据集平台和网站:\n\nKaggle Datasets (https://www.kaggle.com/datasets): Kaggle 是一个著名的数据科学竞赛平台，也提供了丰富的高质量公开数据集，涵盖了各种领域，例如，金融、电商、医疗、教育、自然语言处理、计算机视觉等。 Kaggle Datasets 的数据质量高，格式规范，并且通常附带详细的数据描述和使用案例，是数据科学学习和项目实践的理想数据来源。\nUCI Machine Learning Repository (http://archive.ics.uci.edu/ml/datasets.php): UCI 机器学习仓库是机器学习领域最经典、最常用的公开数据集平台之一。 提供了大量的机器学习数据集，涵盖了分类、回归、聚类、关联规则挖掘等各种机器学习任务。 UCI 数据集历史悠久，被广泛应用于机器学习算法的benchmark测试和研究。\n政府统计网站: 各国政府统计部门通常会发布大量的公开统计数据，例如，国家统计局 (http://www.stats.gov.cn/)、美国人口普查局 (https://www.census.gov/data.html)、英国国家统计局 (https://www.ons.gov.uk/) 等。 政府统计数据权威可靠，覆盖面广，是进行宏观经济分析、社会发展研究的重要数据来源。\n行业协会网站: 各行业协会通常也会发布行业相关的统计数据和报告，例如，中国汽车工业协会 (http://www.caam.org.cn/)、中国互联网络信息中心 (https://www.cnnic.net.cn/)、世界银行公开数据 (https://data.worldbank.org/) 等。 行业协会数据具有行业特色，可以用于进行行业分析和市场研究。\n其他公开数据集平台: Google Dataset Search (https://datasetsearch.research.google.com/), Data.gov (https://www.data.gov/), Awesome Public Datasets (https://github.com/awesomedata/awesome-public-datasets) 等。\n\n如何查找和下载公开数据集:\n\n使用搜索引擎: 可以使用 Google, Baidu 等搜索引擎，输入关键词 “公开数据集”，“public datasets”，“open data” 等，加上您感兴趣的领域或主题，例如 “金融公开数据集”，“电影数据集”，“COVID-19 数据集” 等，进行搜索。\n访问公开数据集平台: 直接访问上述公开数据集平台和网站，浏览和搜索您需要的数据集。 大多数平台都提供了数据集的分类、关键词搜索、筛选、预览、下载等功能。\n查看数据集描述和文档: 在下载数据集之前，务必仔细阅读数据集的描述、数据字典、数据来源、数据质量、使用许可等信息，了解数据集的内容、特点和使用限制，确保数据集符合您的研究需求。\n下载数据集: 根据平台提供的下载方式，下载数据集文件。 常见的数据集文件格式包括 CSV, TXT, JSON, Excel, SQL, Parquet 等。 选择您熟悉的格式进行下载。\n\n公开数据集的优缺点:\n\n优点:\n\n免费获取: 无需付费，降低了数据获取成本。\n数据量大: 通常包含大量数据，可以满足各种研究需求。\n覆盖面广: 涵盖了各种领域和主题，选择范围广。\n质量较高: 许多公开数据集经过清洗和整理，数据质量相对较高。\n易于使用: 数据格式规范，易于导入和分析。\n促进共享: 有利于数据共享和科学研究的开放性。\n\n缺点:\n\n可能不是最新数据: 部分公开数据集可能不是最新的，数据更新频率可能较低。\n数据可能不完整: 部分公开数据集可能存在数据缺失、数据错误等问题。\n数据可能不完全符合需求: 公开数据集是通用的，可能不完全符合特定研究问题的需求，需要进行筛选和处理。\n数据使用限制: 部分公开数据集可能存在使用许可限制，例如，禁止商业用途、需要署名等，需要仔细阅读和遵守数据使用协议。\n\n\n\n公开 API:\n\n什么是 API？ API (Application Programming Interface，应用程序编程接口) 是一组定义了软件组件之间如何交互的规范和协议。 API 允许不同的软件系统相互通信和交换数据，而无需了解彼此的内部实现细节。 API 就像一个 “接口” 或 “桥梁”，连接了不同的系统，实现了数据的互联互通。\n公开 API 的概念和作用: 公开 API (Public API) 是指对外公开的 API 接口，允许第三方开发者或用户通过网络访问和使用其功能和数据。 公开 API 的作用在于：\n\n数据共享: 将数据以结构化的方式对外开放，方便用户获取和使用数据。\n功能开放: 将软件系统的部分功能对外开放，允许第三方开发者在其基础上进行二次开发和应用创新。\n生态构建: 通过开放 API，构建开放的生态系统，吸引更多的开发者和用户参与，共同创造价值。\n\n常见的公开 API 类型:\n\nWeb API: 基于 Web 技术 (HTTP 协议) 的 API，通过 URL 地址进行访问和数据交互。 Web API 是目前最流行的 API 类型。\nREST API (Representational State Transfer API): 一种特殊的 Web API 设计风格，基于 REST 架构风格，使用 HTTP 协议的 GET, POST, PUT, DELETE 等方法进行资源操作。 REST API 具有简洁、易用、可扩展性强等优点，被广泛应用于 Web 服务开发。 我们通常所说的 “API” 在很多情况下就是指 REST API。\n\n相关公开 API 示例:\n\nOMDb API (Open Movie Database API, http://www.omdbapi.com/): 提供电影、电视剧等影视作品信息的 API。 可以根据电影标题、演员、导演等关键词查询电影信息，包括电影海报、剧情简介、演员列表、评分、票房等。 OMDb API 是一个免费的公开 API，但需要注册获取 API Key 才能使用。\nSpotify API (https://developer.spotify.com/documentation/web-api/): Spotify 音乐平台的 API。 可以获取音乐、艺术家、专辑、播放列表等信息，还可以进行音乐搜索、播放控制、用户数据获取等操作。 Spotify API 需要注册开发者账号并创建应用才能使用，部分高级功能需要付费。\nYahoo Finance API (Yahoo 财经 API, https://finance.yahoo.com/): 提供股票、指数、基金等金融产品的实时数据和历史数据。 可以获取股票价格、成交量、财务指标等信息，还可以进行股票搜索、数据导出等操作。 Yahoo Finance API 是一个免费的公开 API，但需要注册账号并获取 API Key 才能使用。\n\n\n如何获取和使用公开 API:\n\n注册 API 账号: 访问 API 提供商的官方网站，注册账号并创建应用，获取 API Key。\n阅读 API 文档: 访问 API 提供商的官方网站，阅读 API 文档，了解 API 的接口、参数、返回结果等。 API 文档通常会详细说明每个 API 接口的功能、请求方法 (GET/POST 等)、请求参数、参数类型、返回值、错误代码、使用示例等信息。 认真阅读 API 文档是正确使用 API 的前提。\n发送 API 请求: 使用编程语言 (例如 R, Python) 或工具 (例如 Postman, curl) 发送 HTTP 请求到 API 接口的 URL 地址。 根据 API 文档的要求，设置请求头 (Headers)、请求参数 (Parameters) 或请求体 (Body)。 通常需要将 API Key 包含在请求头或请求参数中进行身份验证。\n处理 API 响应: API 服务器收到请求后，会返回 HTTP 响应。 响应包含状态码 (Status Code)、响应头 (Headers) 和响应体 (Body)。 状态码表示请求的处理结果 (例如，200 表示成功，404 表示未找到资源，500 表示服务器错误)。 响应体通常是 JSON 或 XML 格式的数据，包含了API 返回的实际数据。 需要解析响应体，提取所需的数据。\nR 语言中使用 httr 包调用 API: 在 R 语言中，可以使用 httr 包来发送 HTTP 请求和处理 API 响应。 httr 包提供了简洁易用的函数，可以方便地进行 API 调用。\n# 安装 httr 包 (如果尚未安装)\n# install.packages(\"httr\")\n\nlibrary(httr)\nlibrary(jsonlite) # 用于解析 JSON 数据\n\n# OMDb API 示例 (需要注册并获取 API Key)\napi_key &lt;- \"YOUR_OMDB_API_KEY\"  # 替换为您的 API Key\ntitle &lt;- \"Titanic\"  # 查询电影标题\n\n# 构造 API 请求 URL\napi_url &lt;- paste0(\"http://www.omdbapi.com/?apikey=\", api_key, \"&t=\", title)\n\n# 发送 GET 请求\nresponse &lt;- GET(api_url)\n\n# 检查状态码\nif (http_status(response)$category == \"Success\") {\n  cat(\"API 请求成功！\\n\")\n  # 解析 JSON 响应内容\n  movie_data &lt;- fromJSON(content(response, \"text\", encoding = \"UTF-8\"))\n  # 打印电影标题和年份\n  cat(\"电影标题:\", movie_data$Title, \"\\n\")\n  cat(\"上映年份:\", movie_data$Year, \"\\n\")\n  # 打印其他电影信息 (可以根据需要提取更多信息)\n  print(movie_data)\n} else {\n  cat(\"API 请求失败！状态码:\", http_status(response)$status_code, \"\\n\")\n}\n代码解释:\n\n加载 httr 和 jsonlite 包: httr 用于发送 HTTP 请求，jsonlite 用于解析 JSON 格式的 API 响应数据。\n设置 API Key 和查询参数: api_key 变量存储您的 OMDb API Key，title 变量存储要查询的电影标题。 请务必替换 YOUR_OMDB_API_KEY 为您自己的 API Key。\n构造 API 请求 URL: 使用 paste0() 函数将 API 根 URL, API Key 和查询参数拼接成完整的 API 请求 URL。\n发送 GET 请求: 使用 GET() 函数发送 GET 请求到 API URL，并将响应结果保存在 response 变量中。\n检查状态码: 使用 http_status(response)$category == \"Success\" 检查 HTTP 状态码是否表示成功 (2xx 状态码)。\n解析 JSON 响应内容: 如果请求成功，使用 content(response, \"text\", encoding = \"UTF-8\") 获取响应内容 (文本格式，并指定编码为 UTF-8)，然后使用 fromJSON() 函数将 JSON 格式的文本数据解析为 R 列表对象 movie_data。\n提取和打印电影信息: 从 movie_data 列表中提取电影标题 (movie_data$Title) 和上映年份 (movie_data$Year)，并使用 cat() 函数打印输出。 print(movie_data) 打印整个 movie_data 列表，您可以根据需要提取更多电影信息。\n处理请求失败情况: 如果请求失败 (状态码不是 2xx)，则打印错误信息，包括状态码。\n\n请注意: OMDb API 是一个免费的 API，但需要注册账号并获取 API Key 才能使用。 请访问 OMDb API 官网 (http://www.omdbapi.com/) 注册账号并获取 API Key。 其他公开 API 的使用方法类似，通常也需要注册账号、阅读 API 文档、发送 API 请求、处理 API 响应等步骤。\n\n公开 API 的优缺点:\n\n优点:\n\n数据实时性: API 通常提供实时更新的数据，可以获取最新的数据信息。\n数据结构化: API 返回的数据通常是结构化的 (例如 JSON, XML)，易于程序解析和处理。\n数据获取自动化: 使用 API 可以实现数据获取的自动化，无需手动下载和整理数据。\n数据来源权威: API 数据通常来自权威的数据提供商，数据质量和可靠性较高。\n\n缺点:\n\n需要编程知识: 使用 API 需要一定的编程知识，例如，了解 HTTP 协议、API 文档、编程语言等。\nAPI 使用限制: 部分 API 可能有使用频率限制、数据量限制、功能限制或收费等。\nAPI 维护成本: API 提供商需要维护 API 接口和服务器，可能会存在 API 不稳定或停止服务的情况。\n数据格式和接口变化: API 的数据格式和接口可能会发生变化，需要及时更新代码以适应变化。\n\n\nPlaywright 爬虫初步介绍:\n\n什么是网络爬虫？ 网络爬虫 (Web Crawler)，也称为网络蜘蛛 (Web Spider) 或网络机器人 (Web Robot)，是一种自动化程序，用于抓取互联网上的信息。 爬虫模拟人类用户浏览网页的行为，自动访问网页，提取网页上的数据，并将数据存储下来。\nPlaywright 简介: Playwright 是一个强大的自动化测试和网络爬虫工具，由 Microsoft 开发。 Playwright 可以模拟多种浏览器 (Chromium, Firefox, WebKit) 的行为，支持 JavaScript 和多种编程语言 (例如 Python, JavaScript, Java, .NET, R)。 Playwright 具有以下优点：\n\n跨浏览器支持: 可以模拟 Chromium, Firefox, WebKit 等多种浏览器的行为，确保爬虫的兼容性和稳定性。\n强大的自动化能力: 可以模拟用户在浏览器中的各种操作，例如，点击、输入、滚动、截图、等待等，实现复杂的网页交互和数据抓取。\n异步非阻塞: Playwright 基于异步非阻塞架构，可以高效地处理大量的并发请求，提高爬虫的抓取效率。\n易于使用: Playwright 提供了简洁易用的 API，学习曲线平缓，上手容易。\n多语言支持: 支持多种编程语言，包括 R 语言 (通过 rplaywright 包)。\n\n爬虫的应用场景: 网络爬虫在数据获取和信息挖掘方面有广泛的应用场景，例如：\n\n搜索引擎: 搜索引擎使用爬虫抓取互联网上的网页，建立索引，提供搜索服务 (例如 Google, Baidu)。\n数据分析: 爬虫可以抓取电商平台商品信息、社交媒体用户数据、新闻网站文章等，用于市场分析、舆情监控、竞争情报等。\n价格监控: 爬虫可以抓取电商网站商品价格，进行价格比较和监控。\n内容聚合: 爬虫可以抓取多个网站的内容，聚合到自己的平台，提供更丰富的信息服务。\n学术研究: 爬虫可以抓取学术论文、专利信息、研究数据等，用于学术研究和知识发现。\n\n爬虫的注意事项 (Robots 协议): 在进行网络爬虫时，需要遵守网站的 Robots 协议 (https://zh.wikipedia.org/wiki/robots.txt)。 Robots 协议是网站通过 robots.txt 文件声明的爬虫访问规则，告知爬虫哪些页面可以抓取，哪些页面禁止抓取。 合法的爬虫应该遵守 Robots 协议，尊重网站的意愿，避免对网站造成不必要的负担或侵犯网站的权益。 通常情况下，robots.txt 文件位于网站的根目录下 (例如 https://www.example.com/robots.txt)。 您可以使用浏览器访问该文件查看网站的爬虫规则。\n\n\n\n\n本周内容总结与下周预告\n\n本周回顾: 回顾本周学习内容，巩固重点知识。 本周我们深入学习了统计学基本概念，以及项目式教学模式、R 语言和 tidyverse 简介 (在 VS Code/Cursor 中)、AI 辅助工具 (VS Code/Cursor 插件)、数据获取方法 (公开数据集、API)、VS Code/Cursor 中 R 语言环境搭建和 tidyverse 包安装。\n下周预告: 下周我们将继续学习数据获取实践技巧，包括使用 API 获取数据，以及学习如何使用 R 语言导入各种格式的数据文件。 数据导入是数据分析的关键步骤，下周我们将重点学习数据导入的方法和技巧。\n\n\n\n课后任务\n\n小组任务:\n\n确定项目主题: 小组讨论并最终确定项目一的研究主题。 下周上课时需要汇报确定后的主题。\n初步确定数据获取方式: 小组讨论并初步确定项目一的数据获取方式。 开始尝试查找和下载数据。\n\n个人任务:\n\n复习本周内容: 回顾本周讲义和课堂笔记，巩固统计学基本概念、数据获取方法和 VS Code/Cursor 中 R 语言环境搭建步骤。\n完成环境搭建 (VS Code/Cursor): 选择 VS Code 或 Cursor 作为 R 语言编程环境，并按照讲义步骤完成 R 语言环境的搭建和 tidyverse 包的安装。 尝试运行简单的 R 代码，确保环境配置成功。 探索和体验 AI 插件的功能。\n\n\n\n\n\n\n\n\nAI 辅助学习小贴士 (VS Code/Cursor)\n\n\n\n\nR 语言练习: 在 VS Code 或 Cursor 中练习 R 语言代码时，充分利用 AI 插件的代码自动补全、代码生成、代码解释、AI 聊天等功能。\n概念理解: 对于本周学习的统计学基本概念，如果遇到理解困难的地方，可以使用 AI 聊天工具进行提问，例如，向 AI 提问 “什么是总体？”, “样本的代表性是什么意思？”, “分类变量和数值变量有什么区别？” 等。 AI 可以提供更详细的解释和例子，帮助您更好地理解概念。\n数据集搜索: 使用 AI 工具搜索公开数据集平台和 API 文档，快速找到所需的数据资源。\n问题解答: 遇到统计学概念或 R 语言代码问题时，尝试使用 AI 插件的 AI 聊天功能提问，获取快速解答。 也可以直接在 Cursor 的聊天框中提问 R 语言问题。\n\n\n\n\n\n\n\n\n\n学习寄语 (VS Code/Cursor + AI)\n\n\n\n选择 VS Code 或 Cursor 配合 AI 插件进行 R 语言学习，是拥抱现代编程工具和 AI 技术的明智之举。 这将使您的学习过程更加高效、智能、有趣。 本周我们深入学习了统计学的基本概念，这是统计学学习的基石。 务必牢固掌握这些概念，为后续的学习打下坚实的基础。 充分利用 AI 插件的强大功能，让 AI 成为您的 R 语言和统计学学习助手！ 相信大家会在统计学和 R 语言的学习中取得更大的进步！ 下周见！",
    "crumbs": [
      "课程内容",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>第一周：项目启动与统计学导论</span>"
    ]
  },
  {
    "objectID": "week02.html",
    "href": "week02.html",
    "title": "第二周：R语言数据导入与常用数据包",
    "section": "",
    "text": "掌握R语言数据读取利器\n上周我们学习了数据获取的基本方法。本周，我们将深入学习R语言数据导入，掌握使用 R 读取各种数据格式的技能。我们将重点介绍 tidyverse 生态中的 readr 包和高性能的 datatable 包，并学习 R 中的基本数据类型、常用统计函数以及 dplyr 包的基础用法，为后续的数据分析打下更坚实的基础。\n继续使用 VS Code 或 Cursor + AI 插件： 请继续使用 VS Code 或 Cursor 编辑器，并充分利用 AI 插件的代码辅助、智能提示、聊天问答等功能，提升学习效率。\n\n\n\n\n\n\n本周学习目标\n\n\n\n\nR 数据导入进阶: 掌握 readr 和 datatable 包导入各种数据格式。\n数据包对比: 了解 readr 和 datatable 的特点和适用场景。\nR 数据类型: 熟悉 R 中的基本数据类型。\n常用统计函数: 掌握 R 中常用的统计函数。\ndplyr 基础: 初步掌握 dplyr 包的基本数据操作。\n实战演练: 使用 flights 数据集进行数据导入和导出练习。\nAI 辅助数据操作: 继续探索使用 AI 工具辅助 R 数据操作。\n\n\n\n\n\n\n1. R 语言数据导入常用包：readr vs datatable\n\ntidyverse readr 包 (回顾与进阶):\n\n快速便捷: readr 包是 tidyverse 核心包之一，专注于快速、方便地读取各种表格数据文件 (CSV, TXT, TSV 等)。\n自动类型推断: readr 能够自动检测列的数据类型，并进行合理的转换。\n灵活的参数设置: readr 提供了丰富的参数，可以灵活控制数据导入过程，例如，指定列名、跳过行、限制读取行数、自定义分隔符、处理缺失值、指定列类型、处理编码问题等。\n返回 tibble 数据框: readr 读取的数据默认是 tibble 格式，是 tidyverse 推荐使用的数据框，打印输出更友好，子集操作更严谨。\n常用函数:\n\nread_csv(): 读取逗号分隔的 CSV 文件。\nread_tsv(): 读取制表符分隔的 TSV 文件。\nread_delim(): 读取更广泛的分隔符文件，可以自定义分隔符。\nread_fwf(): 读取固定宽度的文件。\nread_table(): 读取空格分隔的表格文件。\n\n进阶用法: 上周我们已经学习了 read_csv() 和 read_tsv() 的基本用法。 本周我们进一步学习 readr 的进阶用法，例如：\n\ncol_names 参数: 用于指定列名。 可以传入字符向量作为列名，或者 col_names = FALSE 表示数据文件的第一行不是列名。\nskip 参数: 用于跳过文件开头的若干行。 例如，skip = 1 跳过第一行。\nn_max 参数: 用于限制最多读取的行数。 例如，n_max = 100 只读取前 100 行。\ncol_types 参数: 用于手动指定每一列的数据类型。 例如，col_types = cols(col1 = col_character(), col2 = col_double()) 指定 col1 为字符型，col2 为数值型。 常用的类型包括 col_character(), col_double(), col_integer(), col_logical(), col_factor(), col_date(), col_datetime(), col_time(), col_number(), col_currency(), col_skip(), col_guess().\nlocale 参数: 用于处理不同地区的文化和语言习惯，例如，日期和时间格式、小数点和千位分隔符、字符编码等。 可以使用 locale() 函数创建 locale 对象，并传入 locale 参数。 例如，locale = locale(encoding = \"GBK\") 指定使用 GBK 编码。\n\n\ndatatable 包 (高性能数据读取):\n\n快速高效: datatable 包是一个高性能的数据处理包，其数据读取速度非常快，尤其是在处理大型数据文件时，速度远超 readr 和 R 基础函数。 datatable 包使用 C 语言编写，底层优化，效率极高。\nfread() 函数: datatable 包最核心的函数是 fread()，用于快速读取各种格式的表格数据文件 (包括 CSV, TXT 等)。 fread() 功能强大，参数丰富，可以灵活控制数据导入过程。\n自动类型推断 (更智能): fread() 的自动类型推断功能比 readr 更智能，能够更准确地识别列的数据类型，并进行高效的转换。\n多线程读取: fread() 支持多线程读取，可以充分利用多核 CPU 的性能，进一步提高读取速度 (默认使用所有可用 CPU 核心)。\n语法简洁: fread() 的语法简洁易用，很多参数都有默认值，通常只需指定文件路径即可快速读取数据。\n返回 data.table 数据框: fread() 读取的数据是 data.table 格式。 data.table 是 datatable 包定义的一种高性能数据框，在数据处理和分析方面具有很多优势，例如，速度更快、语法更简洁、功能更强大。 data.table 的语法和操作方式与 R 基础的 data.frame 和 tidyverse 的 tibble 有所不同，需要学习其特有的语法。 本课程中，我们主要使用 tibble 数据框进行数据分析，data.table 作为扩展学习内容，感兴趣的同学可以深入学习。\n基本用法:\n# 安装和加载 datatable 包 (如果已安装，则只需加载)\n# install.packages(\"data.table\")\nlibrary(data.table)\n\n# 使用 fread() 读取 CSV 文件\ndata_dt &lt;- fread(\"your_data.csv\")\n\n# 打印数据框\nprint(data_dt)\n常用参数: fread() 函数有很多参数，常用的参数包括：\n\nfile: 文件路径。\nsep: 分隔符。 默认自动检测，通常无需手动指定。\nheader: 逻辑值，是否将第一行作为列名。 默认为 TRUE。\ncol.names: 用于指定列名。\nskip: 用于跳过文件开头的若干行。\nnrows: 用于限制最多读取的行数。\ncolClasses: 用于手动指定每一列的数据类型。 例如，colClasses = c(\"character\", \"numeric\") 指定第一列为字符型，第二列为数值型。\nencoding: 字符编码。 例如，encoding = \"GBK\" 指定使用 GBK 编码。\n\n\nreadr vs datatable 总结:\n\n\n\n特性\nreadr (tidyverse)\ndatatable (fread())\n\n\n\n\n速度\n较快\n非常快\n\n\n易用性\n非常易用\n易用\n\n\n功能\n功能丰富\n功能强大\n\n\n类型推断\n自动\n更智能自动\n\n\n数据框\ntibble\ndata.table\n\n\n依赖\ntidyverse\ndatatable\n\n\n适用场景\n常用数据导入\n大型数据文件导入\n\n\n\n\n选择建议:\n\n对于一般的数据导入任务，readr 包已经足够快速和方便，是首选。 readr 易用性好，与 tidyverse 生态系统兼容性好，是数据分析的常用工具。\n当需要处理非常大的数据文件，或者对数据读取速度有极高要求时，可以考虑使用 datatable 包的 fread() 函数。 fread() 速度极快，性能卓越，是处理大数据的不二之选。 但需要注意 fread() 返回的是 data.table 数据框，其语法和操作方式与 tibble 有所不同。\n\n\n\n\n\n2. 使用 flights 数据集演示数据导入导出\n\nflights 数据集介绍: nycflights13 包中包含了 2013 年纽约出发的所有航班数据，是一个非常经典的数据分析和演示数据集。 tidyverse 的很多教程和示例都使用 flights 数据集。\n\n加载 nycflights13 包:\n# 安装和加载 nycflights13 包 (如果已安装，则只需加载)\n# install.packages(\"nycflights13\")\nlibrary(nycflights13)\n\n# 查看 flights 数据集\nhead(flights)\nflights 数据框: flights 是一个 tibble 数据框，包含了航班的各种信息，例如，出发时间、到达时间、航空公司、航班号、出发机场、到达机场、飞行距离、飞行时长等。 可以使用 ?flights 查看数据集的详细信息。\n\n保存 flights 数据为 CSV 文件:\n\n使用 readr write_csv() 函数: readr 包提供了 write_csv() 函数，用于将数据框保存为 CSV 文件。\n# 使用 write_csv() 保存 flights 数据为 CSV 文件\nwrite_csv(flights, \"flights.csv\")\n\n# 提示：CSV 文件已保存到当前工作目录下\n\nwrite_csv() 函数: 第一个参数是要保存的数据框，第二个参数是 CSV 文件名 (带引号)。 默认使用逗号作为分隔符，UTF-8 编码，第一行写入列名。\n当前工作目录: CSV 文件默认保存到 R 的当前工作目录下。 可以使用 getwd() 函数查看当前工作目录，使用 setwd(\"your_path\") 设置工作目录。 建议将数据文件保存在项目文件夹下的 data 子文件夹中，方便管理。\n\n\n使用 readr read_csv() 函数读取 CSV 文件:\n\n从 CSV 文件读取数据: 使用 read_csv() 函数读取刚刚保存的 flights.csv 文件。\n# 使用 read_csv() 读取 CSV 文件\nflights_readr &lt;- read_csv(\"flights.csv\")\n\n# 打印读取的数据\nprint(flights_readr)\n\n# 检查数据是否与原始 flights 数据集一致\nidentical(flights, flights_readr)\n\nidentical() 函数: 用于比较两个 R 对象是否完全相同 (包括数据和属性)。 如果返回 TRUE，则表示两个对象完全一致。\n\n\n使用 datatable fwrite() 和 fread() 函数进行数据导入导出:\n\nfwrite() 函数: datatable 包提供了 fwrite() 函数，用于快速将 data.table 或 data.frame 保存为文件 (包括 CSV, TXT 等)。 fwrite() 速度非常快，性能优异。\n# 将 flights 数据转换为 data.table 格式\nflights_dt &lt;- as.data.table(flights)\n\n# 使用 fwrite() 保存 data.table 为 CSV 文件\nfwrite(flights_dt, \"flights_dt.csv\")\n\n# 提示：CSV 文件已保存到当前工作目录下\n\nas.data.table() 函数: 用于将其他格式的数据框 (例如 tibble, data.frame) 转换为 data.table 格式。 如果数据已经是 data.table 格式，则无需转换。\nfwrite() 函数: 第一个参数是要保存的 data.table，第二个参数是文件名。 默认使用逗号分隔符，UTF-8 编码，第一行写入列名。\n\nfread() 函数: 使用 fread() 函数读取 fwrite() 保存的 flights_dt.csv 文件。\n# 使用 fread() 读取 CSV 文件\nflights_fread &lt;- fread(\"flights_dt.csv\")\n\n# 打印读取的数据\nprint(flights_fread)\n\n# 检查数据是否与原始 flights_dt 数据集一致\nidentical(flights_dt, flights_fread)\n\n数据导入导出练习: 鼓励学生尝试使用 readr 和 datatable 包的不同函数和参数，进行数据导入导出练习，例如：\n\n使用 write_tsv() 和 read_tsv() 保存和读取 TSV 文件。\n使用 write.table() 和 read.table() (R 基础函数) 进行数据导入导出，并比较速度和用法。\n尝试使用 col_names, skip, n_max, col_types, encoding 等参数，控制数据导入过程。\n\n\n\n\n3. R 语言基本数据类型\n\nR 的数据类型: R 语言是一种动态类型语言，变量的类型不需要显式声明，R 会自动根据赋值内容判断变量类型。 R 中常用的基本数据类型包括：\n\n数值型 (numeric): 用于表示数值数据，包括整数和小数。 例如，10, 3.14, -5.2。 数值型是 R 中最常用的数据类型。\n字符型 (character): 用于表示文本数据，用引号 (单引号或双引号) 包围。 例如， \"hello\", 'world', \"统计学\", 'R 语言'。\n逻辑型 (logical): 用于表示逻辑值，只有两个取值：TRUE (真) 和 FALSE (假)。 逻辑值常用于条件判断和逻辑运算。 例如， TRUE, FALSE, 10 &gt; 5 (结果为 TRUE), \"a\" == \"b\" (结果为 FALSE)。\n因子型 (factor): 用于表示分类数据或名义变量。 因子型变量的值是有限的、预定义的类别 (levels)。 因子型变量在统计分析中非常重要，例如，用于表示性别、学历、地区、产品类别等。 使用 factor() 函数创建因子型变量。\n日期型 (date): 用于表示日期数据，例如，2023-10-26。 R 提供了 Date 类型来处理日期数据。 可以使用 as.Date() 函数将字符型数据转换为日期型数据。\n日期时间型 (POSIXct/POSIXlt): 用于表示日期和时间数据，例如，2023-10-26 10:30:00。 R 提供了 POSIXct 和 POSIXlt 两种类型来处理日期时间数据。 可以使用 as.POSIXct() 或 as.POSIXlt() 函数将字符型数据转换为日期时间型数据。\n\n数据类型判断和转换:\n\n类型判断函数: R 提供了多种函数用于判断变量的数据类型，例如：\n\nis.numeric(): 判断是否为数值型。\nis.character(): 判断是否为字符型。\nis.logical(): 判断是否为逻辑型。\nis.factor(): 判断是否为因子型。\nis.Date(): 判断是否为日期型。\nis.POSIXct() / is.POSIXlt(): 判断是否为日期时间型。\nclass(): 返回变量的类型名称 (更通用)。\ntypeof(): 返回变量的底层存储类型 (更底层)。\n\n类型转换函数: R 提供了多种函数用于将变量从一种类型转换为另一种类型，例如：\n\nas.numeric(): 转换为数值型。\nas.character(): 转换为字符型。\nas.logical(): 转换为逻辑型。\nas.factor(): 转换为因子型。\nas.Date(): 转换为日期型。\nas.POSIXct() / as.POSIXlt(): 转换为日期时间型。\n\n类型转换注意事项: 类型转换并非总是成功，需要注意数据本身的特点和转换规则。 例如，将字符型转换为数值型时，如果字符型数据不是有效的数值格式，则会转换为 NA (缺失值)。 将数值型转换为逻辑型时，非零数值会转换为 TRUE，零值会转换为 FALSE。\n\n数据类型练习: 鼓励学生创建不同类型的变量，并使用类型判断和转换函数进行练习，例如：\n# 数值型\nx &lt;- 10\nis.numeric(x)  # TRUE\nas.character(x) # \"10\"\n\n# 字符型\ny &lt;- \"hello\"\nis.character(y) # TRUE\nas.numeric(y)  # NA (无法转换为数值)\n\n# 逻辑型\nz &lt;- TRUE\nis.logical(z)  # TRUE\nas.numeric(z)  # 1 (TRUE 转换为 1)\nas.numeric(FALSE) # 0 (FALSE 转换为 0)\n\n# 因子型\ngender &lt;- factor(c(\"Male\", \"Female\", \"Male\", \"Male\", \"Female\"))\nis.factor(gender) # TRUE\nlevels(gender)   # 查看因子水平\n\n# 日期型\ndate_str &lt;- \"2023-10-26\"\ndate_obj &lt;- as.Date(date_str)\nis.Date(date_obj) # TRUE\n\n\n\n4. R 语言常用统计函数\n\n描述性统计函数: R 提供了丰富的函数用于计算描述性统计量，常用的函数包括：\n\n中心趋势度量:\n\nmean(): 均值 (平均值)。\nmedian(): 中位数 (将数据排序后位于中间位置的值)。\nmodeest::mlv(): 众数 (数据中出现频率最高的值)。 需要安装 modeest 包。\n\n离散程度度量:\n\nsd(): 标准差 (度量数据的离散程度)。\nvar(): 方差 (标准差的平方)。\nIQR(): 四分位距 (第三四分位数减去第一四分位数)。\nrange(): 极差 (最大值减去最小值)。\n\n位置度量:\n\nquantile(): 分位数 (计算指定的分位数，例如，四分位数、十分位数、百分位数)。\nmin(): 最小值。\nmax(): 最大值。\n\n求和与计数:\n\nsum(): 求和。\nlength(): 长度 (向量或列表的元素个数)。\ncount() (dplyr): 计数 (统计数据框中不同值的频数)。 dplyr 包的函数。\n\n\n其他常用统计函数:\n\ncor(): 相关系数 (度量两个数值型变量之间的线性相关程度)。\ncov(): 协方差 (度量两个数值型变量的协同变化程度)。\ntable(): 频数统计表 (统计分类变量的频数分布)。\nprop.table(): 比例表 (将频数统计表转换为比例)。\nsummary(): 摘要统计 (提供数据的基本摘要统计信息，包括均值、中位数、最小值、最大值、四分位数等)。 summary() 函数可以应用于不同类型的数据，提供不同的摘要信息。\n\n统计函数的使用注意事项:\n\n缺失值处理: R 的统计函数通常可以处理缺失值 (NA)。 大多数统计函数都有 na.rm 参数，用于控制是否移除缺失值。 na.rm = TRUE 表示在计算时移除缺失值，na.rm = FALSE (默认值) 表示如果数据中存在缺失值，则结果为 NA。 需要根据具体情况选择是否移除缺失值。\n数据类型: 统计函数通常只适用于数值型数据。 对于字符型、因子型等非数值型数据，需要进行适当的转换或使用其他类型的统计方法。\n函数文档: R 的统计函数都有详细的帮助文档。 可以使用 ?函数名 或 help(\"函数名\") 查看函数文档，了解函数的用法、参数和返回值。\n\n统计函数练习: 使用 flights 数据集，练习使用常用统计函数，例如：\n# 计算 flights 数据集中 arr_delay (到达延误时间) 的均值、中位数、标准差\nmean(flights$arr_delay, na.rm = TRUE)\nmedian(flights$arr_delay, na.rm = TRUE)\nsd(flights$arr_delay, na.rm = TRUE)\n\n# 计算 carrier (航空公司) 的频数统计表\ntable(flights$carrier)\n\n# 计算 origin (出发机场) 和 dest (到达机场) 的交叉频数表\ntable(flights$origin, flights$dest)\n\n# 使用 summary() 函数查看 flights 数据集的摘要统计信息\nsummary(flights)\n\n\n\n5. dplyr 包基础：数据框操作利器\n\ndplyr 包简介: dplyr 包是 tidyverse 生态系统中的核心数据处理包，提供了一套简洁、高效、易用的数据框操作 “动词” (verbs)。 dplyr 的设计理念是 “数据操作管道” (data manipulation pipeline)，可以将多个数据操作步骤连接起来，形成清晰、可读性强的数据处理流程。 dplyr 是 R 语言数据分析中最常用的包之一。\ndplyr 核心 “动词” (verbs): dplyr 包提供了以下几个核心 “动词”，用于完成常见的数据框操作：\n\nfilter(): 筛选行 (根据条件筛选数据框的行)。 类似于 SQL 中的 WHERE 语句。\nselect(): 选择列 (选择数据框的列)。 类似于 SQL 中的 SELECT 语句。\nmutate(): 创建新列或修改现有列 (基于现有列计算生成新列，或修改现有列的值)。\narrange(): 排序 (根据指定的列对数据框进行排序)。 类似于 SQL 中的 ORDER BY 语句。\nsummarize(): 汇总统计 (对数据框进行分组汇总统计，计算各种统计量)。 类似于 SQL 中的聚合函数 (例如 SUM(), AVG(), COUNT()) 和 GROUP BY 语句。\ngroup_by(): 分组 (将数据框按照指定的列进行分组，为后续的汇总统计操作做准备)。 类似于 SQL 中的 GROUP BY 语句。\n\n管道操作符 %&gt;%: dplyr 包与管道操作符 %&gt;% (pipe operator) 完美结合，可以实现链式数据操作。 管道操作符 %&gt;% 将上一步操作的结果作为下一步操作的第一个参数传入，使得代码更加简洁、易读。 管道操作符来自 magrittr 包，tidyverse 自动加载 magrittr 包。\ndplyr 基础用法示例 (使用 flights 数据集):\n\n筛选行 (filter()): 筛选出所有 1 月份 (month == 1) 的航班。\nlibrary(dplyr)\n\njanuary_flights &lt;- flights %&gt;%\n  filter(month == 1)\n\nprint(january_flights)\n\n%&gt;% 管道操作符: flights %&gt;% filter(month == 1) 表示将 flights 数据框作为 filter() 函数的第一个参数传入。\nfilter(month == 1): 筛选条件是 month == 1，表示 month 列的值等于 1。 == 是等于比较运算符。\n\n选择列 (select()): 选择 year, month, day, carrier, flight, dep_delay, arr_delay 这几列。\nselected_cols_flights &lt;- flights %&gt;%\n  select(year, month, day, carrier, flight, dep_delay, arr_delay)\n\nprint(selected_cols_flights)\n\nselect(year, month, day, carrier, flight, dep_delay, arr_delay): 直接列出要选择的列名即可。\n\n创建新列 (mutate()): 创建一个新列 gain，表示航班的实际飞行时间 (到达时间 - 出发时间 - 计划飞行时间)。\nflights_with_gain &lt;- flights %&gt;%\n  mutate(gain = arr_time - dep_time - air_time)\n\nprint(flights_with_gain)\n\nmutate(gain = arr_time - dep_time - air_time): gain = ... 表示创建名为 gain 的新列，等号右边是计算新列值的表达式。\n\n排序 (arrange()): 按照出发延误时间 dep_delay 进行升序排序。\narranged_flights &lt;- flights %&gt;%\n  arrange(dep_delay)\n\nprint(arranged_flights)\n\narrange(dep_delay): 按照 dep_delay 列进行升序排序。 默认升序。 降序排序可以使用 desc(dep_delay)。\n\n汇总统计 (summarize()): 计算所有航班的平均到达延误时间 arr_delay。\naverage_delay &lt;- flights %&gt;%\n  summarize(mean_delay = mean(arr_delay, na.rm = TRUE))\n\nprint(average_delay)\n\nsummarize(mean_delay = mean(arr_delay, na.rm = TRUE)): mean_delay = ... 表示创建一个名为 mean_delay 的汇总统计量，等号右边是计算汇总统计量的表达式，这里使用 mean() 函数计算平均值，na.rm = TRUE 表示移除缺失值。\n\n分组汇总 (group_by() + summarize()): 按照航空公司 carrier 分组，计算每个航空公司的平均到达延误时间。\ncarrier_delay &lt;- flights %&gt;%\n  group_by(carrier) %&gt;%\n  summarize(mean_delay = mean(arr_delay, na.rm = TRUE))\n\nprint(carrier_delay)\n\ngroup_by(carrier): 按照 carrier 列进行分组。 后续的 summarize() 操作将在每个分组内进行。\nsummarize(mean_delay = mean(arr_delay, na.rm = TRUE)): 在每个航空公司分组内计算平均到达延误时间。\n\n\ndplyr 练习: 鼓励学生使用 dplyr 的各种 “动词” 和管道操作符，对 flights 数据集进行各种数据操作练习，例如：\n\n筛选出到达延误时间超过 60 分钟的航班。\n选择 carrier, flight, dep_delay, arr_delay 和 distance 列，并按照飞行距离 distance 进行降序排序。\n创建新列 speed，表示航班的平均飞行速度 (距离 / 飞行时间)。\n按照出发机场 origin 分组，计算每个出发机场的航班数量和平均出发延误时间。\n尝试组合多个 dplyr 动词，完成更复杂的数据操作任务。\n\nAI 辅助 dplyr 使用 (可选): 演示如何使用 AI 插件辅助 dplyr 包的使用。 例如：\n\n函数用法查询: 使用 AI 聊天提问： “filter() function in R dplyr package”, “how to use group_by() and summarize() in dplyr”。 AI 可能会提供函数文档或使用示例。\n代码补全: 在 VS Code/Cursor 中输入 flights %&gt;% fil，AI 插件会自动提示 filter() 函数，并提供函数参数提示。\n代码示例生成: 使用 AI 代码生成功能，输入注释: # R code to filter flights data for month == 2 and carrier == \"AA\" using dplyr, 让 AI 生成代码。\n代码解释: 使用 AI 代码解释功能，选中 dplyr 代码片段，让 AI 解释代码的功能和每一行代码的作用。\n\n\n\n\n6. 本周内容总结与下周预告\n\n本周回顾: 回顾本周学习内容，巩固重点知识。 本周我们深入学习了 R 语言数据导入的常用包 readr 和 datatable，对比了它们的特点和适用场景，学习了 R 的基本数据类型和常用统计函数，并初步掌握了 dplyr 包的基本用法。 数据导入、数据类型、统计函数和 dplyr 是 R 语言数据分析的基础，务必熟练掌握本周所学内容。\n下周预告: 下周我们将继续深入学习 dplyr 包，学习更高级的数据操作技巧，例如，多表连接 (join)、数据变形 (reshape)、窗口函数 (window function) 等。 dplyr 是数据清洗和预处理的利器，下周我们将重点学习如何使用 dplyr 进行高效的数据清洗和预处理。\n\n\n\n7. 课后任务\n\n小组任务:\n\n继续项目一数据探索: 各小组继续使用 R 语言导入和探索项目一的数据集，尝试使用 readr 或 datatable 包导入数据，并使用本周学习的 R 基础知识和 dplyr 包进行初步的数据查看和理解。\n小组讨论数据清洗方案: 小组讨论项目一的数据清洗和预处理方案，为下周的数据清洗任务做好准备。\n\n个人任务:\n\n复习本周内容: 回顾本周讲义和课堂笔记，巩固 readr 和 datatable 包的用法、R 基本数据类型、常用统计函数和 dplyr 基础用法。\nR 代码练习: 完成本讲义中布置的 R 代码练习，熟练掌握 readr, datatable, R 基础函数和 dplyr 包的常用函数。 尝试使用 AI 插件辅助 R 代码练习。\nflights 数据集练习: 使用 flights 数据集，练习使用 readr 和 datatable 进行数据导入导出，练习使用 R 基本数据类型和统计函数，练习使用 dplyr 包进行数据操作。 可以尝试完成讲义中提供的练习题，也可以自己设计练习题。\n\n\n\n\n\n\n\n\nAI 辅助学习小贴士\n\n\n\n\nR 代码练习: 继续在 VS Code 或 Cursor 中练习 R 语言代码，充分利用 AI 插件的代码自动补全、代码生成、代码解释、AI 聊天等功能。 遇到 R 代码问题，及时向 AI 提问。\n数据包使用问题: 如果在使用 readr, datatable, dplyr 等数据包时遇到问题，可以查阅包的官方文档，或者使用 AI 聊天提问，寻求帮助。\n统计概念理解: 如果对某些统计概念 (例如，均值、中位数、标准差、相关系数等) 理解不透彻，可以使用 AI 聊天提问，让 AI 提供更详细的解释和例子。\n代码效率优化: 如果希望提高 R 代码的运行效率，可以尝试使用 datatable 包，或者使用 AI 聊天咨询代码优化技巧。\n\n\n\n\n\n\n\n\n\n学习寄语\n\n\n\n工欲善其事，必先利其器！ 本周我们学习了 R 语言数据导入和数据处理的利器，为后续的数据分析打下了坚实的基础。 熟练掌握这些工具，您将能够更高效地进行数据分析！ 继续保持学习的热情，充分利用 VS Code/Cursor 和 AI 插件的强大功能，相信大家会在统计学和 R 语言的学习中取得更大的进步！ 下周见！",
    "crumbs": [
      "课程内容",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>第二周：R语言数据导入与常用数据包</span>"
    ]
  },
  {
    "objectID": "week02.html#第二周r语言数据导入与常用数据包-共4课时",
    "href": "week02.html#第二周r语言数据导入与常用数据包-共4课时",
    "title": "统计学讲义 - 第二周：R语言数据导入与常用数据包",
    "section": "",
    "text": "掌握R语言数据读取利器\n上周我们学习了数据获取的基本方法。本周，我们将深入学习R语言数据导入，掌握使用 R 读取各种数据格式的技能。我们将重点介绍 tidyverse 生态中的 readr 包和高性能的 datatable 包，并学习 R 中的基本数据类型、常用统计函数以及 dplyr 包的基础用法，为后续的数据分析打下更坚实的基础。\n继续使用 VS Code 或 Cursor + AI 插件： 请继续使用 VS Code 或 Cursor 编辑器，并充分利用 AI 插件的代码辅助、智能提示、聊天问答等功能，提升学习效率。\n\n\n\n\n\n\n本周学习目标\n\n\n\n\nR 数据导入进阶: 掌握 readr 和 datatable 包导入各种数据格式。\n数据包对比: 了解 readr 和 datatable 的特点和适用场景。\nR 数据类型: 熟悉 R 中的基本数据类型。\n常用统计函数: 掌握 R 中常用的统计函数。\ndplyr 基础: 初步掌握 dplyr 包的基本数据操作。\n实战演练: 使用 flights 数据集进行数据导入和导出练习。\nAI 辅助数据操作: 继续探索使用 AI 工具辅助 R 数据操作。\n\n\n\n\n\n\n1. R 语言数据导入常用包：readr vs datatable\n\ntidyverse readr 包 (回顾与进阶):\n\n快速便捷: readr 包是 tidyverse 核心包之一，专注于快速、方便地读取各种表格数据文件 (CSV, TXT, TSV 等)。\n自动类型推断: readr 能够自动检测列的数据类型，并进行合理的转换。\n灵活的参数设置: readr 提供了丰富的参数，可以灵活控制数据导入过程，例如，指定列名、跳过行、限制读取行数、自定义分隔符、处理缺失值、指定列类型、处理编码问题等。\n返回 tibble 数据框: readr 读取的数据默认是 tibble 格式，是 tidyverse 推荐使用的数据框，打印输出更友好，子集操作更严谨。\n常用函数:\n\nread_csv(): 读取逗号分隔的 CSV 文件。\nread_tsv(): 读取制表符分隔的 TSV 文件。\nread_delim(): 读取更广泛的分隔符文件，可以自定义分隔符。\nread_fwf(): 读取固定宽度的文件。\nread_table(): 读取空格分隔的表格文件。\n\n进阶用法: 上周我们已经学习了 read_csv() 和 read_tsv() 的基本用法。 本周我们进一步学习 readr 的进阶用法，例如：\n\ncol_names 参数: 用于指定列名。 可以传入字符向量作为列名，或者 col_names = FALSE 表示数据文件的第一行不是列名。\nskip 参数: 用于跳过文件开头的若干行。 例如，skip = 1 跳过第一行。\nn_max 参数: 用于限制最多读取的行数。 例如，n_max = 100 只读取前 100 行。\ncol_types 参数: 用于手动指定每一列的数据类型。 例如，col_types = cols(col1 = col_character(), col2 = col_double()) 指定 col1 为字符型，col2 为数值型。 常用的类型包括 col_character(), col_double(), col_integer(), col_logical(), col_factor(), col_date(), col_datetime(), col_time(), col_number(), col_currency(), col_skip(), col_guess().\nlocale 参数: 用于处理不同地区的文化和语言习惯，例如，日期和时间格式、小数点和千位分隔符、字符编码等。 可以使用 locale() 函数创建 locale 对象，并传入 locale 参数。 例如，locale = locale(encoding = \"GBK\") 指定使用 GBK 编码。\n\n\ndatatable 包 (高性能数据读取):\n\n快速高效: datatable 包是一个高性能的数据处理包，其数据读取速度非常快，尤其是在处理大型数据文件时，速度远超 readr 和 R 基础函数。 datatable 包使用 C 语言编写，底层优化，效率极高。\nfread() 函数: datatable 包最核心的函数是 fread()，用于快速读取各种格式的表格数据文件 (包括 CSV, TXT 等)。 fread() 功能强大，参数丰富，可以灵活控制数据导入过程。\n自动类型推断 (更智能): fread() 的自动类型推断功能比 readr 更智能，能够更准确地识别列的数据类型，并进行高效的转换。\n多线程读取: fread() 支持多线程读取，可以充分利用多核 CPU 的性能，进一步提高读取速度 (默认使用所有可用 CPU 核心)。\n语法简洁: fread() 的语法简洁易用，很多参数都有默认值，通常只需指定文件路径即可快速读取数据。\n返回 data.table 数据框: fread() 读取的数据是 data.table 格式。 data.table 是 datatable 包定义的一种高性能数据框，在数据处理和分析方面具有很多优势，例如，速度更快、语法更简洁、功能更强大。 data.table 的语法和操作方式与 R 基础的 data.frame 和 tidyverse 的 tibble 有所不同，需要学习其特有的语法。 本课程中，我们主要使用 tibble 数据框进行数据分析，data.table 作为扩展学习内容，感兴趣的同学可以深入学习。\n基本用法:\n# 安装和加载 datatable 包 (如果已安装，则只需加载)\n# install.packages(\"data.table\")\nlibrary(data.table)\n\n# 使用 fread() 读取 CSV 文件\ndata_dt &lt;- fread(\"your_data.csv\")\n\n# 打印数据框\nprint(data_dt)\n常用参数: fread() 函数有很多参数，常用的参数包括：\n\nfile: 文件路径。\nsep: 分隔符。 默认自动检测，通常无需手动指定。\nheader: 逻辑值，是否将第一行作为列名。 默认为 TRUE。\ncol.names: 用于指定列名。\nskip: 用于跳过文件开头的若干行。\nnrows: 用于限制最多读取的行数。\ncolClasses: 用于手动指定每一列的数据类型。 例如，colClasses = c(\"character\", \"numeric\") 指定第一列为字符型，第二列为数值型。\nencoding: 字符编码。 例如，encoding = \"GBK\" 指定使用 GBK 编码。\n\n\nreadr vs datatable 总结:\n\n\n\n特性\nreadr (tidyverse)\ndatatable (fread())\n\n\n\n\n速度\n较快\n非常快\n\n\n易用性\n非常易用\n易用\n\n\n功能\n功能丰富\n功能强大\n\n\n类型推断\n自动\n更智能自动\n\n\n数据框\ntibble\ndata.table\n\n\n依赖\ntidyverse\ndatatable\n\n\n适用场景\n常用数据导入\n大型数据文件导入\n\n\n\n\n选择建议:\n\n对于一般的数据导入任务，readr 包已经足够快速和方便，是首选。 readr 易用性好，与 tidyverse 生态系统兼容性好，是数据分析的常用工具。\n当需要处理非常大的数据文件，或者对数据读取速度有极高要求时，可以考虑使用 datatable 包的 fread() 函数。 fread() 速度极快，性能卓越，是处理大数据的不二之选。 但需要注意 fread() 返回的是 data.table 数据框，其语法和操作方式与 tibble 有所不同。\n\n\n\n\n\n2. 使用 flights 数据集演示数据导入导出\n\nflights 数据集介绍: nycflights13 包中包含了 2013 年纽约出发的所有航班数据，是一个非常经典的数据分析和演示数据集。 tidyverse 的很多教程和示例都使用 flights 数据集。\n\n加载 nycflights13 包:\n# 安装和加载 nycflights13 包 (如果已安装，则只需加载)\n# install.packages(\"nycflights13\")\nlibrary(nycflights13)\n\n# 查看 flights 数据集\nhead(flights)\nflights 数据框: flights 是一个 tibble 数据框，包含了航班的各种信息，例如，出发时间、到达时间、航空公司、航班号、出发机场、到达机场、飞行距离、飞行时长等。 可以使用 ?flights 查看数据集的详细信息。\n\n保存 flights 数据为 CSV 文件:\n\n使用 readr write_csv() 函数: readr 包提供了 write_csv() 函数，用于将数据框保存为 CSV 文件。\n# 使用 write_csv() 保存 flights 数据为 CSV 文件\nwrite_csv(flights, \"flights.csv\")\n\n# 提示：CSV 文件已保存到当前工作目录下\n\nwrite_csv() 函数: 第一个参数是要保存的数据框，第二个参数是 CSV 文件名 (带引号)。 默认使用逗号作为分隔符，UTF-8 编码，第一行写入列名。\n当前工作目录: CSV 文件默认保存到 R 的当前工作目录下。 可以使用 getwd() 函数查看当前工作目录，使用 setwd(\"your_path\") 设置工作目录。 建议将数据文件保存在项目文件夹下的 data 子文件夹中，方便管理。\n\n\n使用 readr read_csv() 函数读取 CSV 文件:\n\n从 CSV 文件读取数据: 使用 read_csv() 函数读取刚刚保存的 flights.csv 文件。\n# 使用 read_csv() 读取 CSV 文件\nflights_readr &lt;- read_csv(\"flights.csv\")\n\n# 打印读取的数据\nprint(flights_readr)\n\n# 检查数据是否与原始 flights 数据集一致\nidentical(flights, flights_readr)\n\nidentical() 函数: 用于比较两个 R 对象是否完全相同 (包括数据和属性)。 如果返回 TRUE，则表示两个对象完全一致。\n\n\n使用 datatable fwrite() 和 fread() 函数进行数据导入导出:\n\nfwrite() 函数: datatable 包提供了 fwrite() 函数，用于快速将 data.table 或 data.frame 保存为文件 (包括 CSV, TXT 等)。 fwrite() 速度非常快，性能优异。\n# 将 flights 数据转换为 data.table 格式\nflights_dt &lt;- as.data.table(flights)\n\n# 使用 fwrite() 保存 data.table 为 CSV 文件\nfwrite(flights_dt, \"flights_dt.csv\")\n\n# 提示：CSV 文件已保存到当前工作目录下\n\nas.data.table() 函数: 用于将其他格式的数据框 (例如 tibble, data.frame) 转换为 data.table 格式。 如果数据已经是 data.table 格式，则无需转换。\nfwrite() 函数: 第一个参数是要保存的 data.table，第二个参数是文件名。 默认使用逗号分隔符，UTF-8 编码，第一行写入列名。\n\nfread() 函数: 使用 fread() 函数读取 fwrite() 保存的 flights_dt.csv 文件。\n# 使用 fread() 读取 CSV 文件\nflights_fread &lt;- fread(\"flights_dt.csv\")\n\n# 打印读取的数据\nprint(flights_fread)\n\n# 检查数据是否与原始 flights_dt 数据集一致\nidentical(flights_dt, flights_fread)\n\n数据导入导出练习: 鼓励学生尝试使用 readr 和 datatable 包的不同函数和参数，进行数据导入导出练习，例如：\n\n使用 write_tsv() 和 read_tsv() 保存和读取 TSV 文件。\n使用 write.table() 和 read.table() (R 基础函数) 进行数据导入导出，并比较速度和用法。\n尝试使用 col_names, skip, n_max, col_types, encoding 等参数，控制数据导入过程。\n\n\n\n\n3. R 语言基本数据类型\n\nR 的数据类型: R 语言是一种动态类型语言，变量的类型不需要显式声明，R 会自动根据赋值内容判断变量类型。 R 中常用的基本数据类型包括：\n\n数值型 (numeric): 用于表示数值数据，包括整数和小数。 例如，10, 3.14, -5.2。 数值型是 R 中最常用的数据类型。\n字符型 (character): 用于表示文本数据，用引号 (单引号或双引号) 包围。 例如， \"hello\", 'world', \"统计学\", 'R 语言'。\n逻辑型 (logical): 用于表示逻辑值，只有两个取值：TRUE (真) 和 FALSE (假)。 逻辑值常用于条件判断和逻辑运算。 例如， TRUE, FALSE, 10 &gt; 5 (结果为 TRUE), \"a\" == \"b\" (结果为 FALSE)。\n因子型 (factor): 用于表示分类数据或名义变量。 因子型变量的值是有限的、预定义的类别 (levels)。 因子型变量在统计分析中非常重要，例如，用于表示性别、学历、地区、产品类别等。 使用 factor() 函数创建因子型变量。\n日期型 (date): 用于表示日期数据，例如，2023-10-26。 R 提供了 Date 类型来处理日期数据。 可以使用 as.Date() 函数将字符型数据转换为日期型数据。\n日期时间型 (POSIXct/POSIXlt): 用于表示日期和时间数据，例如，2023-10-26 10:30:00。 R 提供了 POSIXct 和 POSIXlt 两种类型来处理日期时间数据。 可以使用 as.POSIXct() 或 as.POSIXlt() 函数将字符型数据转换为日期时间型数据。\n\n数据类型判断和转换:\n\n类型判断函数: R 提供了多种函数用于判断变量的数据类型，例如：\n\nis.numeric(): 判断是否为数值型。\nis.character(): 判断是否为字符型。\nis.logical(): 判断是否为逻辑型。\nis.factor(): 判断是否为因子型。\nis.Date(): 判断是否为日期型。\nis.POSIXct() / is.POSIXlt(): 判断是否为日期时间型。\nclass(): 返回变量的类型名称 (更通用)。\ntypeof(): 返回变量的底层存储类型 (更底层)。\n\n类型转换函数: R 提供了多种函数用于将变量从一种类型转换为另一种类型，例如：\n\nas.numeric(): 转换为数值型。\nas.character(): 转换为字符型。\nas.logical(): 转换为逻辑型。\nas.factor(): 转换为因子型。\nas.Date(): 转换为日期型。\nas.POSIXct() / as.POSIXlt(): 转换为日期时间型。\n\n类型转换注意事项: 类型转换并非总是成功，需要注意数据本身的特点和转换规则。 例如，将字符型转换为数值型时，如果字符型数据不是有效的数值格式，则会转换为 NA (缺失值)。 将数值型转换为逻辑型时，非零数值会转换为 TRUE，零值会转换为 FALSE。\n\n数据类型练习: 鼓励学生创建不同类型的变量，并使用类型判断和转换函数进行练习，例如：\n# 数值型\nx &lt;- 10\nis.numeric(x)  # TRUE\nas.character(x) # \"10\"\n\n# 字符型\ny &lt;- \"hello\"\nis.character(y) # TRUE\nas.numeric(y)  # NA (无法转换为数值)\n\n# 逻辑型\nz &lt;- TRUE\nis.logical(z)  # TRUE\nas.numeric(z)  # 1 (TRUE 转换为 1)\nas.numeric(FALSE) # 0 (FALSE 转换为 0)\n\n# 因子型\ngender &lt;- factor(c(\"Male\", \"Female\", \"Male\", \"Male\", \"Female\"))\nis.factor(gender) # TRUE\nlevels(gender)   # 查看因子水平\n\n# 日期型\ndate_str &lt;- \"2023-10-26\"\ndate_obj &lt;- as.Date(date_str)\nis.Date(date_obj) # TRUE\n\n\n\n4. R 语言常用统计函数\n\n描述性统计函数: R 提供了丰富的函数用于计算描述性统计量，常用的函数包括：\n\n中心趋势度量:\n\nmean(): 均值 (平均值)。\nmedian(): 中位数 (将数据排序后位于中间位置的值)。\nmodeest::mlv(): 众数 (数据中出现频率最高的值)。 需要安装 modeest 包。\n\n离散程度度量:\n\nsd(): 标准差 (度量数据的离散程度)。\nvar(): 方差 (标准差的平方)。\nIQR(): 四分位距 (第三四分位数减去第一四分位数)。\nrange(): 极差 (最大值减去最小值)。\n\n位置度量:\n\nquantile(): 分位数 (计算指定的分位数，例如，四分位数、十分位数、百分位数)。\nmin(): 最小值。\nmax(): 最大值。\n\n求和与计数:\n\nsum(): 求和。\nlength(): 长度 (向量或列表的元素个数)。\ncount() (dplyr): 计数 (统计数据框中不同值的频数)。 dplyr 包的函数。\n\n\n其他常用统计函数:\n\ncor(): 相关系数 (度量两个数值型变量之间的线性相关程度)。\ncov(): 协方差 (度量两个数值型变量的协同变化程度)。\ntable(): 频数统计表 (统计分类变量的频数分布)。\nprop.table(): 比例表 (将频数统计表转换为比例)。\nsummary(): 摘要统计 (提供数据的基本摘要统计信息，包括均值、中位数、最小值、最大值、四分位数等)。 summary() 函数可以应用于不同类型的数据，提供不同的摘要信息。\n\n统计函数的使用注意事项:\n\n缺失值处理: R 的统计函数通常可以处理缺失值 (NA)。 大多数统计函数都有 na.rm 参数，用于控制是否移除缺失值。 na.rm = TRUE 表示在计算时移除缺失值，na.rm = FALSE (默认值) 表示如果数据中存在缺失值，则结果为 NA。 需要根据具体情况选择是否移除缺失值。\n数据类型: 统计函数通常只适用于数值型数据。 对于字符型、因子型等非数值型数据，需要进行适当的转换或使用其他类型的统计方法。\n函数文档: R 的统计函数都有详细的帮助文档。 可以使用 ?函数名 或 help(\"函数名\") 查看函数文档，了解函数的用法、参数和返回值。\n\n统计函数练习: 使用 flights 数据集，练习使用常用统计函数，例如：\n# 计算 flights 数据集中 arr_delay (到达延误时间) 的均值、中位数、标准差\nmean(flights$arr_delay, na.rm = TRUE)\nmedian(flights$arr_delay, na.rm = TRUE)\nsd(flights$arr_delay, na.rm = TRUE)\n\n# 计算 carrier (航空公司) 的频数统计表\ntable(flights$carrier)\n\n# 计算 origin (出发机场) 和 dest (到达机场) 的交叉频数表\ntable(flights$origin, flights$dest)\n\n# 使用 summary() 函数查看 flights 数据集的摘要统计信息\nsummary(flights)\n\n\n\n5. dplyr 包基础：数据框操作利器\n\ndplyr 包简介: dplyr 包是 tidyverse 生态系统中的核心数据处理包，提供了一套简洁、高效、易用的数据框操作 “动词” (verbs)。 dplyr 的设计理念是 “数据操作管道” (data manipulation pipeline)，可以将多个数据操作步骤连接起来，形成清晰、可读性强的数据处理流程。 dplyr 是 R 语言数据分析中最常用的包之一。\ndplyr 核心 “动词” (verbs): dplyr 包提供了以下几个核心 “动词”，用于完成常见的数据框操作：\n\nfilter(): 筛选行 (根据条件筛选数据框的行)。 类似于 SQL 中的 WHERE 语句。\nselect(): 选择列 (选择数据框的列)。 类似于 SQL 中的 SELECT 语句。\nmutate(): 创建新列或修改现有列 (基于现有列计算生成新列，或修改现有列的值)。\narrange(): 排序 (根据指定的列对数据框进行排序)。 类似于 SQL 中的 ORDER BY 语句。\nsummarize(): 汇总统计 (对数据框进行分组汇总统计，计算各种统计量)。 类似于 SQL 中的聚合函数 (例如 SUM(), AVG(), COUNT()) 和 GROUP BY 语句。\ngroup_by(): 分组 (将数据框按照指定的列进行分组，为后续的汇总统计操作做准备)。 类似于 SQL 中的 GROUP BY 语句。\n\n管道操作符 %&gt;%: dplyr 包与管道操作符 %&gt;% (pipe operator) 完美结合，可以实现链式数据操作。 管道操作符 %&gt;% 将上一步操作的结果作为下一步操作的第一个参数传入，使得代码更加简洁、易读。 管道操作符来自 magrittr 包，tidyverse 自动加载 magrittr 包。\ndplyr 基础用法示例 (使用 flights 数据集):\n\n筛选行 (filter()): 筛选出所有 1 月份 (month == 1) 的航班。\nlibrary(dplyr)\n\njanuary_flights &lt;- flights %&gt;%\n  filter(month == 1)\n\nprint(january_flights)\n\n%&gt;% 管道操作符: flights %&gt;% filter(month == 1) 表示将 flights 数据框作为 filter() 函数的第一个参数传入。\nfilter(month == 1): 筛选条件是 month == 1，表示 month 列的值等于 1。 == 是等于比较运算符。\n\n选择列 (select()): 选择 year, month, day, carrier, flight, dep_delay, arr_delay 这几列。\nselected_cols_flights &lt;- flights %&gt;%\n  select(year, month, day, carrier, flight, dep_delay, arr_delay)\n\nprint(selected_cols_flights)\n\nselect(year, month, day, carrier, flight, dep_delay, arr_delay): 直接列出要选择的列名即可。\n\n创建新列 (mutate()): 创建一个新列 gain，表示航班的实际飞行时间 (到达时间 - 出发时间 - 计划飞行时间)。\nflights_with_gain &lt;- flights %&gt;%\n  mutate(gain = arr_time - dep_time - air_time)\n\nprint(flights_with_gain)\n\nmutate(gain = arr_time - dep_time - air_time): gain = ... 表示创建名为 gain 的新列，等号右边是计算新列值的表达式。\n\n排序 (arrange()): 按照出发延误时间 dep_delay 进行升序排序。\narranged_flights &lt;- flights %&gt;%\n  arrange(dep_delay)\n\nprint(arranged_flights)\n\narrange(dep_delay): 按照 dep_delay 列进行升序排序。 默认升序。 降序排序可以使用 desc(dep_delay)。\n\n汇总统计 (summarize()): 计算所有航班的平均到达延误时间 arr_delay。\naverage_delay &lt;- flights %&gt;%\n  summarize(mean_delay = mean(arr_delay, na.rm = TRUE))\n\nprint(average_delay)\n\nsummarize(mean_delay = mean(arr_delay, na.rm = TRUE)): mean_delay = ... 表示创建一个名为 mean_delay 的汇总统计量，等号右边是计算汇总统计量的表达式，这里使用 mean() 函数计算平均值，na.rm = TRUE 表示移除缺失值。\n\n分组汇总 (group_by() + summarize()): 按照航空公司 carrier 分组，计算每个航空公司的平均到达延误时间。\ncarrier_delay &lt;- flights %&gt;%\n  group_by(carrier) %&gt;%\n  summarize(mean_delay = mean(arr_delay, na.rm = TRUE))\n\nprint(carrier_delay)\n\ngroup_by(carrier): 按照 carrier 列进行分组。 后续的 summarize() 操作将在每个分组内进行。\nsummarize(mean_delay = mean(arr_delay, na.rm = TRUE)): 在每个航空公司分组内计算平均到达延误时间。\n\n\ndplyr 练习: 鼓励学生使用 dplyr 的各种 “动词” 和管道操作符，对 flights 数据集进行各种数据操作练习，例如：\n\n筛选出到达延误时间超过 60 分钟的航班。\n选择 carrier, flight, dep_delay, arr_delay 和 distance 列，并按照飞行距离 distance 进行降序排序。\n创建新列 speed，表示航班的平均飞行速度 (距离 / 飞行时间)。\n按照出发机场 origin 分组，计算每个出发机场的航班数量和平均出发延误时间。\n尝试组合多个 dplyr 动词，完成更复杂的数据操作任务。\n\nAI 辅助 dplyr 使用 (可选): 演示如何使用 AI 插件辅助 dplyr 包的使用。 例如：\n\n函数用法查询: 使用 AI 聊天提问： “filter() function in R dplyr package”, “how to use group_by() and summarize() in dplyr”。 AI 可能会提供函数文档或使用示例。\n代码补全: 在 VS Code/Cursor 中输入 flights %&gt;% fil，AI 插件会自动提示 filter() 函数，并提供函数参数提示。\n代码示例生成: 使用 AI 代码生成功能，输入注释: # R code to filter flights data for month == 2 and carrier == \"AA\" using dplyr, 让 AI 生成代码。\n代码解释: 使用 AI 代码解释功能，选中 dplyr 代码片段，让 AI 解释代码的功能和每一行代码的作用。\n\n\n\n\n6. 本周内容总结与下周预告\n\n本周回顾: 回顾本周学习内容，巩固重点知识。 本周我们深入学习了 R 语言数据导入的常用包 readr 和 datatable，对比了它们的特点和适用场景，学习了 R 的基本数据类型和常用统计函数，并初步掌握了 dplyr 包的基本用法。 数据导入、数据类型、统计函数和 dplyr 是 R 语言数据分析的基础，务必熟练掌握本周所学内容。\n下周预告: 下周我们将继续深入学习 dplyr 包，学习更高级的数据操作技巧，例如，多表连接 (join)、数据变形 (reshape)、窗口函数 (window function) 等。 dplyr 是数据清洗和预处理的利器，下周我们将重点学习如何使用 dplyr 进行高效的数据清洗和预处理。\n\n\n\n7. 课后任务\n\n小组任务:\n\n继续项目一数据探索: 各小组继续使用 R 语言导入和探索项目一的数据集，尝试使用 readr 或 datatable 包导入数据，并使用本周学习的 R 基础知识和 dplyr 包进行初步的数据查看和理解。\n小组讨论数据清洗方案: 小组讨论项目一的数据清洗和预处理方案，为下周的数据清洗任务做好准备。\n\n个人任务:\n\n复习本周内容: 回顾本周讲义和课堂笔记，巩固 readr 和 datatable 包的用法、R 基本数据类型、常用统计函数和 dplyr 基础用法。\nR 代码练习: 完成本讲义中布置的 R 代码练习，熟练掌握 readr, datatable, R 基础函数和 dplyr 包的常用函数。 尝试使用 AI 插件辅助 R 代码练习。\nflights 数据集练习: 使用 flights 数据集，练习使用 readr 和 datatable 进行数据导入导出，练习使用 R 基本数据类型和统计函数，练习使用 dplyr 包进行数据操作。 可以尝试完成讲义中提供的练习题，也可以自己设计练习题。\n\n\n\n\n\n\n\n\nAI 辅助学习小贴士\n\n\n\n\nR 代码练习: 继续在 VS Code 或 Cursor 中练习 R 语言代码，充分利用 AI 插件的代码自动补全、代码生成、代码解释、AI 聊天等功能。 遇到 R 代码问题，及时向 AI 提问。\n数据包使用问题: 如果在使用 readr, datatable, dplyr 等数据包时遇到问题，可以查阅包的官方文档，或者使用 AI 聊天提问，寻求帮助。\n统计概念理解: 如果对某些统计概念 (例如，均值、中位数、标准差、相关系数等) 理解不透彻，可以使用 AI 聊天提问，让 AI 提供更详细的解释和例子。\n代码效率优化: 如果希望提高 R 代码的运行效率，可以尝试使用 datatable 包，或者使用 AI 聊天咨询代码优化技巧。\n\n\n\n\n\n\n\n\n\n学习寄语\n\n\n\n工欲善其事，必先利其器！ 本周我们学习了 R 语言数据导入和数据处理的利器，为后续的数据分析打下了坚实的基础。 熟练掌握这些工具，您将能够更高效地进行数据分析！ 继续保持学习的热情，充分利用 VS Code/Cursor 和 AI 插件的强大功能，相信大家会在统计学和 R 语言的学习中取得更大的进步！ 下周见！",
    "crumbs": [
      "课程内容",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>统计学讲义 - 第二周：R语言数据导入与常用数据包</span>"
    ]
  },
  {
    "objectID": "week03.html",
    "href": "week03.html",
    "title": "第三周：描述性统计：数据探索与可视化",
    "section": "",
    "text": "用数据讲故事：描述性统计与可视化\n前两周我们学习了统计学基本概念、R 语言入门、数据获取和数据导入。 从本周开始，我们将进入数据分析的核心环节：描述性统计。 描述性统计是数据分析的第一步，也是至关重要的一步。 通过描述性统计，我们可以探索数据的基本特征、发现数据中的模式和规律、为后续的推断性统计分析奠定基础。 本周我们将学习使用 dplyr 和 tidyr 包进行数据清洗和预处理的进阶操作，并学习使用强大的 ggplot2 包进行数据可视化，将数据转化为直观、易懂的图表，用数据讲故事！\n继续使用 VS Code 或 Cursor + AI 插件： 请继续使用 VS Code 或 Cursor 编辑器，并充分利用 AI 插件的代码辅助、智能提示、聊天问答等功能，提升学习效率。\n\n\n\n\n\n\n本周学习目标\n\n\n\n\n描述性统计核心概念: 理解描述性统计的目的和常用方法。\ndplyr 数据清洗进阶: 掌握 dplyr 包更高级的数据清洗和预处理技巧。\ntidyr 数据整理: 学习使用 tidyr 包进行数据整理，转换数据结构。\nggplot2 数据可视化入门: 掌握 ggplot2 包的基本语法，绘制常用统计图表 (直方图、散点图、箱线图等)。\ntidyverse 综合应用: 学习 tidyverse 生态的数据处理和可视化流程。\n数据探索实践: 使用 R 和 tidyverse 工具，对实际数据集进行数据探索和可视化分析。\nAI 辅助数据分析: 继续探索使用 AI 工具辅助数据清洗、预处理和可视化。\n\n\n\n\n\n\n1. 描述性统计核心概念回顾与拓展\n\n描述性统计的目的:\n\n概括数据特征: 用简洁的数值或图表，描述数据集的中心趋势 (均值、中位数、众数)、离散程度 (标准差、方差、四分位距)、分布形状 (偏度、峰度) 等特征。\n发现数据模式: 通过统计图表，直观地展示数据分布、变量关系、群体差异 等模式和规律。\n数据质量评估: 检查数据中是否存在异常值、缺失值、错误值 等问题，评估数据质量。\n为推断性统计做准备: 描述性统计的结果可以帮助我们选择合适的推断性统计方法、提出研究假设。\n\n常用描述性统计量:\n\n中心趋势:\n\n均值 (Mean): 所有数据的平均值，对异常值敏感。 R 函数: mean()\n中位数 (Median): 将数据排序后，位于中间位置的值，对异常值不敏感。 R 函数: median()\n众数 (Mode): 数据集中出现次数最多的值。 R 中没有直接计算众数的函数，可以自定义函数或使用 table() 和 sort() 函数组合计算。\n\n离散程度:\n\n标准差 (Standard Deviation): 度量数据分散程度的常用指标，反映数据值偏离均值的平均程度。 R 函数: sd()\n方差 (Variance): 标准差的平方。 R 函数: var()\n四分位距 (Interquartile Range, IQR): 第三四分位数 (Q3) 与第一四分位数 (Q1) 之差，反映中间 50% 数据的离散程度，对异常值不敏感。 R 函数: IQR()\n极差 (Range): 最大值与最小值之差，对异常值非常敏感。 R 函数: range() (返回最小值和最大值), diff(range()) 计算极差。\n\n分布形状:\n\n偏度 (Skewness): 描述数据分布的对称性。 偏度 &gt; 0 为右偏 (正偏)，偏度 &lt; 0 为左偏 (负偏)，偏度 ≈ 0 为对称分布。 R 中 e1071 包的 skewness() 函数可以计算偏度。\n峰度 (Kurtosis): 描述数据分布的尖峭程度。 峰度 &gt; 3 为尖峰分布，峰度 &lt; 3 为平峰分布，峰度 ≈ 3 为正态分布 (峰度为 3)。 R 中 e1071 包的 kurtosis() 函数可以计算峰度。\n\n\n常用描述性统计图表:\n\n直方图 (Histogram): 展示数值型变量的分布情况，X 轴表示数值范围，Y 轴表示频数或频率。 ggplot2 函数: geom_histogram()\n箱线图 (Boxplot): 展示数值型变量的分布、中位数、四分位数、异常值 等信息，方便比较不同组别的数据分布。 ggplot2 函数: geom_boxplot()\n散点图 (Scatter Plot): 展示两个数值型变量之间的关系，X 轴和 Y 轴分别表示两个变量，每个点代表一个观测值。 ggplot2 函数: geom_point()\n条形图 (Bar Chart): 展示分类变量的频数或频率，X 轴表示分类，Y 轴表示计数或比例。 ggplot2 函数: geom_bar() 或 geom_col() (当 Y 轴数据已汇总时使用 geom_col())\n饼图 (Pie Chart): 展示分类变量的占比，不推荐过度使用，条形图通常更清晰。 ggplot2 中绘制饼图较为复杂，可以使用其他包或方法。\n折线图 (Line Chart): 展示时间序列数据的趋势，X 轴通常表示时间，Y 轴表示数值。 ggplot2 函数: geom_line()\n\n选择合适的描述性统计方法: 根据变量类型和分析目的选择合适的描述性统计方法。\n\n数值型变量: 常用均值、中位数、标准差、方差、四分位距、直方图、箱线图、散点图等。\n分类变量: 常用频数、频率、百分比、条形图、饼图等。\n探索变量关系: 常用散点图、相关系数 (数值型变量之间), 分组箱线图/条形图 (分类变量与数值型变量之间), 交叉表 (分类变量之间)。\n数据质量评估: 常用缺失值统计、异常值检测 (箱线图、散点图)、描述性统计量 (检查数据范围和分布是否合理)。\n\n\n\n\n2. dplyr 数据清洗和预处理进阶\n\n回顾 dplyr 基础: 回顾上周学习的 dplyr 基础 “动词”： filter(), select(), mutate(), arrange(), summarize(), group_by(), %&gt;% 管道操作符。\ndplyr 数据清洗常用技巧:\n\n处理缺失值:\n\nfilter(!is.na(列名)): 删除包含缺失值的行。 !is.na() 返回逻辑值，TRUE 表示非缺失值，FALSE 表示缺失值，! 表示取反。\nmutate(新列名 = ifelse(is.na(列名), 替换值, 列名)): 用指定值 (例如，均值、中位数、0、特定值) 替换缺失值。 ifelse() 函数是条件赋值函数，ifelse(条件, 真值, 假值)。\ntidyr::replace_na(list(列名 = 替换值)): 使用 tidyr 包的 replace_na() 函数替换缺失值，语法更简洁。\n\n处理重复值:\n\ndistinct(): 删除完全重复的行。\ndistinct(列名1, 列名2, ...): 根据指定的列组合删除重复行，保留第一次出现的行。\nduplicated(): 检测重复值，返回逻辑向量，TRUE 表示重复值，FALSE 表示非重复值。 常与 filter() 函数结合使用，筛选或删除重复值。\n\n处理异常值:\n\n箱线图可视化: 使用箱线图识别可能的异常值 (超出箱线图 “须” 的点)。\n基于标准差的方法: 例如，将超出均值 ± 3 倍标准差范围的值视为异常值。\n基于 IQR 的方法: 例如，将小于 Q1 - 1.5 * IQR 或大于 Q3 + 1.5 * IQR 的值视为异常值 (箱线图的 “须” 的计算方法)。\n根据业务知识判断: 结合实际业务背景和数据含义，判断哪些值是合理的，哪些值可能是异常的。\n处理异常值的方法: 删除异常值、替换为缺失值、替换为合理值 (例如，均值、 Winsorize 处理)、保留异常值 (如果异常值本身包含重要信息)。\n\n数据类型转换:\n\nmutate(列名 = as.类型(列名)): 使用 as.类型() 函数转换列的数据类型。 例如，as.character(), as.numeric(), as.integer(), as.logical(), as.factor(), as.Date(), as.POSIXct() 等。\nreadr::parse_类型(列名): 使用 readr 包的 parse_类型() 函数进行类型转换，更严格和规范。 例如，parse_character(), parse_double(), parse_integer(), parse_logical(), parse_factor(), parse_date(), parse_datetime(), parse_time(), parse_number(), parse_currency()。\n字符数据处理:\n\nstringr 包: tidyverse 的 stringr 包专门用于字符数据处理，提供了丰富的字符串操作函数，例如，字符串拼接、分割、提取、替换、大小写转换、去除空格、模式匹配 (正则表达式) 等。 常用的 stringr 函数包括： str_c(), str_split(), str_sub(), str_replace(), str_to_lower(), str_to_upper(), str_trim(), str_detect(), str_extract(), str_match() 等。\n示例:\nlibrary(dplyr)\nlibrary(stringr)\n\ndata &lt;- tibble(\n  name = c(\"  John Doe  \", \"Jane Smith\", \"Peter-Pan \", \"Alice_Wonderland\"),\n  city_state = c(\"New York, NY\", \"Los Angeles, CA\", \"London, UK\", \"Paris, FR\")\n)\n\ncleaned_data &lt;- data %&gt;%\n  mutate(\n    name_trimmed = str_trim(name),  # 去除姓名两端空格\n    name_upper = str_to_upper(name_trimmed),  # 姓名转换为大写\n    first_name = str_split_fixed(name_trimmed, \" \", n = 2)[, 1],  # 提取 first name\n    last_name = str_split_fixed(name_trimmed, \" \", n = 2)[, 2],  # 提取 last name\n    city = str_split_fixed(city_state, \", \", n = 2)[, 1],  # 提取城市\n    state_country = str_split_fixed(city_state, \", \", n = 2)[, 2]  # 提取州/国家\n  ) %&gt;%\n  select(-name, -city_state)  # 删除原始列\n\nprint(cleaned_data)\n\n\n\ndplyr 进阶操作:\n\n条件型数据转换 (case_when()): case_when() 函数可以根据多个条件进行赋值，类似于 if-else if-else 结构，但语法更简洁，可读性更高。 r     data_with_category &lt;- data %&gt;%       mutate(         category = case_when(           value &lt; 10 ~ \"Low\",           value &gt;= 10 & value &lt; 50 ~ \"Medium\",           value &gt;= 50 ~ \"High\",           TRUE ~ \"Unknown\"  # 默认情况，类似于 else         )       )\n窗口函数 (window functions): 窗口函数可以在分组数据上进行计算，例如，计算每个分组内的排名、累计值、移动平均值等。 dplyr 提供了 row_number(), rank(), dense_rank(), percent_rank(), lead(), lag(), cumsum(), cummean(), cummax(), cummin() 等窗口函数。 窗口函数通常与 group_by() 和 mutate() 函数结合使用。 r     data_with_rank &lt;- data %&gt;%       group_by(group_col) %&gt;%       mutate(         rank_within_group = rank(value),  # 计算组内排名         cumulative_sum = cumsum(value)  # 计算组内累计和       ) %&gt;%       ungroup()  # 取消分组，后续操作不再分组\n\ndplyr 数据清洗练习: 使用 flights 数据集或其他数据集，练习使用 dplyr 进行数据清洗和预处理，例如：\n\n处理 flights 数据集中的缺失值 (例如，dep_delay, arr_delay, air_time 等列可能存在缺失值)。\n检测和处理 flights 数据集中的异常值 (例如，dep_delay, arr_delay, distance 等列可能存在异常值)。\n将 flights 数据集中的航空公司代码 carrier 转换为航空公司名称 (可以使用 航空公司代码-名称 对照表，进行 join 操作，下周学习 join)。\n使用 stringr 包处理 flights 数据集中的字符型数据 (如果存在)。\n使用 case_when() 函数创建新的分类变量 (例如，根据 dep_delay 将航班分为 “准点”, “轻微延误”, “严重延误” 等类别)。\n使用窗口函数计算每个航空公司的航班数量排名、平均延误时间排名等。\n\n\n\n\n3. tidyr 数据整理：数据变形\n\ntidyr 包的目的: tidyr 包是 tidyverse 生态中专门用于数据整理 (data tidying) 的包。 数据整理的目标是将数据转换为整洁数据 (tidy data) 格式，方便后续的数据分析和可视化。 整洁数据 的核心原则是：\n\n每个变量占一列 (Each variable forms a column).\n每个观测值占一行 (Each observation forms a row).\n每个值自成一个单元格 (Each value forms a cell).\n\ntidyr 数据变形常用函数:\n\npivot_longer() (长数据透视): 将宽格式 (wide format) 数据转换为长格式 (long format) 数据。 宽格式数据中，一个观测值的多个变量可能分布在多列中，长格式数据则将这些变量 “堆叠” 成一列，并使用另一列标识变量名。 pivot_longer() 函数可以将指定的多列 “透视” 成两列：变量名列 (name column) 和 值列 (value column)。\n# 宽格式数据示例\nwide_data &lt;- tibble(\n  id = 1:3,\n  var1_2020 = c(10, 12, 15),\n  var2_2020 = c(20, 25, 30),\n  var1_2021 = c(11, 13, 16),\n  var2_2021 = c(22, 27, 33)\n)\n\n# 使用 pivot_longer() 转换为长格式\nlong_data &lt;- wide_data %&gt;%\n  pivot_longer(\n    cols = starts_with(\"var\"),  # 指定要透视的列，使用 starts_with() 选择以 \"var\" 开头的列\n    names_to = c(\"variable\", \"year\"),  # 指定变量名列和年份列的名称\n    names_sep = \"_\",  # 指定列名分隔符 \"_\"\n    values_to = \"value\"  # 指定值列的名称\n  )\n\nprint(long_data)\n\ncols 参数: 指定要透视的列。 可以使用列名向量、列索引向量、列名选择函数 (例如 starts_with(), ends_with(), contains(), matches(), num_range(), everything(), last_col()) 等。\nnames_to 参数: 指定透视后的变量名列的名称。 可以传入一个字符向量，指定变量名列的名称，如果 names_sep 或 names_pattern 参数被使用，则 names_to 可以传入多个名称，表示将列名拆分成多列。\nnames_sep 参数: 指定列名分隔符。 如果列名包含多个信息，可以使用分隔符将列名拆分成多列。\nnames_pattern 参数: 使用正则表达式匹配列名，并将匹配到的部分拆分成多列。 names_sep 和 names_pattern 只能使用一个。\nvalues_to 参数: 指定透视后的值列的名称。\n\npivot_wider() (宽数据透视): 将长格式 (long format) 数据转换为宽格式 (wide format) 数据。 pivot_wider() 是 pivot_longer() 的逆操作。 pivot_wider() 函数需要指定哪一列作为新的列名 (names_from)，哪一列作为新的值 (values_from)。\n# 长格式数据示例 (上例中的 long_data)\nlong_data &lt;- tibble(\n  id = rep(1:3, each = 4),\n  variable = rep(c(\"var1\", \"var2\"), each = 2, times = 3),\n  year = rep(rep(c(\"2020\", \"2021\"), each = 1), times = 6),\n  value = c(10, 20, 12, 25, 15, 30, 11, 22, 13, 27, 16, 33)\n)\n\n# 使用 pivot_wider() 转换为宽格式\nwide_data_reconstructed &lt;- long_data %&gt;%\n  pivot_wider(\n    names_from = c(\"variable\", \"year\"),  # 指定列名来源列，这里使用 variable 和 year 两列组合作为新列名\n    values_from = \"value\"  # 指定值来源列\n  )\n\nprint(wide_data_reconstructed)\n\nnames_from 参数: 指定列名来源列。 可以使用列名向量，指定一列或多列作为新列名的来源。 如果指定多列，则新列名将由这些列的值组合而成。\nvalues_from 参数: 指定值来源列。 可以使用列名向量，指定一列或多列作为新值的来源。 如果 names_from 指定了多列，values_from 也应该指定相同数量的列，或者只指定一列，表示所有新列的值都来自同一列。\n\nseparate() (列分割): 将一列按照指定的分隔符分割成多列。 separate() 函数类似于 stringr::str_split_fixed() 函数，但 separate() 直接操作数据框列，更方便。\ndata_with_combined_col &lt;- tibble(\n  combined_col = c(\"A-1\", \"B-2\", \"C-3\")\n)\n\nseparated_data &lt;- data_with_combined_col %&gt;%\n  separate(\n    col = combined_col,  # 指定要分割的列\n    into = c(\"col1\", \"col2\"),  # 指定分割后的新列名\n    sep = \"-\"  # 指定分隔符 \"-\"\n  )\n\nprint(separated_data)\n\ncol 参数: 指定要分割的列名。\ninto 参数: 指定分割后的新列名。 传入一个字符向量，指定新列的名称。\nsep 参数: 指定分隔符。 可以使用字符或正则表达式作为分隔符。\n\nunite() (列合并): 将多列合并成一列，并使用指定的分隔符连接。 unite() 是 separate() 的逆操作。\nseparated_data &lt;- tibble(\n  col1 = c(\"A\", \"B\", \"C\"),\n  col2 = c(\"1\", \"2\", \"3\")\n)\n\nunited_data &lt;- separated_data %&gt;%\n  unite(\n    col = combined_col,  # 指定合并后的新列名\n    col1, col2,  # 指定要合并的列\n    sep = \"-\"  # 指定分隔符 \"-\"\n  )\n\nprint(united_data)\n\ncol 参数: 指定合并后的新列名。\n... 参数: 使用 ... 传入要合并的列名，可以传入多个列名。\nsep 参数: 指定分隔符。\n\n\ntidyr 数据整理练习: 使用 flights 数据集或其他数据集，练习使用 tidyr 进行数据整理，例如：\n\n将 flights 数据集转换为长格式，例如，将 dep_delay 和 arr_delay 两列透视为一列 delay_type (取值为 “dep_delay” 或 “arr_delay”) 和一列 delay_time (延误时间)。\n将宽格式的数据 (例如，包含多年份数据的表格) 转换为长格式，方便进行时间序列分析或面板数据分析。\n分割包含复合信息的列，例如，将日期时间列分割成日期列和时间列，将地址列分割成城市列、州列、国家列等。\n合并多列信息，例如，将年、月、日列合并成日期列，将姓、名列合并成姓名列。\n\n\n\n\n4. ggplot2 数据可视化初步：常用图表\n\nggplot2 包简介: ggplot2 包是 R 语言中最强大、最灵活、最流行的数据可视化包，也是 tidyverse 生态的核心包之一。 ggplot2 基于图层语法 (grammar of graphics)，将数据可视化分解为多个独立的图层，用户可以灵活组合这些图层，创建各种复杂的统计图表。 ggplot2 的特点包括：\n\n图层语法: 基于图层语法，灵活、强大、可扩展。\n美观的默认样式: 默认生成的图表美观、专业。\n高度定制化: 可以高度定制图表的各个方面，例如，颜色、形状、大小、标签、标题、主题等。\n与 tidyverse 完美集成: 与 dplyr, tidyr 等 tidyverse 包无缝衔接，数据处理和可视化流程流畅。\n\nggplot2 基本语法: ggplot2 绘图的基本流程是：\n\n创建 ggplot 对象: 使用 ggplot() 函数创建 ggplot 对象，并指定数据 (data) 和映射 (mapping, aes())。 data 参数指定要使用的数据框，mapping 参数使用 aes() 函数指定变量如何映射到图形属性 (aesthetics)，例如，X 轴、Y 轴、颜色、形状、大小、填充等。\n添加几何对象 (geometric objects, geom_xxx()): 使用各种 geom_xxx() 函数添加几何对象图层，例如，geom_point() (散点图), geom_line() (折线图), geom_bar() (条形图), geom_histogram() (直方图), geom_boxplot() (箱线图) 等。 每个 geom_xxx() 函数都对应一种图表类型。 几何对象图层决定了图表的类型和基本形状。\n添加统计变换 (statistical transformations, stat_xxx()): 某些几何对象需要进行统计变换，例如，直方图需要计算频数，条形图需要计算汇总统计量。 ggplot2 会自动进行默认的统计变换，用户也可以使用 stat_xxx() 函数手动指定统计变换。 通常情况下，无需手动添加统计变换图层。\n添加标度 (scales, scale_xxx_yyy()): 标度控制数据值到图形属性的映射方式，例如，X 轴和 Y 轴的刻度范围、颜色标度、形状标度、大小标度等。 ggplot2 会自动使用默认标度，用户可以使用 scale_xxx_yyy() 函数自定义标度，例如，scale_x_continuous(), scale_y_continuous(), scale_color_manual(), scale_shape_manual(), scale_size_continuous() 等。\n添加坐标系 (coordinate systems, coord_xxx()): 坐标系控制图表的坐标轴类型和方向，例如，笛卡尔坐标系 (默认), 极坐标系, 地理坐标系等。 ggplot2 默认使用笛卡尔坐标系，用户可以使用 coord_xxx() 函数自定义坐标系，例如，coord_cartesian(), coord_polar(), coord_map() 等。\n添加分面 (faceting, facet_xxx()): 分面可以将图表分割成多个子图，按照一个或多个分类变量进行分组，方便比较不同组别的数据。 ggplot2 提供了 facet_wrap() (单变量分面) 和 facet_grid() (双变量分面) 函数。\n添加主题 (themes, theme()): 主题控制图表的整体外观样式，例如，背景颜色、网格线、字体、标题位置、图例样式等。 ggplot2 提供了多种内置主题 (例如 theme_bw(), theme_minimal(), theme_classic())，用户也可以使用 theme() 函数自定义主题。\n添加标签、标题等 (labels, titles, etc., labs(), ggtitle(), xlab(), ylab(), caption()): 使用 labs() 函数添加标签 (例如，X 轴标签、Y 轴标签、颜色图例标签、形状图例标签等), 使用 ggtitle() 函数添加主标题, 使用 xlab() 和 ylab() 函数分别添加 X 轴和 Y 轴标签, 使用 caption() 函数添加图表脚注。\n\n常用 ggplot2 图表类型示例 (使用 flights 数据集):\n\n直方图 (Histogram): 展示 dep_delay 出发延误时间的分布。\nlibrary(ggplot2)\n\nggplot(flights, aes(x = dep_delay)) +\n  geom_histogram(binwidth = 15)  # binwidth 参数指定组距\n\nggplot(flights, aes(x = dep_delay)): 创建 ggplot 对象，指定数据为 flights 数据框，X 轴映射为 dep_delay 变量。\ngeom_histogram(binwidth = 15): 添加直方图几何对象图层，binwidth = 15 指定组距为 15 分钟。\n\n散点图 (Scatter Plot): 展示 dep_delay 出发延误时间与 arr_delay 到达延误时间的关系。 r     ggplot(flights, aes(x = dep_delay, y = arr_delay)) +       geom_point()\n\nggplot(flights, aes(x = dep_delay, y = arr_delay)): 创建 ggplot 对象，指定 X 轴映射为 dep_delay，Y 轴映射为 arr_delay。\ngeom_point(): 添加散点图几何对象图层。\n\n箱线图 (Boxplot): 比较不同航空公司 carrier 的 arr_delay 到达延误时间分布。 r     ggplot(flights, aes(x = carrier, y = arr_delay)) +       geom_boxplot()\n\nggplot(flights, aes(x = carrier, y = arr_delay)): 创建 ggplot 对象，指定 X 轴映射为 carrier (分类变量), Y 轴映射为 arr_delay (数值型变量)。\ngeom_boxplot(): 添加箱线图几何对象图层。\n\n条形图 (Bar Chart): 展示不同航空公司 carrier 的航班数量。 r     ggplot(flights, aes(x = carrier)) +       geom_bar()\n\nggplot(flights, aes(x = carrier)): 创建 ggplot 对象，只指定 X 轴映射为 carrier。 geom_bar() 默认统计每个分类的频数。\ngeom_bar(): 添加条形图几何对象图层。\n\n添加颜色、形状、大小等图形属性: 可以使用 aes() 函数在 geom_xxx() 函数内部或 ggplot() 函数内部指定额外的图形属性映射，例如，使用 color 映射颜色, shape 映射形状, size 映射大小, fill 映射填充颜色等。\n# 散点图，使用 color 映射航空公司 carrier\nggplot(flights, aes(x = dep_delay, y = arr_delay, color = carrier)) +\n  geom_point()\n\n# 散点图，使用 size 映射飞行距离 distance\nggplot(flights, aes(x = dep_delay, y = arr_delay, size = distance)) +\n  geom_point()\n添加标题、标签、主题: r     ggplot(flights, aes(x = dep_delay, y = arr_delay, color = carrier)) +       geom_point() +       labs(title = \"出发延误 vs 到达延误\",  # 主标题            subtitle = \"按航空公司着色\",  # 副标题            x = \"出发延误时间 (分钟)\",  # X 轴标签            y = \"到达延误时间 (分钟)\",  # Y 轴标签            color = \"航空公司\",  # 颜色图例标签            caption = \"数据来源：nycflights13 包\") +  # 图表脚注       theme_bw()  # 使用黑白主题\n\nggplot2 可视化练习: 使用 flights 数据集或其他数据集，练习使用 ggplot2 绘制各种常用统计图表，并尝试自定义图表的各个方面，例如：\n\n绘制 flights 数据集 distance 飞行距离的直方图，并尝试调整 binwidth 参数。\n绘制 flights 数据集 air_time 飞行时间的箱线图，按照出发机场 origin 分组。\n绘制 flights 数据集 dep_delay 与 arr_delay 的散点图，并使用颜色或形状映射航空公司 carrier。\n绘制 flights 数据集航空公司 carrier 的条形图，并添加航班数量标签。\n尝试修改图表的标题、标签、颜色、主题等，使图表更美观、更易读。\n\n\n\n\n5. tidyverse 生态综合应用：数据处理与可视化流程\n\ntidyverse 数据分析流程: tidyverse 生态提供了一套完整的数据分析流程，包括：\n\n数据导入 (readr, datatable): 使用 readr 或 datatable 包读取各种数据格式的文件。\n数据整理 (tidyr): 使用 tidyr 包将数据转换为整洁数据格式。\n数据清洗和预处理 (dplyr, stringr): 使用 dplyr 和 stringr 包进行数据清洗、缺失值处理、异常值处理、数据类型转换、字符数据处理等。\n数据探索和描述性统计 (dplyr): 使用 dplyr 包进行数据汇总、分组统计、计算描述性统计量。\n数据可视化 (ggplot2): 使用 ggplot2 包绘制各种统计图表，探索数据模式、展示分析结果。\n数据建模和推断性统计 (后续课程): 使用 R 的统计建模和推断性统计功能进行更深入的数据分析 (本周不涉及)。\n结果沟通和报告 (后续课程): 将数据分析结果整理成报告、幻灯片、交互式应用等形式，进行有效沟通 (本周不涉及)。\n\ntidyverse 流程示例 (使用 flights 数据集): 以分析不同航空公司的平均延误时间为例，演示 tidyverse 数据处理和可视化流程。\nlibrary(tidyverse)\nlibrary(nycflights13)\n\n# 1. 数据导入 (flights 数据集已加载到 nycflights13 包中，无需额外导入)\n\n# 2. 数据整理 (flights 数据集已经是整洁数据格式，无需整理)\n\n# 3. 数据清洗和预处理 (简单处理缺失值，移除到达延误时间为缺失值的航班)\nflights_cleaned &lt;- flights %&gt;%\n  filter(!is.na(arr_delay))\n\n# 4. 数据探索和描述性统计 (按照航空公司分组，计算平均到达延误时间)\ncarrier_delay_summary &lt;- flights_cleaned %&gt;%\n  group_by(carrier) %&gt;%\n  summarize(mean_delay = mean(arr_delay)) %&gt;%\n  arrange(desc(mean_delay))  # 按照平均延误时间降序排序\n\nprint(carrier_delay_summary)\n\n# 5. 数据可视化 (绘制条形图，展示不同航空公司的平均到达延误时间)\nggplot(carrier_delay_summary, aes(x = carrier, y = mean_delay)) +\n  geom_col(fill = \"steelblue\") +  # 柱形图，填充颜色为 steelblue\n  geom_text(aes(label = round(mean_delay, 1)),  # 添加文本标签，显示平均延误时间，保留一位小数\n            vjust = -0.5) +  # 标签垂直位置微调\n  labs(title = \"不同航空公司平均到达延误时间\",\n       x = \"航空公司代码\",\n       y = \"平均到达延误时间 (分钟)\") +\n  theme_minimal()  # 使用 minimal 主题\ntidyverse 综合练习: 选择一个实际数据集 (例如，flights 数据集、项目一的数据集或其他公开数据集)，使用 tidyverse 生态的 readr, tidyr, dplyr, stringr, ggplot2 包，完成一个完整的数据分析和可视化项目，包括数据导入、数据整理、数据清洗、数据预处理、描述性统计分析、数据可视化、结果解释和报告撰写 (报告撰写为可选，重点练习数据处理和可视化)。\n\n\n\n6. 本周内容总结与下周预告\n\n本周回顾: 回顾本周学习内容，巩固重点知识。 本周我们深入学习了描述性统计的核心概念，dplyr 数据清洗和预处理进阶技巧，tidyr 数据整理方法，ggplot2 数据可视化初步，以及 tidyverse 生态的综合应用。 描述性统计、数据清洗、数据整理和数据可视化是数据分析的关键技能，务必熟练掌握本周所学内容。\n下周预告: 下周我们将继续深入学习 ggplot2 包，学习更高级的数据可视化技巧，例如，多图层组合、图形精细调整、交互式图表制作等。 我们将探索更多 ggplot2 的几何对象、统计变换、标度、坐标系、分面、主题等，打造更专业、更精美、更具洞察力的数据可视化作品。\n\n\n\n7. 课后任务\n\n小组任务:\n\n项目一数据清洗和预处理: 各小组根据本周学习的数据清洗和预处理方法，使用 dplyr 和 tidyr 包对项目一的数据集进行数据清洗和预处理。 完成缺失值处理、异常值处理、数据类型转换、数据整理等任务，确保数据质量和整洁性，为后续的数据分析和可视化做好准备。\n项目一数据可视化方案: 小组讨论项目一的数据可视化方案，确定要展示的数据特征和模式，选择合适的图表类型，设计图表布局和样式。\n\n个人任务:\n\n复习本周内容: 回顾本周讲义和课堂笔记，巩固描述性统计概念、dplyr 数据清洗技巧、tidyr 数据整理方法、ggplot2 可视化语法和常用图表类型。\nR 代码练习: 完成本讲义中布置的 R 代码练习，熟练掌握 dplyr, tidyr, stringr, ggplot2 包的常用函数。 尝试使用 AI 插件辅助 R 代码练习。\n数据集可视化探索: 选择 flights 数据集或项目一的数据集，使用 ggplot2 包进行数据可视化探索，尝试绘制各种图表，并自定义图表样式，深入理解数据特征和模式。 可以尝试完成讲义中提供的练习题，也可以自己设计可视化探索任务。\n\n\n\n\n\n\n\n\nAI 辅助学习小贴士\n\n\n\n\nR 代码练习: 继续在 VS Code 或 Cursor 中练习 R 语言代码，充分利用 AI 插件的代码自动补全、代码生成、代码解释、AI 聊天等功能。 遇到 R 代码问题，及时向 AI 提问。\n数据包使用问题: 如果在使用 dplyr, tidyr, stringr, ggplot2 等数据包时遇到问题，可以查阅包的官方文档，或者使用 AI 聊天提问，寻求帮助。\n\ndplyr 数据清洗技巧: 例如，如何使用 filter() 筛选满足多个条件的行？ 如何使用 mutate() 创建多个新列？ 如何使用 group_by() 和 summarize() 进行分组汇总统计？\ntidyr 数据整理方法: 例如，pivot_longer() 和 pivot_wider() 函数的参数如何设置？ separate() 和 unite() 函数如何使用？ 如何将复杂格式的数据转换为整洁数据？\nggplot2 可视化语法: 例如，ggplot() 和 aes() 函数如何使用？ 各种 geom_xxx() 函数的作用是什么？ 如何添加标题、标签、主题？ 如何自定义图表样式？\n\n统计图表选择: 如果不确定使用哪种图表类型来展示数据，可以通过AI聊天工具寻求建议。例如，可以提问：“哪种图表适合比较多个组的分布情况？” 或 “如何可视化两个数值变量之间的关系？”。AI不仅会推荐合适的图表类型，还会提供相应的ggplot2代码示例。\n可视化代码生成: 使用 AI 代码生成功能，输入注释，例如： # 使用 ggplot2 创建价格的直方图, # 使用 ggplot2 创建 'x' 和 'y' 的散点图，并按 'category' 着色, 让 AI 生成可视化代码。\n代码解释和优化: 使用 AI 代码解释功能，选中 tidyverse 代码片段，让 AI 解释代码的功能和每一行代码的作用。 如果代码运行效率较低，可以使用 AI 聊天咨询代码优化技巧。\n\n\n\n\n\n\n\n\n\n学习寄语\n\n\n\n图表胜千言！ 本周我们学习了描述性统计和数据可视化的核心技能，掌握了用数据讲故事的能力。 精美、清晰、有洞察力的图表是数据分析的灵魂！ 继续保持学习的热情，充分利用 VS Code/Cursor 和 AI 插件的强大功能，相信大家会在统计学和 R 语言的学习中取得更大的进步！ 下周见！",
    "crumbs": [
      "课程内容",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>第三周：描述性统计：数据探索与可视化</span>"
    ]
  },
  {
    "objectID": "week03.html#第三周描述性统计数据探索与可视化-共4课时",
    "href": "week03.html#第三周描述性统计数据探索与可视化-共4课时",
    "title": "统计学讲义 - 第三周：描述性统计：数据探索与可视化",
    "section": "",
    "text": "用数据讲故事：描述性统计与可视化\n前两周我们学习了统计学基本概念、R 语言入门、数据获取和数据导入。 从本周开始，我们将进入数据分析的核心环节：描述性统计。 描述性统计是数据分析的第一步，也是至关重要的一步。 通过描述性统计，我们可以探索数据的基本特征、发现数据中的模式和规律、为后续的推断性统计分析奠定基础。 本周我们将学习使用 dplyr 和 tidyr 包进行数据清洗和预处理的进阶操作，并学习使用强大的 ggplot2 包进行数据可视化，将数据转化为直观、易懂的图表，用数据讲故事！\n继续使用 VS Code 或 Cursor + AI 插件： 请继续使用 VS Code 或 Cursor 编辑器，并充分利用 AI 插件的代码辅助、智能提示、聊天问答等功能，提升学习效率。\n\n\n\n\n\n\n本周学习目标\n\n\n\n\n描述性统计核心概念: 理解描述性统计的目的和常用方法。\ndplyr 数据清洗进阶: 掌握 dplyr 包更高级的数据清洗和预处理技巧。\ntidyr 数据整理: 学习使用 tidyr 包进行数据整理，转换数据结构。\nggplot2 数据可视化入门: 掌握 ggplot2 包的基本语法，绘制常用统计图表 (直方图、散点图、箱线图等)。\ntidyverse 综合应用: 学习 tidyverse 生态的数据处理和可视化流程。\n数据探索实践: 使用 R 和 tidyverse 工具，对实际数据集进行数据探索和可视化分析。\nAI 辅助数据分析: 继续探索使用 AI 工具辅助数据清洗、预处理和可视化。\n\n\n\n\n\n\n1. 描述性统计核心概念回顾与拓展\n\n描述性统计的目的:\n\n概括数据特征: 用简洁的数值或图表，描述数据集的中心趋势 (均值、中位数、众数)、离散程度 (标准差、方差、四分位距)、分布形状 (偏度、峰度) 等特征。\n发现数据模式: 通过统计图表，直观地展示数据分布、变量关系、群体差异 等模式和规律。\n数据质量评估: 检查数据中是否存在异常值、缺失值、错误值 等问题，评估数据质量。\n为推断性统计做准备: 描述性统计的结果可以帮助我们选择合适的推断性统计方法、提出研究假设。\n\n常用描述性统计量:\n\n中心趋势:\n\n均值 (Mean): 所有数据的平均值，对异常值敏感。 R 函数: mean()\n中位数 (Median): 将数据排序后，位于中间位置的值，对异常值不敏感。 R 函数: median()\n众数 (Mode): 数据集中出现次数最多的值。 R 中没有直接计算众数的函数，可以自定义函数或使用 table() 和 sort() 函数组合计算。\n\n离散程度:\n\n标准差 (Standard Deviation): 度量数据分散程度的常用指标，反映数据值偏离均值的平均程度。 R 函数: sd()\n方差 (Variance): 标准差的平方。 R 函数: var()\n四分位距 (Interquartile Range, IQR): 第三四分位数 (Q3) 与第一四分位数 (Q1) 之差，反映中间 50% 数据的离散程度，对异常值不敏感。 R 函数: IQR()\n极差 (Range): 最大值与最小值之差，对异常值非常敏感。 R 函数: range() (返回最小值和最大值), diff(range()) 计算极差。\n\n分布形状:\n\n偏度 (Skewness): 描述数据分布的对称性。 偏度 &gt; 0 为右偏 (正偏)，偏度 &lt; 0 为左偏 (负偏)，偏度 ≈ 0 为对称分布。 R 中 e1071 包的 skewness() 函数可以计算偏度。\n峰度 (Kurtosis): 描述数据分布的尖峭程度。 峰度 &gt; 3 为尖峰分布，峰度 &lt; 3 为平峰分布，峰度 ≈ 3 为正态分布 (峰度为 3)。 R 中 e1071 包的 kurtosis() 函数可以计算峰度。\n\n\n常用描述性统计图表:\n\n直方图 (Histogram): 展示数值型变量的分布情况，X 轴表示数值范围，Y 轴表示频数或频率。 ggplot2 函数: geom_histogram()\n箱线图 (Boxplot): 展示数值型变量的分布、中位数、四分位数、异常值 等信息，方便比较不同组别的数据分布。 ggplot2 函数: geom_boxplot()\n散点图 (Scatter Plot): 展示两个数值型变量之间的关系，X 轴和 Y 轴分别表示两个变量，每个点代表一个观测值。 ggplot2 函数: geom_point()\n条形图 (Bar Chart): 展示分类变量的频数或频率，X 轴表示分类，Y 轴表示计数或比例。 ggplot2 函数: geom_bar() 或 geom_col() (当 Y 轴数据已汇总时使用 geom_col())\n饼图 (Pie Chart): 展示分类变量的占比，不推荐过度使用，条形图通常更清晰。 ggplot2 中绘制饼图较为复杂，可以使用其他包或方法。\n折线图 (Line Chart): 展示时间序列数据的趋势，X 轴通常表示时间，Y 轴表示数值。 ggplot2 函数: geom_line()\n\n选择合适的描述性统计方法: 根据变量类型和分析目的选择合适的描述性统计方法。\n\n数值型变量: 常用均值、中位数、标准差、方差、四分位距、直方图、箱线图、散点图等。\n分类变量: 常用频数、频率、百分比、条形图、饼图等。\n探索变量关系: 常用散点图、相关系数 (数值型变量之间), 分组箱线图/条形图 (分类变量与数值型变量之间), 交叉表 (分类变量之间)。\n数据质量评估: 常用缺失值统计、异常值检测 (箱线图、散点图)、描述性统计量 (检查数据范围和分布是否合理)。\n\n\n\n\n2. dplyr 数据清洗和预处理进阶\n\n回顾 dplyr 基础: 回顾上周学习的 dplyr 基础 “动词”： filter(), select(), mutate(), arrange(), summarize(), group_by(), %&gt;% 管道操作符。\ndplyr 数据清洗常用技巧:\n\n处理缺失值:\n\nfilter(!is.na(列名)): 删除包含缺失值的行。 !is.na() 返回逻辑值，TRUE 表示非缺失值，FALSE 表示缺失值，! 表示取反。\nmutate(新列名 = ifelse(is.na(列名), 替换值, 列名)): 用指定值 (例如，均值、中位数、0、特定值) 替换缺失值。 ifelse() 函数是条件赋值函数，ifelse(条件, 真值, 假值)。\ntidyr::replace_na(list(列名 = 替换值)): 使用 tidyr 包的 replace_na() 函数替换缺失值，语法更简洁。\n\n处理重复值:\n\ndistinct(): 删除完全重复的行。\ndistinct(列名1, 列名2, ...): 根据指定的列组合删除重复行，保留第一次出现的行。\nduplicated(): 检测重复值，返回逻辑向量，TRUE 表示重复值，FALSE 表示非重复值。 常与 filter() 函数结合使用，筛选或删除重复值。\n\n处理异常值:\n\n箱线图可视化: 使用箱线图识别可能的异常值 (超出箱线图 “须” 的点)。\n基于标准差的方法: 例如，将超出均值 ± 3 倍标准差范围的值视为异常值。\n基于 IQR 的方法: 例如，将小于 Q1 - 1.5 * IQR 或大于 Q3 + 1.5 * IQR 的值视为异常值 (箱线图的 “须” 的计算方法)。\n根据业务知识判断: 结合实际业务背景和数据含义，判断哪些值是合理的，哪些值可能是异常的。\n处理异常值的方法: 删除异常值、替换为缺失值、替换为合理值 (例如，均值、 Winsorize 处理)、保留异常值 (如果异常值本身包含重要信息)。\n\n数据类型转换:\n\nmutate(列名 = as.类型(列名)): 使用 as.类型() 函数转换列的数据类型。 例如，as.character(), as.numeric(), as.integer(), as.logical(), as.factor(), as.Date(), as.POSIXct() 等。\nreadr::parse_类型(列名): 使用 readr 包的 parse_类型() 函数进行类型转换，更严格和规范。 例如，parse_character(), parse_double(), parse_integer(), parse_logical(), parse_factor(), parse_date(), parse_datetime(), parse_time(), parse_number(), parse_currency()。\n字符数据处理:\n\nstringr 包: tidyverse 的 stringr 包专门用于字符数据处理，提供了丰富的字符串操作函数，例如，字符串拼接、分割、提取、替换、大小写转换、去除空格、模式匹配 (正则表达式) 等。 常用的 stringr 函数包括： str_c(), str_split(), str_sub(), str_replace(), str_to_lower(), str_to_upper(), str_trim(), str_detect(), str_extract(), str_match() 等。\n示例:\nlibrary(dplyr)\nlibrary(stringr)\n\ndata &lt;- tibble(\n  name = c(\"  John Doe  \", \"Jane Smith\", \"Peter-Pan \", \"Alice_Wonderland\"),\n  city_state = c(\"New York, NY\", \"Los Angeles, CA\", \"London, UK\", \"Paris, FR\")\n)\n\ncleaned_data &lt;- data %&gt;%\n  mutate(\n    name_trimmed = str_trim(name),  # 去除姓名两端空格\n    name_upper = str_to_upper(name_trimmed),  # 姓名转换为大写\n    first_name = str_split_fixed(name_trimmed, \" \", n = 2)[, 1],  # 提取 first name\n    last_name = str_split_fixed(name_trimmed, \" \", n = 2)[, 2],  # 提取 last name\n    city = str_split_fixed(city_state, \", \", n = 2)[, 1],  # 提取城市\n    state_country = str_split_fixed(city_state, \", \", n = 2)[, 2]  # 提取州/国家\n  ) %&gt;%\n  select(-name, -city_state)  # 删除原始列\n\nprint(cleaned_data)\n\n\n\ndplyr 进阶操作:\n\n条件型数据转换 (case_when()): case_when() 函数可以根据多个条件进行赋值，类似于 if-else if-else 结构，但语法更简洁，可读性更高。 r     data_with_category &lt;- data %&gt;%       mutate(         category = case_when(           value &lt; 10 ~ \"Low\",           value &gt;= 10 & value &lt; 50 ~ \"Medium\",           value &gt;= 50 ~ \"High\",           TRUE ~ \"Unknown\"  # 默认情况，类似于 else         )       )\n窗口函数 (window functions): 窗口函数可以在分组数据上进行计算，例如，计算每个分组内的排名、累计值、移动平均值等。 dplyr 提供了 row_number(), rank(), dense_rank(), percent_rank(), lead(), lag(), cumsum(), cummean(), cummax(), cummin() 等窗口函数。 窗口函数通常与 group_by() 和 mutate() 函数结合使用。 r     data_with_rank &lt;- data %&gt;%       group_by(group_col) %&gt;%       mutate(         rank_within_group = rank(value),  # 计算组内排名         cumulative_sum = cumsum(value)  # 计算组内累计和       ) %&gt;%       ungroup()  # 取消分组，后续操作不再分组\n\ndplyr 数据清洗练习: 使用 flights 数据集或其他数据集，练习使用 dplyr 进行数据清洗和预处理，例如：\n\n处理 flights 数据集中的缺失值 (例如，dep_delay, arr_delay, air_time 等列可能存在缺失值)。\n检测和处理 flights 数据集中的异常值 (例如，dep_delay, arr_delay, distance 等列可能存在异常值)。\n将 flights 数据集中的航空公司代码 carrier 转换为航空公司名称 (可以使用 航空公司代码-名称 对照表，进行 join 操作，下周学习 join)。\n使用 stringr 包处理 flights 数据集中的字符型数据 (如果存在)。\n使用 case_when() 函数创建新的分类变量 (例如，根据 dep_delay 将航班分为 “准点”, “轻微延误”, “严重延误” 等类别)。\n使用窗口函数计算每个航空公司的航班数量排名、平均延误时间排名等。\n\n\n\n\n3. tidyr 数据整理：数据变形\n\ntidyr 包的目的: tidyr 包是 tidyverse 生态中专门用于数据整理 (data tidying) 的包。 数据整理的目标是将数据转换为整洁数据 (tidy data) 格式，方便后续的数据分析和可视化。 整洁数据 的核心原则是：\n\n每个变量占一列 (Each variable forms a column).\n每个观测值占一行 (Each observation forms a row).\n每个值自成一个单元格 (Each value forms a cell).\n\ntidyr 数据变形常用函数:\n\npivot_longer() (长数据透视): 将宽格式 (wide format) 数据转换为长格式 (long format) 数据。 宽格式数据中，一个观测值的多个变量可能分布在多列中，长格式数据则将这些变量 “堆叠” 成一列，并使用另一列标识变量名。 pivot_longer() 函数可以将指定的多列 “透视” 成两列：变量名列 (name column) 和 值列 (value column)。\n# 宽格式数据示例\nwide_data &lt;- tibble(\n  id = 1:3,\n  var1_2020 = c(10, 12, 15),\n  var2_2020 = c(20, 25, 30),\n  var1_2021 = c(11, 13, 16),\n  var2_2021 = c(22, 27, 33)\n)\n\n# 使用 pivot_longer() 转换为长格式\nlong_data &lt;- wide_data %&gt;%\n  pivot_longer(\n    cols = starts_with(\"var\"),  # 指定要透视的列，使用 starts_with() 选择以 \"var\" 开头的列\n    names_to = c(\"variable\", \"year\"),  # 指定变量名列和年份列的名称\n    names_sep = \"_\",  # 指定列名分隔符 \"_\"\n    values_to = \"value\"  # 指定值列的名称\n  )\n\nprint(long_data)\n\ncols 参数: 指定要透视的列。 可以使用列名向量、列索引向量、列名选择函数 (例如 starts_with(), ends_with(), contains(), matches(), num_range(), everything(), last_col()) 等。\nnames_to 参数: 指定透视后的变量名列的名称。 可以传入一个字符向量，指定变量名列的名称，如果 names_sep 或 names_pattern 参数被使用，则 names_to 可以传入多个名称，表示将列名拆分成多列。\nnames_sep 参数: 指定列名分隔符。 如果列名包含多个信息，可以使用分隔符将列名拆分成多列。\nnames_pattern 参数: 使用正则表达式匹配列名，并将匹配到的部分拆分成多列。 names_sep 和 names_pattern 只能使用一个。\nvalues_to 参数: 指定透视后的值列的名称。\n\npivot_wider() (宽数据透视): 将长格式 (long format) 数据转换为宽格式 (wide format) 数据。 pivot_wider() 是 pivot_longer() 的逆操作。 pivot_wider() 函数需要指定哪一列作为新的列名 (names_from)，哪一列作为新的值 (values_from)。\n# 长格式数据示例 (上例中的 long_data)\nlong_data &lt;- tibble(\n  id = rep(1:3, each = 4),\n  variable = rep(c(\"var1\", \"var2\"), each = 2, times = 3),\n  year = rep(rep(c(\"2020\", \"2021\"), each = 1), times = 6),\n  value = c(10, 20, 12, 25, 15, 30, 11, 22, 13, 27, 16, 33)\n)\n\n# 使用 pivot_wider() 转换为宽格式\nwide_data_reconstructed &lt;- long_data %&gt;%\n  pivot_wider(\n    names_from = c(\"variable\", \"year\"),  # 指定列名来源列，这里使用 variable 和 year 两列组合作为新列名\n    values_from = \"value\"  # 指定值来源列\n  )\n\nprint(wide_data_reconstructed)\n\nnames_from 参数: 指定列名来源列。 可以使用列名向量，指定一列或多列作为新列名的来源。 如果指定多列，则新列名将由这些列的值组合而成。\nvalues_from 参数: 指定值来源列。 可以使用列名向量，指定一列或多列作为新值的来源。 如果 names_from 指定了多列，values_from 也应该指定相同数量的列，或者只指定一列，表示所有新列的值都来自同一列。\n\nseparate() (列分割): 将一列按照指定的分隔符分割成多列。 separate() 函数类似于 stringr::str_split_fixed() 函数，但 separate() 直接操作数据框列，更方便。\ndata_with_combined_col &lt;- tibble(\n  combined_col = c(\"A-1\", \"B-2\", \"C-3\")\n)\n\nseparated_data &lt;- data_with_combined_col %&gt;%\n  separate(\n    col = combined_col,  # 指定要分割的列\n    into = c(\"col1\", \"col2\"),  # 指定分割后的新列名\n    sep = \"-\"  # 指定分隔符 \"-\"\n  )\n\nprint(separated_data)\n\ncol 参数: 指定要分割的列名。\ninto 参数: 指定分割后的新列名。 传入一个字符向量，指定新列的名称。\nsep 参数: 指定分隔符。 可以使用字符或正则表达式作为分隔符。\n\nunite() (列合并): 将多列合并成一列，并使用指定的分隔符连接。 unite() 是 separate() 的逆操作。\nseparated_data &lt;- tibble(\n  col1 = c(\"A\", \"B\", \"C\"),\n  col2 = c(\"1\", \"2\", \"3\")\n)\n\nunited_data &lt;- separated_data %&gt;%\n  unite(\n    col = combined_col,  # 指定合并后的新列名\n    col1, col2,  # 指定要合并的列\n    sep = \"-\"  # 指定分隔符 \"-\"\n  )\n\nprint(united_data)\n\ncol 参数: 指定合并后的新列名。\n... 参数: 使用 ... 传入要合并的列名，可以传入多个列名。\nsep 参数: 指定分隔符。\n\n\ntidyr 数据整理练习: 使用 flights 数据集或其他数据集，练习使用 tidyr 进行数据整理，例如：\n\n将 flights 数据集转换为长格式，例如，将 dep_delay 和 arr_delay 两列透视为一列 delay_type (取值为 “dep_delay” 或 “arr_delay”) 和一列 delay_time (延误时间)。\n将宽格式的数据 (例如，包含多年份数据的表格) 转换为长格式，方便进行时间序列分析或面板数据分析。\n分割包含复合信息的列，例如，将日期时间列分割成日期列和时间列，将地址列分割成城市列、州列、国家列等。\n合并多列信息，例如，将年、月、日列合并成日期列，将姓、名列合并成姓名列。\n\n\n\n\n4. ggplot2 数据可视化初步：常用图表\n\nggplot2 包简介: ggplot2 包是 R 语言中最强大、最灵活、最流行的数据可视化包，也是 tidyverse 生态的核心包之一。 ggplot2 基于图层语法 (grammar of graphics)，将数据可视化分解为多个独立的图层，用户可以灵活组合这些图层，创建各种复杂的统计图表。 ggplot2 的特点包括：\n\n图层语法: 基于图层语法，灵活、强大、可扩展。\n美观的默认样式: 默认生成的图表美观、专业。\n高度定制化: 可以高度定制图表的各个方面，例如，颜色、形状、大小、标签、标题、主题等。\n与 tidyverse 完美集成: 与 dplyr, tidyr 等 tidyverse 包无缝衔接，数据处理和可视化流程流畅。\n\nggplot2 基本语法: ggplot2 绘图的基本流程是：\n\n创建 ggplot 对象: 使用 ggplot() 函数创建 ggplot 对象，并指定数据 (data) 和映射 (mapping, aes())。 data 参数指定要使用的数据框，mapping 参数使用 aes() 函数指定变量如何映射到图形属性 (aesthetics)，例如，X 轴、Y 轴、颜色、形状、大小、填充等。\n添加几何对象 (geometric objects, geom_xxx()): 使用各种 geom_xxx() 函数添加几何对象图层，例如，geom_point() (散点图), geom_line() (折线图), geom_bar() (条形图), geom_histogram() (直方图), geom_boxplot() (箱线图) 等。 每个 geom_xxx() 函数都对应一种图表类型。 几何对象图层决定了图表的类型和基本形状。\n添加统计变换 (statistical transformations, stat_xxx()): 某些几何对象需要进行统计变换，例如，直方图需要计算频数，条形图需要计算汇总统计量。 ggplot2 会自动进行默认的统计变换，用户也可以使用 stat_xxx() 函数手动指定统计变换。 通常情况下，无需手动添加统计变换图层。\n添加标度 (scales, scale_xxx_yyy()): 标度控制数据值到图形属性的映射方式，例如，X 轴和 Y 轴的刻度范围、颜色标度、形状标度、大小标度等。 ggplot2 会自动使用默认标度，用户可以使用 scale_xxx_yyy() 函数自定义标度，例如，scale_x_continuous(), scale_y_continuous(), scale_color_manual(), scale_shape_manual(), scale_size_continuous() 等。\n添加坐标系 (coordinate systems, coord_xxx()): 坐标系控制图表的坐标轴类型和方向，例如，笛卡尔坐标系 (默认), 极坐标系, 地理坐标系等。 ggplot2 默认使用笛卡尔坐标系，用户可以使用 coord_xxx() 函数自定义坐标系，例如，coord_cartesian(), coord_polar(), coord_map() 等。\n添加分面 (faceting, facet_xxx()): 分面可以将图表分割成多个子图，按照一个或多个分类变量进行分组，方便比较不同组别的数据。 ggplot2 提供了 facet_wrap() (单变量分面) 和 facet_grid() (双变量分面) 函数。\n添加主题 (themes, theme()): 主题控制图表的整体外观样式，例如，背景颜色、网格线、字体、标题位置、图例样式等。 ggplot2 提供了多种内置主题 (例如 theme_bw(), theme_minimal(), theme_classic())，用户也可以使用 theme() 函数自定义主题。\n添加标签、标题等 (labels, titles, etc., labs(), ggtitle(), xlab(), ylab(), caption()): 使用 labs() 函数添加标签 (例如，X 轴标签、Y 轴标签、颜色图例标签、形状图例标签等), 使用 ggtitle() 函数添加主标题, 使用 xlab() 和 ylab() 函数分别添加 X 轴和 Y 轴标签, 使用 caption() 函数添加图表脚注。\n\n常用 ggplot2 图表类型示例 (使用 flights 数据集):\n\n直方图 (Histogram): 展示 dep_delay 出发延误时间的分布。\nlibrary(ggplot2)\n\nggplot(flights, aes(x = dep_delay)) +\n  geom_histogram(binwidth = 15)  # binwidth 参数指定组距\n\nggplot(flights, aes(x = dep_delay)): 创建 ggplot 对象，指定数据为 flights 数据框，X 轴映射为 dep_delay 变量。\ngeom_histogram(binwidth = 15): 添加直方图几何对象图层，binwidth = 15 指定组距为 15 分钟。\n\n散点图 (Scatter Plot): 展示 dep_delay 出发延误时间与 arr_delay 到达延误时间的关系。 r     ggplot(flights, aes(x = dep_delay, y = arr_delay)) +       geom_point()\n\nggplot(flights, aes(x = dep_delay, y = arr_delay)): 创建 ggplot 对象，指定 X 轴映射为 dep_delay，Y 轴映射为 arr_delay。\ngeom_point(): 添加散点图几何对象图层。\n\n箱线图 (Boxplot): 比较不同航空公司 carrier 的 arr_delay 到达延误时间分布。 r     ggplot(flights, aes(x = carrier, y = arr_delay)) +       geom_boxplot()\n\nggplot(flights, aes(x = carrier, y = arr_delay)): 创建 ggplot 对象，指定 X 轴映射为 carrier (分类变量), Y 轴映射为 arr_delay (数值型变量)。\ngeom_boxplot(): 添加箱线图几何对象图层。\n\n条形图 (Bar Chart): 展示不同航空公司 carrier 的航班数量。 r     ggplot(flights, aes(x = carrier)) +       geom_bar()\n\nggplot(flights, aes(x = carrier)): 创建 ggplot 对象，只指定 X 轴映射为 carrier。 geom_bar() 默认统计每个分类的频数。\ngeom_bar(): 添加条形图几何对象图层。\n\n添加颜色、形状、大小等图形属性: 可以使用 aes() 函数在 geom_xxx() 函数内部或 ggplot() 函数内部指定额外的图形属性映射，例如，使用 color 映射颜色, shape 映射形状, size 映射大小, fill 映射填充颜色等。\n# 散点图，使用 color 映射航空公司 carrier\nggplot(flights, aes(x = dep_delay, y = arr_delay, color = carrier)) +\n  geom_point()\n\n# 散点图，使用 size 映射飞行距离 distance\nggplot(flights, aes(x = dep_delay, y = arr_delay, size = distance)) +\n  geom_point()\n添加标题、标签、主题: r     ggplot(flights, aes(x = dep_delay, y = arr_delay, color = carrier)) +       geom_point() +       labs(title = \"出发延误 vs 到达延误\",  # 主标题            subtitle = \"按航空公司着色\",  # 副标题            x = \"出发延误时间 (分钟)\",  # X 轴标签            y = \"到达延误时间 (分钟)\",  # Y 轴标签            color = \"航空公司\",  # 颜色图例标签            caption = \"数据来源：nycflights13 包\") +  # 图表脚注       theme_bw()  # 使用黑白主题\n\nggplot2 可视化练习: 使用 flights 数据集或其他数据集，练习使用 ggplot2 绘制各种常用统计图表，并尝试自定义图表的各个方面，例如：\n\n绘制 flights 数据集 distance 飞行距离的直方图，并尝试调整 binwidth 参数。\n绘制 flights 数据集 air_time 飞行时间的箱线图，按照出发机场 origin 分组。\n绘制 flights 数据集 dep_delay 与 arr_delay 的散点图，并使用颜色或形状映射航空公司 carrier。\n绘制 flights 数据集航空公司 carrier 的条形图，并添加航班数量标签。\n尝试修改图表的标题、标签、颜色、主题等，使图表更美观、更易读。\n\n\n\n\n5. tidyverse 生态综合应用：数据处理与可视化流程\n\ntidyverse 数据分析流程: tidyverse 生态提供了一套完整的数据分析流程，包括：\n\n数据导入 (readr, datatable): 使用 readr 或 datatable 包读取各种数据格式的文件。\n数据整理 (tidyr): 使用 tidyr 包将数据转换为整洁数据格式。\n数据清洗和预处理 (dplyr, stringr): 使用 dplyr 和 stringr 包进行数据清洗、缺失值处理、异常值处理、数据类型转换、字符数据处理等。\n数据探索和描述性统计 (dplyr): 使用 dplyr 包进行数据汇总、分组统计、计算描述性统计量。\n数据可视化 (ggplot2): 使用 ggplot2 包绘制各种统计图表，探索数据模式、展示分析结果。\n数据建模和推断性统计 (后续课程): 使用 R 的统计建模和推断性统计功能进行更深入的数据分析 (本周不涉及)。\n结果沟通和报告 (后续课程): 将数据分析结果整理成报告、幻灯片、交互式应用等形式，进行有效沟通 (本周不涉及)。\n\ntidyverse 流程示例 (使用 flights 数据集): 以分析不同航空公司的平均延误时间为例，演示 tidyverse 数据处理和可视化流程。\nlibrary(tidyverse)\nlibrary(nycflights13)\n\n# 1. 数据导入 (flights 数据集已加载到 nycflights13 包中，无需额外导入)\n\n# 2. 数据整理 (flights 数据集已经是整洁数据格式，无需整理)\n\n# 3. 数据清洗和预处理 (简单处理缺失值，移除到达延误时间为缺失值的航班)\nflights_cleaned &lt;- flights %&gt;%\n  filter(!is.na(arr_delay))\n\n# 4. 数据探索和描述性统计 (按照航空公司分组，计算平均到达延误时间)\ncarrier_delay_summary &lt;- flights_cleaned %&gt;%\n  group_by(carrier) %&gt;%\n  summarize(mean_delay = mean(arr_delay)) %&gt;%\n  arrange(desc(mean_delay))  # 按照平均延误时间降序排序\n\nprint(carrier_delay_summary)\n\n# 5. 数据可视化 (绘制条形图，展示不同航空公司的平均到达延误时间)\nggplot(carrier_delay_summary, aes(x = carrier, y = mean_delay)) +\n  geom_col(fill = \"steelblue\") +  # 柱形图，填充颜色为 steelblue\n  geom_text(aes(label = round(mean_delay, 1)),  # 添加文本标签，显示平均延误时间，保留一位小数\n            vjust = -0.5) +  # 标签垂直位置微调\n  labs(title = \"不同航空公司平均到达延误时间\",\n       x = \"航空公司代码\",\n       y = \"平均到达延误时间 (分钟)\") +\n  theme_minimal()  # 使用 minimal 主题\ntidyverse 综合练习: 选择一个实际数据集 (例如，flights 数据集、项目一的数据集或其他公开数据集)，使用 tidyverse 生态的 readr, tidyr, dplyr, stringr, ggplot2 包，完成一个完整的数据分析和可视化项目，包括数据导入、数据整理、数据清洗、数据预处理、描述性统计分析、数据可视化、结果解释和报告撰写 (报告撰写为可选，重点练习数据处理和可视化)。\n\n\n\n6. 本周内容总结与下周预告\n\n本周回顾: 回顾本周学习内容，巩固重点知识。 本周我们深入学习了描述性统计的核心概念，dplyr 数据清洗和预处理进阶技巧，tidyr 数据整理方法，ggplot2 数据可视化初步，以及 tidyverse 生态的综合应用。 描述性统计、数据清洗、数据整理和数据可视化是数据分析的关键技能，务必熟练掌握本周所学内容。\n下周预告: 下周我们将继续深入学习 ggplot2 包，学习更高级的数据可视化技巧，例如，多图层组合、图形精细调整、交互式图表制作等。 我们将探索更多 ggplot2 的几何对象、统计变换、标度、坐标系、分面、主题等，打造更专业、更精美、更具洞察力的数据可视化作品。\n\n\n\n7. 课后任务\n\n小组任务:\n\n项目一数据清洗和预处理: 各小组根据本周学习的数据清洗和预处理方法，使用 dplyr 和 tidyr 包对项目一的数据集进行数据清洗和预处理。 完成缺失值处理、异常值处理、数据类型转换、数据整理等任务，确保数据质量和整洁性，为后续的数据分析和可视化做好准备。\n项目一数据可视化方案: 小组讨论项目一的数据可视化方案，确定要展示的数据特征和模式，选择合适的图表类型，设计图表布局和样式。\n\n个人任务:\n\n复习本周内容: 回顾本周讲义和课堂笔记，巩固描述性统计概念、dplyr 数据清洗技巧、tidyr 数据整理方法、ggplot2 可视化语法和常用图表类型。\nR 代码练习: 完成本讲义中布置的 R 代码练习，熟练掌握 dplyr, tidyr, stringr, ggplot2 包的常用函数。 尝试使用 AI 插件辅助 R 代码练习。\n数据集可视化探索: 选择 flights 数据集或项目一的数据集，使用 ggplot2 包进行数据可视化探索，尝试绘制各种图表，并自定义图表样式，深入理解数据特征和模式。 可以尝试完成讲义中提供的练习题，也可以自己设计可视化探索任务。\n\n\n\n\n\n\n\n\nAI 辅助学习小贴士\n\n\n\n\nR 代码练习: 继续在 VS Code 或 Cursor 中练习 R 语言代码，充分利用 AI 插件的代码自动补全、代码生成、代码解释、AI 聊天等功能。 遇到 R 代码问题，及时向 AI 提问。\n数据包使用问题: 如果在使用 dplyr, tidyr, stringr, ggplot2 等数据包时遇到问题，可以查阅包的官方文档，或者使用 AI 聊天提问，寻求帮助。\n\ndplyr 数据清洗技巧: 例如，如何使用 filter() 筛选满足多个条件的行？ 如何使用 mutate() 创建多个新列？ 如何使用 group_by() 和 summarize() 进行分组汇总统计？\ntidyr 数据整理方法: 例如，pivot_longer() 和 pivot_wider() 函数的参数如何设置？ separate() 和 unite() 函数如何使用？ 如何将复杂格式的数据转换为整洁数据？\nggplot2 可视化语法: 例如，ggplot() 和 aes() 函数如何使用？ 各种 geom_xxx() 函数的作用是什么？ 如何添加标题、标签、主题？ 如何自定义图表样式？\n\n统计图表选择: 如果不确定使用哪种图表类型来展示数据，可以通过AI聊天工具寻求建议。例如，可以提问：“哪种图表适合比较多个组的分布情况？” 或 “如何可视化两个数值变量之间的关系？”。AI不仅会推荐合适的图表类型，还会提供相应的ggplot2代码示例。\n可视化代码生成: 使用 AI 代码生成功能，输入注释，例如： # 使用 ggplot2 创建价格的直方图, # 使用 ggplot2 创建 'x' 和 'y' 的散点图，并按 'category' 着色, 让 AI 生成可视化代码。\n代码解释和优化: 使用 AI 代码解释功能，选中 tidyverse 代码片段，让 AI 解释代码的功能和每一行代码的作用。 如果代码运行效率较低，可以使用 AI 聊天咨询代码优化技巧。\n\n\n\n\n\n\n\n\n\n学习寄语\n\n\n\n图表胜千言！ 本周我们学习了描述性统计和数据可视化的核心技能，掌握了用数据讲故事的能力。 精美、清晰、有洞察力的图表是数据分析的灵魂！ 继续保持学习的热情，充分利用 VS Code/Cursor 和 AI 插件的强大功能，相信大家会在统计学和 R 语言的学习中取得更大的进步！ 下周见！",
    "crumbs": [
      "课程内容",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>统计学讲义 - 第三周：描述性统计：数据探索与可视化</span>"
    ]
  },
  {
    "objectID": "week04.html",
    "href": "week04.html",
    "title": "第四周：推断性统计初步：参数估计与假设检验",
    "section": "",
    "text": "从样本推断总体：推断性统计入门\n前三周我们学习了描述性统计，掌握了如何概括和可视化数据。 从本周开始，我们将进入统计学的核心领域：推断性统计。 推断性统计的目标是利用样本数据来推断总体特征。 由于我们通常无法获取总体的全部数据，只能通过抽样获得样本数据，因此需要使用推断性统计方法，基于样本信息，对总体参数进行估计和检验。 本周我们将学习推断性统计的两个基本内容：参数估计和 假设检验，并初步接触常用的 t 检验。\n继续使用 VS Code 或 Cursor + AI 插件： 请继续使用 VS Code 或 Cursor 编辑器，并充分利用 AI 插件的代码辅助、智能提示、聊天问答等功能，提升学习效率。\n\n\n\n\n\n\n本周学习目标\n\n\n\n\n推断性统计核心思想: 理解推断性统计的目的和基本逻辑。\n参数估计: 掌握点估计和区间估计的基本概念和方法。\n假设检验: 理解假设检验的基本原理和步骤。\n假设检验的错误、功效与效应量: 理解假设检验中 Type I 错误和 Type II 错误，掌握检验功效和效应量的概念和意义。\nt 检验: 掌握单样本 t 检验和双样本 t 检验 (独立样本、配对样本) 的适用条件和 R 语言实现，并能计算效应量 Cohen’s d 和进行功效分析。\n抽样分布: 理解抽样分布的概念，为理解推断性统计奠定基础。\n项目中期检查准备: 开始准备项目一的中期检查汇报。\nAI 辅助统计推断: 探索使用 AI 工具辅助统计推断学习和应用。\n\n\n\n\n\n\n1. 推断性统计核心思想：从样本到总体\n\n总体 (Population) 与 样本 (Sample) 回顾: 回顾第一周学习的总体和样本的概念。\n\n总体: 研究对象的全体，是我们想要了解的真实情况。 例如，所有本科生、所有股票、所有商品。 总体通常很大，甚至无限，难以直接获取总体全部数据。\n样本: 从总体中抽取的一部分个体，是实际观测到的数据。 例如，随机抽取的 100 名本科生、某只股票过去一年的交易数据、某批次商品中抽取的 10 件商品。 样本数据是总体信息的载体，我们通过分析样本数据来推断总体特征。\n\n参数 (Parameter) 与 统计量 (Statistic):\n\n参数: 描述总体特征的数值，例如，总体均值 (μ)、总体标准差 (σ)、总体比例 (P)。 总体参数是未知的，是我们想要估计的目标。\n统计量: 描述样本特征的数值，例如，样本均值 (\\(\\\\bar{x}\\))、样本标准差 (s)、样本比例 (\\(\\\\hat{p}\\))。 统计量是已知的，可以根据样本数据计算出来，用于估计总体参数。\n\n抽样 (Sampling) 与 随机性 (Randomness):\n\n抽样: 从总体中抽取样本的过程。 随机抽样是推断性统计的基础，保证样本的代表性，避免抽样偏差。 常用的随机抽样方法包括简单随机抽样、分层抽样、整群抽样等。\n随机性: 抽样过程中的随机性导致样本统计量具有随机性，不同的样本会得到不同的统计量。 抽样分布描述了样本统计量的随机性规律。\n\n\n\n\n2. 参数估计：用样本估计总体\n\n点估计 (Point Estimation):\n\n用样本统计量直接估计总体参数。 例如，用样本均值 \\(\\\\bar{x}\\) 估计总体均值 μ，用样本标准差 s 估计总体标准差 σ，用样本比例 \\(\\\\hat{p}\\) 估计总体比例 P。\n点估计的优点是简单直观，易于计算。 缺点是只给出一个估计值，没有说明估计的精确程度，可能存在较大误差。 例如，我们用一个样本均值 52 来估计总体均值，但总体均值可能是 50，也可能是 55，我们不知道 52 这个估计值有多可靠。\n\n区间估计 (Interval Estimation):\n\n给出一个总体参数的可能取值范围，并说明该范围包含总体参数真值的可信程度。 例如，总体均值的 95% 置信区间为 [48, 56]，表示我们有 95% 的把握认为总体均值落在 48 到 56 之间。\n区间估计比点估计提供更丰富的信息，既给出了估计范围，又说明了估计的可靠性。 常用的区间估计方法是置信区间 (Confidence Interval)。\n\n置信区间 (Confidence Interval, CI):\n\n置信区间是指由样本数据计算出的、包含总体参数真值的某个概率范围。 例如，95% 置信区间表示，如果重复抽样 100 次，每次都计算一个置信区间，那么平均会有 95 个区间包含总体参数的真值。\n置信水平 (Confidence Level): 表示置信区间包含总体参数真值的概率，常用百分数表示，例如 90%, 95%, 99%。 常用的置信水平是 95%，对应的 \\(\\\\alpha = 1 - 0.95 = 0.05\\)。 置信水平越高，置信区间越宽，包含总体参数真值的可能性越大，但估计的精确度降低。 置信水平越低，置信区间越窄，估计的精确度提高，但包含总体参数真值的可能性降低。\n置信区间的计算: 置信区间的计算公式取决于总体参数类型、样本统计量分布、样本容量等因素。 例如，总体均值 μ 的置信区间 (样本容量较大时，总体标准差 σ 已知)：\n\\[\n置信区间 = 样本均值 \\\\pm 临界值 \\\\times 标准误差 = \\\\bar{x} \\\\pm Z_{\\\\alpha/2} \\\\times \\\\frac{\\\\sigma}{\\\\sqrt{n}}\n\\]\n其中，\\(\\\\bar{x}\\) 是样本均值，\\(\\\\sigma\\) 是总体标准差，n 是样本容量，\\(Z_{\\\\alpha/2}\\) 是标准正态分布的临界值 (例如，95% 置信水平时，\\(\\\\alpha = 0.05\\), \\(\\\\alpha/2 = 0.025\\), \\(Z_{0.025} = 1.96\\))，\\(\\frac{\\\\sigma}{\\\\sqrt{n}}\\) 是样本均值 \\(\\\\bar{x}\\) 的标准误差。\nR 函数 t.test() 计算 t 检验的置信区间: t.test() 函数可以进行 t 检验，并输出均值差的置信区间。 例如，独立样本 t 检验，比较两组均值差异，t.test() 输出的是两组均值差的置信区间。\n\n\n\n\n3. 假设检验：检验关于总体的假设\n\n假设检验的基本思想:\n\n先对总体参数提出一个假设 (原假设 H₀)，然后利用样本数据，判断是否有充分的证据拒绝原假设 H₀，接受备择假设 H₁。 类似于法庭判案，先假设被告无罪 (原假设 H₀)，然后收集证据 (样本数据)，判断是否有充分证据证明被告有罪 (拒绝原假设 H₀，接受备择假设 H₁)。\n假设检验是一种反证法。 我们通常无法直接证明备择假设 H₁ 为真，但可以通过否定原假设 H₀，间接支持备择假设 H₁。 如果样本数据与原假设 H₀ 矛盾，我们就有理由拒绝 H₀，转而接受 H₁。 如果样本数据与原假设 H₀ 并不矛盾，我们则没有充分证据拒绝 H₀，但也不能说 H₀ 一定为真，只能说 “接受 H₀” 或 “不拒绝 H₀”。\n\n原假设 (H₀) 与 备择假设 (H₁):\n\n原假设 (Null Hypothesis, H₀): 研究者想要检验的假设，通常是关于总体参数 “没有效应”、“没有差异”、“没有关系” 的假设。 例如，总体均值等于某个特定值 (μ = μ₀)，两组总体均值相等 (μ₁ = μ₂)，变量之间没有相关关系 (ρ = 0)。 原假设 H₀ 是假设检验的出发点，也是我们要试图拒绝的假设。\n备择假设 (Alternative Hypothesis, H₁): 与原假设 H₀ 对立的假设，是研究者希望支持的假设，通常是关于总体参数 “存在效应”、“存在差异”、“存在关系” 的假设。 例如，总体均值不等于某个特定值 (μ ≠ μ₀)，两组总体均值不相等 (μ₁ ≠ μ₂)，变量之间存在相关关系 (ρ ≠ 0)。 备择假设 H₁ 是当原假设 H₀ 被拒绝时，我们接受的结论。\n假设类型:\n\n双侧检验 (Two-tailed Test): 备择假设 H₁ 是总体参数 “不等于” 某个特定值，检验方向是双侧的。 例如，H₀: μ = μ₀, H₁: μ ≠ μ₀。\n单侧检验 (One-tailed Test): 备择假设 H₁ 是总体参数 “大于” 或 “小于” 某个特定值，检验方向是单侧的 (左侧或右侧)。 例如，右侧检验：H₀: μ ≤ μ₀, H₁: μ &gt; μ₀； 左侧检验：H₀: μ ≥ μ₀, H₁: μ &lt; μ₀。 选择单侧检验需要有充分的理由，并且在研究开始前就应该确定检验方向。 通常情况下，更常用双侧检验，因为它更保守，适用范围更广。\n\n\n假设检验的逻辑：\n\n假设原假设 H₀ 为真。 先假定原假设 H₀ 是正确的，作为出发点。\n在 H₀ 为真的前提下，推导样本统计量的抽样分布。 根据原假设 H₀ 和抽样分布理论，推导出检验统计量 (例如，t 统计量、F 统计量、\\(\\\\chi^2\\) 统计量) 的抽样分布。\n计算检验统计量的值和 p 值。 根据样本数据，计算检验统计量的值。 p 值 (p-value) 是指，在原假设 H₀ 为真的前提下，出现当前样本结果或更极端结果的概率。 p 值越小，说明在 H₀ 为真的情况下，出现当前样本结果的可能性越小，样本数据越不支持 H₀。\n根据 p 值和显著性水平 \\(\\\\alpha\\)，做出决策。 显著性水平 \\(\\\\alpha\\) 是事先设定的一个概率值，通常取 0.05, 0.01, 0.10，表示我们愿意容忍犯 Type I 错误的最大概率。 将 p 值与 \\(\\\\alpha\\) 进行比较：\n\n如果 p 值 ≤ \\(\\\\alpha\\)，则拒绝原假设 H₀，接受备择假设 H₁。 认为样本数据提供了充分的证据，否定了原假设 H₀，支持了备择假设 H₁。 结果具有统计显著性 (Statistically Significant)。\n如果 p 值 &gt; \\(\\\\alpha\\)，则没有充分证据拒绝原假设 H₀，接受原假设 H₀ (或 “不拒绝” H₀)。 认为样本数据没有提供充分的证据，否定原假设 H₀。 不能说原假设 H₀ 一定为真，只能说目前没有足够的证据推翻它。 结果不具有统计显著性 (Not Statistically Significant)。\n\n\n假设检验可能犯的错误：Type I 错误 & Type II 错误\n\n在假设检验中，我们的决策 (拒绝 H₀ 或 接受 H₀) 是基于样本数据做出的，有可能犯错误。 根据原假设 H₀ 的真实情况和我们的决策，可能出现两种类型的错误：\n\n\n\n决策\nH₀ 真实 (True)\nH₀ 错误 (False)\n\n\n\n\n拒绝 H₀\nType I 错误\n正确决策\n\n\n接受 H₀\n正确决策\nType II 错误\n\n\n\n\nType I 错误 (Type I Error, \\(\\\\alpha\\) 错误, 拒真错误): 当原假设 H₀ 实际上为真时，我们却拒绝了 H₀。 就好比 “真阳性” 的反面，把真原假设当成假原假设拒绝了。 Type I 错误的概率用 \\(\\\\alpha\\) 表示，\\(\\\\alpha\\) 也被称为 显著性水平 (Significance Level)，通常取值 0.05, 0.01, 0.10。 显著性水平 \\(\\\\alpha\\) 是我们事先设定的，我们愿意容忍犯 Type I 错误的最大概率。 例如，如果 \\(\\\\alpha = 0.05\\)，意味着如果我们重复进行 100 次假设检验，当 H₀ 均为真时，平均会有 5 次犯 Type I 错误。 我们希望尽可能控制 Type I 错误的概率，避免 “冤枉好人”。\nType II 错误 (Type II Error, \\(\\\\beta\\) 错误, 纳伪错误): 当原假设 H₀ 实际上为假时，我们却没有拒绝 H₀，反而接受了 H₀。 就好比 “假阴性”，把假原假设当成真原假设接受了。 Type II 错误的概率用 \\(\\\\beta\\) 表示，\\(\\\\beta\\) 的值通常是未知的，与总体参数的真实值、样本容量、显著性水平等因素有关。 我们希望尽可能减小 Type II 错误的概率，避免 “放过坏人”。\n\n\\(\\\\alpha\\) 与 \\(\\\\beta\\) 的权衡: \\(\\\\alpha\\) 和 \\(\\\\beta\\) 之间存在权衡关系。 当我们试图减小 \\(\\\\alpha\\) (例如，降低显著性水平，使拒绝 H₀ 更困难) 时，\\(\\\\beta\\) 通常会增大 (更容易接受错误的 H₀)。 反之，当我们试图减小 \\(\\\\beta\\) (例如，增大样本容量，提高检验功效) 时，\\(\\\\alpha\\) 可能会增大。 在实际应用中，我们需要根据具体情况，权衡 Type I 错误和 Type II 错误的重要性，选择合适的 \\(\\\\alpha\\) 水平，并尽可能提高检验功效，减小 \\(\\\\beta\\)。 通常情况下，我们更关注控制 Type I 错误的概率 \\(\\\\alpha\\)，因为拒绝原假设通常意味着发现了新的、重要的结论。**\n\n检验功效 (Power of a Test, 1 - \\(\\\\beta\\)):\n\n检验功效是指当原假设 H₀ 实际上为假时，我们正确地拒绝 H₀ 的概率。 检验功效 = 1 - \\(\\\\beta\\)。 检验功效越高，犯 Type II 错误的概率 \\(\\\\beta\\) 就越低，检验就越有效。 我们希望检验具有较高的功效，能够有效地发现真实存在的效应或差异。\n影响检验功效的因素:\n\n效应量 (Effect Size): 效应量是指总体参数偏离原假设 H₀ 的程度。 效应量越大，总体参数与原假设的差异越大，越容易被检验出来，检验功效越高。 例如，如果两个总体均值差异很大，就更容易通过 t 检验发现均值差异。\n样本容量 (Sample Size, n): 样本容量越大，样本信息越丰富，抽样误差越小，检验功效越高。 增大样本容量是提高检验功效的常用方法。\n显著性水平 (Significance Level, \\(\\\\alpha\\)): 显著性水平 \\(\\\\alpha\\) 越大，拒绝 H₀ 越容易，检验功效越高。 但增大 \\(\\\\alpha\\) 也会增大犯 Type I 错误的概率。 通常在保证 \\(\\\\alpha\\) 水平的前提下，尽可能提高检验功效。\n总体标准差 (\\(\\\\sigma\\)): 总体标准差越小，数据变异性越小，抽样误差越小，检验功效越高。 减小总体标准差通常无法直接控制，但在实验设计中，可以尽量控制无关变量，减小实验误差，从而减小数据变异性。\n单侧检验 vs 双侧检验: 在其他条件相同的情况下，单侧检验的功效通常比双侧检验高 (当效应方向与备择假设方向一致时)。 但选择单侧检验需要有充分的理由，并且在研究开始前就应该确定检验方向。\n\n功效分析 (Power Analysis): 功效分析是一种用于评估和提高检验功效的方法。 功效分析可以在研究设计阶段，预先计算所需的样本容量，以达到预期的检验功效。 也可以在研究结束后，评估已完成研究的检验功效，判断未拒绝原假设是否是因为检验功效不足。 R 中 pwr 包可以进行功效分析。 常用的功效分析类型包括：\n\n事前功效分析 (A-priori Power Analysis): 在研究开始前，为了达到预期的检验功效，计算所需的最小样本容量。 例如，研究者希望在显著性水平 \\(\\\\alpha = 0.05\\) 下，以 80% 的功效 (power = 0.8) 检测到中等效应量 (Cohen’s d = 0.5) 的均值差异，需要计算每组至少需要多少样本量。\n# 安装和加载 pwr 包 (如果尚未安装)\n# install.packages(\"pwr\")\nlibrary(pwr)\n\n# 设置参数\ndesired_power &lt;- 0.8      # 期望的检验功效 (通常为 0.8)\nsig_level &lt;- 0.05         # 显著性水平 (通常为 0.05)\neffect_size &lt;- 0.5       # 预期效应量 Cohen's d (例如，小效应 0.2, 中等效应 0.5, 大效应 0.8)\nalternative_hypothesis &lt;- \"two.sided\" # 双侧检验\ntest_type &lt;- \"two.sample\" # 独立样本 t 检验\n\n# 进行事前功效分析，计算所需样本容量\npower_analysis_result &lt;- pwr.t.test(power = desired_power,\n                                      sig.level = sig_level,\n                                      d = effect_size,\n                                      type = test_type,\n                                      alternative = alternative_hypothesis)\n\nprint(power_analysis_result)\n\n# 提取所需样本容量 (每组样本量)\nrequired_sample_size &lt;- ceiling(power_analysis_result$n) # 向上取整\ncat(\"Required sample size per group:\", required_sample_size, \"\\n\")\n\n# 解释结果\ncat(\"为了在显著性水平为\", sig_level, \"，检测到 Cohen's d =\", effect_size, \"的效应量，\\n\")\ncat(\"并达到\", desired_power * 100, \"% 的检验功效，每组至少需要\", required_sample_size, \"个样本。\\n\")\n事后功效分析 (Post-hoc Power Analysis): 在研究结束后，根据已获得的样本数据和效应量，计算检验的实际功效。 事后功效分析存在争议，因为其结果高度依赖于样本效应量，可能无法提供关于检验功效的可靠信息。 更推荐在研究设计阶段进行事前功效分析。\n# 假设 group1_vector 和 group2_vector 是已收集的两组独立样本数据向量\ngroup1_vector &lt;- rnorm(30, mean = 50, sd = 10) # 模拟数据\ngroup2_vector &lt;- rnorm(30, mean = 55, sd = 10) # 模拟数据\nsample_size &lt;- length(group1_vector) # 样本容量 (每组样本量)\n\n# 计算样本效应量 Cohen's d\ncohen_d_result &lt;- cohen.d(group1_vector, group2_vector, paired = FALSE, var.equal = TRUE)\nsample_effect_size &lt;- cohen_d_result$estimate\n\n# 进行事后功效分析，计算实际功效\npost_hoc_power_analysis_result &lt;- pwr.t.test(n = sample_size,\n                                              d = sample_effect_size,\n                                              sig.level = 0.05,\n                                              type = \"two.sample\",\n                                              alternative = \"two.sided\")\n\nprint(post_hoc_power_analysis_result)\n\n# 提取实际功效\nactual_power &lt;- post_hoc_power_analysis_result$power\ncat(\"Actual power:\", actual_power, \"\\n\")\n\n# 解释结果\ncat(\"在样本容量为\", sample_size, \"，显著性水平为 0.05，样本效应量 Cohen's d =\", sample_effect_size, \"的情况下，\\n\")\ncat(\"该独立样本 t 检验的实际功效为\", actual_power * 100, \"%。\\n\")\ncat(\"这意味着，如果总体中真实存在 Cohen's d =\", sample_effect_size, \"的效应，\\n\")\ncat(\"我们有\", actual_power * 100, \"% 的概率通过该检验发现这个效应。\\n\")\n\n\n效应量 (Effect Size):\n\n效应量是用于衡量效应或差异大小的指标，它独立于样本容量，不受样本容量的影响。 p 值只告诉我们效应是否 “显著”，但不告诉我们效应 “有多大”。 效应量弥补了 p 值的不足，提供了效应大小的信息，有助于判断研究结果的实际意义和重要性。 “统计显著性” (p 值) 不等于 “实际显著性” (效应量)。 一个很小的效应，如果样本容量足够大，也可能达到统计显著性，但这并不意味着这个效应在实际应用中很重要。 反之，一个较大的效应，如果样本容量太小，可能无法达到统计显著性，但这并不意味着这个效应不存在或不重要。 在报告假设检验结果时，除了 p 值，还应该报告效应量和置信区间，以便更全面地评价研究结果。\n常用的效应量指标:\n\nCohen’s d: 用于独立样本 t 检验，衡量两个总体均值差异的标准化指标。 Cohen’s d = (\\(\\\\bar{x}_1\\) - \\(\\\\bar{x}_2\\)) / s_pooled，其中 s_pooled 是合并样本标准差。 Cohen 提出的经验法则：d = 0.2 (小效应), d = 0.5 (中等效应), d = 0.8 (大效应)。 R 中 effsize 包的 cohen.d() 函数可以计算 Cohen’s d。 代码示例 (独立样本 t 检验):\n# 安装和加载 effsize 包 (如果尚未安装)\n# install.packages(\"effsize\")\nlibrary(effsize)\n\n# 假设 group1_vector 和 group2_vector 是两组独立样本数据向量\ncohen_d_result &lt;- cohen.d(group1_vector, group2_vector,\n                           paired = FALSE,  # 独立样本\n                           var.equal = TRUE) # 假设方差相等 (如果使用 Welch's t 检验，则设置为 FALSE)\nprint(cohen_d_result)\n\n# 提取 Cohen's d 值\ncohen_d_value &lt;- cohen_d_result$estimate\ncat(\"Cohen's d:\", cohen_d_value, \"\\n\")\n\n# 解释效应量大小 (根据 Cohen's 经验法则)\nif (abs(cohen_d_value) &gt;= 0.8) {\n  cat(\"效应量很大 (Large effect size).\\n\")\n} else if (abs(cohen_d_value) &gt;= 0.5) {\n  cat(\"效应量为中等 (Medium effect size).\\n\")\n} else if (abs(cohen_d_value) &gt;= 0.2) {\n  cat(\"效应量为小 (Small effect size).\\n\")\n} else {\n  cat(\"效应量很小或无效应 (Very small or negligible effect size).\\n\")\n}\n相关系数 (Correlation Coefficient, r): 用于衡量两个变量之间线性关系的强度和方向。 r 的取值范围为 [-1, 1]。 r = 0.1 (小效应), r = 0.3 (中等效应), r = 0.5 (大效应)。 R 函数 cor() 可以计算相关系数。\nR² (R-squared, 决定系数): 用于回归分析，衡量回归模型对因变量变异的解释程度。 R² 的取值范围为 [0, 1]。 R² = 0.01 (小效应), R² = 0.09 (中等效应), R² = 0.25 (大效应)。 R 函数 summary() 回归模型结果可以得到 R²。\n\\(\\\\eta^2\\) (Eta-squared, 偏\\(\\\\eta^2\\)): 用于方差分析 (ANOVA)，衡量自变量对因变量变异的解释程度。 \\(\\\\eta^2\\) 的取值范围为 [0, 1]。 \\(\\\\eta^2\\) = 0.01 (小效应), \\(\\\\eta^2\\) = 0.06 (中等效应), \\(\\\\eta^2\\) = 0.14 (大效应)。 R 中 effectsize 包的 eta_squared() 函数可以计算 \\(\\\\eta^2\\) 和 偏\\(\\\\eta^2\\)。\n\n效应量的报告: 在报告假设检验结果时，除了 p 值，应该报告相应的效应量指标，并解释效应量的大小，例如： “独立样本 t 检验结果显示，两组均值差异显著 (t(df) = t 值, p &lt; .05, Cohen’s d = d 值, 95% CI [下限, 上限])，效应量为中等水平，表明…”。\n\n假设检验步骤总结:\n\n提出研究问题，确定研究假设。 明确研究目的，根据研究问题，提出关于总体参数的原假设 H₀ 和备择假设 H₁。 确定检验方向 (双侧或单侧)。\n选择合适的检验方法和检验统计量。 根据数据类型、研究设计、假设类型，选择合适的假设检验方法 (例如，t 检验、方差分析、卡方检验等)。 确定检验统计量 (例如，t 统计量、F 统计量、\\(\\\\chi^2\\) 统计量)。\n设定显著性水平 \\(\\\\alpha\\)。 通常取 \\(\\\\alpha = 0.05\\)。 根据研究的重要性、后果、以及对 Type I 错误和 Type II 错误的权衡，选择合适的 \\(\\\\alpha\\) 水平。\n收集样本数据，计算检验统计量的值。 使用 R 或其他统计软件，计算样本统计量和检验统计量的值。\n计算 p 值，并与显著性水平 \\(\\\\alpha\\) 进行比较，做出决策。 根据检验统计量的值，计算 p 值。 如果 p 值 ≤ \\(\\\\alpha\\)，则拒绝原假设 H₀，接受备择假设 H₁，认为结果具有统计显著性。 如果 p 值 &gt; \\(\\\\alpha\\)，则没有充分证据拒绝原假设 H₀，接受原假设 H₀ (或 “不拒绝” H₀)。\n解释结果，报告结论。 根据假设检验的结果，结合研究背景和实际意义，解释统计结果，并得出研究结论。 在报告结果时，除了 p 值，还应该报告效应量、置信区间、样本描述性统计量等信息，并讨论可能存在的 Type I 错误和 Type II 错误的风险，以及检验功效的局限性。\n\n单样本 t 检验、双样本 t 检验 (独立样本、配对样本):\n\n单样本 t 检验 (One-Sample t-test): 检验单个样本的均值是否与已知的总体均值 (或某个特定值) 存在显著差异。 适用条件：\n\n因变量为连续变量。\n样本来自正态分布总体 (或近似正态分布，样本容量较大时可放宽)。\n总体标准差 σ 未知，用样本标准差 s 估计。\n假设:\n\nH₀: μ = μ₀ (总体均值等于 μ₀)\nH₁: μ ≠ μ₀ (总体均值不等于 μ₀，双侧检验) 或 H₁: μ &gt; μ₀ (右侧检验) 或 H₁: μ &lt; μ₀ (左侧检验)\n\n检验统计量: t 统计量\n\\[\nt = \\\\frac{\\\\bar{x} - \\\\mu_0}{s / \\\\sqrt{n}}\n\\]\n其中，\\(\\\\bar{x}\\) 是样本均值，μ₀ 是原假设的总体均值，s 是样本标准差，n 是样本容量。 t 统计量服从自由度为 n-1 的 t 分布。\n\nR 函数 t.test() 进行单样本 t 检验:\n# 假设 sample_vector 是样本数据向量，mu_0 是原假设的总体均值\nt.test(sample_vector, mu = mu_0,\n       alternative = \"two.sided\",  # 双侧检验 (默认)\n       # alternative = \"greater\",  # 右侧检验\n       # alternative = \"less\",     # 左侧检验\n       conf.level = 0.95)         # 置信水平 (默认 95%)\n双样本 t 检验 (Two-Sample t-test): 比较两个样本所代表的总体均值是否存在显著差异。 分为独立样本 t 检验和配对样本 t 检验。\n\n独立样本 t 检验 (Independent Samples t-test): 比较两个独立样本组的均值是否存在显著差异。 适用条件：\n\n因变量为连续变量。\n两个样本分别来自正态分布总体 (或近似正态分布，样本容量较大时可放宽)。\n两个总体相互独立。\n方差齐性 (Homogeneity of Variance): 两个总体的方差相等 (或近似相等)。 如果方差不齐，可以使用 Welch’s t 检验 (R 中 t.test() 默认 Welch’s t 检验)。\n假设:\n\nH₀: μ₁ = μ₂ (两个总体均值相等)\nH₁: μ₁ ≠ μ₂ (两个总体均值不相等，双侧检验) 或 H₁: μ₁ &gt; μ₂ (右侧检验) 或 H₁: μ₁ &lt; μ₂ (左侧检验)\n\n检验统计量: t 统计量 (假设方差齐性) 或 Welch’s t 统计量 (方差不齐)\n\\[\nt = \\\\frac{\\\\bar{x}_1 - \\\\bar{x}_2}{s_{pooled} \\\\sqrt{\\\\frac{1}{n_1} + \\\\frac{1}{n_2}}}  (方差齐性)\n\\]\n\\[\nt = \\\\frac{\\\\bar{x}_1 - \\\\bar{x}_2}{\\\\sqrt{\\\\frac{s_1^2}{n_1} + \\\\frac{s_2^2}{n_2}}}  (Welch's t 检验，方差不齐)\n\\]\n其中，\\(\\\\bar{x}_1, \\\\bar{x}_2\\) 是两个样本均值，\\(s_{pooled}\\) 是合并样本标准差，\\(s_1, s_2\\) 是两个样本标准差，\\(n_1, n_2\\) 是两个样本容量。 t 统计量服从 t 分布，自由度根据方差齐性与否有所不同。\n\nR 函数 t.test() 进行独立样本 t 检验:\n# 假设 group1_vector 和 group2_vector 是两组独立样本数据向量\nt.test(group1_vector, group2_vector,\n       paired = FALSE,         # 独立样本 (默认)\n       var.equal = TRUE,      # 假设方差相等 (默认 FALSE，使用 Welch's t 检验)\n       alternative = \"two.sided\",  # 双侧检验 (默认)\n       # alternative = \"greater\",  # 右侧检验 (group1 &gt; group2)\n       # alternative = \"less\",     # 左侧检验 (group1 &lt; group2)\n       conf.level = 0.95)         # 置信水平 (默认 95%)\n配对样本 t 检验 (Paired Samples t-test): 比较配对样本 (例如，同一对象处理前后的数据) 的均值是否存在显著差异。 适用条件：\n\n因变量为连续变量。\n配对样本差值来自正态分布总体 (或近似正态分布，样本容量较大时可放宽)。\n配对样本数据之间存在配对关系。\n假设: 配对样本 t 检验实际上是对配对样本差值进行单样本 t 检验。 设 \\(D_i = X_{1i} - X_{2i}\\) 为第 i 对样本的差值，总体均值差为 μ_D。\n\nH₀: μ_D = 0 (总体均值差为 0，即两个总体均值相等)\nH₁: μ_D ≠ 0 (总体均值差不为 0，双侧检验) 或 H₁: μ_D &gt; 0 (右侧检验) 或 H₁: μ_D &lt; 0 (左侧检验)\n\n检验统计量: t 统计量 (基于配对样本差值)\n\\[\nt = \\\\frac{\\\\bar{D} - 0}{s_D / \\\\sqrt{n}}\n\\]\n其中，\\(\\\\bar{D}\\) 是配对样本差值的样本均值，\\(s_D\\) 是配对样本差值的样本标准差，n 是配对样本对数。 t 统计量服从自由度为 n-1 的 t 分布。\n\nR 函数 t.test() 进行配对样本 t 检验:\n# 假设 before_vector 和 after_vector 是配对样本数据向量\nt.test(before_vector, after_vector,\n       paired = TRUE,          # 配对样本\n       alternative = \"two.sided\",  # 双侧检验 (默认)\n       # alternative = \"greater\",  # 右侧检验 (before &lt; after)\n       # alternative = \"less\",     # 左侧检验 (before &gt; after)\n       conf.level = 0.95)         # 置信水平 (默认 95%)\n\nt 检验的 R 语言实战练习:\n\n单样本 t 检验: 检验 mtcars 数据集 mpg 列的平均值是否等于 20。 计算效应量 (Cohen’s d 的变体，或报告均值差异)。 进行事后功效分析 (可选)。\n# 单样本 t 检验：检验 mtcars 数据集 mpg 列的平均值是否等于 20\nt.test(mtcars$mpg, mu = 20)\n\n# 计算均值差异 (效应量的一种简单形式)\nmean_mpg &lt;- mean(mtcars$mpg)\nmean_difference &lt;- mean_mpg - 20\ncat(\"Mean difference:\", mean_difference, \"\\n\")\n\n# (可选) 事后功效分析 (单样本 t 检验的功效分析相对复杂，这里省略)\n独立样本 t 检验: 比较 mtcars 数据集不同 am (变速器类型) 组别 mpg 的平均值是否存在显著差异。 计算效应量 (Cohen’s d)。 进行事前功效分析 (例如，计算达到 80% 功效所需的样本容量，假设预期效应量为中等)。 进行事后功效分析 (计算实际功效)。\n# 独立样本 t 检验：比较 mtcars 数据集不同 am 组别 mpg 的平均值\nindependent_t_test_result &lt;- t.test(mpg ~ am, data = mtcars, var.equal = TRUE) # 假设方差相等\nprint(independent_t_test_result)\n\n# 计算 Cohen's d 效应量\nlibrary(effsize)\ncohen_d_result &lt;- cohen.d(mpg ~ am, data = mtcars, paired = FALSE, var.equal = TRUE)\nprint(cohen_d_result)\n\n# 事前功效分析：计算达到 80% 功效所需的样本容量 (假设效应量为 Cohen's d = 0.5)\nlibrary(pwr)\npower_analysis_result &lt;- pwr.t.test(d = 0.5, power = 0.8, sig.level = 0.05,\n                                      type = \"two.sample\", alternative = \"two.sided\")\nprint(power_analysis_result)\nrequired_n &lt;- ceiling(power_analysis_result$n)\ncat(\"Required sample size per group (for power = 80%, Cohen's d = 0.5):\", required_n, \"\\n\")\n\n# 事后功效分析：计算实际功效\nactual_power_analysis_result &lt;- pwr.t.test(n = length(mtcars$mpg[mtcars$am == 0]), # 或 length(mtcars$mpg[mtcars$am == 1])\n                                             d = cohen_d_result$estimate,\n                                             sig.level = 0.05,\n                                             type = \"two.sample\", alternative = \"two.sided\")\nprint(actual_power_analysis_result)\nactual_power &lt;- actual_power_analysis_result$power\ncat(\"Actual power:\", actual_power, \"\\n\")\n配对样本 t 检验: 分析 sleep 数据集 extra 列在 group 为 1 和 2 时的差异 (实际上 sleep 数据集不是真正的配对数据，这里仅作为演示配对 t 检验的例子)。 计算效应量 (Cohen’s d 的变体，或报告均值差异)。 进行事后功效分析 (可选)。 或者，寻找真正的配对数据集进行配对 t 检验练习。\n# 配对样本 t 检验：分析 sleep 数据集 extra 列在 group 为 1 和 2 时的差异 (演示配对 t 检验)\npaired_t_test_result &lt;- t.test(extra ~ group, data = sleep, paired = TRUE) # 注意：sleep 数据集不是真正的配对数据\nprint(paired_t_test_result)\n\n# 计算均值差异 (效应量的一种简单形式)\nmean_difference_paired &lt;- mean(sleep$extra[sleep$group == 1] - sleep$extra[sleep$group == 2])\ncat(\"Mean difference (paired):\", mean_difference_paired, \"\\n\")\n\n# (可选) 事后功效分析 (配对样本 t 检验的功效分析相对复杂，这里省略)\n\n\n\n\n\n5. 项目一汇报准备\n\n汇报内容框架: 为帮助学生更好地准备项目汇报，提供以下内容框架建议：\n\n项目背景与目标: 清晰阐述项目背景、研究意义和具体研究目标\n数据概况: 详细说明数据来源、样本量、变量特征，以及数据质量评估\n分析方法: 介绍已采用的数据清洗、预处理和统计分析方法\n初步发现: 展示描述性统计和可视化分析结果，突出数据特征和潜在模式\n挑战与展望: 总结当前遇到的困难，并提出后续研究计划和改进方向\n\n汇报质量要求: 为确保汇报效果，提出以下具体要求：\n\n时间控制: 每组汇报时间控制在4-5分钟\n演示文稿: 使用PPT进行展示，要求结构清晰、重点突出\n数据可视化: 图表设计规范，信息传达准确\n团队协作: 小组成员需共同参与准备，明确分工\n预演准备: 建议提前进行小组演练，确保汇报流畅\n\n评估标准: 汇报将根据以下维度进行评估：\n\n内容完整性: 是否涵盖所有关键要素\n逻辑清晰度: 汇报结构是否合理，论证是否严谨\n分析深度: 是否充分挖掘数据价值，提出有价值见解\n展示效果: 演示文稿设计是否专业，表达是否清晰\n团队协作: 小组成员配合是否默契，分工是否合理\n\n\n\n\n6. 本周内容总结与下周预告\n\n本周回顾: 回顾本周学习内容，巩固重点知识。 本周我们初步学习了推断性统计的基本思想，参数估计 (点估计和区间估计)，假设检验的基本原理和步骤，以及假设检验中可能犯的 Type I 错误和 Type II 错误，检验功效和效应量的概念和计算方法，以及常用的 t 检验 (单样本 t 检验、独立样本 t 检验、配对样本 t 检验)。 推断性统计是统计学的核心内容，参数估计和假设检验是推断性统计的基础，t 检验是均值检验的常用方法，理解假设检验的错误类型、功效和效应量，掌握效应量 Cohen’s d 的计算和功效分析的基本方法，能够更全面、更深入、更严谨地理解和应用假设检验。 务必理解和掌握本周所学内容。\n下周预告: 下周我们将继续学习假设检验，深入学习方差分析 (ANOVA)，用于检验多个总体均值是否相等。 方差分析是 t 检验的扩展，可以处理三个或更多组别均值比较的问题。 我们还将学习非参数检验，用于处理不满足参数检验条件的数据。 下周内容将更加深入，敬请期待！\n\n\n\n7. 课后任务\n\n小组任务:\n\n项目一汇报准备:\n\n根据项目一汇报框架，准备完整的汇报材料（PPT）\n明确小组成员分工，确定主要汇报人\n进行至少2次小组预演，确保汇报流畅\n重点准备以下内容：\n\n项目背景与目标（1分钟）\n数据概况与质量评估（1分钟）\n分析方法与初步发现（2分钟）\n挑战与后续计划（1分钟）\n\n\n项目一数据分析深化:\n\n在已完成的数据清洗和描述性统计基础上\n提出2-3个具体的假设检验问题\n使用t检验方法进行验证\n计算效应量（Cohen’s d）\n进行简单的事后功效分析\n将分析结果整合到项目汇报中\n\n\n个人任务:\n\n复习本周内容: 回顾本周讲义和课堂笔记，巩固推断性统计基本概念、参数估计方法、假设检验步骤、t 检验的适用条件和 R 语言实现，重点理解 Type I 错误、Type II 错误、检验功效和效应量的概念和意义，掌握 Cohen’s d 的计算和功效分析的基本 R 代码和结果解释。\nR 代码练习: 完成本讲义中布置的 R 代码练习，熟练掌握 t.test() 函数的用法，能够使用 R 进行单样本 t 检验、独立样本 t 检验和配对样本 t 检验。 练习使用 effsize 包计算 Cohen’s d 效应量 (独立样本 t 检验)，练习使用 pwr 包进行事前功效分析和事后功效分析 (独立样本 t 检验)。 尝试使用 AI 插件辅助 R 代码练习。\n概念理解和辨析: 重点理解和辨析以下概念：总体与样本，参数与统计量，点估计与区间估计，置信水平与显著性水平，原假设与备择假设，双侧检验与单侧检验，第一类错误与第二类错误，p 值，单样本 t 检验、独立样本 t 检验、配对样本 t 检验的适用场景和区别，Type I 错误与 Type II 错误，检验功效，效应量 (Cohen’s d, 相关系数 r, R², \\(\\\\eta^2\\))，统计显著性与实际显著性，事前功效分析与事后功效分析。\n\n\n\n\n\n\n\n\nAI 辅助学习小贴士\n\n\n\n\nR 代码练习: 继续在 VS Code 或 Cursor 中练习 R 语言代码，充分利用 AI 插件的代码自动补全、代码生成、代码解释、AI 聊天等功能。 遇到 R 代码问题，及时向 AI 提问。\n统计概念理解: 如果对推断性统计的概念 (例如，置信区间、假设检验、p 值、t 检验、第一类错误、第二类错误、检验功效、效应量、事前功效分析、事后功效分析 等) 理解不透彻，可以使用 AI 聊天提问，让 AI 提供更详细的解释和例子。 例如，提问： “解释假设检验中的第一类错误和第二类错误”, “什么是统计检验的功效，为什么它很重要？”, “什么是效应量，如何解释 Cohen’s d？”, “事前功效分析和事后功效分析有什么区别？”。\nR 函数用法查询: 使用 AI 聊天提问： “R 中 t.test() 函数的用法”, “如何使用 effsize 包在 R 中计算 Cohen’s d”, “如何使用 pwr 包在 R 中进行 t 检验的功效分析”, “R 中用于功效分析的包”。 AI 可能会提供函数文档或使用示例，以及 effsize 包和 pwr 包的更详细使用方法和参数解释。\n假设检验步骤指导: 如果不清楚假设检验的步骤，可以使用 AI 聊天咨询，例如，提问： “假设检验的步骤”, “如何设置原假设和备择假设”, “如何解释假设检验中的 p 值”。 AI 可能会提供步骤指导和示例。\n结果解释辅助: 如果对 R t.test() 函数输出结果的含义不清楚，可以使用 AI 代码解释功能，选中 t.test() 函数的输出结果，让 AI 解释结果的含义，例如，p 值、置信区间、t 统计量、自由度等。 也可以使用 AI 聊天提问，例如，提问： “解释 R 中 t.test() 函数的输出结果”, “如何在 t 检验结果中报告效应量和置信区间？”, “如何解释功效分析结果？”。 特别是关于功效分析结果中 n（样本量）、d（效应量）、power（检验功效）等参数的含义和解释。\n\n\n\n\n\n\n\n学习寄语\n\n\n\n工欲善其事，必先利其器！ 本周我们不仅学习了假设检验的基本方法，还掌握了评估检验质量和效应大小的工具：功效分析和效应量。 更完善的统计工具箱，助您在数据分析的道路上行稳致远！ 继续保持学习的热情，充分利用 VS Code/Cursor 和 AI 插件的强大功能，相信大家会在统计学和 R 语言的学习中取得更大的进步！ 下周中期检查见！",
    "crumbs": [
      "课程内容",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>第四周：推断性统计初步：参数估计与假设检验</span>"
    ]
  },
  {
    "objectID": "week04.html#第四周推断性统计初步参数估计与假设检验-共4课时",
    "href": "week04.html#第四周推断性统计初步参数估计与假设检验-共4课时",
    "title": "统计学讲义 - 第四周：推断性统计初步：参数估计与假设检验",
    "section": "",
    "text": "从样本推断总体：推断性统计入门\n前三周我们学习了描述性统计，掌握了如何概括和可视化数据。 从本周开始，我们将进入统计学的核心领域：推断性统计。 推断性统计的目标是利用样本数据来推断总体特征。 由于我们通常无法获取总体的全部数据，只能通过抽样获得样本数据，因此需要使用推断性统计方法，基于样本信息，对总体参数进行估计和检验。 本周我们将学习推断性统计的两个基本内容：参数估计和 假设检验，并初步接触常用的 t 检验。\n继续使用 VS Code 或 Cursor + AI 插件： 请继续使用 VS Code 或 Cursor 编辑器，并充分利用 AI 插件的代码辅助、智能提示、聊天问答等功能，提升学习效率。\n\n\n\n\n\n\n本周学习目标\n\n\n\n\n推断性统计核心思想: 理解推断性统计的目的和基本逻辑。\n参数估计: 掌握点估计和区间估计的基本概念和方法。\n假设检验: 理解假设检验的基本原理和步骤。\n假设检验的错误、功效与效应量: 理解假设检验中 Type I 错误和 Type II 错误，掌握检验功效和效应量的概念和意义。\nt 检验: 掌握单样本 t 检验和双样本 t 检验 (独立样本、配对样本) 的适用条件和 R 语言实现，并能计算效应量 Cohen’s d 和进行功效分析。\n抽样分布: 理解抽样分布的概念，为理解推断性统计奠定基础。\n项目中期检查准备: 开始准备项目一的中期检查汇报。\nAI 辅助统计推断: 探索使用 AI 工具辅助统计推断学习和应用。\n\n\n\n\n\n\n1. 推断性统计核心思想：从样本到总体\n\n总体 (Population) 与 样本 (Sample) 回顾: 回顾第一周学习的总体和样本的概念。\n\n总体: 研究对象的全体，是我们想要了解的真实情况。 例如，所有本科生、所有股票、所有商品。 总体通常很大，甚至无限，难以直接获取总体全部数据。\n样本: 从总体中抽取的一部分个体，是实际观测到的数据。 例如，随机抽取的 100 名本科生、某只股票过去一年的交易数据、某批次商品中抽取的 10 件商品。 样本数据是总体信息的载体，我们通过分析样本数据来推断总体特征。\n\n参数 (Parameter) 与 统计量 (Statistic):\n\n参数: 描述总体特征的数值，例如，总体均值 (μ)、总体标准差 (σ)、总体比例 (P)。 总体参数是未知的，是我们想要估计的目标。\n统计量: 描述样本特征的数值，例如，样本均值 (\\(\\\\bar{x}\\))、样本标准差 (s)、样本比例 (\\(\\\\hat{p}\\))。 统计量是已知的，可以根据样本数据计算出来，用于估计总体参数。\n\n抽样 (Sampling) 与 随机性 (Randomness):\n\n抽样: 从总体中抽取样本的过程。 随机抽样是推断性统计的基础，保证样本的代表性，避免抽样偏差。 常用的随机抽样方法包括简单随机抽样、分层抽样、整群抽样等。\n随机性: 抽样过程中的随机性导致样本统计量具有随机性，不同的样本会得到不同的统计量。 抽样分布描述了样本统计量的随机性规律。\n\n\n\n\n2. 参数估计：用样本估计总体\n\n点估计 (Point Estimation):\n\n用样本统计量直接估计总体参数。 例如，用样本均值 \\(\\\\bar{x}\\) 估计总体均值 μ，用样本标准差 s 估计总体标准差 σ，用样本比例 \\(\\\\hat{p}\\) 估计总体比例 P。\n点估计的优点是简单直观，易于计算。 缺点是只给出一个估计值，没有说明估计的精确程度，可能存在较大误差。 例如，我们用一个样本均值 52 来估计总体均值，但总体均值可能是 50，也可能是 55，我们不知道 52 这个估计值有多可靠。\n\n区间估计 (Interval Estimation):\n\n给出一个总体参数的可能取值范围，并说明该范围包含总体参数真值的可信程度。 例如，总体均值的 95% 置信区间为 [48, 56]，表示我们有 95% 的把握认为总体均值落在 48 到 56 之间。\n区间估计比点估计提供更丰富的信息，既给出了估计范围，又说明了估计的可靠性。 常用的区间估计方法是置信区间 (Confidence Interval)。\n\n置信区间 (Confidence Interval, CI):\n\n置信区间是指由样本数据计算出的、包含总体参数真值的某个概率范围。 例如，95% 置信区间表示，如果重复抽样 100 次，每次都计算一个置信区间，那么平均会有 95 个区间包含总体参数的真值。\n置信水平 (Confidence Level): 表示置信区间包含总体参数真值的概率，常用百分数表示，例如 90%, 95%, 99%。 常用的置信水平是 95%，对应的 \\(\\\\alpha = 1 - 0.95 = 0.05\\)。 置信水平越高，置信区间越宽，包含总体参数真值的可能性越大，但估计的精确度降低。 置信水平越低，置信区间越窄，估计的精确度提高，但包含总体参数真值的可能性降低。\n置信区间的计算: 置信区间的计算公式取决于总体参数类型、样本统计量分布、样本容量等因素。 例如，总体均值 μ 的置信区间 (样本容量较大时，总体标准差 σ 已知)：\n\\[\n置信区间 = 样本均值 \\\\pm 临界值 \\\\times 标准误差 = \\\\bar{x} \\\\pm Z_{\\\\alpha/2} \\\\times \\\\frac{\\\\sigma}{\\\\sqrt{n}}\n\\]\n其中，\\(\\\\bar{x}\\) 是样本均值，\\(\\\\sigma\\) 是总体标准差，n 是样本容量，\\(Z_{\\\\alpha/2}\\) 是标准正态分布的临界值 (例如，95% 置信水平时，\\(\\\\alpha = 0.05\\), \\(\\\\alpha/2 = 0.025\\), \\(Z_{0.025} = 1.96\\))，\\(\\frac{\\\\sigma}{\\\\sqrt{n}}\\) 是样本均值 \\(\\\\bar{x}\\) 的标准误差。\nR 函数 t.test() 计算 t 检验的置信区间: t.test() 函数可以进行 t 检验，并输出均值差的置信区间。 例如，独立样本 t 检验，比较两组均值差异，t.test() 输出的是两组均值差的置信区间。\n\n\n\n\n3. 假设检验：检验关于总体的假设\n\n假设检验的基本思想:\n\n先对总体参数提出一个假设 (原假设 H₀)，然后利用样本数据，判断是否有充分的证据拒绝原假设 H₀，接受备择假设 H₁。 类似于法庭判案，先假设被告无罪 (原假设 H₀)，然后收集证据 (样本数据)，判断是否有充分证据证明被告有罪 (拒绝原假设 H₀，接受备择假设 H₁)。\n假设检验是一种反证法。 我们通常无法直接证明备择假设 H₁ 为真，但可以通过否定原假设 H₀，间接支持备择假设 H₁。 如果样本数据与原假设 H₀ 矛盾，我们就有理由拒绝 H₀，转而接受 H₁。 如果样本数据与原假设 H₀ 并不矛盾，我们则没有充分证据拒绝 H₀，但也不能说 H₀ 一定为真，只能说 “接受 H₀” 或 “不拒绝 H₀”。\n\n原假设 (H₀) 与 备择假设 (H₁):\n\n原假设 (Null Hypothesis, H₀): 研究者想要检验的假设，通常是关于总体参数 “没有效应”、“没有差异”、“没有关系” 的假设。 例如，总体均值等于某个特定值 (μ = μ₀)，两组总体均值相等 (μ₁ = μ₂)，变量之间没有相关关系 (ρ = 0)。 原假设 H₀ 是假设检验的出发点，也是我们要试图拒绝的假设。\n备择假设 (Alternative Hypothesis, H₁): 与原假设 H₀ 对立的假设，是研究者希望支持的假设，通常是关于总体参数 “存在效应”、“存在差异”、“存在关系” 的假设。 例如，总体均值不等于某个特定值 (μ ≠ μ₀)，两组总体均值不相等 (μ₁ ≠ μ₂)，变量之间存在相关关系 (ρ ≠ 0)。 备择假设 H₁ 是当原假设 H₀ 被拒绝时，我们接受的结论。\n假设类型:\n\n双侧检验 (Two-tailed Test): 备择假设 H₁ 是总体参数 “不等于” 某个特定值，检验方向是双侧的。 例如，H₀: μ = μ₀, H₁: μ ≠ μ₀。\n单侧检验 (One-tailed Test): 备择假设 H₁ 是总体参数 “大于” 或 “小于” 某个特定值，检验方向是单侧的 (左侧或右侧)。 例如，右侧检验：H₀: μ ≤ μ₀, H₁: μ &gt; μ₀； 左侧检验：H₀: μ ≥ μ₀, H₁: μ &lt; μ₀。 选择单侧检验需要有充分的理由，并且在研究开始前就应该确定检验方向。 通常情况下，更常用双侧检验，因为它更保守，适用范围更广。\n\n\n假设检验的逻辑：\n\n假设原假设 H₀ 为真。 先假定原假设 H₀ 是正确的，作为出发点。\n在 H₀ 为真的前提下，推导样本统计量的抽样分布。 根据原假设 H₀ 和抽样分布理论，推导出检验统计量 (例如，t 统计量、F 统计量、\\(\\\\chi^2\\) 统计量) 的抽样分布。\n计算检验统计量的值和 p 值。 根据样本数据，计算检验统计量的值。 p 值 (p-value) 是指，在原假设 H₀ 为真的前提下，出现当前样本结果或更极端结果的概率。 p 值越小，说明在 H₀ 为真的情况下，出现当前样本结果的可能性越小，样本数据越不支持 H₀。\n根据 p 值和显著性水平 \\(\\\\alpha\\)，做出决策。 显著性水平 \\(\\\\alpha\\) 是事先设定的一个概率值，通常取 0.05, 0.01, 0.10，表示我们愿意容忍犯 Type I 错误的最大概率。 将 p 值与 \\(\\\\alpha\\) 进行比较：\n\n如果 p 值 ≤ \\(\\\\alpha\\)，则拒绝原假设 H₀，接受备择假设 H₁。 认为样本数据提供了充分的证据，否定了原假设 H₀，支持了备择假设 H₁。 结果具有统计显著性 (Statistically Significant)。\n如果 p 值 &gt; \\(\\\\alpha\\)，则没有充分证据拒绝原假设 H₀，接受原假设 H₀ (或 “不拒绝” H₀)。 认为样本数据没有提供充分的证据，否定原假设 H₀。 不能说原假设 H₀ 一定为真，只能说目前没有足够的证据推翻它。 结果不具有统计显著性 (Not Statistically Significant)。\n\n\n假设检验可能犯的错误：Type I 错误 & Type II 错误\n\n在假设检验中，我们的决策 (拒绝 H₀ 或 接受 H₀) 是基于样本数据做出的，有可能犯错误。 根据原假设 H₀ 的真实情况和我们的决策，可能出现两种类型的错误：\n\n\n\n决策\nH₀ 真实 (True)\nH₀ 错误 (False)\n\n\n\n\n拒绝 H₀\nType I 错误\n正确决策\n\n\n接受 H₀\n正确决策\nType II 错误\n\n\n\n\nType I 错误 (Type I Error, \\(\\\\alpha\\) 错误, 拒真错误): 当原假设 H₀ 实际上为真时，我们却拒绝了 H₀。 就好比 “真阳性” 的反面，把真原假设当成假原假设拒绝了。 Type I 错误的概率用 \\(\\\\alpha\\) 表示，\\(\\\\alpha\\) 也被称为 显著性水平 (Significance Level)，通常取值 0.05, 0.01, 0.10。 显著性水平 \\(\\\\alpha\\) 是我们事先设定的，我们愿意容忍犯 Type I 错误的最大概率。 例如，如果 \\(\\\\alpha = 0.05\\)，意味着如果我们重复进行 100 次假设检验，当 H₀ 均为真时，平均会有 5 次犯 Type I 错误。 我们希望尽可能控制 Type I 错误的概率，避免 “冤枉好人”。\nType II 错误 (Type II Error, \\(\\\\beta\\) 错误, 纳伪错误): 当原假设 H₀ 实际上为假时，我们却没有拒绝 H₀，反而接受了 H₀。 就好比 “假阴性”，把假原假设当成真原假设接受了。 Type II 错误的概率用 \\(\\\\beta\\) 表示，\\(\\\\beta\\) 的值通常是未知的，与总体参数的真实值、样本容量、显著性水平等因素有关。 我们希望尽可能减小 Type II 错误的概率，避免 “放过坏人”。\n\n\\(\\\\alpha\\) 与 \\(\\\\beta\\) 的权衡: \\(\\\\alpha\\) 和 \\(\\\\beta\\) 之间存在权衡关系。 当我们试图减小 \\(\\\\alpha\\) (例如，降低显著性水平，使拒绝 H₀ 更困难) 时，\\(\\\\beta\\) 通常会增大 (更容易接受错误的 H₀)。 反之，当我们试图减小 \\(\\\\beta\\) (例如，增大样本容量，提高检验功效) 时，\\(\\\\alpha\\) 可能会增大。 在实际应用中，我们需要根据具体情况，权衡 Type I 错误和 Type II 错误的重要性，选择合适的 \\(\\\\alpha\\) 水平，并尽可能提高检验功效，减小 \\(\\\\beta\\)。 通常情况下，我们更关注控制 Type I 错误的概率 \\(\\\\alpha\\)，因为拒绝原假设通常意味着发现了新的、重要的结论。**\n\n检验功效 (Power of a Test, 1 - \\(\\\\beta\\)):\n\n检验功效是指当原假设 H₀ 实际上为假时，我们正确地拒绝 H₀ 的概率。 检验功效 = 1 - \\(\\\\beta\\)。 检验功效越高，犯 Type II 错误的概率 \\(\\\\beta\\) 就越低，检验就越有效。 我们希望检验具有较高的功效，能够有效地发现真实存在的效应或差异。\n影响检验功效的因素:\n\n效应量 (Effect Size): 效应量是指总体参数偏离原假设 H₀ 的程度。 效应量越大，总体参数与原假设的差异越大，越容易被检验出来，检验功效越高。 例如，如果两个总体均值差异很大，就更容易通过 t 检验发现均值差异。\n样本容量 (Sample Size, n): 样本容量越大，样本信息越丰富，抽样误差越小，检验功效越高。 增大样本容量是提高检验功效的常用方法。\n显著性水平 (Significance Level, \\(\\\\alpha\\)): 显著性水平 \\(\\\\alpha\\) 越大，拒绝 H₀ 越容易，检验功效越高。 但增大 \\(\\\\alpha\\) 也会增大犯 Type I 错误的概率。 通常在保证 \\(\\\\alpha\\) 水平的前提下，尽可能提高检验功效。\n总体标准差 (\\(\\\\sigma\\)): 总体标准差越小，数据变异性越小，抽样误差越小，检验功效越高。 减小总体标准差通常无法直接控制，但在实验设计中，可以尽量控制无关变量，减小实验误差，从而减小数据变异性。\n单侧检验 vs 双侧检验: 在其他条件相同的情况下，单侧检验的功效通常比双侧检验高 (当效应方向与备择假设方向一致时)。 但选择单侧检验需要有充分的理由，并且在研究开始前就应该确定检验方向。\n\n功效分析 (Power Analysis): 功效分析是一种用于评估和提高检验功效的方法。 功效分析可以在研究设计阶段，预先计算所需的样本容量，以达到预期的检验功效。 也可以在研究结束后，评估已完成研究的检验功效，判断未拒绝原假设是否是因为检验功效不足。 R 中 pwr 包可以进行功效分析。 常用的功效分析类型包括：\n\n事前功效分析 (A-priori Power Analysis): 在研究开始前，为了达到预期的检验功效，计算所需的最小样本容量。 例如，研究者希望在显著性水平 \\(\\\\alpha = 0.05\\) 下，以 80% 的功效 (power = 0.8) 检测到中等效应量 (Cohen’s d = 0.5) 的均值差异，需要计算每组至少需要多少样本量。\n# 安装和加载 pwr 包 (如果尚未安装)\n# install.packages(\"pwr\")\nlibrary(pwr)\n\n# 设置参数\ndesired_power &lt;- 0.8      # 期望的检验功效 (通常为 0.8)\nsig_level &lt;- 0.05         # 显著性水平 (通常为 0.05)\neffect_size &lt;- 0.5       # 预期效应量 Cohen's d (例如，小效应 0.2, 中等效应 0.5, 大效应 0.8)\nalternative_hypothesis &lt;- \"two.sided\" # 双侧检验\ntest_type &lt;- \"two.sample\" # 独立样本 t 检验\n\n# 进行事前功效分析，计算所需样本容量\npower_analysis_result &lt;- pwr.t.test(power = desired_power,\n                                      sig.level = sig_level,\n                                      d = effect_size,\n                                      type = test_type,\n                                      alternative = alternative_hypothesis)\n\nprint(power_analysis_result)\n\n# 提取所需样本容量 (每组样本量)\nrequired_sample_size &lt;- ceiling(power_analysis_result$n) # 向上取整\ncat(\"Required sample size per group:\", required_sample_size, \"\\n\")\n\n# 解释结果\ncat(\"为了在显著性水平为\", sig_level, \"，检测到 Cohen's d =\", effect_size, \"的效应量，\\n\")\ncat(\"并达到\", desired_power * 100, \"% 的检验功效，每组至少需要\", required_sample_size, \"个样本。\\n\")\n事后功效分析 (Post-hoc Power Analysis): 在研究结束后，根据已获得的样本数据和效应量，计算检验的实际功效。 事后功效分析存在争议，因为其结果高度依赖于样本效应量，可能无法提供关于检验功效的可靠信息。 更推荐在研究设计阶段进行事前功效分析。\n# 假设 group1_vector 和 group2_vector 是已收集的两组独立样本数据向量\ngroup1_vector &lt;- rnorm(30, mean = 50, sd = 10) # 模拟数据\ngroup2_vector &lt;- rnorm(30, mean = 55, sd = 10) # 模拟数据\nsample_size &lt;- length(group1_vector) # 样本容量 (每组样本量)\n\n# 计算样本效应量 Cohen's d\ncohen_d_result &lt;- cohen.d(group1_vector, group2_vector, paired = FALSE, var.equal = TRUE)\nsample_effect_size &lt;- cohen_d_result$estimate\n\n# 进行事后功效分析，计算实际功效\npost_hoc_power_analysis_result &lt;- pwr.t.test(n = sample_size,\n                                              d = sample_effect_size,\n                                              sig.level = 0.05,\n                                              type = \"two.sample\",\n                                              alternative = \"two.sided\")\n\nprint(post_hoc_power_analysis_result)\n\n# 提取实际功效\nactual_power &lt;- post_hoc_power_analysis_result$power\ncat(\"Actual power:\", actual_power, \"\\n\")\n\n# 解释结果\ncat(\"在样本容量为\", sample_size, \"，显著性水平为 0.05，样本效应量 Cohen's d =\", sample_effect_size, \"的情况下，\\n\")\ncat(\"该独立样本 t 检验的实际功效为\", actual_power * 100, \"%。\\n\")\ncat(\"这意味着，如果总体中真实存在 Cohen's d =\", sample_effect_size, \"的效应，\\n\")\ncat(\"我们有\", actual_power * 100, \"% 的概率通过该检验发现这个效应。\\n\")\n\n\n效应量 (Effect Size):\n\n效应量是用于衡量效应或差异大小的指标，它独立于样本容量，不受样本容量的影响。 p 值只告诉我们效应是否 “显著”，但不告诉我们效应 “有多大”。 效应量弥补了 p 值的不足，提供了效应大小的信息，有助于判断研究结果的实际意义和重要性。 “统计显著性” (p 值) 不等于 “实际显著性” (效应量)。 一个很小的效应，如果样本容量足够大，也可能达到统计显著性，但这并不意味着这个效应在实际应用中很重要。 反之，一个较大的效应，如果样本容量太小，可能无法达到统计显著性，但这并不意味着这个效应不存在或不重要。 在报告假设检验结果时，除了 p 值，还应该报告效应量和置信区间，以便更全面地评价研究结果。\n常用的效应量指标:\n\nCohen’s d: 用于独立样本 t 检验，衡量两个总体均值差异的标准化指标。 Cohen’s d = (\\(\\\\bar{x}_1\\) - \\(\\\\bar{x}_2\\)) / s_pooled，其中 s_pooled 是合并样本标准差。 Cohen 提出的经验法则：d = 0.2 (小效应), d = 0.5 (中等效应), d = 0.8 (大效应)。 R 中 effsize 包的 cohen.d() 函数可以计算 Cohen’s d。 代码示例 (独立样本 t 检验):\n# 安装和加载 effsize 包 (如果尚未安装)\n# install.packages(\"effsize\")\nlibrary(effsize)\n\n# 假设 group1_vector 和 group2_vector 是两组独立样本数据向量\ncohen_d_result &lt;- cohen.d(group1_vector, group2_vector,\n                           paired = FALSE,  # 独立样本\n                           var.equal = TRUE) # 假设方差相等 (如果使用 Welch's t 检验，则设置为 FALSE)\nprint(cohen_d_result)\n\n# 提取 Cohen's d 值\ncohen_d_value &lt;- cohen_d_result$estimate\ncat(\"Cohen's d:\", cohen_d_value, \"\\n\")\n\n# 解释效应量大小 (根据 Cohen's 经验法则)\nif (abs(cohen_d_value) &gt;= 0.8) {\n  cat(\"效应量很大 (Large effect size).\\n\")\n} else if (abs(cohen_d_value) &gt;= 0.5) {\n  cat(\"效应量为中等 (Medium effect size).\\n\")\n} else if (abs(cohen_d_value) &gt;= 0.2) {\n  cat(\"效应量为小 (Small effect size).\\n\")\n} else {\n  cat(\"效应量很小或无效应 (Very small or negligible effect size).\\n\")\n}\n相关系数 (Correlation Coefficient, r): 用于衡量两个变量之间线性关系的强度和方向。 r 的取值范围为 [-1, 1]。 r = 0.1 (小效应), r = 0.3 (中等效应), r = 0.5 (大效应)。 R 函数 cor() 可以计算相关系数。\nR² (R-squared, 决定系数): 用于回归分析，衡量回归模型对因变量变异的解释程度。 R² 的取值范围为 [0, 1]。 R² = 0.01 (小效应), R² = 0.09 (中等效应), R² = 0.25 (大效应)。 R 函数 summary() 回归模型结果可以得到 R²。\n\\(\\\\eta^2\\) (Eta-squared, 偏\\(\\\\eta^2\\)): 用于方差分析 (ANOVA)，衡量自变量对因变量变异的解释程度。 \\(\\\\eta^2\\) 的取值范围为 [0, 1]。 \\(\\\\eta^2\\) = 0.01 (小效应), \\(\\\\eta^2\\) = 0.06 (中等效应), \\(\\\\eta^2\\) = 0.14 (大效应)。 R 中 effectsize 包的 eta_squared() 函数可以计算 \\(\\\\eta^2\\) 和 偏\\(\\\\eta^2\\)。\n\n效应量的报告: 在报告假设检验结果时，除了 p 值，应该报告相应的效应量指标，并解释效应量的大小，例如： “独立样本 t 检验结果显示，两组均值差异显著 (t(df) = t 值, p &lt; .05, Cohen’s d = d 值, 95% CI [下限, 上限])，效应量为中等水平，表明…”。\n\n假设检验步骤总结:\n\n提出研究问题，确定研究假设。 明确研究目的，根据研究问题，提出关于总体参数的原假设 H₀ 和备择假设 H₁。 确定检验方向 (双侧或单侧)。\n选择合适的检验方法和检验统计量。 根据数据类型、研究设计、假设类型，选择合适的假设检验方法 (例如，t 检验、方差分析、卡方检验等)。 确定检验统计量 (例如，t 统计量、F 统计量、\\(\\\\chi^2\\) 统计量)。\n设定显著性水平 \\(\\\\alpha\\)。 通常取 \\(\\\\alpha = 0.05\\)。 根据研究的重要性、后果、以及对 Type I 错误和 Type II 错误的权衡，选择合适的 \\(\\\\alpha\\) 水平。\n收集样本数据，计算检验统计量的值。 使用 R 或其他统计软件，计算样本统计量和检验统计量的值。\n计算 p 值，并与显著性水平 \\(\\\\alpha\\) 进行比较，做出决策。 根据检验统计量的值，计算 p 值。 如果 p 值 ≤ \\(\\\\alpha\\)，则拒绝原假设 H₀，接受备择假设 H₁，认为结果具有统计显著性。 如果 p 值 &gt; \\(\\\\alpha\\)，则没有充分证据拒绝原假设 H₀，接受原假设 H₀ (或 “不拒绝” H₀)。\n解释结果，报告结论。 根据假设检验的结果，结合研究背景和实际意义，解释统计结果，并得出研究结论。 在报告结果时，除了 p 值，还应该报告效应量、置信区间、样本描述性统计量等信息，并讨论可能存在的 Type I 错误和 Type II 错误的风险，以及检验功效的局限性。\n\n单样本 t 检验、双样本 t 检验 (独立样本、配对样本):\n\n单样本 t 检验 (One-Sample t-test): 检验单个样本的均值是否与已知的总体均值 (或某个特定值) 存在显著差异。 适用条件：\n\n因变量为连续变量。\n样本来自正态分布总体 (或近似正态分布，样本容量较大时可放宽)。\n总体标准差 σ 未知，用样本标准差 s 估计。\n假设:\n\nH₀: μ = μ₀ (总体均值等于 μ₀)\nH₁: μ ≠ μ₀ (总体均值不等于 μ₀，双侧检验) 或 H₁: μ &gt; μ₀ (右侧检验) 或 H₁: μ &lt; μ₀ (左侧检验)\n\n检验统计量: t 统计量\n\\[\nt = \\\\frac{\\\\bar{x} - \\\\mu_0}{s / \\\\sqrt{n}}\n\\]\n其中，\\(\\\\bar{x}\\) 是样本均值，μ₀ 是原假设的总体均值，s 是样本标准差，n 是样本容量。 t 统计量服从自由度为 n-1 的 t 分布。\n\nR 函数 t.test() 进行单样本 t 检验:\n# 假设 sample_vector 是样本数据向量，mu_0 是原假设的总体均值\nt.test(sample_vector, mu = mu_0,\n       alternative = \"two.sided\",  # 双侧检验 (默认)\n       # alternative = \"greater\",  # 右侧检验\n       # alternative = \"less\",     # 左侧检验\n       conf.level = 0.95)         # 置信水平 (默认 95%)\n双样本 t 检验 (Two-Sample t-test): 比较两个样本所代表的总体均值是否存在显著差异。 分为独立样本 t 检验和配对样本 t 检验。\n\n独立样本 t 检验 (Independent Samples t-test): 比较两个独立样本组的均值是否存在显著差异。 适用条件：\n\n因变量为连续变量。\n两个样本分别来自正态分布总体 (或近似正态分布，样本容量较大时可放宽)。\n两个总体相互独立。\n方差齐性 (Homogeneity of Variance): 两个总体的方差相等 (或近似相等)。 如果方差不齐，可以使用 Welch’s t 检验 (R 中 t.test() 默认 Welch’s t 检验)。\n假设:\n\nH₀: μ₁ = μ₂ (两个总体均值相等)\nH₁: μ₁ ≠ μ₂ (两个总体均值不相等，双侧检验) 或 H₁: μ₁ &gt; μ₂ (右侧检验) 或 H₁: μ₁ &lt; μ₂ (左侧检验)\n\n检验统计量: t 统计量 (假设方差齐性) 或 Welch’s t 统计量 (方差不齐)\n\\[\nt = \\\\frac{\\\\bar{x}_1 - \\\\bar{x}_2}{s_{pooled} \\\\sqrt{\\\\frac{1}{n_1} + \\\\frac{1}{n_2}}}  (方差齐性)\n\\]\n\\[\nt = \\\\frac{\\\\bar{x}_1 - \\\\bar{x}_2}{\\\\sqrt{\\\\frac{s_1^2}{n_1} + \\\\frac{s_2^2}{n_2}}}  (Welch's t 检验，方差不齐)\n\\]\n其中，\\(\\\\bar{x}_1, \\\\bar{x}_2\\) 是两个样本均值，\\(s_{pooled}\\) 是合并样本标准差，\\(s_1, s_2\\) 是两个样本标准差，\\(n_1, n_2\\) 是两个样本容量。 t 统计量服从 t 分布，自由度根据方差齐性与否有所不同。\n\nR 函数 t.test() 进行独立样本 t 检验:\n# 假设 group1_vector 和 group2_vector 是两组独立样本数据向量\nt.test(group1_vector, group2_vector,\n       paired = FALSE,         # 独立样本 (默认)\n       var.equal = TRUE,      # 假设方差相等 (默认 FALSE，使用 Welch's t 检验)\n       alternative = \"two.sided\",  # 双侧检验 (默认)\n       # alternative = \"greater\",  # 右侧检验 (group1 &gt; group2)\n       # alternative = \"less\",     # 左侧检验 (group1 &lt; group2)\n       conf.level = 0.95)         # 置信水平 (默认 95%)\n配对样本 t 检验 (Paired Samples t-test): 比较配对样本 (例如，同一对象处理前后的数据) 的均值是否存在显著差异。 适用条件：\n\n因变量为连续变量。\n配对样本差值来自正态分布总体 (或近似正态分布，样本容量较大时可放宽)。\n配对样本数据之间存在配对关系。\n假设: 配对样本 t 检验实际上是对配对样本差值进行单样本 t 检验。 设 \\(D_i = X_{1i} - X_{2i}\\) 为第 i 对样本的差值，总体均值差为 μ_D。\n\nH₀: μ_D = 0 (总体均值差为 0，即两个总体均值相等)\nH₁: μ_D ≠ 0 (总体均值差不为 0，双侧检验) 或 H₁: μ_D &gt; 0 (右侧检验) 或 H₁: μ_D &lt; 0 (左侧检验)\n\n检验统计量: t 统计量 (基于配对样本差值)\n\\[\nt = \\\\frac{\\\\bar{D} - 0}{s_D / \\\\sqrt{n}}\n\\]\n其中，\\(\\\\bar{D}\\) 是配对样本差值的样本均值，\\(s_D\\) 是配对样本差值的样本标准差，n 是配对样本对数。 t 统计量服从自由度为 n-1 的 t 分布。\n\nR 函数 t.test() 进行配对样本 t 检验:\n# 假设 before_vector 和 after_vector 是配对样本数据向量\nt.test(before_vector, after_vector,\n       paired = TRUE,          # 配对样本\n       alternative = \"two.sided\",  # 双侧检验 (默认)\n       # alternative = \"greater\",  # 右侧检验 (before &lt; after)\n       # alternative = \"less\",     # 左侧检验 (before &gt; after)\n       conf.level = 0.95)         # 置信水平 (默认 95%)\n\nt 检验的 R 语言实战练习:\n\n单样本 t 检验: 检验 mtcars 数据集 mpg 列的平均值是否等于 20。 计算效应量 (Cohen’s d 的变体，或报告均值差异)。 进行事后功效分析 (可选)。\n# 单样本 t 检验：检验 mtcars 数据集 mpg 列的平均值是否等于 20\nt.test(mtcars$mpg, mu = 20)\n\n# 计算均值差异 (效应量的一种简单形式)\nmean_mpg &lt;- mean(mtcars$mpg)\nmean_difference &lt;- mean_mpg - 20\ncat(\"Mean difference:\", mean_difference, \"\\n\")\n\n# (可选) 事后功效分析 (单样本 t 检验的功效分析相对复杂，这里省略)\n独立样本 t 检验: 比较 mtcars 数据集不同 am (变速器类型) 组别 mpg 的平均值是否存在显著差异。 计算效应量 (Cohen’s d)。 进行事前功效分析 (例如，计算达到 80% 功效所需的样本容量，假设预期效应量为中等)。 进行事后功效分析 (计算实际功效)。\n# 独立样本 t 检验：比较 mtcars 数据集不同 am 组别 mpg 的平均值\nindependent_t_test_result &lt;- t.test(mpg ~ am, data = mtcars, var.equal = TRUE) # 假设方差相等\nprint(independent_t_test_result)\n\n# 计算 Cohen's d 效应量\nlibrary(effsize)\ncohen_d_result &lt;- cohen.d(mpg ~ am, data = mtcars, paired = FALSE, var.equal = TRUE)\nprint(cohen_d_result)\n\n# 事前功效分析：计算达到 80% 功效所需的样本容量 (假设效应量为 Cohen's d = 0.5)\nlibrary(pwr)\npower_analysis_result &lt;- pwr.t.test(d = 0.5, power = 0.8, sig.level = 0.05,\n                                      type = \"two.sample\", alternative = \"two.sided\")\nprint(power_analysis_result)\nrequired_n &lt;- ceiling(power_analysis_result$n)\ncat(\"Required sample size per group (for power = 80%, Cohen's d = 0.5):\", required_n, \"\\n\")\n\n# 事后功效分析：计算实际功效\nactual_power_analysis_result &lt;- pwr.t.test(n = length(mtcars$mpg[mtcars$am == 0]), # 或 length(mtcars$mpg[mtcars$am == 1])\n                                             d = cohen_d_result$estimate,\n                                             sig.level = 0.05,\n                                             type = \"two.sample\", alternative = \"two.sided\")\nprint(actual_power_analysis_result)\nactual_power &lt;- actual_power_analysis_result$power\ncat(\"Actual power:\", actual_power, \"\\n\")\n配对样本 t 检验: 分析 sleep 数据集 extra 列在 group 为 1 和 2 时的差异 (实际上 sleep 数据集不是真正的配对数据，这里仅作为演示配对 t 检验的例子)。 计算效应量 (Cohen’s d 的变体，或报告均值差异)。 进行事后功效分析 (可选)。 或者，寻找真正的配对数据集进行配对 t 检验练习。\n# 配对样本 t 检验：分析 sleep 数据集 extra 列在 group 为 1 和 2 时的差异 (演示配对 t 检验)\npaired_t_test_result &lt;- t.test(extra ~ group, data = sleep, paired = TRUE) # 注意：sleep 数据集不是真正的配对数据\nprint(paired_t_test_result)\n\n# 计算均值差异 (效应量的一种简单形式)\nmean_difference_paired &lt;- mean(sleep$extra[sleep$group == 1] - sleep$extra[sleep$group == 2])\ncat(\"Mean difference (paired):\", mean_difference_paired, \"\\n\")\n\n# (可选) 事后功效分析 (配对样本 t 检验的功效分析相对复杂，这里省略)\n\n\n\n\n\n5. 项目一汇报准备\n\n汇报内容框架: 为帮助学生更好地准备项目汇报，提供以下内容框架建议：\n\n项目背景与目标: 清晰阐述项目背景、研究意义和具体研究目标\n数据概况: 详细说明数据来源、样本量、变量特征，以及数据质量评估\n分析方法: 介绍已采用的数据清洗、预处理和统计分析方法\n初步发现: 展示描述性统计和可视化分析结果，突出数据特征和潜在模式\n挑战与展望: 总结当前遇到的困难，并提出后续研究计划和改进方向\n\n汇报质量要求: 为确保汇报效果，提出以下具体要求：\n\n时间控制: 每组汇报时间控制在4-5分钟\n演示文稿: 使用PPT进行展示，要求结构清晰、重点突出\n数据可视化: 图表设计规范，信息传达准确\n团队协作: 小组成员需共同参与准备，明确分工\n预演准备: 建议提前进行小组演练，确保汇报流畅\n\n评估标准: 汇报将根据以下维度进行评估：\n\n内容完整性: 是否涵盖所有关键要素\n逻辑清晰度: 汇报结构是否合理，论证是否严谨\n分析深度: 是否充分挖掘数据价值，提出有价值见解\n展示效果: 演示文稿设计是否专业，表达是否清晰\n团队协作: 小组成员配合是否默契，分工是否合理\n\n\n\n\n6. 本周内容总结与下周预告\n\n本周回顾: 回顾本周学习内容，巩固重点知识。 本周我们初步学习了推断性统计的基本思想，参数估计 (点估计和区间估计)，假设检验的基本原理和步骤，以及假设检验中可能犯的 Type I 错误和 Type II 错误，检验功效和效应量的概念和计算方法，以及常用的 t 检验 (单样本 t 检验、独立样本 t 检验、配对样本 t 检验)。 推断性统计是统计学的核心内容，参数估计和假设检验是推断性统计的基础，t 检验是均值检验的常用方法，理解假设检验的错误类型、功效和效应量，掌握效应量 Cohen’s d 的计算和功效分析的基本方法，能够更全面、更深入、更严谨地理解和应用假设检验。 务必理解和掌握本周所学内容。\n下周预告: 下周我们将继续学习假设检验，深入学习方差分析 (ANOVA)，用于检验多个总体均值是否相等。 方差分析是 t 检验的扩展，可以处理三个或更多组别均值比较的问题。 我们还将学习非参数检验，用于处理不满足参数检验条件的数据。 下周内容将更加深入，敬请期待！\n\n\n\n7. 课后任务\n\n小组任务:\n\n项目一汇报准备:\n\n根据项目一汇报框架，准备完整的汇报材料（PPT）\n明确小组成员分工，确定主要汇报人\n进行至少2次小组预演，确保汇报流畅\n重点准备以下内容：\n\n项目背景与目标（1分钟）\n数据概况与质量评估（1分钟）\n分析方法与初步发现（2分钟）\n挑战与后续计划（1分钟）\n\n\n项目一数据分析深化:\n\n在已完成的数据清洗和描述性统计基础上\n提出2-3个具体的假设检验问题\n使用t检验方法进行验证\n计算效应量（Cohen’s d）\n进行简单的事后功效分析\n将分析结果整合到项目汇报中\n\n\n个人任务:\n\n复习本周内容: 回顾本周讲义和课堂笔记，巩固推断性统计基本概念、参数估计方法、假设检验步骤、t 检验的适用条件和 R 语言实现，重点理解 Type I 错误、Type II 错误、检验功效和效应量的概念和意义，掌握 Cohen’s d 的计算和功效分析的基本 R 代码和结果解释。\nR 代码练习: 完成本讲义中布置的 R 代码练习，熟练掌握 t.test() 函数的用法，能够使用 R 进行单样本 t 检验、独立样本 t 检验和配对样本 t 检验。 练习使用 effsize 包计算 Cohen’s d 效应量 (独立样本 t 检验)，练习使用 pwr 包进行事前功效分析和事后功效分析 (独立样本 t 检验)。 尝试使用 AI 插件辅助 R 代码练习。\n概念理解和辨析: 重点理解和辨析以下概念：总体与样本，参数与统计量，点估计与区间估计，置信水平与显著性水平，原假设与备择假设，双侧检验与单侧检验，第一类错误与第二类错误，p 值，单样本 t 检验、独立样本 t 检验、配对样本 t 检验的适用场景和区别，Type I 错误与 Type II 错误，检验功效，效应量 (Cohen’s d, 相关系数 r, R², \\(\\\\eta^2\\))，统计显著性与实际显著性，事前功效分析与事后功效分析。\n\n\n\n\n\n\n\n\nAI 辅助学习小贴士\n\n\n\n\nR 代码练习: 继续在 VS Code 或 Cursor 中练习 R 语言代码，充分利用 AI 插件的代码自动补全、代码生成、代码解释、AI 聊天等功能。 遇到 R 代码问题，及时向 AI 提问。\n统计概念理解: 如果对推断性统计的概念 (例如，置信区间、假设检验、p 值、t 检验、第一类错误、第二类错误、检验功效、效应量、事前功效分析、事后功效分析 等) 理解不透彻，可以使用 AI 聊天提问，让 AI 提供更详细的解释和例子。 例如，提问： “解释假设检验中的第一类错误和第二类错误”, “什么是统计检验的功效，为什么它很重要？”, “什么是效应量，如何解释 Cohen’s d？”, “事前功效分析和事后功效分析有什么区别？”。\nR 函数用法查询: 使用 AI 聊天提问： “R 中 t.test() 函数的用法”, “如何使用 effsize 包在 R 中计算 Cohen’s d”, “如何使用 pwr 包在 R 中进行 t 检验的功效分析”, “R 中用于功效分析的包”。 AI 可能会提供函数文档或使用示例，以及 effsize 包和 pwr 包的更详细使用方法和参数解释。\n假设检验步骤指导: 如果不清楚假设检验的步骤，可以使用 AI 聊天咨询，例如，提问： “假设检验的步骤”, “如何设置原假设和备择假设”, “如何解释假设检验中的 p 值”。 AI 可能会提供步骤指导和示例。\n结果解释辅助: 如果对 R t.test() 函数输出结果的含义不清楚，可以使用 AI 代码解释功能，选中 t.test() 函数的输出结果，让 AI 解释结果的含义，例如，p 值、置信区间、t 统计量、自由度等。 也可以使用 AI 聊天提问，例如，提问： “解释 R 中 t.test() 函数的输出结果”, “如何在 t 检验结果中报告效应量和置信区间？”, “如何解释功效分析结果？”。 特别是关于功效分析结果中 n（样本量）、d（效应量）、power（检验功效）等参数的含义和解释。\n\n\n\n\n\n\n\n学习寄语\n\n\n\n工欲善其事，必先利其器！ 本周我们不仅学习了假设检验的基本方法，还掌握了评估检验质量和效应大小的工具：功效分析和效应量。 更完善的统计工具箱，助您在数据分析的道路上行稳致远！ 继续保持学习的热情，充分利用 VS Code/Cursor 和 AI 插件的强大功能，相信大家会在统计学和 R 语言的学习中取得更大的进步！ 下周中期检查见！",
    "crumbs": [
      "课程内容",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>统计学讲义 - 第四周：推断性统计初步：参数估计与假设检验</span>"
    ]
  }
]