[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "统计学与R语言",
    "section": "",
    "text": "欢迎\n这是统计学课程的在线教材。本教材包含了课程大纲和每周的课程内容。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>欢迎</span>"
    ]
  },
  {
    "objectID": "index.html#课程目标",
    "href": "index.html#课程目标",
    "title": "统计学与R语言",
    "section": "课程目标",
    "text": "课程目标\n本课程旨在帮助学生：\n\n掌握统计学的基本概念和方法\n学会使用统计软件进行数据分析\n培养统计思维和实践能力",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>欢迎</span>"
    ]
  },
  {
    "objectID": "index.html#使用说明",
    "href": "index.html#使用说明",
    "title": "统计学与R语言",
    "section": "使用说明",
    "text": "使用说明\n\n左侧导航栏包含课程大纲和每周的课程内容\n代码块可以点击展开/折叠\n每章都有详细的目录导航",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>欢迎</span>"
    ]
  },
  {
    "objectID": "syllbus.html",
    "href": "syllbus.html",
    "title": "课程概述",
    "section": "",
    "text": "课程大纲 (按周次和项目)",
    "crumbs": [
      "课程概述"
    ]
  },
  {
    "objectID": "syllbus.html#课程大纲-按周次和项目",
    "href": "syllbus.html#课程大纲-按周次和项目",
    "title": "课程概述",
    "section": "",
    "text": "项目一：数据探索与初步洞察：以兴趣领域为例 (第1-4周，共16课时)\n\n\n\n\n\n\n项目主题 (学生可选择以下主题之一，或自拟主题经教师批准)\n\n\n\n\n主题一：电影偏好分析\n\n项目目标：通过获取电影数据集（例如IMDb, MovieLens等公开数据集或API），运用描述性统计方法和初步推断方法，分析不同类型电影的特征、用户评分分布、流行趋势等，洞察电影市场和用户偏好。\n\n主题二：音乐流派分析\n\n项目目标：通过获取音乐数据集（例如Spotify API, Last.fm API, 或公开音乐数据集），运用描述性统计方法和初步推断方法，分析不同音乐流派的特征、用户收听习惯、流行趋势等，洞察音乐市场和用户偏好。\n\n主题三：游戏类型分析\n\n项目目标：通过获取游戏数据集（例如Steam API, 游戏数据平台API, 或游戏销售数据集），运用描述性统计方法和初步推断方法，分析不同游戏类型的特征、用户偏好、流行趋势等，洞察游戏市场和用户偏好。\n\n主题四：股票市场分析\n\n项目目标：通过获取股票市场数据集（例如Yahoo Finance API, Tushare API, 或股票交易数据集），运用描述性统计方法和初步推断方法，分析不同股票的特征、价格波动规律、市场趋势等，洞察股票市场和投资机会。\n\n\n学生可以从以上四个主题中选择一个，或者结合自己的兴趣和专业背景，自拟项目主题，并提交给教师审批。鼓励学生发挥创新思维，选择具有实际意义和研究价值的主题。\n\n\n\n\n\n\n\n\n第一周 (4课时)\n\n\n\n\n项目启动与统计学导论\n\n课程和项目介绍、项目主题选择、分组\n统计学基本概念、应用领域、R语言和 tidyverse 简介\nR环境搭建和 tidyverse 安装\nR 基础语法\n\n\n\n\n\n\n\n\n\n\n第二周 (4课时)\n\n\n\n\n数据获取与R语言数据导入\n\n项目讨论：确定数据来源和获取方案\n公开数据集、API获取实践\nR语言数据导入：readr 包，CSV, TXT等格式\n数据初步查看和理解\n数据类型回顾与数据质量\n描述性统计量：均值、中位数、标准差等\ndplyr 包：数据清洗和预处理初步\n\n\n\n\n\n\n\n\n\n\n第三周 (4课时)\n\n\n\n\n描述性统计：数据探索与可视化\n\ndplyr 、tidyr 包：数据清洗和预处理进阶\nggplot2 包：数据可视化初步，直方图、散点图、箱线图等\ntidyverse 生态：数据处理和可视化的综合应用\n\n\n\n\n\n\n\n\n\n\n第四周 (4课时)\n\n\n\n\n推断性统计初步：参数估计与假设检验\n\n参数估计：点估计、区间估计\n假设检验基本原理与步骤\n单样本t检验、双样本t检验 (独立样本、配对样本)\n项目一检查与汇报准备\n\n\n\n\n\n\n项目二：商业数据分析与统计推断 (第5-8周，共16课时)\n\n\n\n\n\n\n项目主题 (学生可选择以下主题之一，或自拟主题经教师批准)\n\n\n\n\n主题一：消费者行为分析\n\n项目目标：通过获取电商平台数据（例如淘宝、京东等公开数据集），运用方差分析、回归分析等方法，分析影响消费者购买决策的因素，探索消费者行为模式。\n\n主题二：企业绩效分析\n\n项目目标：通过获取上市公司财务数据（例如Wind、东方财富等数据源），运用统计推断方法，分析企业财务指标与绩效之间的关系，探索影响企业绩效的关键因素。\n\n主题三：市场调研分析\n\n项目目标：通过问卷调查或公开市场调研数据，运用分类数据分析和相关分析方法，研究市场需求、消费者偏好、品牌认知等问题。\n\n主题四：运营效率分析\n\n项目目标：通过企业运营数据（例如物流配送、客服响应等数据），运用统计分析方法，评估运营效率，识别改进机会。\n\n\n学生可以从以上四个主题中选择一个，或者结合自己的兴趣和专业背景，自拟项目主题，并提交给教师审批。\n\n\n\n\n\n\n\n\n第五周 (4课时)\n\n\n\n\n方差分析 (ANOVA)\n\n方差分析原理与应用场景\n单因素方差分析\n多重比较\nR语言实现和案例分析\n\n\n\n\n\n\n\n\n\n\n第六周 (4课时)\n\n\n\n\n回归分析初步\n\n线性回归模型\n最小二乘法\n回归系数的解释和检验\nR语言实现和案例分析\n\n\n\n\n\n\n\n\n\n\n第七周 (4课时)\n\n\n\n\n分类数据分析\n\n卡方检验：拟合优度检验、独立性检验\n相关分析：Pearson相关系数、Spearman相关系数\nR语言实现和案例分析\n\n\n\n\n\n\n\n\n\n\n第八周 (4课时)\n\n\n\n\n项目二总结与汇报\n\n项目成果展示与答辩\n非参数检验方法在项目中的应用\n优秀案例分享与经验总结\n项目二评价与反馈\n\n\n\n\n\n\n项目三：预测建模与高级统计分析 (第9-12周，共16课时)\n\n\n\n\n\n\n项目主题 (学生可选择以下主题之一，或自拟主题经教师批准)\n\n\n\n\n主题一：销售预测分析\n\n项目目标：通过企业销售数据，运用多元回归和时间序列分析方法，构建销售预测模型，为企业决策提供支持。\n\n主题二：信用风险评估\n\n项目目标：通过金融机构信贷数据，运用Logistic回归等方法，构建信用风险评估模型，预测违约概率。\n\n主题三：客户流失预警\n\n项目目标：通过客户行为数据，运用多元统计方法，构建客户流失预警模型，识别高风险客户。\n\n主题四：市场趋势预测\n\n项目目标：通过市场历史数据，运用时间序列分析方法，预测市场趋势，为投资决策提供参考。\n\n\n学生可以从以上四个主题中选择一个，或者结合自己的兴趣和专业背景，自拟项目主题，并提交给教师审批。\n\n\n\n\n\n\n\n\n第九周 (4课时)\n\n\n\n\n多元回归分析\n\n多元线性回归模型\n模型诊断与改进\n变量选择\nR语言实现和案例分析\n\n\n\n\n\n\n\n\n\n\n第十周 (4课时)\n\n\n\n\nLogistic 回归\n\nLogistic 回归模型原理\n模型评估与解释\nR语言实现和案例分析\n\n\n\n\n\n\n\n\n\n\n第十一周 (4课时)\n\n\n\n\n时间序列分析初步 (或根据学生兴趣选择其他专题)\n\n时间序列基本概念\n平稳性检验\nARIMA模型初步\nR语言实现和案例分析\n\n\n\n\n\n\n\n\n\n\n第十二周 (4课时)\n\n\n\n\n项目三总结与汇报\n\n项目成果展示与答辩\n高级统计方法在项目中的应用\n优秀案例分享与经验总结\n项目三评价与反馈\n\n\n\n\n\n\n综合项目：经管综合案例分析与决策支持 (第13-16周，共16课时)\n\n\n\n\n\n\n项目主题 (学生可选择以下主题之一，或自拟主题经教师批准)\n\n\n\n\n主题一：企业经营诊断与优化\n\n项目目标：通过综合企业数据（财务、运营、市场、人力资源等），运用多种统计方法，对企业经营状况进行全面诊断，发现问题并提出优化建议。\n建议方法：描述性统计、假设检验、回归分析、时间序列分析等多种方法的综合应用。\n预期成果：完整的企业诊断报告，包含数据分析、问题识别、解决方案和预期效果。\n\n主题二：商业生态系统分析\n\n项目目标：通过产业链相关数据（上下游企业、市场环境、竞争态势等），分析特定行业的商业生态系统，预测发展趋势。\n建议方法：网络分析、聚类分析、预测模型、多元统计分析等方法的综合运用。\n预期成果：行业生态系统分析报告，包含关键影响因素分析、发展趋势预测和战略建议。\n\n主题三：投资组合优化\n\n项目目标：通过多市场金融数据（股票、债券、基金等），构建和优化投资组合，平衡风险和收益。\n建议方法：时间序列分析、风险模型、投资组合理论、统计套利等方法的综合应用。\n预期成果：投资组合策略报告，包含资产配置方案、风险评估和绩效预测。\n\n主题四：商业智能决策系统\n\n项目目标：通过多源商业数据，构建商业智能决策支持系统，辅助企业经营决策。\n建议方法：数据挖掘、预测建模、决策树分析、情景模拟等方法的综合运用。\n预期成果：决策支持系统原型，包含数据分析模块、预测模型和决策建议生成机制。\n\n\n学生可以从以上四个主题中选择一个，或者结合自己的兴趣和专业背景，自拟项目主题。综合项目要求学生整合课程中学习的各种统计方法，并结合实际经管问题进行深入分析。\n\n\n\n\n\n\n\n\n第十三周 (4课时)\n\n\n\n\n综合项目启动与选题指导\n\n综合项目介绍和要求\n选题原则和方法指导\n小组讨论和选题\n\n\n\n\n\n\n\n\n\n\n第十四周 (4课时)\n\n\n\n\n综合项目数据分析方法指导\n\n针对不同项目选题的数据分析方法建议\nR语言高级数据分析技巧\nAI辅助统计分析工具介绍和使用\n\n\n\n\n\n\n\n\n\n\n第十五周 (4课时)\n\n\n\n\n综合项目中期检查与辅导\n\n小组汇报项目进展，展示初步分析结果\n教师巡回指导，解答学生疑问，提供个性化辅导\n项目报告撰写指导\n\n\n\n\n\n\n\n\n\n\n第十六周 (4课时)\n\n\n\n\n综合项目展示与答辩\n\n各小组进行综合项目展示和答辩\n课程总结与期末考试安排\n优秀综合项目展示",
    "crumbs": [
      "课程概述"
    ]
  },
  {
    "objectID": "syllbus.html#项目式教学说明",
    "href": "syllbus.html#项目式教学说明",
    "title": "课程概述",
    "section": "项目式教学说明",
    "text": "项目式教学说明\n\n\n\n\n\n\n项目分组\n\n\n\n\n建议每组2-3人，鼓励学生自由组队，也可由教师根据情况进行分组。\n\n\n\n\n\n\n\n\n\n项目选题\n\n\n\n\n项目主题为示例，教师可以根据教学目标、学生专业背景和兴趣、以及实际数据可获得性等因素，调整项目主题。鼓励学生结合自身专业和兴趣自主选题。\n\n\n\n\n\n\n\n\n\n项目成果\n\n\n\n\n每个项目小组需要提交项目报告，并在指定时间进行项目展示和答辩。项目报告应包括：项目背景、研究问题、数据来源、研究方法、数据分析过程、结果解释、结论与建议、参考文献、R代码 (使用 tidyverse 风格) 等。\n\n\n\n\n\n\n\n\n\n项目评价\n\n\n\n\n项目评价包括小组互评和教师评价。评价内容包括：项目报告质量、项目展示效果、答辩表现、团队合作、创新性、R代码质量 (包括 tidyverse 的合理使用) 等。",
    "crumbs": [
      "课程概述"
    ]
  },
  {
    "objectID": "syllbus.html#ai辅助教学说明",
    "href": "syllbus.html#ai辅助教学说明",
    "title": "课程概述",
    "section": "AI辅助教学说明",
    "text": "AI辅助教学说明\n\n\n\n\n\n\nAI辅助教学\n\n\n\n\n课堂互动与答疑： 利用AI工具（如Cursor, VS Code插件的AI聊天功能）辅助课堂答疑，快速解答学生在统计概念、R语言代码等方面的问题。\n代码演示与生成： 使用AI工具进行R代码的实时演示和生成，例如，在讲解统计方法时，可以使用AI工具快速生成R代码，并展示运行结果，提高教学效率。\n个性化学习辅导： 鼓励学生使用AI工具进行个性化学习，例如，利用AI的代码解释功能理解代码逻辑，利用AI的代码错误诊断功能解决编程问题。教师也可以利用AI工具分析学生的学习数据，提供个性化辅导建议。\n拓展学习资源： 教师可以利用AI工具搜索和推荐与课程相关的学习资源，例如，公开数据集、API文档、R语言教程、统计学案例分析等，拓展学生的学习视野。\n\n\n\n\n\n\n\n\n\n教学方法\n\n\n\n\n课堂讲授 (传统教学 + AI辅助)： 结合传统讲授，利用AI工具（如Cursor, VS Code插件）进行代码演示、实时答疑、个性化辅导等，提升课堂互动性和效率。\n项目式教学： 以小组为单位，围绕实际经管问题开展统计项目，学生在项目实践中学习和应用统计知识。\nR语言 & tidyverse 实践： 强调R语言和 tidyverse 生态的实际操作，通过案例分析、实验练习等方式，让学生掌握 tidyverse 在数据处理、可视化和统计分析中的应用。\nAI辅助学习： 引导学生使用AI工具辅助学习，例如利用AI代码生成、代码解释、错误诊断等功能，提高学习效率和解决问题的能力。\n\n\n\n\n\n\n\n\n\n考核方式\n\n\n\n\n课堂参与 (10%)： 出勤、课堂互动、课堂表现\n小组项目3次 (30%)： 包括项目选题、数据收集、统计分析、结果解释和结论。\n最终项目1次 (20%)： 包括项目选题、数据收集、统计分析、结果解释和结论。\n期末考试 (40%)： 闭卷考试，考察学生对统计学基本概念、原理和方法的掌握程度。",
    "crumbs": [
      "课程概述"
    ]
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "第一周：统计学导论",
    "section": "",
    "text": "第一次课：课程和项目介绍 + 统计学导论",
    "crumbs": [
      "项目一：统计分析基础与数据可视化",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>第一周：统计学导论</span>"
    ]
  },
  {
    "objectID": "week1.html#第一次课课程和项目介绍-统计学导论",
    "href": "week1.html#第一次课课程和项目介绍-统计学导论",
    "title": "第一周：统计学导论",
    "section": "",
    "text": "核心概念\n\n\n\n统计学是从数据中提取信息，发现规律，并做出合理决策的科学。\n\n\n\n1. 课程和项目介绍\n\n课程和项目概览\n\n课程总体目标\n\n通过四个项目，学习和应用统计知识。\n\n\n\n项目式教学\n\n强调以项目为驱动，学生通过完成实际项目来学习。\n\n\n\n项目一：数据探索与初步洞察\n\n目标： 掌握数据探索的基本方法，获得初步的数据洞察。\n主题选择： 电影、音乐、游戏、股票等 (学生自选)。\n项目周期： 第1-4周。\n成果要求： 分析报告和项目汇报。\n\n\n\n分组\n\n现场自由组队，每组2-3人。\n\n\n\n\n\n2. 统计学基本概念\n\n什么是统计学？\n\n定义：研究如何收集、分析、解释和呈现数据的科学。\n目标：从数据中提取信息，发现规律，做出决策。\n应用案例： 经管领域案例 (结合学生专业背景)，例如市场调查、销售数据分析、财务报表分析等。 此外，统计学也被广泛应用于自然科学、社会科学、医学、工程等领域。\n\n\n\n统计学的基本概念\n\n\n\n\n\n\n总体 (Population) 与 样本 (Sample)\n\n\n\n\n总体： 研究对象的全体。例如，如果我们想研究某个城市所有成年人的平均身高，那么该城市所有成年人就是一个总体。\n样本： 从总体中抽取的一部分个体。由于直接测量所有成年人的身高是不现实的，我们通常会抽取一部分成年人作为样本进行测量。\n\n\n\n\n\n\n\n\n\n变量 (Variable) 的类型\n\n\n\n\n分类变量 (Categorical)： 描述类别或属性，如性别、地区。例如，血型 (A, B, AB, O)、教育程度 (小学, 初中, 高中, 大学) 等。 分类变量的取值是离散的类别，通常不能进行数值运算。\n数值变量 (Numerical)： 可以数值度量的变量，如身高、收入。例如，年龄、体重、考试成绩等。 数值变量的取值是数值，可以进行数学运算。 数值变量又可以分为离散型变量 (discrete) 和连续型变量 (continuous)。\n\n\n\n\n\n\n\n\n\n描述性统计 (Descriptive Statistics) 与 推断性统计 (Inferential Statistics)\n\n\n\n\n描述性统计： 描述和总结样本数据的特征，如均值、标准差、图表。描述性统计旨在概括和呈现数据的基本特征，例如使用平均数描述数据的中心位置，使用标准差描述数据的离散程度，使用直方图或条形图可视化数据的分布。\n推断性统计： 利用样本数据推断总体特征，如参数估计、假设检验。推断性统计则更进一步，它利用样本数据的信息来对总体进行推断，例如通过样本的平均身高来估计总体成年人的平均身高，或者通过假设检验来判断某种新药是否有效。\n\n\n\n\n\n统计思维的重要性\n\n核心思想： 如何从数据中提取信息，发现规律，做出决策。统计思维不仅仅是一种分析数据的技能，更是一种看待问题和解决问题的思维方式。 具备统计思维的人能够更加理性地分析问题，更加科学地做出决策，从而在工作和生活中取得更大的成功。 在当今这个数据爆炸的时代，统计思维显得尤为重要。\n\n\n\n\n3. R语言和tidyverse简介\n\nR语言和tidyverse生态系统\n\nR语言的特点和优势\n\n开源、免费。\n强大的统计分析和可视化功能。\n活跃的社区和丰富的扩展包。\n\n\n\ntidyverse生态系统\n\n核心包： dplyr (数据处理), ggplot2 (数据可视化), readr (数据导入), tidyr (数据整理) 等。\n简洁、高效、易读的语法风格。\n统一的数据处理流程 (管道操作符 %&gt;%)。\n\n\n\n为什么选择tidyverse?\n\n更符合现代数据分析的习惯。\n提高数据处理和分析效率。",
    "crumbs": [
      "项目一：统计分析基础与数据可视化",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>第一周：统计学导论</span>"
    ]
  },
  {
    "objectID": "week1.html#第二次课r环境搭建与r基础语法",
    "href": "week1.html#第二次课r环境搭建与r基础语法",
    "title": "第一周：统计学导论",
    "section": "第二次课：R环境搭建与R基础语法",
    "text": "第二次课：R环境搭建与R基础语法\n\n1. R及RStudio/Cursor安装\n\nR 环境安装\n\n下载R\n\n访问 R官方网站，根据操作系统选择合适的R版本下载并安装。\n建议安装最新版本的R。\n\n\n\nVSCode (可选，推荐)\n\n访问 VSCode官网，下载并安装VSCode。\n如果选择VSCode，需要安装R语言和AI相关的插件以获得更好的R语言编程体验。\n\n\n\n安装Cursor (可选，推荐)\n\n访问 Cursor官网，下载并安装Cursor。\nCursor 是一个支持AI辅助编程的代码编辑器，可以作为VSCode的替代品，提供更强大的AI代码生成和编辑功能。\n\n\n\n安装RStudio Desktop (可选)\n\n访问 RStudio Desktop官网，下载并安装RStudio Desktop。\nRStudio是一个集成开发环境 (IDE)，提供更友好的R语言编程界面。\n\n\n\n\n\n2. VSCode/Cursor 插件安装\n\nVSCode/Cursor 插件配置\n\n安装R插件 (VSCode 或 Cursor)\n\n打开 VSCode 或 Cursor，进入扩展市场 (Extensions)。\n搜索 “R” 插件 (R Extension for Visual Studio Code) 并安装。\n安装 R 插件后，VSCode 或 Cursor 可以提供 R 代码的语法高亮、代码补全、调试等功能。\n\n\n\n安装 AI 辅助插件 (VSCode 或 Cursor)\n\nGitHub Copilot (推荐)： 在 VSCode 或 Cursor 扩展市场搜索 “GitHub Copilot” 并安装。 安装后可能需要登录GitHub账号并进行配置。\n通义灵码 (可选)： 在 VSCode 或 Cursor 扩展市场搜索 “TONGYI Lingma” 并安装。 安装后可能需要登录通义账号并进行配置。\nCursor 内置 AI 功能： Cursor 编辑器本身就内置了强大的 AI 辅助功能，无需额外安装插件，可以直接使用。\n\n\n\n修改 CRAN 镜像源 (可选，国内用户推荐)\n\n为了加快R包的下载速度，可以修改 CRAN 镜像源为国内镜像。\n永久修改 CRAN 镜像源 (推荐，修改 .Rprofile 文件):\n\n打开你的用户目录 (例如，Windows 下的 “文档” 目录，macOS/Linux 下的 “~” 目录)。\n查找或创建 .Rprofile 文件。如果文件不存在，新建一个文本文件并命名为 .Rprofile。\n使用文本编辑器打开 .Rprofile 文件，添加以下代码，选择国内镜像 (例如 清华大学 [China (Tsinghua University)])：\n\noptions(repos = c(CRAN = \"https://mirrors.tuna.tsinghua.edu.cn/CRAN/\"))\n\n保存 .Rprofile 文件。\n重启 R 或 RStudio/Cursor，新的 CRAN 镜像源将永久生效。\n\n临时修改 CRAN 镜像源 (不推荐永久使用，仅用于测试)：\n\n在R控制台中运行以下代码，选择国内镜像 (例如 清华大学 [China (Tsinghua University)])：\noptions(repos = c(CRAN = \"https://mirrors.tuna.tsinghua.edu.cn/CRAN/\"))\n这种方法只在当前 R 会话中有效，关闭 R 后会失效。\n\n\n\n\n\n\n3. R 包安装和R基础语法\n\nR 包安装和基础语法\n\n安装 R 包\n\n使用 install.packages() 函数安装 R 包。 例如，安装 tidyverse 包：\ninstall.packages(\"tidyverse\")\n可以一次安装多个包，例如：\ninstall.packages(c(\"dplyr\", \"ggplot2\", \"readr\"))\n\n\n\n加载 R 包\n\n使用 library() 函数加载已安装的 R 包。 例如，加载 tidyverse 包：\nlibrary(tidyverse)\n\n\n\n使用 pacman 包安装和加载 R 包\n\npacman 包是一个方便的包管理工具，可以使用 p_load() 函数一次性安装并加载多个 R 包。如果包尚未安装，p_load() 会自动安装它。\n首先，如果还没有安装 pacman 包，需要先安装它：\nif (!requireNamespace(\"pacman\", quietly = TRUE)) {\n  install.packages(\"pacman\")\n}\n然后，使用 pacman::p_load() 函数来安装和加载包。 例如，安装并加载 dplyr 和 ggplot2 包：\npacman::p_load(dplyr, ggplot2)\np_load() 函数的优点是可以一次性处理多个包，并且会自动安装缺失的包，简化了包管理流程。你只需要列出你想要安装和加载的包名，用逗号分隔即可。\n\n\n\nR 基础语法\n\n变量赋值和基本运算\n\n变量赋值: 使用 &lt;- 或 = 进行变量赋值。\nx &lt;- 10\ny = 20\n基本运算: 加减乘除等基本运算符 +, -, *, /。\nz &lt;- x + y\n\n\n\n常用数据类型\n\n常用数据类型:\n\n数值型 (numeric): 10, 3.14\n字符型 (character): \"hello\", 'world'\n逻辑型 (logical): TRUE, FALSE\n\n\n\n\n向量 (vector)\n\n向量 (vector): 使用 c() 函数创建向量。\nvec &lt;- c(1, 2, 3, 4, 5)\nchar_vec &lt;- c(\"a\", \"b\", \"c\")\n向量索引: 使用 [] 和索引值访问向量元素 (R 语言索引从1开始)。\nvec[1]  # 访问第一个元素，结果为 1\nvec[c(2, 4)] # 访问第二个和第四个元素，结果为 c(2, 4)\nvec[-1] # 排除第一个元素，访问剩余元素\nvec[vec &gt; 3] # 逻辑索引，访问大于 3 的元素，结果为 c(4, 5)\n\n\n\n列表 (list)\n\n列表 (list): 使用 list() 函数创建列表，列表可以包含不同类型的数据。\nlist_example &lt;- list(\n  name = \"Alice\",\n  age = 30,\n  scores = c(85, 90, 92),\n  is_student = TRUE\n)\n命名列表: 在创建列表时为元素命名，方便后续访问。上面的 list_example 就是一个命名列表。\n列表元素访问: 使用 $ 符号或 [[]] 访问列表元素。\nlist_example$name # 使用 $ 符号按名称访问，结果为 \"Alice\"\nlist_example[[\"age\"]] # 使用 [[]] 按名称访问，结果为 30\nlist_example[[3]] # 使用 [[]] 按索引访问，结果为 c(85, 90, 92)\n\n\n\n数据框 (data.frame)\n\n数据框 (data.frame): 用于存储表格数据。\ndf &lt;- data.frame(\n  name = c(\"Alice\", \"Bob\", \"Charlie\"),\n  age = c(25, 30, 28),\n  gender = c(\"F\", \"M\", \"M\")\n)\n数据框引用: 使用 $ 符号、[] 或 [[]] 访问数据框的列或元素。\ndf$name # 使用 $ 符号按列名访问，结果为 name 列的向量\ndf[, \"age\"] # 使用 [] 按列名访问，结果为 age 列的向量\ndf[, 2] # 使用 [] 按列索引访问，结果为 age 列的向量\ndf[1, ] # 使用 [] 访问第一行，结果为第一行的数据框\ndf[1, 1] # 使用 [] 访问第一行第一列的元素，结果为 \"Alice\"\ndf[[\"gender\"]] # 使用 [[]] 按列名访问，结果为 gender 列的向量\n\n\n\n注释和帮助文档\n\n注释: 使用 # 符号添加注释。\n# 这是一个注释\n帮助文档: 使用 help() 函数或 ? 符号查看函数帮助文档。\nhelp(install.packages)\n?library\n\n\n\n\n\n\n\n课后作业 (第一周)\n\n\n\n\n完成R和RStudio (或 Cursor, VSCode) 的安装。\n安装必要的R和AI辅助插件。\n修改CRAN镜像源 (国内用户)。\n安装 tidyverse 包，并尝试加载。\n第一周小组需要完成项目选题，并开始调研相关数据来源。\n尝试使用 readr 包导入自己找到的 (或老师提供的) 示例数据文件到R中。\n思考题： 结合自己感兴趣的项目主题，初步思考可以从数据中探索哪些问题？希望获得哪些洞察？\n\n\n\n\n\n\n\nAI 辅助学习建议 (贯穿第一周)\n\nR环境搭建和tidyverse安装\n\n使用AI搜索R和RStudio/Cursor的最新安装指南。\n使用AI查找R插件和AI辅助插件的安装教程。\n使用AI工具 (如Cursor) 辅助代码编写和理解，例如，让AI解释 install.packages() 和 library() 函数的作用。\n\n\n\n数据获取方法\n\n使用AI工具 (如Cursor, 搜索引擎) 辅助查找数据资源。 例如，使用AI搜索 “电影公开数据集” 或 “Spotify API”。\n使用AI总结API文档的关键信息，或者解释API请求的参数含义。\n\n\n\nR语言数据导入\n\n使用AI工具 (如Cursor) 辅助代码编写和调试。 例如，如果学生在导入数据时遇到错误，可以使用AI工具诊断错误原因并提供解决方案。\n使用AI工具学习R基础语法，例如，让AI解释变量赋值、数据类型、向量和数据框的概念和用法，并生成示例代码。",
    "crumbs": [
      "项目一：统计分析基础与数据可视化",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>第一周：统计学导论</span>"
    ]
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "第二周：R语言数据导入与数据初步理解",
    "section": "",
    "text": "第三次课：数据获取与R语言数据导入",
    "crumbs": [
      "项目一：统计分析基础与数据可视化",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>第二周：R语言数据导入与数据初步理解</span>"
    ]
  },
  {
    "objectID": "week2.html#第三次课数据获取与r语言数据导入",
    "href": "week2.html#第三次课数据获取与r语言数据导入",
    "title": "第二周：R语言数据导入与数据初步理解",
    "section": "",
    "text": "项目小组讨论：确定数据来源和获取方案\n\n\n\n小组交流： 大家分享上周找到的数据资源，互相看看有什么好的数据集或者 API。\n一起讨论： * 看看大家找的数据怎么样，靠不靠谱。 * 重点是确定怎么拿到数据： * 如果是公开数据集，怎么下载，数据长什么样。 * 如果是 API，怎么注册账号，API 怎么用，先简单了解一下。 * 选数据的时候，要考虑能不能快速拿到数据，别选太难搞的。 * 互相学习： 大家可以互相交流经验，看看别人是怎么找数据、拿数据的。\n\n\n\n数据获取实践：常用方法\n\n公开数据集\n\n常用网站：\n\n综合数据平台：\n\nKaggle: https://www.kaggle.com/datasets (全球综合性数据竞赛和数据集平台，需要注册账号)\n阿里云天池: https://tianchi.aliyun.com/dataset (阿里巴巴旗下数据竞赛和数据集平台，中文，需要注册账号)\nDataFountain (DF 平台): https://www.datafountain.cn/datasets (中国的数据竞赛和数据集平台，中文)\n\n政府开放数据平台：\n\n中国政府数据开放平台: http://data.gov.cn/ (国家级政府数据开放平台，覆盖多领域)\n北京市政府数据开放平台: https://data.beijing.gov.cn/ (省级/市级政府数据平台示例，中文)\n中国政府信息公开: https://www.gov.cn/zhengce/xxgk/ (国务院政策文件等，政府信息公开)\n美国政府开放数据: https://www.data.gov/ (政府公开数据示例，英文，可对比参考)\n\n机构/组织数据平台：\n\n世界银行公开数据: https://data.worldbank.org/ (国际组织数据，多领域)\n联合国数据: http://data.un.org/ (国际组织数据，全球统计数据)\n国家统计局: http://www.stats.gov.cn/ (中国国家统计数据，权威统计信息)\n中国人民银行: http://www.pbc.gov.cn/ (中国金融数据，金融统计信息)\n\n特定领域数据平台:\n\nUCI Machine Learning Repository: https://archive.ics.uci.edu/datasets (机器学习领域常用数据集，英文)\n豆瓣电影、读书、音乐: https://www.douban.com/ (中文电影、图书、音乐评分、评论等数据，可能需要爬虫或API)\nSteam 游戏数据: https://store.steampowered.com/ (Steam 平台游戏信息，例如用户评价、游戏类型等，可能需要爬虫或API)\n\n\n\n\n\nAPI (应用程序编程接口)\n\nAPI 是什么？ API 可以理解为网站或平台提供的数据接口。通过 API，我们可以用程序（比如 R 代码）直接从网站服务器获取数据，而不需要手动下载文件。\n常用 API 平台：\n\n娱乐内容 API (音乐/电影/图书/游戏)：\n\nSpotify API: https://developer.spotify.com/documentation/web-api/ (获取 Spotify 音乐数据)\n豆瓣 API (非官方，但常用): https://developers.douban.com/wiki/?title=api_v2 (获取电影、图书、音乐数据)\nOMDb API (电影): http://www.omdbapi.com/ (获取电影信息，免费 API，但有访问限制)\nSteam API: https://steamapi.xpaw.me/ (非官方 Steam API, 获取游戏信息和玩家数据)\nRAWG API: https://rawg.io/apidocs (游戏数据库 API, 包含游戏信息、评测等)\n\n金融数据 API：\n\nYahoo Finance API (非官方，但常用): https://finance.yahoo.com/quote/AAPL/history/ (获取股票市场数据)\nTushare: https://tushare.pro/ (中国股票、期货、宏观经济数据，需要注册账号)\nQuandl (Nasdaq Data Link): https://www.nasdaq.com/solutions/nasdaq-datalink (各种金融和经济数据，部分免费，部分收费)\n\n通用数据 API 平台：\n\n聚合数据: https://www.juhe.cn/ (提供各种生活、出行等 API，部分免费，部分收费)\nApipost: https://www.apipost.cn/api-store (API 商店，提供各种类型的 API)\n\n实用工具 API：\n\n天气 API：\n\nOpenWeatherMap: https://openweathermap.org/api (全球天气数据)\n和风天气: https://dev.qweather.com/ (中国及全球天气数据)\n\n地理编码 API (Geocoding API)：\n\n高德地图API: https://lbs.amap.com/api/webservice/guide/api/georegeo (地址和坐标转换，中国常用)\n\n\n\n如何使用 API 获取数据？\n\n注册 API 账号 (如果需要)： 很多 API 平台需要注册账号并获取 API 密钥 (API Key) 才能使用。\n阅读 API 文档： API 文档会告诉你如何发送 API 请求，需要哪些参数，以及 API 返回的数据格式。\n使用 API 请求工具： 可以使用 Postman 等工具测试 API 请求，或者在 R 中使用 httr 包发送 API 请求 (本周课不深入 httr 包的具体用法)。\nAI 辅助： 可以使用 Cursor, ChatGPT 等 AI 工具辅助理解 API 文档，生成 API 请求代码。 例如，让 AI 总结 API 文档的关键信息，或者解释 API 请求的参数含义。\n\n\n\n\n\nR语言数据导入进阶\n在R语言中，readr 包提供了一系列高效读取各种文本数据文件的函数。最常用的包括：\n\nread_csv() 函数：用于读取逗号分隔的 .csv 文件。这是最常见的数据文件格式。\nread_tsv() 函数：用于读取制表符分隔的 .tsv 文件。\nread_delim() 函数：更通用的读取文本文件的函数，可以自定义分隔符。\n\n这些函数都属于 readr 包，通常在RStudio等环境中已经默认安装，如果没有，可以使用 install.packages(\"readr\") 安装，并使用 library(readr) 加载。\n下面是一些基本用法示例：\n\nread_excel() 函数： 读取 Excel 文件\n\n可以读取 .xls 和 .xlsx 格式的 Excel 文件。\n需要先安装和加载 readxl 包 (install.packages(\"readxl\"), library(readxl)).\n\n# 安装 readxl 包 (如果还没安装)\ninstall.packages(\"readxl\")\n# 加载 readxl 包\nlibrary(readxl)\n# 读取 Excel 文件\nexcel_data &lt;- read_excel(\"你的Excel文件.xlsx\")\n\n\nread_json() 函数： 读取 JSON 文件\n\n可以读取 JSON 格式的文件。\n需要安装和加载 jsonlite 包 (install.packages(\"jsonlite\"), library(jsonlite)).\n\n\n\n# 安装 jsonlite 包 (如果还没安装)\ninstall.packages(\"jsonlite\")\n# 加载 jsonlite 包\nlibrary(jsonlite)\n# 读取 JSON 文件\njson_data &lt;- read_json(\"你的JSON文件.json\")\n\n\nread_html() 函数： 读取 HTML 表格\n\n可以读取网页上的表格数据。\n需要安装和加载 rvest 包 (install.packages(\"rvest\"), library(rvest)).\n注意： 网页数据抓取比较复杂，这里只是简单了解一下。\n\n\n\n# 安装 rvest 包 (如果还没安装)\ninstall.packages(\"rvest\")\n# 加载 rvest 包\nlibrary(rvest)\n# 读取 HTML 页面\nwebpage &lt;- read_html(\"你的网页地址\")\n# 提取 HTML 表格 (假设表格在页面中是第一个表格)\nhtml_table &lt;- html_table(html_nodes(webpage, \"table\")[[1]])\n\n\nfread() 函数 (data.table 包)： 快速读取大型数据文件\n\nfread() 函数读取大文件速度很快，可以用来替代 read_csv()。\ndata.table 包功能很强大，但我们这门课初期主要用 readr 包。\n\n\n\n# 安装 data.table 包 (如果还没安装)\nif(!requireNamespace(\"data.table\", quietly = TRUE)){\n    install.packages(\"data.table\")\n}\n# 加载 data.table 包\nlibrary(data.table)\n# 使用 fread 读取 CSV 文件\nlarge_csv_data &lt;- fread(\"你的大型CSV文件.csv\")",
    "crumbs": [
      "项目一：统计分析基础与数据可视化",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>第二周：R语言数据导入与数据初步理解</span>"
    ]
  },
  {
    "objectID": "week2.html#第四次课数据初步理解与描述性统计",
    "href": "week2.html#第四次课数据初步理解与描述性统计",
    "title": "第二周：R语言数据导入与数据初步理解",
    "section": "第四次课：数据初步理解与描述性统计",
    "text": "第四次课：数据初步理解与描述性统计\n\n初步认识数据：常用R函数\n在拿到数据之后，我们通常需要先快速了解数据的大致情况。R 语言提供了一系列函数，可以帮助我们快速查看数据的基本信息，例如数据的维度、列名、数据类型、以及数据的前几行和后几行等等。下面介绍一些常用的 R 函数。\n\n常用 R 函数\n\nhead() 和 tail(): 看数据的前几行和后几行。\n\nhead(你的数据框) # 默认看前 6 行\nhead(你的数据框, 10) # 看前 10 行\ntail(你的数据框) # 默认看后 6 行\n\nglimpse() (dplyr 包): 更清楚地展示数据结构，包括列名、数据类型和数据预览。\n\nlibrary(dplyr) # 确保加载 dplyr 包\nglimpse(你的数据框)\n\nsummary(): 看每列数据的描述性统计信息 (平均值、中位数、最小值、最大值等等)。\n\nsummary(你的数据框)\n\nstr(): 查看数据框的结构，包括数据类型和维度。\n\nstr(你的数据框)\n\nnames(): 查看列名。\n\nnames(你的数据框)\n\n\n\n\n\n\n练习\n\n\n\n\n练习任务： 用上面这些函数，查看你导入的数据，初步了解数据大概是什么样的。\n\n\n\n\n\n\n数据类型与数据质量\n在进行数据分析之前，理解数据的类型和质量至关重要。不同的数据类型决定了我们可以对数据进行的操作，而数据质量则直接影响分析结果的可靠性。本节将简要介绍常见的数据类型和数据质量问题。\n\n常见数据类型\n\n数值型 (numeric, integer): 数字，可以用来计算。\n字符型 (character): 文本，字符串。\n逻辑型 (logical): TRUE (真) / FALSE (假)。\n因子型 (factor): 分类数据，比如学历 (小学，初中，高中)。\n日期型 (Date, POSIXct): 日期和时间。\n\n\n\n数据质量问题\n\n缺失值 (NA): 数据不见了，不知道是什么值。\n重复值: 数据重复出现。\n异常值 (Outliers): 不正常的数据，和大部分数据差别很大。\n数据不一致: 比如单位不一样，格式不统一。\n数据质量很重要，如果数据有问题，分析结果可能也会错 (“Garbage in, garbage out”)。\n\n\n\n\n描述性统计量\n在拿到数据之后，我们首先需要对数据有一个初步的认识。描述性统计量就是帮助我们概括和描述数据基本特征的统计方法。通过学习和计算描述性统计量，例如均值、中位数、标准差等等，我们可以快速了解数据的集中趋势、离散程度和大致分布，为后续的数据分析和建模打下基础。\n\n集中趋势\n\n均值 (Mean): 平均数，用 mean() 函数计算。\n\nmean(你的数据框$列名)\n\n\n\n\n\n\nNote\n\n\n\n\n优点： 均值是最常用的集中趋势度量，易于理解和计算。它利用了数据集中的所有数值信息，能够充分反映数据的中心位置。在数据分布对称的情况下，均值能够很好地代表数据的典型水平。\n缺点： 均值对异常值（outliers）非常敏感。如果数据集中存在极端值，均值会受到很大影响，不能准确反映大多数数据的集中趋势。例如，如果一组收入数据中存在极少数高收入人群，均值会被显著拉高，无法代表普通收入水平。\n使用技巧： 当数据分布接近对称且没有明显异常值时，均值是衡量集中趋势的良好选择。在需要考虑所有数据点的情况下，也应优先考虑均值。但当数据存在偏斜分布或异常值时，均值可能会产生误导，此时应结合其他统计量一起使用。\n\n\n\n\n中位数 (Median): 把数据排序后，最中间的那个数，用 median() 函数计算。\n\nmedian(你的数据框$列名)\n\n\n\n\n\n\nNote\n\n\n\n\n优点： 中位数不受异常值的影响，对数据分布的形状不敏感。即使数据集中存在极端值，中位数仍然能够稳健地反映数据的中心位置。因此，中位数是衡量偏斜分布数据集中趋势的良好指标。\n缺点： 中位数没有充分利用数据集中的所有数值信息，因为它只关注排序后中间位置的数值，而忽略了其他数值的大小。在数据分布对称的情况下，中位数可能不如均值那样精确地反映数据的中心位置。\n使用技巧： 当数据分布偏斜或存在异常值时，中位数是比均值更稳健的集中趋势度量。在关注数据集中间水平，而不希望受到极端值干扰时，应优先考虑中位数。可以结合均值和中位数一起使用，比较它们之间的差异，判断数据分布的偏斜程度。\n\n\n\n\n众数 (Mode): 出现次数最多的数 (R 没有直接计算众数的函数，可以自己写代码或者用包，这里先不深入)。\n\n\n\n\n\n\n\nNote\n\n\n\n\n优点： 众数易于理解，直接反映了数据集中出现频率最高的数值。众数不受极端值的影响，并且适用于任何类型的数据，包括数值型和类别型数据。对于类别数据，众数是唯一可用的集中趋势度量。\n缺点： 众数可能不存在或不唯一。当数据集分布均匀或有多个数值出现频率相近时，众数可能无法明确指示数据的集中趋势。众数没有利用数据集中数值大小的信息，仅仅关注频率，因此信息量较少。\n使用技巧： 众数主要用于描述类别数据的集中趋势，例如，调查学生最喜欢的颜色，众数可以告诉我们哪个颜色最受欢迎。对于数值数据，当数据集中存在明显的峰值，且关注最常见的数值时，可以使用众数。但当众数不唯一或不存在时，或者需要更精确地描述数据的中心位置时，应结合其他集中趋势度量。\n\n\n\n\n\n离散程度\n\n标准差 (Standard Deviation): 数据离散程度的一种度量，用 sd() 函数计算。\n\nsd(你的数据框$列名)\n\n\n\n\n\n\nNote\n\n\n\n\n优点： 标准差是最常用的离散程度度量，易于理解和计算。它考虑了数据集中所有数值与均值的偏差，能够全面反映数据的离散程度。标准差具有明确的数学意义，可以用于正态分布数据的分析和参数估计。\n缺点： 标准差对异常值敏感。当数据集中存在极端值时，标准差会被放大，不能准确反映大多数数据的离散程度。标准差只能用于数值型数据，不能用于类别型数据。\n使用技巧： 当数据分布接近对称且没有明显异常值时，标准差是衡量离散程度的良好选择。在需要全面考虑数据波动情况，并进行进一步统计分析时，应优先考虑标准差。但当数据存在偏斜分布或异常值时，标准差可能会产生误导，此时应结合其他离散程度度量一起使用，例如四分位距。\n\n\n\n\n方差 (Variance): 也是数据离散程度的度量，用 var() 函数计算。\n\nvar(你的数据框$列名)\n\n\n\n\n\n\nNote\n\n\n\n\n优点： 方差与标准差类似，也考虑了数据集中所有数值与均值的偏差，能够反映数据的离散程度。方差具有良好的数学性质，在统计理论中有很多应用，例如方差分析。\n缺点： 方差的单位是原始数据单位的平方，解释性不如标准差直观。例如，如果身高单位是厘米，方差的单位就是平方厘米，不符合日常理解习惯。方差也对异常值敏感，与标准差类似。\n使用技巧： 方差和标准差在实际应用中常常一起使用，它们反映的离散程度信息基本一致。在需要进行统计推断或理论分析时，方差可能更常用。但在描述性统计和结果解释时，标准差通常更直观易懂。\n\n\n\n\n四分位距 (IQR): 第三四分位数减去第一四分位数，用 IQR() 函数计算。\n\nIQR(你的数据框$列名)\n\n\n\n\n\n\nNote\n\n\n\n\n优点： 四分位距不受异常值的影响，对数据分布的形状不敏感。它只关注数据中间 50% 的离散程度，能够稳健地反映数据的变异性。四分位距易于计算和理解，常用于箱线图的绘制。\n缺点： 四分位距只利用了数据集中间部分的信息，忽略了数据两端的变化，信息量不如标准差丰富。四分位距不能充分反映数据的整体分布情况。\n使用技巧： 当数据分布偏斜或存在异常值时，四分位距是比标准差更稳健的离散程度度量。在关注数据中间 50% 的波动范围，而不希望受到极端值干扰时，应优先考虑四分位距。可以结合标准差和四分位距一起使用，从不同角度理解数据的离散程度。\n\n\n\n\n极差 (Range): 最大值减去最小值，用 range() 函数计算，然后自己算一下。\n\ndata_range &lt;- range(你的数据框$列名)\nrange_value &lt;- data_range[2] - data_range[1] # 最大值 - 最小值\n\n\n\n\n\n\nNote\n\n\n\n\n优点： 极差非常容易计算和理解，直接反映了数据的最大波动范围。\n缺点： 极差只利用了最大值和最小值两个极端值的信息，忽略了中间数据的分布，不能全面反映数据的离散程度。极差非常容易受到异常值的影响，如果数据集中存在极端值，极差会被显著放大，无法准确反映大多数数据的波动范围。\n使用技巧： 极差通常只作为对数据波动范围的粗略估计，或者在数据量较小的情况下使用。在需要快速了解数据大致范围时，可以使用极差。但由于其对异常值敏感且信息量少，不宜作为主要的离散程度度量。在实际应用中，更常用标准差或四分位距来描述数据的离散程度。\n\n\n\n\n\n\ndplyr 包：数据清洗入门\n数据清洗 (Data Cleaning) 是数据分析中非常重要的一个环节。真实世界的数据往往是“脏乱”的，可能包含缺失值、重复值、格式错误、异常值等等问题。数据清洗的目的就是处理这些数据质量问题，让数据变得更加干净、规范、可用，为后续的分析和建模打下良好的基础。\ndplyr 包是 R 语言中一个非常流行和强大的数据处理包，它提供了一系列简洁高效的函数，可以帮助我们快速完成各种数据清洗和转换任务。接下来我们来学习 dplyr 包的一些常用函数。\n\n\n\n\n\n\ndplyr 包的核心动词\n\n\n\n\nselect(): 选择列\nfilter(): 筛选行\nmutate(): 创建新列或修改列\narrange(): 排序\nsummarise(): 汇总统计\ngroup_by(): 分组\n%&gt;% (管道操作符): 把上一步的结果传给下一步\n\n\n\n\nselect() 函数： 选择需要的列\n# 选择单列\nselect(你的数据框, 列名)\n\n# 选择多列\nselect(你的数据框, 列1, 列2, 列3)\n\n# 选择列名以特定字符开头的列\nselect(你的数据框, starts_with(\"前缀\"))\n\n# 选择列名以特定字符结尾的列\nselect(你的数据框, ends_with(\"后缀\"))\n\n# 选择列名包含特定字符的列\nselect(你的数据框, contains(\"字符串\"))\n\n# 排除特定列\nselect(你的数据框, -要排除的列名)\n\n\n\n\n\n\n使用技巧\n\n\n\n\n灵活组合选择方法: select() 可以灵活组合各种选择列的方法，例如 starts_with(), ends_with(), contains() 等，以及 - 排除列，来快速选择需要的列。\n配合管道操作符 %&gt;%: select() 经常和管道操作符 %&gt;% 结合使用，作为数据清洗的第一步，先选择需要的列，再进行后续的数据处理。\n保持代码简洁易读: 合理使用 select() 可以让代码更简洁易读，只保留分析需要的列，减少干扰信息。\n在数据探索阶段使用: 在数据探索的初期，可以使用 select() 快速查看不同列的数据，了解数据的大致结构和内容。\n\n\n\n\n\nfilter() 函数： 筛选符合条件的行\n# 筛选单条件\nfilter(你的数据框, 列名 &gt; 值)\n\n# 筛选多条件 (AND，并且)\nfilter(你的数据框, 列1 == 值1 & 列2 &lt; 值2)\n\n# 筛选多条件 (OR，或者)\nfilter(你的数据框, 列1 == 值1 | 列2 &lt; 值2)\n\n# 使用 %in% 筛选多个值\nfilter(你的数据框, 列名 %in% c(\"值1\", \"值2\", \"值3\"))\n\n# 筛选缺失值 (NA)\nfilter(你的数据框, is.na(列名))\n\n# 筛选非缺失值\nfilter(你的数据框, !is.na(列名))\n\n\n\n\n\n\n使用技巧\n\n\n\n\n多条件灵活组合: filter() 可以使用 & (AND) 和 | (OR) 组合多个筛选条件，构建复杂的筛选逻辑。\n使用 %in% 简化多值筛选: 当需要筛选某一列的多个特定值时，使用 %in% 操作符可以使代码更简洁。\n处理缺失值: is.na() 和 !is.na() 可以方便地筛选缺失值和非缺失值，用于数据清洗中处理缺失值的情况。\n在数据清洗和预处理阶段使用: filter() 是数据清洗和预处理中非常常用的函数，用于筛选出符合特定条件的子数据集，为后续分析做准备。\n结合其他 dplyr 函数: filter() 经常与其他 dplyr 函数 (如 group_by(), summarise(), mutate()) 结合使用，完成更复杂的数据处理任务。\n\n\n\n\n\n演示\n\n演示： 用 dplyr 函数对示例数据做一些简单的列选择和行筛选。\n\n\n\n\n描述性统计和数据清洗练习\n\n练习任务： 计算示例数据的描述性统计量，用 dplyr 的 select() 和 filter() 函数做简单的数据清洗。\n可以用 AI 工具 (Cursor) 帮忙，比如让 AI 解释 select() 和 filter() 函数怎么用。\n\n\n\n\n\n\n\n课后作业 (第二周)\n\n\n\n\n完成数据获取： 下载数据集，或者尝试用 API 获取数据 (API 这周主要是尝试，不要求成功拿到完整数据)。\n用 readr (或其他包) 把数据导入到 R。\n用 head(), glimpse(), summary(), str() 等函数看看数据。\n计算数据中重要变量的描述性统计量 (平均值、中位数、标准差等)。\n尝试用 dplyr 的 select() 和 filter() 函数做简单的数据清洗。\n思考题： 你现在拿到的数据有什么质量问题吗？ 比如有没有缺失值、异常值、重复值？ 想想可以怎么处理这些问题 (可以查资料或者用 AI 搜索)。\n\n\n\n\n\n\n\n\n\nAI 辅助学习建议 (第二周)\n\n\n\n\n数据获取： 用 AI 帮你看 API 文档，找数据集，总结数据信息。\nR 数据导入： 用 AI 帮你写和调试数据导入代码，解决导入问题。\n数据理解和描述性统计： 用 AI 帮你写代码，理解数据查看和描述性统计的代码，学习各种统计量的意思。\ndplyr 数据清洗： 用 AI 帮你学习 dplyr 的 select() 和 filter() 函数，生成 dplyr 代码，完成数据清洗练习。",
    "crumbs": [
      "项目一：统计分析基础与数据可视化",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>第二周：R语言数据导入与数据初步理解</span>"
    ]
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "第三周：描述性统计：数据探索与可视化",
    "section": "",
    "text": "第五次课：数据清洗进阶、可视化初步",
    "crumbs": [
      "项目一：统计分析基础与数据可视化",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>第三周：描述性统计：数据探索与可视化</span>"
    ]
  },
  {
    "objectID": "week3.html#第五次课数据清洗进阶可视化初步",
    "href": "week3.html#第五次课数据清洗进阶可视化初步",
    "title": "第三周：描述性统计：数据探索与可视化",
    "section": "",
    "text": "dplyr 包：数据清洗和预处理进阶\n\n\n\n在第二周，我们学习了 dplyr 包的 select() 和 filter() 函数，用于列选择和行筛选。dplyr 包还提供了很多其他强大的函数，可以帮助我们更高效地进行数据清洗和预处理。\n\n\n\nmutate() 函数： 创建新列或修改现有列\nmutate() 函数可以基于现有列进行计算，创建新的列，或者修改已有的列。\n\n# 首先加载必要的包\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n\n# 创建新列：计算每只企鹅的体重与体长的比值\npenguins &lt;- penguins %&gt;%\n  mutate(weight_length_ratio = body_mass_g / bill_length_mm)\n\n# 修改现有列：将体重从克转换为千克\npenguins &lt;- penguins %&gt;%\n  mutate(body_mass_kg = body_mass_g / 1000)\n\n\n\n\n\n\n\n使用技巧\n\n\n\n\n创建新列: mutate() 最常用的功能是创建新列，可以基于现有列进行各种计算，例如加减乘除、取对数、标准化等。\n修改现有列: mutate() 也可以用于修改现有列的值，例如将单位转换、数据类型转换等。\n创建多个列: mutate() 可以同时创建多个新列，只需在函数中指定多个赋值语句即可。\n条件创建列: 结合 if_else() 或 case_when() 函数，可以根据条件判断创建不同的列值。\n链式操作: mutate() 可以和 dplyr 包的其他函数 (如 select(), filter(), group_by(), summarise()) 灵活组合使用，实现复杂的数据处理流程。\n保持数据框结构: mutate() 不会改变数据框的行数，只会增加或修改列。\n\n\n\n\n\narrange() 函数： 排序数据\narrange() 函数可以按照指定的列对数据进行排序，可以升序，也可以降序。\n\n# 按企鹅体重降序排序\npenguins %&gt;%\n  arrange(desc(body_mass_g))\n\n# A tibble: 344 × 10\n   species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Gentoo  Biscoe           49.2          15.2               221        6300\n 2 Gentoo  Biscoe           59.6          17                 230        6050\n 3 Gentoo  Biscoe           51.1          16.3               220        6000\n 4 Gentoo  Biscoe           48.8          16.2               222        6000\n 5 Gentoo  Biscoe           45.2          16.4               223        5950\n 6 Gentoo  Biscoe           49.8          15.9               229        5950\n 7 Gentoo  Biscoe           48.4          14.6               213        5850\n 8 Gentoo  Biscoe           49.3          15.7               217        5850\n 9 Gentoo  Biscoe           55.1          16                 230        5850\n10 Gentoo  Biscoe           49.5          16.2               229        5800\n# ℹ 334 more rows\n# ℹ 4 more variables: sex &lt;fct&gt;, year &lt;int&gt;, weight_length_ratio &lt;dbl&gt;,\n#   body_mass_kg &lt;dbl&gt;\n\n# 按企鹅种类升序、体重降序排序\npenguins %&gt;%\n  arrange(species, desc(body_mass_g))\n\n# A tibble: 344 × 10\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Biscoe              43.2          19                 197        4775\n 2 Adelie  Biscoe              41            20                 203        4725\n 3 Adelie  Torgersen           42.9          17.6               196        4700\n 4 Adelie  Torgersen           39.2          19.6               195        4675\n 5 Adelie  Dream               39.8          19.1               184        4650\n 6 Adelie  Dream               39.6          18.8               190        4600\n 7 Adelie  Biscoe              45.6          20.3               191        4600\n 8 Adelie  Torgersen           42.5          20.7               197        4500\n 9 Adelie  Dream               37.5          18.5               199        4475\n10 Adelie  Torgersen           41.8          19.4               198        4450\n# ℹ 334 more rows\n# ℹ 4 more variables: sex &lt;fct&gt;, year &lt;int&gt;, weight_length_ratio &lt;dbl&gt;,\n#   body_mass_kg &lt;dbl&gt;\n\n\n\n\n\n\n\n\n使用技巧\n\n\n\n\n单列排序和多列排序: arrange() 可以指定一个或多个列进行排序，实现单条件排序和多条件排序。多列排序时，先按第一列排序，再在第一列相同的情况下按第二列排序，以此类推。\n升序和降序: 默认升序排序，使用 desc() 函数可以实现降序排序。\n缺失值处理: arrange() 默认将缺失值 (NA) 排在最后。\n保持数据框结构: arrange() 不会改变数据框的列数和行数，只是改变行的顺序。\n数据探索和报告中使用: arrange() 常用于数据探索阶段，例如找出评分最高的电影、票房最高的电影等。在生成报告时，排序后的数据表格更易于阅读和理解。\n为后续操作准备数据: 排序后的数据可以为后续的数据分析和可视化提供便利，例如绘制折线图、计算累计值等。\n\n\n\n\n\nrename() 函数： 重命名列名\nrename() 函数可以修改数据框的列名，使其更易于理解和使用。\n\n# 将列名 bill_length_mm 重命名为 beak_length\npenguins %&gt;%\n  rename(beak_length = bill_length_mm)\n\n# A tibble: 344 × 10\n   species island  beak_length bill_depth_mm flipper_length_mm body_mass_g sex  \n   &lt;fct&gt;   &lt;fct&gt;         &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt; &lt;fct&gt;\n 1 Adelie  Torger…        39.1          18.7               181        3750 male \n 2 Adelie  Torger…        39.5          17.4               186        3800 fema…\n 3 Adelie  Torger…        40.3          18                 195        3250 fema…\n 4 Adelie  Torger…        NA            NA                  NA          NA &lt;NA&gt; \n 5 Adelie  Torger…        36.7          19.3               193        3450 fema…\n 6 Adelie  Torger…        39.3          20.6               190        3650 male \n 7 Adelie  Torger…        38.9          17.8               181        3625 fema…\n 8 Adelie  Torger…        39.2          19.6               195        4675 male \n 9 Adelie  Torger…        34.1          18.1               193        3475 &lt;NA&gt; \n10 Adelie  Torger…        42            20.2               190        4250 &lt;NA&gt; \n# ℹ 334 more rows\n# ℹ 3 more variables: year &lt;int&gt;, weight_length_ratio &lt;dbl&gt;, body_mass_kg &lt;dbl&gt;\n\n# 同时重命名多列\npenguins %&gt;%\n  rename(beak_length = bill_length_mm, beak_depth = bill_depth_mm)\n\n# A tibble: 344 × 10\n   species island    beak_length beak_depth flipper_length_mm body_mass_g sex   \n   &lt;fct&gt;   &lt;fct&gt;           &lt;dbl&gt;      &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt; &lt;fct&gt; \n 1 Adelie  Torgersen        39.1       18.7               181        3750 male  \n 2 Adelie  Torgersen        39.5       17.4               186        3800 female\n 3 Adelie  Torgersen        40.3       18                 195        3250 female\n 4 Adelie  Torgersen        NA         NA                  NA          NA &lt;NA&gt;  \n 5 Adelie  Torgersen        36.7       19.3               193        3450 female\n 6 Adelie  Torgersen        39.3       20.6               190        3650 male  \n 7 Adelie  Torgersen        38.9       17.8               181        3625 female\n 8 Adelie  Torgersen        39.2       19.6               195        4675 male  \n 9 Adelie  Torgersen        34.1       18.1               193        3475 &lt;NA&gt;  \n10 Adelie  Torgersen        42         20.2               190        4250 &lt;NA&gt;  \n# ℹ 334 more rows\n# ℹ 3 more variables: year &lt;int&gt;, weight_length_ratio &lt;dbl&gt;, body_mass_kg &lt;dbl&gt;\n\n\n\n\n\n\n\n\n使用技巧\n\n\n\n\n清晰的列名: 使用 rename() 将列名修改为更清晰、更具描述性的名称，提高代码可读性和数据理解度。\n统一列名风格: 在数据整合和清洗过程中，可以使用 rename() 统一不同数据源的列名风格，例如统一使用小写、下划线分隔等。\n避免中文列名: 虽然 R 语言支持中文列名，但英文列名在编程中更通用，可以避免编码和兼容性问题。可以使用 rename() 将中文列名转换为英文列名。\n不改变数据内容: rename() 只修改列名，不改变列的数据内容。\n配合 select() 使用: rename() 和 select() 经常一起使用，先用 select() 选择需要的列，再用 rename() 修改列名。\n\n\n\n\n\ndistinct() 函数： 去除重复行\ndistinct() 函数可以去除数据框中的重复行，只保留唯一的行。\n\n# 去除 penguins 中的重复行\npenguins %&gt;%\n  distinct()\n\n# A tibble: 344 × 10\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 4 more variables: sex &lt;fct&gt;, year &lt;int&gt;, weight_length_ratio &lt;dbl&gt;,\n#   body_mass_kg &lt;dbl&gt;\n\n# 基于指定列去除重复行 (例如，只考虑企鹅种类和性别)\npenguins %&gt;%\n  distinct(species, sex)\n\n# A tibble: 8 × 2\n  species   sex   \n  &lt;fct&gt;     &lt;fct&gt; \n1 Adelie    male  \n2 Adelie    female\n3 Adelie    &lt;NA&gt;  \n4 Gentoo    female\n5 Gentoo    male  \n6 Gentoo    &lt;NA&gt;  \n7 Chinstrap female\n8 Chinstrap male  \n\n\n\n\n\n\n\n\n使用技巧\n\n\n\n\n去除完全重复行: 默认情况下，distinct() 会去除数据框中所有列值都相同的行，即完全重复的行。\n基于指定列去重: 可以使用 distinct(col1, col2, ...) 指定基于哪些列判断重复行。\n保留所有列: 使用 .keep_all = TRUE 参数可以在去重的同时保留数据框的所有列，只去除指定的重复行。\n数据清洗常用步骤: distinct() 是数据清洗中常用的步骤，用于去除重复数据，避免重复数据对分析结果产生干扰。\n检查去重效果: 去重后，应该检查去重后的数据行数是否符合预期，以及是否正确去除了重复行。\n\n\n\n\n\nsummarise() 函数： 计算汇总统计量\nsummarise() 函数可以对数据框进行汇总统计，计算例如均值、中位数、标准差等。通常和 group_by() 函数一起使用，进行分组汇总统计。\n\n# 计算所有企鹅的平均体重和体重标准差\npenguins %&gt;%\n  summarise(\n    mean_mass = mean(body_mass_g, na.rm = TRUE),\n    sd_mass = sd(body_mass_g, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 2\n  mean_mass sd_mass\n      &lt;dbl&gt;   &lt;dbl&gt;\n1     4202.    802.\n\n# 分组计算：按企鹅种类计算平均体重\npenguins %&gt;%\n  group_by(species) %&gt;%\n  summarise(\n    mean_mass = mean(body_mass_g, na.rm = TRUE),\n    n_penguins = n() # 统计每种类型企鹅的数量\n  )\n\n# A tibble: 3 × 3\n  species   mean_mass n_penguins\n  &lt;fct&gt;         &lt;dbl&gt;      &lt;int&gt;\n1 Adelie        3701.        152\n2 Chinstrap     3733.         68\n3 Gentoo        5076.        124\n\n\n\n\n\n\n\n\n使用技巧\n\n\n\n\n计算多种统计量: summarise() 可以同时计算多个统计量，例如均值 (mean())、中位数 (median())、标准差 (sd())、求和 (sum())、计数 (n())、最小值 (min())、最大值 (max()) 等。\n结合 group_by() 进行分组汇总: summarise() 最强大的功能是和 group_by() 结合使用，实现分组汇总统计，例如计算不同类别、不同组别的均值、总和等。\n自定义汇总结果的列名: 在 summarise() 中，可以使用 列名 = 统计函数(列) 的形式，自定义汇总结果的列名，使其更易于理解。\n数据探索和报告生成: summarise() 常用于数据探索阶段，快速了解数据的总体统计特征和分组统计特征。在生成报告时，汇总统计表格可以清晰地展示数据的主要特征。\n为可视化提供数据: summarise() 计算的汇总统计结果，可以作为 ggplot2 等可视化工具的数据来源，用于绘制柱状图、箱线图等。\n\n\n\n\n\ngroup_by() 函数： 分组数据\ngroup_by() 函数可以将数据框按照指定的列进行分组，后续的 summarise(), mutate() 等操作会在每个分组内进行。\n\n# 按企鹅种类分组\npenguins %&gt;%\n  group_by(species)\n\n# A tibble: 344 × 10\n# Groups:   species [3]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 4 more variables: sex &lt;fct&gt;, year &lt;int&gt;, weight_length_ratio &lt;dbl&gt;,\n#   body_mass_kg &lt;dbl&gt;\n\n# 按企鹅种类和性别分组\npenguins %&gt;%\n  group_by(species, sex)\n\n# A tibble: 344 × 10\n# Groups:   species, sex [8]\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 4 more variables: sex &lt;fct&gt;, year &lt;int&gt;, weight_length_ratio &lt;dbl&gt;,\n#   body_mass_kg &lt;dbl&gt;\n\n\n\n\n\n\n\n\n使用技巧\n\n\n\n\n单列分组和多列分组: group_by() 可以指定一个或多个列进行分组，实现单层分组和多层分组。\n分组后进行汇总统计: group_by() 最常用的场景是和 summarise() 结合使用，进行分组汇总统计。\n分组后进行mutate操作: group_by() 也可以和 mutate() 结合使用，在每个分组内进行数据转换和衍生。例如，计算每个电影类型内的评分排名。\n取消分组: 使用 ungroup() 函数可以取消分组状态，将数据框恢复为未分组状态。\n分组操作的顺序: group_by() 操作通常放在数据处理流程的早期，为后续的分组汇总、分组转换等操作做准备。\n分组变量的选择: 选择合适的分组变量非常重要，分组变量应该能够有效区分不同的数据子集，并有助于发现数据中的模式和规律。\n\n\n\n\n\n管道操作符 %&gt;% 的深入应用\n管道操作符 %&gt;% 是 tidyverse 系列包的核心特色之一，它可以将多个函数调用连接起来，使代码从左向右、从上向下流动，更加符合人的阅读习惯，也更易于理解和维护。\n\n# 链式操作示例：\n# 1. 选择种类、体重和嘴峰长度列\n# 2. 筛选体重大于 4000g 的企鹅\n# 3. 按企鹅种类分组\n# 4. 汇总计算每种类型企鹅的平均体重和数量\npenguins %&gt;%\n  select(species, body_mass_g, bill_length_mm) %&gt;%\n  filter(body_mass_g &gt; 4000) %&gt;%\n  group_by(species) %&gt;%\n  summarise(\n    mean_mass = mean(body_mass_g, na.rm = TRUE),\n    n_penguins = n()\n  )\n\n# A tibble: 3 × 3\n  species   mean_mass n_penguins\n  &lt;fct&gt;         &lt;dbl&gt;      &lt;int&gt;\n1 Adelie        4346.         35\n2 Chinstrap     4267.         15\n3 Gentoo        5085.        122\n\n\n\n\n\n\n\n\n使用技巧\n\n\n\n\n提高代码可读性: 使用管道操作符 %&gt;% 可以将复杂的数据处理流程分解为一系列简单的步骤，每一步都清晰可见，代码更易于阅读和理解。\n减少中间变量: 使用管道操作符 %&gt;% 可以避免创建大量的中间变量，使代码更简洁。\n链式调用多个函数: 管道操作符 %&gt;% 可以连接任意多个 dplyr 函数，以及其他 R 包的函数，实现复杂的数据处理流程。\n从左向右、从上向下: 管道操作符 %&gt;% 让代码的执行顺序从左向右、从上向下，更符合人的思维习惯。\n易于调试和维护: 使用管道操作符 %&gt;% 组织的代码，更易于调试和维护，每一步操作都是独立的，可以单独测试和修改。\n与其他 tidyverse 包协同工作: 管道操作符 %&gt;% 是 tidyverse 系列包的通用操作符，可以与 dplyr, tidyr, ggplot2 等包的函数无缝衔接，构建完整的数据分析流程。\n\n\n\n\n\ntidyr 包：数据整理\n\n\n\n\n\n\ntidyr 包：数据整理\n\n\n\ntidyr 包是 tidyverse 生态系统中专门用于数据整理的包。数据整理 (Data Wrangling/Data Reshaping) 是指将数据从一种格式转换为另一种格式，使其更适合分析和可视化。tidyr 包主要解决 “tidy data” (整洁数据) 的问题。\n\n\n\n\n\n\n\n\n“Tidy Data” 的概念\n\n\n\n“Tidy Data” (整洁数据) 是一种规范的数据组织形式，它具有以下三个核心原则：\n\n每一列是一个变量 (variable)。\n每一行是一个观测 (observation)。\n每个单元格是一个值 (value)。\n\n简单来说，“tidy data” 就是我们通常说的规范化的表格数据，每一列代表一个属性，每一行代表一个记录。\n\n\n\npivot_longer() 函数： 宽格式转长格式\npivot_longer() 函数可以将宽格式 (wide format) 的数据转换为长格式 (long format) 的数据。\n\n宽格式数据: 有些列名本身不是变量名，而是变量的取值，这种数据格式称为宽格式。例如，一份学生成绩单，列名可能是 “语文成绩”, “数学成绩”, “英语成绩” 等，这些列名 “语文”, “数学”, “英语” 实际上是 “科目” 变量的取值。\n长格式数据: 将宽格式数据转换为长格式后，原来的列名会变成一个新的变量 (例如 “科目” 变量)，原来的列值会变成一个新的变量 (例如 “成绩” 变量)。长格式数据更符合 “tidy data” 的规范。\n\n\n# 示例数据：宽格式的学生成绩数据\nwide_data &lt;- data.frame(\n  姓名 = c(\"小明\", \"小红\"),\n  语文成绩 = c(80, 90),\n  数学成绩 = c(85, 92),\n  英语成绩 = c(78, 88)\n)\n\n# 使用 pivot_longer() 将宽格式数据转换为长格式\nlong_data &lt;- wide_data %&gt;%\n  pivot_longer(\n    cols = c(语文成绩, 数学成绩, 英语成绩), # 指定要转换的列\n    names_to = \"科目\",        # 转换后的列名，存储原来的列名 (语文成绩, 数学成绩, 英语成绩)\n    values_to = \"成绩\"       # 转换后的列名，存储原来的列值 (80, 90, 85, 92, 78, 88)\n  )\n\nlong_data\n\n# A tibble: 6 × 3\n  姓名  科目      成绩\n  &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt;\n1 小明  语文成绩    80\n2 小明  数学成绩    85\n3 小明  英语成绩    78\n4 小红  语文成绩    90\n5 小红  数学成绩    92\n6 小红  英语成绩    88\n\n\n\n\n\n\n\n\n使用技巧\n\n\n\n\n指定要转换的列: 使用 cols 参数指定要从宽格式转换为长格式的列。可以使用列名向量、列名选择函数 (例如 starts_with(), ends_with(), contains()) 等灵活选择。\n命名新变量: 使用 names_to 参数指定转换后存储原列名的变量名，使用 values_to 参数指定转换后存储原列值的变量名。\n处理多列: pivot_longer() 可以同时处理多列，将多组宽格式列转换为长格式。\n数据分析和可视化准备: 长格式数据更适合进行数据分析和可视化，例如使用 ggplot2 绘制不同科目的成绩比较图。\n与 pivot_wider() 函数配合使用: pivot_longer() 和 pivot_wider() 是一对互逆的函数，可以灵活地在宽格式和长格式之间转换数据。\n\n\n\n\n\npivot_wider() 函数： 长格式转宽格式\npivot_wider() 函数可以将长格式 (long format) 的数据转换为宽格式 (wide format) 的数据，是 pivot_longer() 函数的逆操作。\n\n# 示例数据：长格式的学生成绩数据 (上例转换后的 long_data)\n\n# 使用 pivot_wider() 将长格式数据转换为宽格式\nlong_data %&gt;%\n  pivot_wider(\n    names_from = \"科目\",      # 指定列名来源，科目列的取值 (语文, 数学, 英语) 将作为新的列名\n    values_from = \"成绩\"     # 指定列值来源，成绩列的值将作为新列的值\n  )\n\n# A tibble: 2 × 4\n  姓名  语文成绩 数学成绩 英语成绩\n  &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 小明        80       85       78\n2 小红        90       92       88\n\n\n\n\n\n\n\n\n使用技巧\n\n\n\n\n指定列名和列值来源: 使用 names_from 参数指定从哪一列获取新的列名，使用 values_from 参数指定从哪一列获取新列的值。\n处理多行: 当长格式数据中，相同的观测 (由其他列唯一确定) 对应多行数据时，pivot_wider() 可以将多行数据合并为一行，并将不同的值分别放入不同的列中。\n数据格式转换: pivot_wider() 常用于将数据转换为特定的格式，以满足特定的分析或可视化需求。\n与 pivot_longer() 函数配合使用: pivot_longer() 和 pivot_wider() 是一对互逆的函数，可以灵活地在宽格式和长格式之间转换数据。\n\n\n\n\n\nseparate() 函数： 将一列拆分成多列\nseparate() 函数可以将一列按照指定的分隔符拆分成多列。\n\n# 示例数据：包含 \"年份-月份-日期\" 格式日期的列\ndate_data &lt;- data.frame(\n  日期 = c(\"2023-10-26\", \"2023-10-27\", \"2023-10-28\"),\n  value = c(100, 120, 110)\n)\n\n# 使用 separate() 将 \"日期\" 列拆分成 \"年份\", \"月份\", \"日期\" 三列\nseparated_data &lt;-date_data %&gt;%\n  separate(\n    col = 日期,          # 指定要拆分的列\n    into = c(\"年份\", \"月份\", \"日期\"), # 拆分后的新列名\n    sep = \"-\"           # 分隔符为 \"-\"\n  )\n\nseparated_data\n\n  年份 月份 日期 value\n1 2023   10   26   100\n2 2023   10   27   120\n3 2023   10   28   110\n\n\n\n\n\n\n\n\n使用技巧\n\n\n\n\n指定分隔符: 使用 sep 参数指定分隔符，可以是字符、正则表达式等。\n命名新列: 使用 into 参数指定拆分后的新列名，需要提供一个字符向量，向量的长度应该等于拆分后的列数。\n处理多种分隔符: separate() 可以处理多种分隔符，例如空格、逗号、下划线等。\n数据清洗和特征工程: separate() 常用于数据清洗和特征工程，例如将日期时间列拆分成年、月、日、时、分、秒等，提取地址中的省、市、区等信息。\n与 unite() 函数配合使用: separate() 和 unite() 是一对互逆的函数，separate() 拆分列，unite() 合并列。\n\n\n\n\n\nunite() 函数： 将多列合并成一列\nunite() 函数可以将多列按照指定的分隔符合并成一列，是 separate() 函数的逆操作。\n\n# 示例数据：包含 \"年份\", \"月份\", \"日期\" 列的数据 (上例拆分后的 separated_data)\n\n# 使用 unite() 将 \"年份\", \"月份\", \"日期\" 三列合并成 \"完整日期\" 列\nseparated_data %&gt;%\n  unite(\n    col = 完整日期,       # 合并后的新列名\n    年份, 月份, 日期,      # 要合并的列\n    sep = \"-\"           # 分隔符为 \"-\"\n  )\n\n    完整日期 value\n1 2023-10-26   100\n2 2023-10-27   120\n3 2023-10-28   110\n\n\n\n\n\n\n\n\n使用技巧\n\n\n\n\n指定分隔符: 使用 sep 参数指定合并时使用的分隔符。\n命名新列: 使用 col 参数指定合并后的新列名。\n选择要合并的列: 在 unite() 函数中，直接列出要合并的列名即可。\n数据格式转换: unite() 常用于将多列合并成一列，例如将年、月、日合并成日期列，将省、市、区合并成地址列。\n与 separate() 函数配合使用: separate() 和 unite() 是一对互逆的函数，separate() 拆分列，unite() 合并列。\n\n\n\n\n\n\nggplot2 包：数据可视化初步\n\n\n\n\n\n\nggplot2 包：数据可视化初步\n\n\n\nggplot2 包是 tidyverse 生态系统中用于数据可视化的核心包，也是 R 语言中最强大、最流行的可视化包之一。ggplot2 基于 “图形语法” (Grammar of Graphics) 理论，提供了一套灵活、强大、美观的数据可视化方案。\n\n\n\n\n\n\n\n\nggplot2 的基本语法结构\n\n\n\nggplot2 的图形由图层 (layer) 构成，每个图层包含数据 (data)、映射 (mapping) 和几何对象 (geom) 三个基本要素。\n\n数据 (data)： 要可视化的数据，通常是一个数据框。\n映射 (mapping)： 使用 aes() 函数将数据中的变量映射到图形的视觉属性 (aesthetic)，例如 x 轴位置、y 轴位置、颜色、大小、形状等。\n几何对象 (geom)： 决定图形的类型，例如散点图 (geom_point())、直方图 (geom_histogram())、箱线图 (geom_boxplot())、柱状图 (geom_bar())、折线图 (geom_line()) 等。\n\n\n\n\n常用几何对象\n\ngeom_histogram() (直方图)： 展示数值变量的分布。将数值变量的值域划分为若干个区间 (bin)，统计每个区间内的数据频数，用柱形的高度表示频数。\n\nggplot(data = penguins, aes(x = body_mass_g)) +\n  geom_histogram(bins = 30, fill = \"#69b3a2\", color = \"white\", alpha = 0.8) +\n  labs(\n    title = \"企鹅体重分布\",\n    subtitle = \"基于Palmer Penguins数据集\",\n    x = \"体重 (g)\",\n    y = \"频数\"\n  )\n\n\n\n\n\n\n\n\ngeom_point() (散点图)： 展示两个数值变量之间的关系。用点的 x 轴和 y 轴位置表示两个变量的值。\n\nggplot(data = penguins, aes(x = bill_length_mm, y = body_mass_g, color = species)) +\n  geom_point(alpha = 0.7, size = 3) +\n  scale_color_manual(values = custom_colors,\n                    labels = c(\"阿德利企鹅\", \"帽带企鹅\", \"巴布亚企鹅\")) +\n  labs(\n    title = \"企鹅嘴峰长度与体重的关系\",\n    subtitle = \"按企鹅种类分类\",\n    x = \"嘴峰长度 (mm)\",\n    y = \"体重 (g)\",\n    color = \"企鹅种类\"\n  )\n\n\n\n\n\n\n\n\ngeom_boxplot() (箱线图)： 展示数值变量在不同组别的分布，检测异常值。箱线图用箱子和须线展示数据的四分位数、中位数、上下限等信息，可以直观地比较不同组别数据的分布差异，并识别潜在的异常值。\n\nggplot(data = penguins, aes(x = species, y = body_mass_g, fill = species)) +\n  geom_boxplot(alpha = 0.7) +\n  scale_fill_manual(values = custom_colors,\n                   labels = c(\"阿德利企鹅\", \"帽带企鹅\", \"巴布亚企鹅\")) +\n  labs(\n    title = \"不同种类企鹅的体重分布\",\n    subtitle = \"使用箱线图展示\",\n    x = \"企鹅种类\",\n    y = \"体重 (g)\",\n    fill = \"企鹅种类\"\n  ) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n基本图形属性设置\n\n\n\n\n颜色 (color, fill)：\n\ncolor 属性： 通常用于设置线条、点、边框的颜色。\nfill 属性： 通常用于设置填充区域的颜色，例如柱子、箱子、多边形等。\n可以在 geom_xxx() 函数中直接设置固定颜色值 (例如 color = \"red\", fill = \"blue\")，也可以在 aes() 函数中将颜色属性映射到数据变量 (例如 aes(color = species), aes(fill = species))，让颜色根据数据变量的取值而变化。\n\n大小 (size)： 设置点的大小、线条的粗细等。可以在 geom_xxx() 函数中直接设置固定大小值 (例如 size = 3)，也可以在 aes() 函数中将大小属性映射到数据变量 (例如 aes(size = body_mass_g))，让大小根据数据变量的取值而变化。\n形状 (shape)： 设置点的形状。ggplot2 提供了多种点的形状，可以通过数字或形状名称指定 (例如 shape = 16 或 shape = \"circle\"). 可以在 geom_point() 函数中直接设置固定形状值 (例如 shape = 16)，也可以在 aes() 函数中将形状属性映射到数据变量 (例如 aes(shape = species))，让形状根据数据变量的取值而变化。\n透明度 (alpha)： 设置图形的透明度，取值范围为 0-1，越小越透明。可以用于处理数据重叠的问题，例如在散点图中，当数据点重叠较多时，可以降低透明度，使图形更清晰。可以在 geom_xxx() 函数中直接设置固定透明度值 (例如 alpha = 0.5)。\n\n\n\n\n\n演示：使用 ggplot2 绘制基本图表\n\n# 1. 直方图：展示企鹅体重的分布\nggplot(data = penguins, aes(x = body_mass_g)) +\n  geom_histogram(bins = 30, fill = \"#69b3a2\", color = \"white\", alpha = 0.8) +\n  labs(\n    title = \"企鹅体重分布\",\n    subtitle = \"基于Palmer Penguins数据集\",\n    x = \"体重 (g)\",\n    y = \"频数\"\n  )\n\n\n\n\n\n\n\n# 2. 散点图：展示企鹅嘴峰长度和体重的关系\nggplot(data = penguins, aes(x = bill_length_mm, y = body_mass_g, color = species)) +\n  geom_point(alpha = 0.7, size = 3) +\n  scale_color_manual(values = custom_colors,\n                    labels = c(\"阿德利企鹅\", \"帽带企鹅\", \"巴布亚企鹅\")) +\n  labs(\n    title = \"企鹅嘴峰长度与体重的关系\",\n    subtitle = \"按企鹅种类分类\",\n    x = \"嘴峰长度 (mm)\",\n    y = \"体重 (g)\",\n    color = \"企鹅种类\"\n  )\n\n\n\n\n\n\n\n# 3. 箱线图：比较不同种类企鹅的体重分布\nggplot(data = penguins, aes(x = species, y = body_mass_g, fill = species)) +\n  geom_boxplot(alpha = 0.7) +\n  scale_fill_manual(values = custom_colors,\n                   labels = c(\"阿德利企鹅\", \"帽带企鹅\", \"巴布亚企鹅\")) +\n  labs(\n    title = \"不同种类企鹅的体重分布\",\n    subtitle = \"使用箱线图展示\",\n    x = \"企鹅种类\",\n    y = \"体重 (g)\",\n    fill = \"企鹅种类\"\n  ) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n数据可视化练习\n\n\n\n\n练习任务：\n\n使用 ggplot2 包，选择合适的可视化方法 (直方图、散点图、箱线图)，对示例数据进行可视化探索。\n\n尝试调整图形属性 (颜色、标题、标签等)，美化图形 (这部分下节课会详细介绍)。\n鼓励使用 AI 工具 (Cursor) 辅助 ggplot2 代码编写和图形美化。 例如，让 AI 生成绘制特定类型图形的 ggplot2 代码，或者提供美化图形的建议。",
    "crumbs": [
      "项目一：统计分析基础与数据可视化",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>第三周：描述性统计：数据探索与可视化</span>"
    ]
  },
  {
    "objectID": "week3.html#第六次课可视化进阶数据探索与可视化综合应用",
    "href": "week3.html#第六次课可视化进阶数据探索与可视化综合应用",
    "title": "第三周：描述性统计：数据探索与可视化",
    "section": "第六次课：可视化进阶、数据探索与可视化综合应用",
    "text": "第六次课：可视化进阶、数据探索与可视化综合应用\n\nggplot2 包：数据可视化进阶\n在第五次课，我们学习了 ggplot2 的基本语法和常用几何对象。为了创建更精美、更信息丰富的可视化图表，我们还需要学习 ggplot2 的更多高级功能。\n\n图例和轴标签设置： labs() 函数\nlabs() 函数用于设置图形的各种标签，包括标题 (title)、副标题 (subtitle)、坐标轴标签 (x 轴和 y 轴)、图例标题 (legend title) 等。\n\nggplot(data = penguins, aes(x = bill_length_mm, y = body_mass_g, color = species)) +\n  geom_point() +\n  labs(\n    title = \"企鹅嘴峰长度与体重的关系\",\n    subtitle = \"不同种类企鹅的散点图\",\n    x = \"嘴峰长度 (mm)\",\n    y = \"体重 (g)\",\n    color = \"企鹅种类\"\n  )\n\n\n\n\n\n\n\n\n\n\n主题设置： theme_xxx() 函数和 theme() 函数\nggplot2 提供了主题 (theme) 系统，用于控制图形的整体外观风格，例如背景颜色、网格线、字体、字号、边框、图例位置等。\n\n预设主题： theme_xxx() 函数: ggplot2 内置了一些预设主题，例如 theme_minimal(), theme_bw(), theme_classic(), theme_void() 等。这些预设主题提供了不同的视觉风格，可以快速改变图形的整体外观。\n\nggplot(data = penguins, aes(x = body_mass_g)) +\n  geom_histogram() +\n  theme_minimal() # 使用 minimal 主题\n\n\n\n\n\n\n\n\n自定义主题： theme() 函数: theme() 函数允许用户自定义主题的各个元素，例如背景、面板、坐标轴、网格线、文本、图例等。通过 theme() 函数，可以精细地控制图形的每一个细节，实现高度定制化的可视化效果。\n\nggplot(data = penguins, aes(x = body_mass_g)) +\n  geom_histogram(fill = \"lightblue\", color = \"black\") +\n  theme(\n    panel.background = element_rect(fill = \"lightyellow\"), # 设置背景颜色\n    panel.grid.major.x = element_line(color = \"gray\", linetype = \"dashed\"), # 设置 x 轴主要网格线\n    axis.text.x = element_text(angle = 45, hjust = 1) # 设置 x 轴刻度标签角度\n  )\n\n\n\n\n\n\n\n\n\n\n\n刻度设置： scale_x_xxx() 和 scale_y_xxx() 函数\nscale_x_xxx() 和 scale_y_xxx() 函数用于设置 x 轴和 y 轴的刻度，包括刻度范围、刻度标签、刻度格式等。\n\n常用刻度函数:\n\nscale_x_continuous(), scale_y_continuous(): 连续型刻度，用于数值型变量。\nscale_x_discrete(), scale_y_discrete(): 离散型刻度，用于分类型变量。\nscale_x_log10(), scale_y_log10(): 对数刻度，用于展示数据跨度较大的数据。\nscale_x_date(), scale_y_date(): 日期刻度，用于日期型变量。\nscale_x_datetime(), scale_y_datetime(): 日期时间刻度，用于日期时间型变量。\n\n\nggplot(data = penguins, aes(x = body_mass_g)) +\n  geom_histogram() +\n  scale_x_log10(labels = scales::comma) # 设置 x 轴为对数刻度，并使用逗号分隔的标签格式\n\n\n\n\n\n\n\n\n\nlabels 参数： 设置刻度标签的格式，可以使用 scales 包提供的格式化函数，例如 scales::comma (逗号分隔), scales::percent (百分比格式) 等。\n\n\n\n\n\n\n\n\n使用技巧\n\n\n\n\n调整刻度范围: 使用 limits 参数可以调整刻度的显示范围，例如 scale_x_continuous(limits = c(0, 10000))。\n自定义刻度标签: 使用 labels 参数可以自定义刻度标签的文本内容，例如 scale_x_continuous(labels = c(\"Low\", \"Medium\", \"High\"))。\n设置刻度格式: 使用 labels 参数和 scales 包提供的格式化函数，可以设置刻度标签的显示格式，例如逗号分隔、百分比、货币符号等。\n使用对数刻度: 当数据跨度较大，或数据分布偏斜时，可以考虑使用对数刻度，使图形更易于阅读和理解。\n日期时间刻度: 对于日期时间型变量，应使用日期时间刻度函数，例如 scale_x_date(), scale_x_datetime()，ggplot2 会自动处理日期时间的刻度显示。\n\n\n\n\n\n分面图： facet_wrap() 和 facet_grid() 函数\n分面 (facet) 是将数据按照一个或多个分类变量分组，为每个分组绘制一个子图，并将所有子图排列在一个页面上。分面图可以有效地展示不同分组数据的分布或关系，便于比较不同组别之间的差异。\n\nfacet_wrap() 函数: 单变量分面，将数据按照一个分类变量分组，并将子图按行或按列排列 (通常是按行排列，自动换行)。\n\nggplot(data = penguins, aes(x = body_mass_g, fill = species)) +\n  geom_histogram(alpha = 0.5, position = \"identity\") +\n  facet_wrap(~ species, ncol = 2) # 按企鹅种类分面，每行 2 个子图\n\n\n\n\n\n\n\n\n\n~ species： 分面公式，~ 符号后面跟分类变量名。\nncol 参数： 设置每行子图的数量。\n\nfacet_grid() 函数: 双变量分面，可以将数据按照两个分类变量分组，行和列分别对应一个分类变量，形成网格状的分面图。\n\nggplot(data = penguins, aes(x = body_mass_g, fill = species)) +\n  geom_histogram(alpha = 0.5, position = \"identity\") +\n  facet_grid(species ~ sex) # 按企鹅种类 (行) 和性别分组 (列) 分面\n\n\n\n\n\n\n\n\n\nspecies ~ sex： 分面公式，~ 符号左边是行分面变量，右边是列分面变量。\n\n\n\n\n\n\n\n\n使用技巧\n\n\n\n\n选择合适的分面变量: 分面变量应选择能够有效区分不同数据子集的分类变量，例如类别、组别、时间段等。\n控制分面数量: 分面数量不宜过多，否则子图会变得太小，难以阅读。通常情况下，分面数量控制在 10-20 个以内为宜。\n结合几何对象和图形属性: 分面图可以和各种几何对象 (例如直方图、散点图、箱线图) 和图形属性 (例如颜色、形状、大小) 结合使用，展示更丰富的数据信息。\n比较不同分组数据: 分面图最主要的应用场景是比较不同分组数据的分布或关系，例如比较不同类别产品的销售额分布、不同地区人群的收入水平等。\n探索多维数据: 分面图可以将多维数据 (例如包含多个分类变量的数据) 降维到二维平面上进行可视化，便于探索多维数据中的模式和规律。\n\n\n\n\n\n统计变换：stat_summary() 和 stat_smooth() 函数\nggplot2 提供了多种统计变换函数，用于在图形中添加统计信息，如统计摘要、平滑曲线等。这些函数以 stat_ 开头，可以与几何对象结合使用。\n\nstat_summary() 函数：用于在图形中添加统计摘要信息，如均值、中位数等。\n\n\nggplot(penguins, aes(x = species, y = body_mass_g)) +\n  geom_boxplot() +\n  stat_summary(fun = mean, geom = \"point\", color = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n使用技巧\n\n\n\n\n选择合适的统计函数: fun 参数允许你指定任何统计函数，例如 mean (均值), median (中位数), sd (标准差), IQR (四分位距) 等。你也可以自定义函数来计算更复杂的统计量。\n选择合适的几何对象: geom 参数决定了统计摘要的展示形式。常用的几何对象包括：\n\n\"point\": 用点表示均值或中位数等。\n\"errorbar\": 添加误差线，展示数据的变异性 (例如标准差)。\n\"crossbar\": 用带中心横线的柱状图表示均值和置信区间。\n\"boxplot\": 绘制箱线图 (实际上 geom_boxplot() 已经做了统计摘要，但 stat_summary(geom = \"boxplot\") 也是可以的)。\n\"line\" 或 \"path\": 连接不同组别的统计量，展示趋势。\n\n自定义外观: 你可以使用 color, size, shape, linetype, fill 等图形属性来自定义统计摘要的外观，使其更符合你的需求。\n分组统计: stat_summary() 会自动根据图形的分组 (例如通过 aes(color = ...) 或 facet_wrap()) 进行分组统计，分别计算每个组的统计摘要。\n添加多个统计量: 你可以多次调用 stat_summary() 函数，添加多个不同的统计量，例如同时展示均值和中位数。\n结合其他几何对象: stat_summary() 可以和各种几何对象结合使用，例如在散点图上添加均值点，在箱线图上标记均值点等。\n\n\n\n\nstat_smooth() 函数：用于在散点图中添加平滑曲线，展示变量间的趋势关系。\n\n\nggplot(penguins, aes(x = body_mass_g, y = flipper_length_mm)) +\n  geom_point() +\n  stat_smooth(method = \"loess\", color = \"blue\") # 添加 LOESS 平滑曲线\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n使用技巧\n\n\n\n\n选择合适的平滑方法: method 参数可以选择不同的平滑方法，例如 \"loess\" (局部加权回归，默认方法，适合非线性关系), \"lm\" (线性回归，适合线性关系), \"glm\" (广义线性模型), \"gam\" (广义加法模型) 等。根据数据的特点和分析目的选择合适的平滑方法。\n调整平滑程度: 对于 \"loess\" 方法，span 参数可以控制平滑程度，取值范围为 0-1，越小越灵活 (曲线越弯曲)，越大越平滑。\n添加置信区间: se = TRUE (默认值) 会在平滑曲线周围添加置信区间阴影，展示平滑估计的不确定性。se = FALSE 则不显示置信区间。\n分组平滑: stat_smooth() 会自动根据图形的分组 (例如通过 aes(color = ...) 或 group = ...) 分组) 进行分组平滑，分别拟合每个组的平滑曲线。\n自定义外观: 可以使用 color, linetype, size 等图形属性来自定义平滑曲线和置信区间的颜色、线型、粗细等外观，使其更符合你的需求。\n理解平滑曲线的含义: 平滑曲线展示的是数据的大致趋势和模式，帮助我们发现变量之间的潜在关系。但需要注意，平滑曲线并不代表真实的函数关系，只是一种数据趋势的近似展示。\n与其他几何对象结合: stat_smooth() 通常与 geom_point() 结合使用，在散点图的基础上添加平滑曲线，更清晰地展示变量之间的关系。\n\n\n\n\n\n\ntidyverse 生态：数据处理和可视化的综合应用\n\n案例：企鹅数据分析\n让我们通过一个完整的案例，展示如何使用 dplyr, tidyr, ggplot2 进行数据探索和可视化分析。\n\n# 1. 数据清洗和预处理\npenguins_clean &lt;- penguins %&gt;%\n  # 选择需要的列\n  select(species, island, bill_length_mm, bill_depth_mm, body_mass_g, sex) %&gt;%\n  # 去除缺失值\n  filter(!is.na(bill_length_mm), !is.na(body_mass_g), !is.na(sex))\n\n# 2. 按种类和性别统计平均体征\nspecies_sex_stats &lt;- penguins_clean %&gt;%\n  group_by(species, sex) %&gt;%\n  summarise(\n    mean_bill_length = mean(bill_length_mm),\n    mean_body_mass = mean(body_mass_g),\n    n_penguins = n()\n  ) %&gt;%\n  ungroup()\n\n# 3. 可视化展示\n# 3.1 不同种类企鹅的体重分布\nggplot(penguins_clean, aes(x = species, y = body_mass_g)) +\n  geom_boxplot(fill = \"lightblue\", alpha = 0.5) +\n  stat_summary(fun = \"mean\", geom = \"point\", color = \"red\", size = 3) +\n  theme_minimal() +\n  labs(\n    title = \"不同种类企鹅的体重分布\",\n    x = \"企鹅种类\",\n    y = \"体重 (g)\"\n  ) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n# 3.2 不同种类企鹅的嘴峰长度和体重关系\nggplot(penguins_clean, aes(x = bill_length_mm, y = body_mass_g, color = species)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  facet_wrap(~ species, scales = \"free_y\") +\n  theme_minimal() +\n  labs(\n    title = \"不同种类企鹅的嘴峰长度和体重关系\",\n    x = \"嘴峰长度 (mm)\",\n    y = \"体重 (g)\",\n    color = \"企鹅种类\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n数据探索与可视化练习\n\n练习任务：\n\n使用 dplyr 和 tidyr 对数据进行清洗和整理\n使用 ggplot2 创建至少三种不同类型的可视化图表\n尝试使用 ggplot2 的高级功能美化图表\n探索数据中的有趣模式和规律\n\n建议探索方向：\n\n分析不同类型企鹅的体重分布和趋势\n探索体重与其他变量 (如嘴峰长度、性别) 的关系\n研究企鹅种类随时间的变化趋势\n\n鼓励使用 AI 工具 (Cursor) 辅助：\n\n生成数据处理和可视化代码\n优化图表美化方案\n解释发现的数据模式\n\n\n\n\n\n\n\n\n课后作业 (第三周)\n\n\n\n\n继续深入探索自己项目的数据集：\n\n使用 dplyr, tidyr 进行数据清洗和整理\n处理缺失值、异常值等数据质量问题\n创建新的变量，进行必要的数据转换\n\n使用 ggplot2 包进行可视化探索：\n\n选择合适的图表类型，展示数据的分布和关系\n使用分面图比较不同组别的数据特征\n添加统计信息，如均值线、趋势线等\n美化图表，添加标题、标签、调整主题等\n\n撰写项目一的初步分析报告，包括：\n\n项目主题和目标\n数据来源和描述\n数据清洗和预处理步骤\n数据探索和可视化结果\n初步的发现和洞察\n\n思考题：\n\n通过数据探索和可视化，你发现了哪些有趣的模式或规律？\n这些发现对你的研究问题有什么启示？\n还有哪些方面需要进一步分析？\n\n\n\n\n\n\n\n\n\n\nAI 辅助学习建议 (第三周)\n\n\n\n\n数据清洗和整理：\n\n让 AI 生成 dplyr 和 tidyr 代码\n请 AI 解释数据转换的逻辑\n使用 AI 检查数据质量问题\n\n数据可视化：\n\n让 AI 推荐适合的图表类型\n请 AI 生成 ggplot2 代码\n使用 AI 优化图表美化方案\n\n数据分析报告：\n\n让 AI 帮助组织报告结构\n请 AI 解释数据发现的含义\n使用 AI 改进报告的表达",
    "crumbs": [
      "项目一：统计分析基础与数据可视化",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>第三周：描述性统计：数据探索与可视化</span>"
    ]
  },
  {
    "objectID": "week4.html",
    "href": "week4.html",
    "title": "第四周：推断性统计初步：参数估计与假设检验",
    "section": "",
    "text": "第七次课：参数估计、假设检验原理",
    "crumbs": [
      "项目一：统计分析基础与数据可视化",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>第四周：推断性统计初步：参数估计与假设检验</span>"
    ]
  },
  {
    "objectID": "week4.html#第七次课参数估计假设检验原理",
    "href": "week4.html#第七次课参数估计假设检验原理",
    "title": "第四周：推断性统计初步：参数估计与假设检验",
    "section": "",
    "text": "推断统计初步：参数估计\n\n\n\n在之前的课程中，我们主要学习了描述统计，即如何用图表和统计量描述样本数据的特征。从本周开始，我们将进入推断统计的学习。推断统计的核心思想是用样本数据推断总体特征。\n参数估计是推断统计的重要内容之一，它的目的是用样本统计量估计总体参数。\n\n\n\n描述统计 vs. 推断统计\n\n描述统计 (Descriptive Statistics):\n\n目的: 描述和总结样本数据的特征。\n方法: 计算描述性统计量 (均值、中位数、标准差等)，绘制图表 (直方图、箱线图、散点图等)。\n结论: 结论仅限于样本数据本身，不能推广到总体。\n例子: 计算样本电影评分的平均分，绘制样本电影评分的分布图。\n\n推断统计 (Inferential Statistics):\n\n目的: 利用样本数据推断总体特征。\n方法: 参数估计 (点估计、区间估计)，假设检验。\n结论: 结论可以推广到总体，但存在不确定性。\n例子: 用样本电影评分的平均分估计所有电影的平均评分，检验总体电影评分的平均分是否高于某个值。\n\n\n\n\n参数估计的目的\n\n总体 (Population): 我们感兴趣的所有个体的集合。例如，所有电影，所有大学生，所有股票。\n参数 (Parameter): 描述总体特征的数值，通常是未知的，需要用样本数据估计。例如，总体均值 μ，总体标准差 σ，总体比例 p。\n样本 (Sample): 从总体中随机抽取的一部分个体。\n统计量 (Statistic): 描述样本特征的数值，可以根据样本数据计算得到，用于估计总体参数。例如，样本均值 \\(\\bar{x}\\)，样本标准差 s，样本比例 \\(\\hat{p}\\)。\n参数估计 (Parameter Estimation): 用样本统计量估计总体参数 的过程。\n\n点估计 (Point Estimation): 用一个样本统计量的值作为总体参数的估计值。\n区间估计 (Interval Estimation): 给出一个总体参数的可能取值范围，通常以置信区间的形式呈现。\n\n\n\n\n点估计 (Point Estimation)\n\n点估计: 用一个样本统计量的值直接作为总体参数的估计值。\n\n用样本均值 \\(\\bar{x}\\) 估计总体均值 μ。\n用样本比例 \\(\\hat{p}\\) 估计总体比例 p。\n用样本标准差 s 估计总体标准差 σ。\n\n常用点估计量:\n\n样本均值 \\(\\bar{x}\\): 总体均值 μ 的点估计。\n样本中位数 Median: 总体中位数的点估计。\n样本标准差 s: 总体标准差 σ 的点估计。\n样本比例 \\(\\hat{p}\\): 总体比例 p 的点估计。\n\n点估计量的评价标准 (概念性了解):\n\n无偏性 (Unbiasedness): 估计量的期望值等于总体参数的真值。\n有效性 (Efficiency): 对于同一个总体参数，多个无偏估计量中，方差最小的估计量更有效。\n一致性 (Consistency): 随着样本量增大，估计量的值越来越接近总体参数的真值。\n\nR 语言实现点估计: 使用 R 函数直接计算样本统计量，作为总体参数的点估计值。\n\n# 示例数据 (电影评分)\nmovie_ratings &lt;- c(4.5, 4.2, 3.8, 4.7, 4.0, 4.3, 3.9, 4.6, 4.1, 4.4)\n\n# 计算样本均值 (点估计总体均值)\nmean_rating_point_estimate &lt;- mean(movie_ratings)\nmean_rating_point_estimate\n\n[1] 4.25\n\n# 计算样本标准差 (点估计总体标准差)\nsd_rating_point_estimate &lt;- sd(movie_ratings)\nsd_rating_point_estimate\n\n[1] 0.302765\n\n# 计算样本中位数 (点估计总体中位数)\nmedian_rating_point_estimate &lt;- median(movie_ratings)\nmedian_rating_point_estimate\n\n[1] 4.25\n\n\n\n\n\n区间估计 (Interval Estimation)\n\n为什么需要区间估计？: 点估计存在误差。点估计只给出一个具体的数值，无法反映估计的精确程度。区间估计提供一个参数的可能取值范围，并给出置信水平，能够反映估计的不确定性。\n置信区间 (Confidence Interval, CI): 由样本数据计算出的，包含总体参数真值的可能性为 \\((1-\\alpha)\\) 的区间。\n\n置信水平 (Confidence Level, \\(1-\\alpha\\)): 表示置信区间包含总体参数真值的概率。常用的置信水平为 95% ( \\(\\alpha = 0.05\\) ) 和 99% ( \\(\\alpha = 0.01\\) )。\n置信区间的宽度: 置信区间的上限减去下限。宽度越小，估计越精确。\n\n影响置信区间宽度的因素:\n\n样本量 (n): 样本量越大，置信区间越窄。\n置信水平 (\\(1-\\alpha\\)): 置信水平越高，置信区间越宽。\n总体标准差 (σ) 或样本标准差 (s): 标准差越大，置信区间越宽。\n\n正态分布的置信区间 (总体均值 μ 的置信区间):\n\n已知总体标准差 σ 或大样本情况 (n ≥ 30)，可以使用 Z 分布 构建置信区间。\n总体均值 μ 的 \\((1-\\alpha)\\) 置信区间为: \\[\n\\bar{x} \\pm Z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}\n\\] 其中，\\(\\bar{x}\\) 为样本均值，\\(\\sigma\\) 为总体标准差 (或用样本标准差 s 近似)，n 为样本量，\\(Z_{\\alpha/2}\\) 为标准正态分布的 \\(1-\\alpha/2\\) 分位数。\n未知总体标准差 σ 且小样本情况 (n &lt; 30)，如果总体服从正态分布，可以使用 t 分布 构建置信区间。\n总体均值 μ 的 \\((1-\\alpha)\\) 置信区间为: \\[\n\\bar{x} \\pm t_{\\alpha/2, n-1} \\frac{s}{\\sqrt{n}}\n\\] 其中，\\(\\bar{x}\\) 为样本均值，s 为样本标准差，n 为样本量，\\(t_{\\alpha/2, n-1}\\) 为自由度为 n-1 的 t 分布的 \\(t_{\\alpha/2, n-1}\\) 分位数。\nR 语言实现区间估计: 手动计算置信区间的公式。\n\n# 示例数据 (电影评分)\nmovie_ratings &lt;- c(4.5, 4.2, 3.8, 4.7, 4.0, 4.3, 3.9, 4.6, 4.1, 4.4)\nsample_mean &lt;- mean(movie_ratings)\nsample_sd &lt;- sd(movie_ratings)\nsample_size &lt;- length(movie_ratings)\nconfidence_level &lt;- 0.95\nalpha &lt;- 1 - confidence_level\n\n# 查 t 分布临界值 (双尾)\nt_critical &lt;- qt(1 - alpha/2, df = sample_size - 1)\n\n# 计算标准误差 (Standard Error, SE)\nstandard_error &lt;- sample_sd / sqrt(sample_size)\n\n# 计算边际误差 (Margin of Error, ME)\nmargin_of_error &lt;- t_critical * standard_error\n\n# 计算置信区间\nconfidence_interval &lt;- c(sample_mean - margin_of_error, sample_mean + margin_of_error)\nconfidence_interval\n\n[1] 4.033415 4.466585\n\n# 解释置信区间\ncat(paste(\"总体均值\", confidence_level*100, \"% 的置信区间为:\",\n          round(confidence_interval[1], 2), \"到\", round(confidence_interval[2], 2)))\n\n总体均值 95 % 的置信区间为: 4.03 到 4.47\n\n\n\n参数估计练习:\n\n练习任务： 提供一个示例数据集 (例如，电影评分数据)。\n计算样本均值和样本标准差，作为总体均值和总体标准差的点估计值。\n手动计算总体均值的 95% 和 99% 置信区间 (假设总体服从正态分布，使用样本标准差近似总体标准差)。\n解释置信区间的含义。\n鼓励学生使用AI工具 (如Cursor) 辅助公式计算和R代码编写。 例如，让AI生成计算置信区间的R代码，或者解释置信区间的公式。\n\n\n\n\n\n\n\n\n推断统计初步：假设检验\n\n\n\n假设检验 (Hypothesis Testing) 是推断统计的另一个重要内容。它的目的是检验关于总体参数的假设是否成立。\n\n\n\n\n假设检验的目的\n\n研究问题: 研究者通常会针对某个总体参数提出一个假设，例如：\n\n某电影类型的平均评分是否高于 4.0 分？\n不同类型电影的平均评分是否相等？\n广告投放后，产品销量是否显著增加？\n\n假设检验的目的: 通过样本数据提供的证据，判断提出的假设是否合理。\n\n\n\n假设检验的基本思想\n\n反证法: 先提出一个与研究目的相反的假设 (原假设)，然后试图用样本数据反驳原假设。\n小概率事件原理: 如果原假设成立，某个事件发生的概率很小 (小概率事件)，但在一次试验中，该事件竟然发生了，那么我们就有理由怀疑原假设的真实性，从而拒绝原假设。\n逻辑:\n\n假设 \\(H_0\\) 成立 (原假设) \\(\\Rightarrow\\) 小概率事件 A 发生 \\(\\Rightarrow\\) 拒绝 \\(H_0\\)。\n\n\n\n\n假设检验的步骤\n\n提出原假设 (Null Hypothesis, \\(H_0\\)) 和备择假设 (Alternative Hypothesis, \\(H_1\\))。\n选择检验统计量 (Test Statistic)。\n确定显著性水平 (Significance Level, \\(\\alpha\\), 例如 0.05, 0.01)。\n计算检验统计量的 p 值 (p-value)。\n做出决策： 如果 p-value \\(\\leq \\alpha\\)，拒绝原假设 \\(H_0\\)，接受备择假设 \\(H_1\\)；如果 p-value \\(&gt; \\alpha\\)，不拒绝原假设 \\(H_0\\)。\n\n\n\n原假设 (\\(H_0\\)) 和备择假设 (\\(H_1\\))\n\n原假设 (\\(H_0\\)): 研究者想要检验的假设，通常是”没有效应”、“没有差异”、“没有关系”的假设。\n\n例如： 总体均值等于某个特定值 (\\(\\mu = \\mu_0\\))，两个总体均值相等 (\\(\\mu_1 = \\mu_2\\))，变量之间没有关系 (相关系数为 0)。\n总是关于总体参数的假设，而不是关于样本统计量的假设。\n在假设检验的框架下，总是先假定原假设 \\(H_0\\) 成立。\n\n备择假设 (\\(H_1\\)): 研究者希望证明的假设，通常是”存在效应”、“存在差异”、“存在关系”的假设。\n\n例如： 总体均值不等于某个特定值 (\\(\\mu \\neq \\mu_0\\))，总体均值大于某个特定值 (\\(\\mu &gt; \\mu_0\\))，两个总体均值不相等 (\\(\\mu_1 \\neq \\mu_2\\))，变量之间存在关系 (相关系数不为 0)。\n与原假设 \\(H_0\\) 互斥，即 \\(H_0\\) 和 \\(H_1\\) 不可能同时成立。\n备择假设的形式:\n\n双尾检验 (two-tailed test): \\(H_1: \\mu \\neq \\mu_0\\) (不等于)。 检验总体均值是否不同于某个特定值，不关心是大于还是小于。\n右尾检验 (right-tailed test): \\(H_1: \\mu &gt; \\mu_0\\) (大于)。 检验总体均值是否显著大于某个特定值。\n左尾检验 (left-tailed test): \\(H_1: \\mu &lt; \\mu_0\\) (小于)。 检验总体均值是否显著小于某个特定值。\n\n研究者需要根据研究问题和目的，选择合适的备择假设形式。\n\n原假设和备择假设的设定原则:\n\n互相排斥: \\(H_0\\) 和 \\(H_1\\) 必须是互相排斥的，不能同时成立。\n完备性: \\(H_0\\) 和 \\(H_1\\) 应该覆盖所有可能的情况。\n优先保护原假设: 在没有充分证据的情况下，我们倾向于不拒绝原假设 \\(H_0\\)。 只有当样本数据提供足够强的证据时，我们才拒绝 \\(H_0\\)，接受 \\(H_1\\)。\n\n\n\n\n显著性水平 (\\(\\alpha\\))\n\n显著性水平 (\\(\\alpha\\)): 预先设定的一个概率值，作为判断小概率事件的标准。\n\n常用取值: \\(\\alpha = 0.05\\) (5%), \\(\\alpha = 0.01\\) (1%), \\(\\alpha = 0.10\\) (10%)。\n\\(\\alpha = 0.05\\) 的含义: 如果原假设 \\(H_0\\) 成立，拒绝 \\(H_0\\) 的概率为 5%。 也就是说，在 100 次假设检验中，平均有 5 次会犯第一类错误 (拒真错误)。\n\\(\\alpha\\) 越小，拒绝 \\(H_0\\) 的标准越严格，犯第一类错误的概率越小。\n\\(\\alpha\\) 的选择需要根据研究的具体情况和后果来决定。 一般来说，探索性研究可以适当放宽 \\(\\alpha\\)，验证性研究和高风险决策需要严格控制 \\(\\alpha\\)。\n\n\n\n\np 值 (p-value)\n\np 值 (p-value): 在原假设 \\(H_0\\) 成立的条件下，观察到样本结果或更极端结果的概率。\n\n“更极端”: 指更有利于备择假设 \\(H_1\\) 的样本结果。 例如，对于右尾检验 (\\(H_1: \\mu &gt; \\mu_0\\))，样本均值 \\(\\bar{x}\\) 越大，就越极端。\np 值的意义: 衡量样本数据与原假设 \\(H_0\\) 的不一致程度。 p 值越小，说明样本数据与原假设 \\(H_0\\) 越不一致，拒绝 \\(H_0\\) 的理由越充分。\np 值是一个概率值，取值范围为 [0, 1]。\n\n\n\n\n决策规则\n\n比较 p 值和显著性水平 \\(\\alpha\\):\n\n如果 p-value \\(\\leq \\alpha\\): 拒绝原假设 \\(H_0\\)，接受备择假设 \\(H_1\\)。 结论为“在 \\(\\alpha\\) 显著性水平下，拒绝原假设 $H_0”，或“在 \\(\\alpha\\) 显著性水平下，存在统计学显著的效应/差异/关系”。\n如果 p-value \\(&gt; \\alpha\\): 不拒绝原假设 \\(H_0\\)。 结论为“在 \\(\\alpha\\) 显著性水平下，不拒绝原假设 $H_0”，或“在 \\(\\alpha\\) 显著性水平下，没有足够证据拒绝原假设 $H_0”，或“不能得出统计学显著的效应/差异/关系”。\n注意: “不拒绝原假设 $H_0” 不等于 “接受原假设 $H_0”。 我们只能说没有足够证据拒绝 $H_0”，但不能说 \\(H_0\\) 一定成立。 假设检验只能证伪，不能证真。\n\n\n\n\n两类错误\n\n第一类错误 (Type I error, 拒真错误): 原假设 \\(H_0\\) 实际上是成立的，但我们却拒绝了 \\(H_0\"**。\n*   **概率**:  犯第一类错误的概率为 **\\)$ (显著性水平)。 这是我们可以控制的错误概率。\n\n例子: 本来某电影类型的平均评分没有高于 4.0 分 (\\(H_0\\) 成立)，但假设检验结果却错误地认为该类型电影的平均评分高于 4.0 分 (拒绝 \\(H_0\\))。\n\n第二类错误 (Type II error, 受伪错误): 原假设 \\(H_0\\) 实际上是不成立的，但我们却没有拒绝 \\(H_0\"**。\n*   **概率**:  犯第二类错误的概率为 **\\)\\(**，**通常是未知的，难以直接控制**。\n*   **例子**:  本来某电影类型的平均评分**确实**高于 4.0 分 (\\)H_0$ 不成立)，但假设检验结果却错误地认为该类型电影的平均评分没有**高于 4.0 分 (不拒绝 \\(H_0\\))。\n两类错误的权衡:\n\n\\(\\alpha\\) 和 \\(\\beta\\) 之间存在权衡关系。 减小 \\(\\alpha\\) (更严格地拒绝 \\(H_0\\))，会增大 \\(\\beta\\) (更容易犯第二类错误)； 增大 \\(\\alpha\\) (更宽松地拒绝 \\(H_0\\))，会减小 \\(\\beta\\) (更不容易犯第二类错误)。\n在实际研究中，需要根据研究目的和后果，权衡两类错误的重要性，选择合适的 \\(\\alpha\\) 水平。 一般来说，更重视控制第一类错误，通常取 \\(\\alpha = 0.05\\)。\n\n\n\n\n效应量 (Effect Size)\n\n效应量 (Effect Size): 反映效应/差异/关系 的真实大小的指标，不受到样本量大小的影响。\n\n与 p 值不同: p 值只反映统计学显著性，不反映效应的实际大小。 即使 p 值很小 (统计学显著)，效应量也可能很小 (实际意义不大)。 反之，即使 p 值较大 (统计学不显著)，效应量也可能很大 (但由于样本量不足，未能达到统计学显著)。\n常用的效应量指标:\n\nCohen’s d: 用于衡量两组均值差异的效应量，常用于 t 检验。 Cohen’s d = (Mean1 - Mean2) / Pooled SD。\n相关系数 r: 用于衡量两个变量之间线性关系强度的效应量，取值范围为 [-1, 1]。\nR 平方 (\\(R^2\\)): 用于衡量回归模型解释变异的比例的效应量，取值范围为 [0, 1]。\n\n效应量大小的解释 (Cohen’s d 为例):\n\n小效应 (small effect): Cohen’s d ≈ 0.2\n中等效应 (medium effect): Cohen’s d ≈ 0.5\n大效应 (large effect): Cohen’s d ≈ 0.8\n\n效应量的大小解释标准是相对的，需要结合具体的研究领域和背景进行判断。\n\n\n\n\n检验功效 (Power)\n\n检验功效 (Power, \\(1-\\beta\\)): 当备择假设 \\(H_1\\) 实际上成立时，我们正确地拒绝原假设 \\(H_0\\) 的概率。\n\n与第二类错误 (\\(\\beta\\)) 的关系: Power = \\(1 - \\beta\\)。 Power 越高，犯第二类错误的概率 \\(\\beta\\) 越小。\nPower 的意义: 衡量假设检验的灵敏度。 Power 越高，越容易发现真实存在的效应/差异/关系。 Power 太低，即使真实存在效应，也可能由于样本量不足等原因，无法通过假设检验发现 (导致不拒绝 \\(H_0\\))。\n一般认为，Power 至少要达到 0.8 (80%) 以上，才能认为检验是有效的。\n\n影响检验功效的因素:\n\n效应量 (Effect Size): 效应量越大，Power 越高。效应越大，越容易被检验出来。\n样本量 (Sample Size, n): 样本量越大，Power 越高。样本量越大，估计越精确，越容易发现真实效应。\n显著性水平 (\\(\\alpha\\)): \\(\\alpha\\) 越大，Power 越高。\\(\\alpha\\) 越大，拒绝 \\(H_0\\) 的标准越宽松，Power 越高，但犯第一类错误的概率也增大。\n总体标准差 (\\(\\sigma\\)): 总体标准差越小，Power 越高。标准差越小，数据变异性越小，越容易发现真实效应。\n单尾检验 vs. 双尾检验: 单尾检验的 Power 通常高于双尾检验 (在效应方向与检验方向一致时)。\n\n检验功效分析 (Power Analysis): 在研究设计阶段，为了达到一定的 Power 水平，需要计算所需的最小样本量。\n\n先设定期望的 Power 值 (如 0.8)，以及预期的效应量大小、显著性水平 \\(\\alpha\\)、总体标准差 (或估计值)。\n然后，使用统计软件或公式计算所需的最小样本量。\n检验功效分析有助于研究者合理规划研究设计，避免样本量不足导致无法发现真实效应。\n\nR 语言中进行功效分析: 可以使用 pwr 包进行功效分析。\n\n# 安装 pwr 包 (如果未安装)\n# install.packages(\"pwr\")\nlibrary(pwr)\n\n# 示例：单样本 t 检验的功效分析\n# 假设：预期效应量 d = 0.5 (中等效应)，显著性水平 alpha = 0.05，期望功效 power = 0.8\n# 计算所需样本量\npower_analysis_result &lt;- pwr.t.test(\n  d = 0.5, # 效应量 Cohen's d\n  sig.level = 0.05, # 显著性水平 alpha\n  power = 0.8, # 期望功效\n  type = \"one.sample\", # 单样本 t 检验\n  alternative = \"two.sided\" # 双尾检验\n)\n\npower_analysis_result\n\n\n     One-sample t test power calculation \n\n              n = 33.36713\n              d = 0.5\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\n# 结果解读：\n# 需要样本量 n 大约为 33.36，向上取整，至少需要 34 个样本。\n\n\npwr.t.test() 函数可以进行单样本 t 检验、双样本 t 检验 (独立样本和配对样本) 的功效分析。\n常用参数：\n\nd: 效应量 Cohen’s d。\nsig.level: 显著性水平 \\(\\alpha\\)。\npower: 功效 \\(1-\\beta\\)。\nn: 样本量 (如果要计算所需样本量，则此参数留空)。\ntype: 检验类型，\"one.sample\" (单样本 t 检验), \"two.sample\" (独立样本 t 检验), \"paired\" (配对样本 t 检验)。\nalternative: 备择假设类型，\"two.sided\", \"greater\", \"less\"。\n\n\n效应量和检验功效的意义:\n\n更全面地理解假设检验结果: 除了 p 值，还需要关注效应量和检验功效，才能更完整地评价研究结果。\n提高研究质量: 在研究设计阶段进行功效分析，合理确定样本量，提高研究的可靠性和可重复性。\n避免过度解读 p 值: 避免仅仅根据 p 值大小判断效应的实际意义，要结合效应量进行判断。\n科学决策: 在实际应用中，需要综合考虑效应量、检验功效、研究成本等因素，做出更科学合理的决策。\n\n\n\n\n\n\n\n\n假设检验基本原理练习\n\n\n\n\n练习任务： 提供一个假设检验的应用场景 (例如，检验某电影类型的平均评分是否高于某个值)。\n\n引导学生完成假设检验的五个步骤： 设定原假设和备择假设，选择合适的检验统计量 (本周先概念性选择，下节课具体介绍)，确定显著性水平，理解 p 值和决策规则。\n重点理解原假设、备择假设、显著性水平、p 值、效应量和检验功效的含义。\n鼓励学生使用 AI 工具 (如 Cursor, 搜索引擎) 辅助理解假设检验的概念和步骤。 例如，让 AI 解释原假设和备择假设的区别，或者显著性水平的意义，以及效应量和检验功效的概念。\n\n\n\n\n\n\n第八次课 (90分钟)\n上半场 (单样本t检验、双样本t检验，约45分钟):\n\n常用假设检验方法：t检验 (30分钟): {#week-4-t-test}\n\nt检验的应用场景： 检验总体均值是否等于某个值，或检验两个总体的均值是否相等。\n单样本t检验 (One-Sample t-test)：\n\n适用条件： 检验一个正态分布总体的均值是否等于某个已知值。\n原假设 \\(H_0：\\mu = \\mu_0\\)，备择假设 \\(H_1：\\mu \\neq \\mu_0\\) (双尾检验), \\(\\mu &gt; \\mu_0\\) (右尾检验), \\(\\mu &lt; \\mu_0\\) (左尾检验)。\n检验统计量：t统计量公式。 \\[\nt = \\frac{\\bar{x} - \\mu_0}{s / \\sqrt{n}}\n\\] 其中，\\(\\bar{x}\\) 为样本均值，\\(\\mu_0\\) 为原假设下的总体均值，\\(s\\) 为样本标准差，\\(n\\) 为样本量。\n自由度 (degrees of freedom, df) = n - 1。\np值的计算：使用t分布的累积分布函数 (CDF) 或生存函数 (SF)。\nR语言实现： t.test() 函数是 R 中进行 t 检验的核心函数。\n\n基本用法： t.test(data, mu = ?, alternative = ?, conf.level = ?, ...)\n主要参数：\n\ndata: 必需参数。 包含样本数据的数值向量。\nmu: 单样本 t 检验时使用。 原假设中总体均值 \\(\\mu_0\\) 的值。 默认为 mu = 0。\nalternative: 备择假设类型。 字符串，可选值包括：\n\n\"two.sided\" (默认值): 双尾检验，\\(H_1: \\mu \\neq \\mu_0\\)。\n\"less\": 左尾检验，\\(H_1: \\mu &lt; \\mu_0\\)。\n\"greater\": 右尾检验，\\(H_1: \\mu &gt; \\mu_0\\)。\n\nconf.level: 置信水平。 数值，介于 0 和 1 之间，表示置信区间的置信水平。 默认为 conf.level = 0.95 (95% 置信区间)。\npaired: 配对样本 t 检验时使用。 逻辑值，TRUE 表示进行配对样本 t 检验，FALSE (默认值) 表示进行独立样本 t 检验。\nvar.equal: 独立样本 t 检验时使用。 逻辑值，TRUE 表示假设两个总体的方差相等 (等方差 t 检验)，FALSE (默认值) 表示不假设方差相等 (Welch’s t 检验)。\n\n示例 (单样本 t 检验):\n\n# 示例数据 (电影评分)\nmovie_ratings &lt;- c(4.5, 4.2, 3.8, 4.7, 4.0, 4.3, 3.9, 4.6, 4.1, 4.4)\n\n# 进行单样本 t 检验，检验均值是否为 4.0\nt.test(movie_ratings, mu = 4.0)\n\n\n    One Sample t-test\n\ndata:  movie_ratings\nt = 2.6112, df = 9, p-value = 0.02822\nalternative hypothesis: true mean is not equal to 4\n95 percent confidence interval:\n 4.033415 4.466585\nsample estimates:\nmean of x \n     4.25 \n\n\n\n\n双样本t检验 (Two-Sample t-test)：\n\n独立样本t检验 (Independent Samples t-test)：\n\n适用条件： 检验两个独立的正态分布总体的均值是否相等。例如，比较不同类型电影的平均评分，不同超市的商品平均价格，不同学校学生的平均成绩等。\n原假设 \\(H_0：\\mu_1 = \\mu_2\\)，备择假设 \\(H_1：\\mu_1 \\neq \\mu_2\\) (双尾检验), \\(\\mu_1 &gt; \\mu_2\\) (右尾检验), \\(\\mu_1 &lt; \\mu_2\\) (左尾检验)。\n检验统计量：独立样本t统计量公式 (等方差和不等方差两种情况)。\n\n等方差 (Pooled Variance) t 检验: 假设两个总体的方差相等 (\\(\\sigma_1^2 = \\sigma_2^2\\))。 \\[\nt = \\frac{(\\bar{x}_1 - \\bar{x}_2) - (\\mu_1 - \\mu_2)}{s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}\n\\] 其中：\n\n\\(\\bar{x}_1, \\bar{x}_2\\) 分别为两个样本的均值。\n\\(\\mu_1 - \\mu_2\\) 为原假设下两个总体均值之差，通常为 0。\n\\(n_1, n_2\\) 分别为两个样本的样本量。\n\\(s_p\\) 为合并样本标准差 (pooled standard deviation)，计算公式为： \\[\ns_p = \\sqrt{\\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}}\n\\] 其中 \\(s_1^2, s_2^2\\) 分别为两个样本的方差。\n\n不等方差 (Welch’s) t 检验: 不假设两个总体的方差相等 (\\(\\sigma_1^2 \\neq \\sigma_2^2\\))。 \\[\nt = \\frac{(\\bar{x}_1 - \\bar{x}_2) - (\\mu_1 - \\mu_2)}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n\\] 其中：\n\n\\(\\bar{x}_1, \\bar{x}_2\\) 分别为两个样本的均值。\n\\(\\mu_1 - \\mu_2\\) 为原假设下两个总体均值之差，通常为 0。\n\\(n_1, n_2\\) 分别为两个样本的样本量。\n\\(s_1^2, s_2^2\\) 分别为两个样本的方差。\n\n\n自由度 (df) 的计算 (等方差和不等方差两种情况)。\n方差相等性检验: 在进行独立样本 t 检验时，需要考虑两个总体的方差是否相等。\n\n\n\n\n\n\n\n\n等方差假设 (Equal Variance)\n\n\n\n如果假设两个总体的方差相等 (\\(\\sigma_1^2 = \\sigma_2^2\\))，则使用等方差 t 检验 (Pooled Variance t-test)。\n\n\n\n\n\n\n\n\n适用情况\n\n\n\n当事先有理由相信两个总体的方差接近，或者通过方差相等性检验 (如 F 检验或 Levene 检验) 结果不拒绝方差相等的原假设时，可以使用等方差 t 检验。\n\n\n\n\n\n\n\n\n不等方差假设 (Unequal Variance)\n\n\n\n如果不能假设两个总体的方差相等 (\\(\\sigma_1^2 \\neq \\sigma_2^2\\))，或者方差相等性检验拒绝了方差相等的原假设，则使用 Welch’s t 检验 (Welch’s t-test)。\n\n\n\n\n\n\n\n\n适用情况\n\n\n\n当不确定两个总体的方差是否相等，或者怀疑方差存在显著差异时，建议使用 Welch’s t 检验。 Welch’s t 检验对总体方差是否相等不敏感，适用性更广，通常作为默认选择。\n\n\n\n\n\n\n\n\nR 语言 t.test() 函数\n\n\n\n通过 var.equal 参数指定是否假设方差相等。\n\nvar.equal = TRUE: 进行等方差 t 检验。\nvar.equal = FALSE (默认值): 进行 Welch’s t 检验。\n\n\n\n\n配对样本t检验 (Paired Samples t-test)：\n\n适用条件： 检验两个配对样本的均值差是否为零。例如，检验同一组用户对电影观看预告片前后的评分是否有显著差异。\n原假设 \\(H_0：\\mu_d = 0\\)，备择假设 \\(H_1：\\mu_d \\neq 0\\) (双尾检验), \\(\\mu_d &gt; 0\\) (右尾检验), \\(\\mu_d &lt; 0\\) (左尾检验)，其中 \\(\\mu_d\\) 是配对样本差值的总体均值。\n检验统计量：配对样本t统计量公式： \\[\nt = \\frac{\\bar{d} - \\mu_{d0}}{s_d / \\sqrt{n}}\n\\] 其中：\n\n\\(\\bar{d}\\) 为配对样本差值的均值。\n\\(\\mu_{d0}\\) 为原假设下配对样本差值的总体均值，通常为 0。\n\\(s_d\\) 为配对样本差值的标准差。\n\\(n\\) 为配对样本的数量。\n\n自由度 (df) = n - 1，其中 n 是配对样本的数量。\nR语言实现： t.test() 函数，设置 paired = TRUE。\n\n\n\nt检验练习 (15分钟):\n\n练习任务： 提供几个t检验的应用场景 (例如，检验某类型电影的平均评分是否为特定值，检验不同类型电影的平均评分是否相等，检验同一组用户对某电影评分前后的变化)。\n学生分组练习： 使用 t.test() 函数对示例数据进行单样本t检验和双样本t检验。\n解释t检验的结果 (p值、置信区间、决策结论)。 重点关注 p 值、置信区间和效应量，并尝试解释检验功效。\n鼓励学生使用 AI 工具 (如 Cursor) 辅助 t.test() 函数的使用和结果解释。 例如，让 AI 解释 t.test() 函数的输出结果，或者根据 t 检验的结果给出结论建议。\n\n\n下半场 (项目一检查与汇报准备，约45分钟):\n\n项目一检查与中期汇报准备 (30分钟):\n\n各小组展示项目一的最终数据探索和可视化成果 (非正式展示)。\n教师检查各小组的项目进展情况，包括：\n\n数据获取和质量\n数据清洗和整理\n描述性统计和可视化探索\n初步的发现和洞察\n\n教师提供针对性的项目反馈和改进建议。\n布置项目一正式汇报的要求和格式 (例如，PPT汇报，汇报时间，评分标准)。\n指导学生准备项目汇报内容，重点突出：\n\n项目主题和目标\n数据来源和描述\n数据清洗和预处理方法\n数据探索和可视化结果 (重点展示图表，并进行解释)\n初步的发现和洞察 (从数据中得出的结论)\n项目总结和反思\n\n\n项目汇报准备指导 (15分钟):\n\n汇报技巧指导： 如何清晰、简洁、有效地展示项目成果。\nPPT制作建议： 图文并茂，重点突出，逻辑清晰。\n答辩准备建议： 预想可能被提问的问题，做好充分准备。\n鼓励小组内部分工合作，共同完成汇报准备。\n鼓励学生使用AI工具 (如Cursor, ChatGPT) 辅助PPT制作和汇报稿撰写。 例如，让AI根据项目报告草稿，生成PPT大纲或汇报稿初稿。\n\n\n\n\n\n\n\n\n课后作业 (第四周)\n\n\n\n\n完成项目一的正式分析报告，并根据教师反馈进行修改和完善。\n准备项目一的 PPT 汇报，并进行小组内部预演。\n复习本周学习的参数估计和假设检验的基本概念和方法，重点理解效应量和检验功效。\n思考题： 在项目一的数据探索过程中，你使用了哪些描述性统计和可视化方法？这些方法帮助你发现了哪些数据规律和洞察？你认为项目一的成果有哪些局限性？下一步可以如何深入分析？ 如果要进行假设检验，你可能会提出哪些假设？如何进行检验？ 尝试思考如何计算效应量和检验功效，并解释其意义。\n\n\n\n\n\n\n\n\n\nAI 辅助学习建议 (第四周)\n\n\n\n\n参数估计和假设检验：\n\n让 AI 解释统计学概念 (置信区间、p 值、假设检验步骤、效应量、检验功效等)\n请 AI 生成 R 代码进行参数估计、假设检验和功效分析\n使用 AI 辅助理解 t.test() 函数和 pwr.t.test() 函数的输出结果\n\n项目汇报准备：\n\n让 AI 帮助组织汇报内容，生成 PPT 大纲\n请 AI 润色项目报告和汇报稿\n使用 AI 辅助 PPT 美化和排版\n\n\n\n\n\n\n\n\n\n\n参数估计的关键概念\n\n\n\n\n点估计: 用一个样本统计量的值直接作为总体参数的估计值\n区间估计: 给出一个总体参数的可能取值范围，通常以置信区间的形式呈现\n置信区间: 由样本数据计算出的，包含总体参数真值的可能性为 \\((1-\\alpha)\\) 的区间\n\n\n\n\n\n\n\n\n\n假设检验的五个步骤\n\n\n\n\n提出原假设 (\\(H_0\\)) 和备择假设 (\\(H_1\\))\n选择检验统计量\n确定显著性水平 (\\(\\alpha\\))\n计算检验统计量的 p 值\n做出决策：\n\n如果 p-value ≤ α，拒绝 \\(H_0\\)，接受 \\(H_1\\)\n如果 p-value &gt; α，不拒绝 \\(H_0\\)\n\n\n\n\n\n\n\n\n\n\n两类错误与检验功效\n\n\n\n\n第一类错误 (Type I): 错误地拒绝真实的 \\(H_0\\)，概率为 α\n第二类错误 (Type II): 错误地接受错误的 \\(H_0\\)，概率为 β\n检验功效 (Power): 正确拒绝 \\(H_0\\) 的概率，等于 1-β\n\n\n\n\n\n\n\n\n\nt检验的三种类型\n\n\n\n\n单样本t检验\n\n检验一个正态分布总体的均值是否等于某个已知值\n\\(H_0：\\mu = \\mu_0\\) vs \\(H_1：\\mu \\neq \\mu_0\\) (或 &gt; 或 &lt;)\n\n独立样本t检验\n\n检验两个独立的正态分布总体的均值是否相等\n\\(H_0：\\mu_1 = \\mu_2\\) vs \\(H_1：\\mu_1 \\neq \\mu_2\\) (或 &gt; 或 &lt;)\n\n配对样本t检验\n\n检验配对样本的差异是否显著\n\\(H_0：\\mu_d = 0\\) vs \\(H_1：\\mu_d \\neq 0\\) (或 &gt; 或 &lt;)\n\n\n\n\n\n\n\n\n\n\n置信区间的计算公式\n\n\n\n\n大样本情况 (n ≥ 30) 或已知总体标准差: \\[\n\\bar{x} \\pm Z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}\n\\]\n小样本情况 (n &lt; 30) 且未知总体标准差: \\[\n\\bar{x} \\pm t_{\\alpha/2, n-1} \\frac{s}{\\sqrt{n}}\n\\]\n\n\n\n\n\n\n\n\n\n假设检验的基本思想\n\n\n\n\n反证法: 先提出一个与研究目的相反的假设(原假设)\n小概率事件原理: 如果原假设成立，某事件发生概率很小，但该事件发生了\n逻辑: \\(H_0\\) 成立 → 小概率事件发生 → 拒绝 \\(H_0\\)\n\n\n\n\n\n\n\n\n\n原假设和备择假设的设定原则\n\n\n\n\n互相排斥: \\(H_0\\) 和 \\(H_1\\) 不能同时成立\n完备性: 覆盖所有可能的情况\n优先保护原假设: 没有充分证据时不拒绝 \\(H_0\\)\n\n\n\n\n\n\n\n\n\n影响检验功效的因素\n\n\n\n\n效应量: 效应量越大，Power越高\n样本量: 样本量越大，Power越高\n显著性水平: α越大，Power越高\n总体标准差: 标准差越小，Power越高\n检验类型: 单尾检验的Power通常高于双尾检验\n\n\n\n\n\n\n\n\n\n项目汇报准备要点\n\n\n\n\n内容准备:\n\n项目主题和目标\n数据来源和描述\n数据清洗和预处理方法\n数据探索和可视化结果\n初步发现和洞察\n项目总结和反思\n\n汇报技巧:\n\n清晰简洁的表达\n图文并茂的PPT\n充分的答辩准备\n团队分工合作",
    "crumbs": [
      "项目一：统计分析基础与数据可视化",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>第四周：推断性统计初步：参数估计与假设检验</span>"
    ]
  },
  {
    "objectID": "week5.html",
    "href": "week5.html",
    "title": "第五周：方差分析",
    "section": "",
    "text": "第九次课：项目一成果展示\n本课为项目一的成果展示环节，各小组依次进行项目一的汇报和答辩。",
    "crumbs": [
      "项目二：商业数据分析与统计推断",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>第五周：方差分析</span>"
    ]
  },
  {
    "objectID": "week5.html#第十次课方差分析",
    "href": "week5.html#第十次课方差分析",
    "title": "第五周：方差分析",
    "section": "第十次课：方差分析",
    "text": "第十次课：方差分析\n\n方差分析概述\n方差分析(ANOVA)的核心目标：\n\n检验多个总体均值是否相等\n将总变异分解为组间变异和组内变异\n通过比较组间变异与组内变异的大小，判断总体均值是否存在显著差异\n\n方差分析本质上是扩展的t检验，允许我们同时比较多个组别之间的差异。在商业分析中，我们经常需要比较多个处理或群体之间的效果差异，例如：\n\n# 创建示例数据\nmarketing_data &lt;- data.frame(\n  campaign = rep(c(\"A\", \"B\", \"C\", \"D\"), each = 30),\n  sales = c(rnorm(30, 100, 15), rnorm(30, 110, 18), \n            rnorm(30, 95, 20), rnorm(30, 115, 25))\n)\n\n# 绘制箱线图比较各营销活动的销售效果\nggplot(marketing_data, aes(x = campaign, y = sales, fill = campaign)) +\n  geom_boxplot() +\n  labs(title = \"不同营销活动的销售效果比较\",\n       x = \"营销活动\", y = \"销售额\")\n\n\n\n\n\n\n\n\n应用场景：\n\n市场营销：不同营销活动对销售额的影响比较\n用户体验：不同网站设计对用户停留时间的影响\n产品研发：不同配方对产品质量的影响\n人力资源：不同培训方法对员工绩效的影响\n\n方差分析的基本假设条件：\n\n正态性：每个组别的数据都来自正态分布总体\n方差齐性：各组别总体方差相等（可使用Levene’s检验或Bartlett检验）\n独立性：观测值之间相互独立（尤其是组间观测值）\n\n\n# 正态性检验\n#   - 原假设 (H0): 数据服从正态分布\n#   - 备择假设 (H1): 数据不服从正态分布\nmarketing_data %&gt;%\n  group_by(campaign) %&gt;%\n  summarise(\n    shapiro_p_value = shapiro.test(sales)$p.value # 使用 Shapiro-Wilk 检验正态性\n  )\n\n# A tibble: 4 × 2\n  campaign shapiro_p_value\n  &lt;chr&gt;              &lt;dbl&gt;\n1 A                  0.930\n2 B                  0.302\n3 C                  0.541\n4 D                  0.970\n\n# 检验方差齐性\n#   - 原假设 (H0): 各组别总体方差相等\n#   - 备择假设 (H1): 至少有一组别总体方差与其他组别总体方差不相等\nlibrary(car)\nleveneTest(sales ~ campaign, data = marketing_data) # Levene's 检验 - 检验方差齐性\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value Pr(&gt;F)\ngroup   3  1.4566 0.2301\n      116               \n\n\n\n\n单因素方差分析\n单因素方差分析的概念：只有一个因素(自变量)的方差分析。\n总体变异的分解：\n\n总平方和(SST) = 组间平方和(SSB) + 组内平方和(SSW)\n组间平方和反映因素引起的变异\n组内平方和反映随机误差引起的变异\n\n模型表示：\\(y_{ij} = \\mu + \\tau_i + \\epsilon_{ij}\\)\n\n\\(y_{ij}\\)：第\\(i\\)组的第\\(j\\)个观测值\n\\(\\mu\\)：总体均值\n\\(\\tau_i\\)：第\\(i\\)组的效应（偏离总均值的程度）\n\\(\\epsilon_{ij}\\)：随机误差（假设服从正态分布\\(N(0, \\sigma^2)\\)）\n\n假设检验：\n\n原假设(H0)：\\(\\mu_1 = \\mu_2 = \\dots = \\mu_k\\) (所有组别总体均值相等)\n备择假设(H1)：至少有一对总体均值不相等\nF统计量：\\(F = \\frac{MSB}{MSW} = \\frac{SSB/(k-1)}{SSW/(n-k)}\\)，其中：\n\nk是组数\nn是总样本量\nMSB是组间均方\nMSW是组内均方\n\n\n方差分析表的解读：\n\n\n\n变异来源\n平方和\n自由度\n均方\nF值\np值\n\n\n\n\n组间\nSSB\nk-1\nMSB\nF=MSB/MSW\np\n\n\n组内\nSSW\nn-k\nMSW\n\n\n\n\n总计\nSST\nn-1\n\n\n\n\n\n\nR语言实现：\n\n# 单因素方差分析\naov_result &lt;- aov(sales ~ campaign, data = marketing_data)\nsummary(aov_result)\n\n             Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ncampaign      3  11877    3959   10.75 2.74e-06 ***\nResiduals   116  42710     368                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# 如果方差分析结果表明组间存在显著差异，则需要进行多重比较，进一步分析哪些组别之间存在显著差异\n# TukeyHSD (Tukey's Honestly Significant Differences) 函数用于执行Tukey事后多重比较，\n# 它可以检验所有可能的组别配对之间的均值差异，并控制族错误率 (family-wise error rate)，\n# 从而避免由于进行多次比较而增加犯第一类错误的概率。\nTukeyHSD(aov_result)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = sales ~ campaign, data = marketing_data)\n\n$campaign\n          diff         lwr       upr     p adj\nB-A   6.138836  -6.7756564 19.053328 0.6034096\nC-A  -8.235640 -21.1501326  4.678852 0.3483496\nD-A  19.028038   6.1135458 31.942530 0.0011363\nC-B -14.374476 -27.2889683 -1.459984 0.0227515\nD-B  12.889202  -0.0252899 25.803694 0.0506507\nD-C  27.263678  14.3491862 40.178171 0.0000013\n\n\n结果可视化：\n\n# 可视化多重比较结果\ntukey_result &lt;- TukeyHSD(aov_result)\ntukey_df &lt;- as.data.frame(tukey_result$campaign)\ntukey_df$comparison &lt;- rownames(tukey_df)\n\nggplot(tukey_df, aes(x = comparison, y = diff)) +\n  geom_point() +\n  geom_errorbar(aes(ymin = lwr, ymax = upr), width = 0.2) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  labs(title = \"Tukey多重比较结果\",\n       x = \"组间比较\", y = \"均值差异\")\n\n\n\n\n\n\n\n\n\n\n多因素方差分析\n多因素方差分析的概念：研究两个或多个因素(自变量)对因变量的影响，以及因素之间的交互作用。\n双因素方差分析模型：\\(y_{ijk} = \\mu + \\alpha_i + \\beta_j + (\\alpha\\beta)_{ij} + \\epsilon_{ijk}\\)\n\n\\(\\alpha_i\\)：因素A的第\\(i\\)个水平的主效应\n\\(\\beta_j\\)：因素B的第\\(j\\)个水平的主效应\n\\((\\alpha\\beta)_{ij}\\)：因素A和因素B的交互效应\n\n交互效应的理解： 交互效应表示一个因素的效应会因另一个因素的不同水平而发生变化。例如，某款产品的价格效应可能在不同的消费者群体中有所不同（高收入群体对价格不敏感，低收入群体对价格敏感）。\n\n# 创建包含交互效应的示例数据\npricing_data &lt;- data.frame(\n  price_level = factor(rep(c(\"低\", \"中\", \"高\"), each = 60), levels = c(\"低\", \"中\", \"高\")),\n  consumer_group = rep(rep(c(\"年轻人\", \"中年人\"), each = 30), 3),\n  purchase_amount = c(\n    rnorm(30, 120, 20), rnorm(30, 100, 15),  # 低价格，两个消费群体\n    rnorm(30, 100, 25), rnorm(30, 110, 20),  # 中价格，两个消费群体\n    rnorm(30, 70, 30), rnorm(30, 130, 35)    # 高价格，两个消费群体\n  )\n)\n\n假设检验流程：\n\n检验交互效应是否显著\n如果交互效应显著，分别在每个因素的不同水平下分析另一个因素的简单主效应\n如果交互效应不显著，直接分析各因素的主效应\n\nR语言实现：\n\n# 双因素方差分析（包含交互效应）\ninteraction_model &lt;- aov(purchase_amount ~ price_level * consumer_group, \n                         data = pricing_data)\nsummary(interaction_model)\n\n                            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nprice_level                  2   3775    1888   3.106   0.0473 *  \nconsumer_group               1  14133   14133  23.252 3.09e-06 ***\nprice_level:consumer_group   2  50542   25271  41.577 1.74e-15 ***\nResiduals                  174 105760     608                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# 不包含交互效应的模型\nmain_effects_model &lt;- aov(purchase_amount ~ price_level + consumer_group, \n                          data = pricing_data)\nsummary(main_effects_model)\n\n                Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nprice_level      2   3775    1888   2.126    0.122    \nconsumer_group   1  14133   14133  15.914 9.71e-05 ***\nResiduals      176 156301     888                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# 交互作用图\nggplot(pricing_data, aes(x = price_level, y = purchase_amount, \n                        color = consumer_group, group = consumer_group)) +\n  stat_summary(fun = mean, geom = \"point\", size = 3) +\n  stat_summary(fun = mean, geom = \"line\") +\n  labs(title = \"价格水平与消费者群体的交互效应\",\n       x = \"价格水平\", y = \"购买金额\")\n\n\n\n\n\n\n\n\n\n\n单向重复测量方差分析\n当实验设计采用重复测量方法，意味着我们对同一批受试者在多个不同的处理条件（例如，不同的药物剂量、不同的刺激类型）下，或者在不同的时间点（例如，治疗前、治疗中、治疗后）进行多次测量。 在这种情况下，由于数据来自同一批受试者，观测值之间存在相关性，传统的独立样本方差分析不再适用。 为了正确分析这类数据，检验不同条件或时间点下受试者反应的平均水平是否存在显著差异，并有效控制受试者个体差异带来的影响，我们应当采用重复测量方差分析。\n\n# 重复测量方差分析示例\nlibrary(ez)\nrepeated_data &lt;- data.frame(\n  subject = factor(rep(1:30, each = 3)),\n  time = factor(rep(c(\"before\", \"during\", \"after\"), 30)),\n  performance = c(\n    rnorm(30, 70, 10),   # before\n    rnorm(30, 85, 12),   # during\n    rnorm(30, 75, 15)    # after\n  )\n)\n\n# 使用ezANOVA函数进行重复测量方差分析\nezANOVA(\n  data = repeated_data,\n  dv = .(performance),\n  wid = .(subject),\n  within = .(time),\n  detailed = TRUE\n)\n\n$ANOVA\n       Effect DFn DFd          SSn      SSd            F            p p&lt;.05\n1 (Intercept)   1  29 532851.79967 5555.766 2.781381e+03 2.326909e-30     *\n2        time   2  58     24.92404 9965.112 7.253277e-02 9.301195e-01      \n          ges\n1 0.971696478\n2 0.001603265\n\n$`Mauchly's Test for Sphericity`\n  Effect         W        p p&lt;.05\n2   time 0.9718508 0.670493      \n\n$`Sphericity Corrections`\n  Effect       GGe     p[GG] p[GG]&lt;.05      HFe     p[HF] p[HF]&lt;.05\n2   time 0.9726215 0.9260045           1.041541 0.9301195          \n\n\n\n\n\n\n\n\nezANOVA 函数参数解释\n\n\n\nezANOVA 函数用于执行重复测量方差分析。以下是常用参数的解释：\n\ndata: 数据框，包含需要分析的数据。\ndv: 因变量 (Dependent Variable)，需要分析的测量变量，使用 .(变量名) 的形式指定。例如，. (performance) 表示 performance 列是因变量。\nwid: 被试者变量 (Within-Subject ID)，用于标识每个被试者的唯一ID，使用 .(变量名) 的形式指定。例如，. (subject) 表示 subject 列是被试者ID。\nwithin: 组内变量 (Within-Subject Factors)，重复测量设计的组内因素，使用 .(因素1, 因素2, ...) 的形式指定。例如，. (time) 表示 time 列是组内因素。\ndetailed: 是否输出详细结果，逻辑值 (TRUE 或 FALSE)。设置为 TRUE 时，输出更详细的方差分析结果，包括效应大小等信息。\n\n\n\n\n\nezANOVA 函数输出结果解读\nezANOVA 函数的输出结果主要是一个详细的方差分析表，用于解读重复测量方差分析的结果。以下是表格中各列的含义：\n\nEffect: 效应名称，表示正在检验的效应。对于重复测量方差分析，主要关注组内因素（例如，示例中的 time）以及可能的交互效应。\nDFn: 分子自由度 (Degrees of Freedom numerator)。对于组内因素，其自由度通常是因素水平数减1。例如，如果 time 因素有三个水平 (before, during, after)，则 DFn 为 3 - 1 = 2。\nDFd: 分母自由度 (Degrees of Freedom denominator)。对于组内因素，分母自由度与被试者数量和组内因素水平数有关，更具体地说是 (被试者数量 - 1) * (组内因素水平数 - 1)。在 ezANOVA 的详细输出中，会使用更精确的计算方法来处理重复测量设计的自由度。\nF: F 统计量。这是方差分析的核心统计量，用于检验组间方差与组内方差的比率。F 值越大，说明组间变异相对于组内变异越大，越有可能拒绝原假设。\np: p 值 (p-value)。这是在原假设成立的条件下，观察到当前样本结果或更极端结果的概率。p 值是判断效应是否具有统计学显著性的关键指标。\n\n如果 p 值小于预设的显著性水平 (\\(\\alpha\\)，通常为 0.05)，则拒绝原假设，认为该效应在统计上是显著的。例如，如果 time 效应的 p 值小于 0.05，则认为不同时间点（before, during, after）的平均 performance 存在显著差异。\n如果 p 值大于或等于 \\(\\alpha\\)，则不拒绝原假设，认为没有足够的证据表明该效应是显著的。\n\nges: 广义效应量 (Generalized Eta-Squared)。用于衡量效应量的大小，即组内因素对因变量变异的解释程度。ges 的取值范围为 0 到 1，值越大表示效应量越大。\n\nges 提供了一个关于效应实际大小的指标，而不仅仅是统计显著性。即使 p 值很小，如果 ges 很小，也可能意味着效应在实际应用中意义不大。\n通常，ges 的解释可以参考以下标准（Cohen, 1988）：\n\n小效应：ges ≈ 0.01\n中等效应：ges ≈ 0.06\n大效应：ges ≈ 0.14\n\n\n\n\n\n方差分析的替代方法\n当方差分析的假设不满足时，可以考虑以下替代方法：\n\n数据转换：对数转换、平方根转换等使数据更接近正态分布\n稳健方差分析：使用白化技术的修正方差分析\n非参数方法：Kruskal-Wallis检验（单因素方差分析的非参数替代）\n\n\n# Kruskal-Wallis检验\nkruskal.test(sales ~ campaign, data = marketing_data)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  sales by campaign\nKruskal-Wallis chi-squared = 22.747, df = 3, p-value = 4.56e-05\n\n\n\n\n方差分析在R中的高级应用\n\n# 包含协变量的ANCOVA模型\nancova_model &lt;- aov(sales ~ campaign + customer_loyalty, data = marketing_extended)\nsummary(ancova_model)\n\n# 嵌套设计方差分析\nnested_model &lt;- aov(performance ~ treatment + Error(subject/time), \n                   data = nested_data)\nsummary(nested_model)\n\n# 多变量方差分析(MANOVA)\nmanova_result &lt;- manova(cbind(sales, satisfaction) ~ campaign, \n                        data = multi_response_data)\nsummary(manova_result)\n\n\n\n综合练习与案例分析\n练习1：市场营销策略评估\n某电商平台测试了四种不同的营销策略（A：折扣优惠，B：会员积分，C：免费赠品，D：限时秒杀），每种策略在10个不同城市实施。收集了每种策略的点击率数据。\n\n# 读取营销策略数据\nmarketing_data &lt;- read_csv(\"data/week5/marketing_strategy.csv\")\n\n# 查看数据\nhead(marketing_data)\n\n# A tibble: 6 × 4\n  strategy strategy_name city  clickthrough_rate\n  &lt;chr&gt;    &lt;chr&gt;         &lt;chr&gt;             &lt;dbl&gt;\n1 A        折扣优惠      城市1            0.0875\n2 A        折扣优惠      城市2            0.0779\n3 A        折扣优惠      城市3            0.0897\n4 A        折扣优惠      城市4            0.103 \n5 A        折扣优惠      城市5            0.0765\n6 A        折扣优惠      城市6            0.0765\n\n# 绘制四种策略的点击率箱线图\nggplot(marketing_data, aes(x = strategy_name, y = clickthrough_rate, fill = strategy_name)) +\n  geom_boxplot() +\n  labs(title = \"不同营销策略的点击率比较\",\n       x = \"营销策略\", y = \"点击率\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n任务： 1. 使用单因素方差分析判断四种营销策略的点击率是否存在显著差异 2. 如有显著差异，确定哪些策略间的差异显著 3. 可视化分析结果\n练习2：区域与季节对销售的影响\n某连锁零售商收集了不同区域（北区、南区、东区、西区）在不同季节（春、夏、秋、冬）的销售数据。\n\n# 读取区域销售数据\nregional_data &lt;- read_csv(\"data/week5/regional_sales.csv\") %&gt;%\n  mutate(\n    season = factor(season, levels = c(\"春\", \"夏\", \"秋\", \"冬\")),\n    region = factor(region, levels = c(\"东区\", \"南区\",  \"西区\", \"北区\"))\n  )\n\n# 查看数据\nhead(regional_data)\n\n# A tibble: 6 × 4\n  region season store_id sales\n  &lt;fct&gt;  &lt;fct&gt;  &lt;chr&gt;    &lt;dbl&gt;\n1 北区   春     北区-1   1396.\n2 北区   春     北区-2   1322.\n3 北区   春     北区-3   1285.\n4 北区   春     北区-4   1261.\n5 北区   春     北区-5   1108.\n6 北区   夏     北区-1   1299.\n\n# 计算每个区域和季节组合的平均销售额\nregion_season_means &lt;- regional_data %&gt;%\n  group_by(region, season) %&gt;%\n  summarise(mean_sales = mean(sales), .groups = \"drop\")\n\n# 绘制交互作用图\nggplot(region_season_means, aes(x = season, y = mean_sales, \n                               color = region, group = region)) +\n  geom_point(size = 3) +\n  geom_line() +\n  labs(title = \"区域与季节对销售的交互效应\",\n       x = \"季节\", y = \"平均销售额\") +\n  scale_color_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\n\n任务： 1. 进行双因素方差分析，分析区域和季节对销售的主效应和交互效应 2. 解释分析结果，并提出营销建议 3. 使用交互作用图可视化区域与季节的交互关系\n练习3：广告媒体效果分析\n分析不同广告媒体（电视、广播、社交媒体、印刷媒体）对不同产品类别（电子产品、服装、食品）的广告效果数据。\n\n# 读取广告媒体效果数据\nad_data &lt;- read_csv(\"data/week5/ad_media_effect.csv\")\n\n# 查看数据\nhead(ad_data)\n\n# A tibble: 6 × 4\n  media product_category campaign_id effect\n  &lt;chr&gt; &lt;chr&gt;            &lt;chr&gt;        &lt;dbl&gt;\n1 电视  电子产品         电电-1       10.1 \n2 电视  电子产品         电电-2        8.86\n3 电视  电子产品         电电-3       10.5 \n4 电视  电子产品         电电-4        8.52\n5 电视  电子产品         电电-5        9.91\n6 电视  电子产品         电电-6       11.0 \n\n# 计算每个媒体和产品类别组合的平均效果\nmedia_product_means &lt;- ad_data %&gt;%\n  group_by(media, product_category) %&gt;%\n  summarise(mean_effect = mean(effect), .groups = \"drop\")\n\n# 绘制交互作用图\nggplot(media_product_means, aes(x = product_category, y = mean_effect, \n                               color = media, group = media)) +\n  geom_point(size = 3) +\n  geom_line() +\n  labs(title = \"广告媒体与产品类别的交互效应\",\n       x = \"产品类别\", y = \"平均效果\") +\n  scale_color_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\n任务： 1. 进行双因素方差分析 2. 如果存在交互效应，分析不同产品类别下最有效的广告媒体 3. 根据分析结果提出广告投放建议\n\n\n\n\n\n\nAI辅助学习建议（第五周）\n\n\n\n\n方差分析理解与应用\n\n请AI解释方差分析的直观含义：要求AI使用简单的商业案例解释方差分析的本质\n让AI比较t检验与方差分析：了解何时使用t检验，何时使用方差分析\n让AI解释交互效应：用图形直观展示交互效应的概念\n\n\n\nR代码编写与优化\n\n请AI生成方差分析的完整代码：针对特定数据集自动生成包含数据检查、分析和可视化的完整代码\n让AI优化方差分析结果的可视化：将默认图表优化为更专业的数据可视化\n请AI编写多重比较的代码：生成不同类型的事后检验方法（如Tukey、Bonferroni等）\n\n\n\n方差分析结果解读\n\n让AI解释F统计量和p值：将统计术语转化为商业语言\n请AI分析交互效应图：解读交互图中的模式并给出业务建议\n要求AI解释方差分析的假设检验结果：判断数据是否满足方差分析的基本假设\n\n\n\n方差分析应用场景\n\n请AI推荐适合方差分析的商业问题：根据项目主题获取适合应用方差分析的具体问题建议\n让AI设计方差分析实验方案：帮助设计合理的数据收集和分析方案\n要求AI分析方差分析的局限性：了解何时应该考虑其他统计方法\n\n\n\n\n\n\n参考文献与扩展阅读\n\nField, A. (2018). Discovering Statistics Using IBM SPSS Statistics (5th ed.). SAGE Publications.\nFox, J. (2016). Applied Regression Analysis and Generalized Linear Models (3rd ed.). SAGE Publications.\nR Core Team. (2021). R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing.\n黄湘通. (2019). 方差分析在商业数据分析中的应用. 统计与决策, 35(10), 98-101.\n温忠麟, 许小苹. (2017). 交互效应的本质、检验与分析. 心理科学进展, 25(6), 951-965.",
    "crumbs": [
      "项目二：商业数据分析与统计推断",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>第五周：方差分析</span>"
    ]
  },
  {
    "objectID": "week6.html",
    "href": "week6.html",
    "title": "第六周：回归分析初步",
    "section": "",
    "text": "第十一次课：线性回归模型与最小二乘法",
    "crumbs": [
      "项目二：商业数据分析与统计推断",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>第六周：回归分析初步</span>"
    ]
  },
  {
    "objectID": "week6.html#第十一次课线性回归模型与最小二乘法",
    "href": "week6.html#第十一次课线性回归模型与最小二乘法",
    "title": "第六周：回归分析初步",
    "section": "",
    "text": "回归分析概述\n回归分析的目的： - 研究因变量与一个或多个自变量之间的关系 - 建立模型进行预测和解释 - 评估变量之间的关联程度和方向\n回归分析是商业分析中最常用的分析技术之一，它能够帮助我们回答以下问题： - 影响销售额的关键因素有哪些？每个因素的影响程度如何？ - 如何根据产品特征预测价格？ - 不同营销投入对业绩的边际贡献是多少？\n回归分析的应用场景： - 预测销售额、房价、股票价格等 - 分析影响消费者购买行为的因素 - 评估营销活动的效果 - 识别影响企业绩效的关键指标\n回归分析的类型： - 线性回归：因变量与自变量之间呈线性关系 - 非线性回归：因变量与自变量之间呈非线性关系 - 简单线性回归：只有一个自变量 - 多元线性回归：有多个自变量\n回归分析与其他统计方法的区别： - 与相关分析相比：回归不仅描述关系，还建立预测模型 - 与方差分析相比：回归处理连续自变量，方差分析处理分类自变量\n回归分析的基本步骤： 1. 确定回归模型：选择合适的回归模型类型 2. 估计模型参数：使用样本数据估计模型中的未知参数 3. 模型检验：检验模型的拟合效果和显著性 4. 模型应用：使用建立的模型进行预测、解释和决策\n\n# 创建示例数据\nset.seed(123)\nadvertising_data &lt;- data.frame(\n  TV = runif(100, 5, 50),\n  Radio = runif(100, 1, 30),\n  Newspaper = runif(100, 0, 20)\n)\n# 生成销售额数据，使其与广告投入有一定关系\nadvertising_data$Sales &lt;- 5 + 0.15 * advertising_data$TV + \n                            0.3 * advertising_data$Radio + \n                            0.1 * advertising_data$Newspaper + \n                            rnorm(100, 0, 2)\n\n# 探索性数据分析\nsummary(advertising_data)\ncor(advertising_data)\n\n# 可视化变量关系\nlibrary(ggplot2)\nlibrary(gridExtra)\n\np1 &lt;- ggplot(advertising_data, aes(x = TV, y = Sales)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"电视广告与销售额关系\")\n\np2 &lt;- ggplot(advertising_data, aes(x = Radio, y = Sales)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"广播广告与销售额关系\")\n\np3 &lt;- ggplot(advertising_data, aes(x = Newspaper, y = Sales)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"报纸广告与销售额关系\")\n\ngrid.arrange(p1, p2, p3, ncol = 2)\n\n\n\n简单线性回归模型\n模型形式：\\(y = \\beta_0 + \\beta_1 x + \\epsilon\\) - \\(y\\)：因变量 - \\(x\\)：自变量 - \\(\\beta_0\\)：截距，当\\(x=0\\)时，\\(y\\)的期望值 - \\(\\beta_1\\)：斜率，自变量\\(x\\)每增加一个单位，因变量\\(y\\)的平均变化量 - \\(\\epsilon\\)：随机误差项，反映模型无法解释的随机变异\n简单线性回归是理解回归分析的基础，它描述了一个自变量和一个因变量之间的线性关系。例如，我们可以建立一个模型来描述广告支出（自变量）与销售额（因变量）之间的关系。\n最小二乘法(OLS)：\n最小二乘法是一种估计回归系数的方法，其目标是找到能使误差平方和最小的回归线。\n\n目标：使残差平方和(RSS)最小化\n\\(\\text{RSS} = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 = \\sum_{i=1}^{n} (y_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i))^2\\)\n\\(\\hat{\\beta}_0\\)和\\(\\hat{\\beta}_1\\)是\\(\\beta_0\\)和\\(\\beta_1\\)的估计值\n\\(\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i\\)是因变量\\(y_i\\)的预测值\n\n最小二乘估计的公式： - \\(\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}\\) - \\(\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x}\\)\n回归系数的解释： - \\(\\hat{\\beta}_0\\)：当自变量\\(x\\)为0时，因变量\\(y\\)的预测值（在实际情况中，自变量为0可能没有现实意义） - \\(\\hat{\\beta}_1\\)：自变量\\(x\\)每增加一个单位，因变量\\(y\\)的预测值平均增加\\(\\hat{\\beta}_1\\)个单位（边际效应）\n回归模型的评估指标：\n\n拟合优度 \\(R^2\\)：\n\n表示模型解释的因变量方差比例\n取值范围[0,1]，越接近1表示模型拟合越好\n\\(R^2 = 1 - \\frac{SSE}{SST} = 1 - \\frac{\\sum(y_i - \\hat{y}_i)^2}{\\sum(y_i - \\bar{y})^2}\\)\n\n残差标准误差(RSE)：\n\n衡量因变量实际值偏离预测值的平均程度\n\\(RSE = \\sqrt{\\frac{SSE}{n-2}} = \\sqrt{\\frac{\\sum(y_i - \\hat{y}_i)^2}{n-2}}\\)\n\n\n回归模型的假设条件： - 线性性：因变量与自变量之间存在线性关系 - 独立性：误差项之间相互独立 - 同方差性：误差项的方差为常数（同质性） - 正态性：误差项服从均值为0的正态分布\n\n# 简单线性回归示例：电视广告与销售额\ntv_model &lt;- lm(Sales ~ TV, data = advertising_data)\n\n# 查看回归结果\nsummary(tv_model)\n\n# 可视化回归线和预测区间\nggplot(advertising_data, aes(x = TV, y = Sales)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", level = 0.95) +\n  labs(title = \"电视广告支出与销售额的简单线性回归\",\n       x = \"电视广告支出（千元）\",\n       y = \"销售额（万元）\") +\n  theme_minimal()\n\n# 残差分析\npar(mfrow = c(2, 2))\nplot(tv_model)\n\n\n\nR语言实现简单线性回归\n基本函数：\n\n# 建立简单线性回归模型\nlm_model &lt;- lm(Sales ~ TV, data = advertising_data)\n\n# 查看模型摘要\nsummary(lm_model)\n\n# 提取回归系数\ncoef(lm_model)\n\n# 置信区间\nconfint(lm_model, level = 0.95)\n\n# 模型预测\nnew_data &lt;- data.frame(TV = c(10, 20, 30, 40))\npredict(lm_model, newdata = new_data, interval = \"confidence\")\npredict(lm_model, newdata = new_data, interval = \"prediction\")\n\n# 残差和拟合值\nresiduals(lm_model)\nfitted(lm_model)\n\n# 回归诊断图\npar(mfrow = c(2, 2))\nplot(lm_model)\n\nggplot2进行回归可视化：\n\nlibrary(ggplot2)\n\n# 基本散点图和回归线\nggplot(advertising_data, aes(x = TV, y = Sales)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  labs(title = \"电视广告支出与销售额关系\",\n       x = \"电视广告支出（千元）\", \n       y = \"销售额（万元）\") +\n  theme_minimal()\n\n# 回归残差可视化\nadvertising_data$predicted &lt;- fitted(lm_model)\nadvertising_data$residuals &lt;- residuals(lm_model)\n\nggplot(advertising_data, aes(x = predicted, y = residuals)) +\n  geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  labs(title = \"残差vs拟合值\",\n       x = \"拟合值\", y = \"残差\") +\n  theme_minimal()\n\n# QQ图检验正态性\nggplot(advertising_data, aes(sample = residuals)) +\n  stat_qq() +\n  stat_qq_line() +\n  labs(title = \"残差QQ图\") +\n  theme_minimal()\n\n结果解读： - 系数估计值：截距(\\(\\hat{\\beta}_0\\))和斜率(\\(\\hat{\\beta}_1\\))的估计值 - 标准误差：系数估计值的标准误差，表示估计的精确度 - t值：系数估计值与标准误差的比值，用于检验系数是否显著不为0 - p值：系数是否显著不为0的显著性水平 - R²值：模型解释的方差比例，衡量拟合优度 - F统计量：整个模型的显著性检验\n案例解读：\n\n# 假设这是summary(lm_model)的输出结果：\n# Coefficients:\n#             Estimate Std. Error t value Pr(&gt;|t|)    \n# (Intercept)   7.0326     0.4578  15.361  &lt; 2e-16 ***\n# TV            0.0475     0.0097   4.897 4.75e-06 ***\n# ---\n# R-squared: 0.612, Adjusted R-squared: 0.606 \n# F-statistic: 23.97 on 1 and 98 DF, p-value: 4.75e-06\n\n# 商业解读：\n# 1. 截距7.0326表示当电视广告支出为0时，预期销售额为7.0326万元\n# 2. 电视广告系数0.0475表示每增加1千元的电视广告支出，销售额平均增加0.0475万元\n# 3. 电视广告变量的p值非常小(&lt;0.0001)，表示电视广告支出对销售额有显著影响\n# 4. R²值为0.612，说明模型解释了约61.2%的销售额变异\n# 5. 整体模型F检验显著(p&lt;0.0001)，表明模型有统计学意义",
    "crumbs": [
      "项目二：商业数据分析与统计推断",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>第六周：回归分析初步</span>"
    ]
  },
  {
    "objectID": "week6.html#第十二次课多元线性回归模型",
    "href": "week6.html#第十二次课多元线性回归模型",
    "title": "第六周：回归分析初步",
    "section": "第十二次课：多元线性回归模型",
    "text": "第十二次课：多元线性回归模型\n\n多元线性回归模型\n多元线性回归的意义： 在商业环境中，一个因变量往往受多个因素影响。例如，销售额不仅受电视广告的影响，还可能受广播、报纸、社交媒体等多种营销渠道的影响。多元线性回归能够同时考虑多个自变量的影响，更全面地分析因素间的关系。\n模型形式：\\(y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p + \\epsilon\\) - \\(y\\)：因变量 - \\(x_1, x_2, \\dots, x_p\\)：\\(p\\)个自变量 - \\(\\beta_0\\)：截距 - \\(\\beta_1, \\beta_2, \\dots, \\beta_p\\)：偏回归系数，控制其他自变量不变时，每个自变量对因变量的边际影响 - \\(\\epsilon\\)：随机误差项\n偏回归系数的解释： - \\(\\beta_1\\)表示在其他自变量\\(x_2, \\dots, x_p\\)保持不变的情况下，自变量\\(x_1\\)每增加一个单位，因变量\\(y\\)的平均变化量\n这个解释非常重要，因为它体现了”控制变量”的思想，即我们能够分离出单个自变量的”净效应”。这在商业分析中尤为有用，例如，我们可以分析在广播广告投入不变的情况下，增加电视广告对销售的边际贡献。\n参数估计： - 同样使用最小二乘法(OLS) - 通过矩阵运算求解：\\(\\hat{\\beta} = (X^TX)^{-1}X^Ty\\) - 其中\\(X\\)是自变量矩阵，\\(y\\)是因变量向量\n多元线性回归模型的假设条件： - 线性性：因变量与每个自变量之间存在线性关系 - 独立性：观测值之间相互独立 - 同方差性：误差项方差恒定 - 正态性：误差项服从正态分布 - 无多重共线性：自变量之间不存在高度相关性\n多重共线性问题： - 定义：自变量之间存在强相关关系 - 后果：回归系数估计不稳定，标准误增大 - 诊断：方差膨胀因子(VIF) - 处理：变量选择、正则化、主成分分析等\n\n# 检测多重共线性\nlibrary(car)\nmulti_model &lt;- lm(Sales ~ TV + Radio + Newspaper, data = advertising_data)\nvif(multi_model)\n# VIF &gt; 10通常表示存在严重多重共线性\n\n模型拟合与检验： - R²：衡量模型对数据的拟合程度，取值范围[0,1] - 调整R²：考虑自变量个数对R²的影响，防止过拟合 - F检验：检验模型整体的显著性 - t检验：检验每个偏回归系数的显著性\n解释多元回归模型时需注意： - 解释系数时必须强调”控制其他变量不变” - R²会随自变量增加而增加，应关注调整R² - 显著性水平应解释为”在控制了其他变量后”\n\n\nR语言实现多元线性回归\n下面我们将使用广告投入数据集建立多元线性回归模型，分析不同广告渠道对销售额的影响：\n\n# 多元线性回归示例\nmulti_model &lt;- lm(Sales ~ TV + Radio + Newspaper, data = advertising_data)\n\n# 查看模型摘要\nsummary(multi_model)\n\n# 方差分析表，展示模型整体显著性\nanova(multi_model)\n\n# 检验多重共线性\nlibrary(car)\nvif(multi_model)\n\n嵌套模型比较：\n\n# 构建不同的嵌套模型\nmodel1 &lt;- lm(Sales ~ TV, data = advertising_data)\nmodel2 &lt;- lm(Sales ~ TV + Radio, data = advertising_data)\nmodel3 &lt;- lm(Sales ~ TV + Radio + Newspaper, data = advertising_data)\n\n# 使用anova函数比较嵌套模型\nanova(model1, model2, model3)\n\n# 使用AIC比较模型\nAIC(model1, model2, model3)\nBIC(model1, model2, model3)\n\n偏回归图：观察单个自变量的边际贡献\n\nlibrary(car)\navPlots(multi_model)\n\n变量重要性评估：\n\nlibrary(relaimpo)\ncalc.relimp(multi_model, type = \"lmg\", rela = TRUE)\n\n多元回归的可视化：\n\n# 可视化不同渠道的边际效应\nlibrary(ggplot2)\nlibrary(gridExtra)\n\n# 构建效应图\neffect_tv &lt;- ggplot(advertising_data, aes(x = TV, y = Sales)) +\n  geom_point(alpha = 0.3) +\n  geom_smooth(method = \"lm\") +\n  labs(title = \"电视广告的边际效应\") +\n  theme_minimal()\n\neffect_radio &lt;- ggplot(advertising_data, aes(x = Radio, y = Sales)) +\n  geom_point(alpha = 0.3) +\n  geom_smooth(method = \"lm\") +\n  labs(title = \"广播广告的边际效应\") +\n  theme_minimal()\n\neffect_newspaper &lt;- ggplot(advertising_data, aes(x = Newspaper, y = Sales)) +\n  geom_point(alpha = 0.3) +\n  geom_smooth(method = \"lm\") +\n  labs(title = \"报纸广告的边际效应\") +\n  theme_minimal()\n\ngrid.arrange(effect_tv, effect_radio, effect_newspaper, ncol = 2)\n\n# 3D可视化（针对两个自变量）\nlibrary(plotly)\nfit &lt;- lm(Sales ~ TV + Radio, data = advertising_data)\n\n# 创建网格点\ngrid.lines = 50\nx.pred &lt;- seq(min(advertising_data$TV), max(advertising_data$TV), length.out = grid.lines)\ny.pred &lt;- seq(min(advertising_data$Radio), max(advertising_data$Radio), length.out = grid.lines)\nxy &lt;- expand.grid(TV = x.pred, Radio = y.pred)\n\n# 预测z值\nz.pred &lt;- matrix(predict(fit, newdata = xy), \n                nrow = grid.lines, ncol = grid.lines)\n\n# 创建3D图\nplot_ly() %&gt;%\n  add_trace(data = advertising_data, \n            x = ~TV, y = ~Radio, z = ~Sales,\n            type = \"scatter3d\", mode = \"markers\",\n            marker = list(size = 5, color = \"blue\", opacity = 0.5)) %&gt;%\n  add_surface(x = x.pred, y = y.pred, z = z.pred,\n              colorscale = \"Viridis\", opacity = 0.8) %&gt;%\n  layout(title = \"销售额与电视、广播广告投入的关系\",\n         scene = list(xaxis = list(title = \"电视广告\"),\n                     yaxis = list(title = \"广播广告\"),\n                     zaxis = list(title = \"销售额\")))\n\n变量选择方法： 当有多个潜在自变量时，我们需要选择一个最佳的变量子集：\n\n# 向前逐步回归\nnull_model &lt;- lm(Sales ~ 1, data = advertising_data)\nfull_model &lt;- lm(Sales ~ ., data = advertising_data)\nforward_model &lt;- step(null_model, scope = list(lower = null_model, upper = full_model), \n                    direction = \"forward\")\n\n# 向后逐步回归\nbackward_model &lt;- step(full_model, direction = \"backward\")\n\n# 双向逐步回归（同时考虑增加和删除变量）\nstepwise_model &lt;- step(null_model, scope = list(lower = null_model, upper = full_model), \n                     direction = \"both\")\n\n# 使用Leaps包进行最优子集选择\nlibrary(leaps)\nsubsets &lt;- regsubsets(Sales ~ ., data = advertising_data, nvmax = ncol(advertising_data) - 1)\nsummary(subsets)\nplot(subsets, scale = \"r2\")\nplot(subsets, scale = \"adjr2\")\nplot(subsets, scale = \"Cp\")\nplot(subsets, scale = \"bic\")\n\n正则化回归： 处理多重共线性和预防过拟合的现代方法：\n\n# 岭回归\nlibrary(glmnet)\nx &lt;- as.matrix(advertising_data[, c(\"TV\", \"Radio\", \"Newspaper\")])\ny &lt;- advertising_data$Sales\nridge_model &lt;- glmnet(x, y, alpha = 0)\nplot(ridge_model, xvar = \"lambda\", label = TRUE)\ncv_ridge &lt;- cv.glmnet(x, y, alpha = 0)\nbest_lambda &lt;- cv_ridge$lambda.min\nridge_coef &lt;- coef(ridge_model, s = best_lambda)\n\n# Lasso回归\nlasso_model &lt;- glmnet(x, y, alpha = 1)\nplot(lasso_model, xvar = \"lambda\", label = TRUE)\ncv_lasso &lt;- cv.glmnet(x, y, alpha = 1)\nbest_lambda &lt;- cv_lasso$lambda.min\nlasso_coef &lt;- coef(lasso_model, s = best_lambda)\n\n\n\n回归分析的实际应用案例\n案例1：房价预测模型\n\n# 导入波士顿房价数据集\nlibrary(MASS)\ndata(Boston)\nhead(Boston)\n\n# 变量说明\n# medv: 自住房屋的中位数价值（千美元）（因变量）\n# rm: 每套住宅的平均房间数\n# lstat: 人口中地位较低人群的百分比\n# crim: 城镇人均犯罪率\n# zn: 占地面积超过2.5万平方英尺的住宅用地比例\n# indus: 每个城镇非零售业务的比例\n# chas: 查尔斯河虚拟变量（1 = 边界在河边；0 = 否）\n# nox: 一氧化氮浓度（千万分之一）\n# ...\n\n# 探索性分析\npairs(Boston[, c(\"medv\", \"rm\", \"lstat\", \"crim\", \"nox\")])\ncor(Boston)\n\n# 建立模型\nmodel_all &lt;- lm(medv ~ ., data = Boston)\nsummary(model_all)\n\n# 变量选择\nstep_model &lt;- step(model_all, direction = \"both\")\nsummary(step_model)\n\n# 最优模型解释与诊断\npar(mfrow = c(2, 2))\nplot(step_model)\n\n# 预测\nnew_house &lt;- data.frame(\n  rm = 6.5,\n  lstat = 10,\n  crim = 0.5,\n  zn = 50,\n  indus = 5,\n  chas = 0,\n  nox = 0.5,\n  age = 50,\n  dis = 4,\n  rad = 6,\n  tax = 400,\n  ptratio = 15,\n  black = 380,\n  chas = 0\n)\n\npredict(step_model, newdata = new_house, interval = \"prediction\")\n\n案例2：销售额预测与营销投资优化\n\n# 使用前面的广告数据\n# 假设我们有一个额外的数据集，包含不同产品线的广告效果\nproduct_data &lt;- data.frame(\n  product = rep(c(\"A\", \"B\", \"C\"), each = 30),\n  TV = runif(90, 5, 50),\n  Radio = runif(90, 1, 30),\n  Newspaper = runif(90, 0, 20)\n)\n# 生成不同的效应模式\nproduct_data$Sales &lt;- 5 + \n  ifelse(product_data$product == \"A\", 0.2, \n         ifelse(product_data$product == \"B\", 0.1, 0.05)) * product_data$TV +\n  ifelse(product_data$product == \"A\", 0.15, \n         ifelse(product_data$product == \"B\", 0.3, 0.1)) * product_data$Radio +\n  ifelse(product_data$product == \"A\", 0.05, \n         ifelse(product_data$product == \"B\", 0.1, 0.2)) * product_data$Newspaper +\n  rnorm(90, 0, 2)\n\n# 分析不同产品线的广告效果\nlibrary(ggplot2)\nggplot(product_data, aes(x = TV, y = Sales, color = product)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_wrap(~product) +\n  labs(title = \"不同产品线的电视广告效果\") +\n  theme_minimal()\n\n# 为每个产品线建立单独的模型\nproduct_models &lt;- list()\nfor(p in unique(product_data$product)) {\n  subset_data &lt;- product_data[product_data$product == p, ]\n  product_models[[p]] &lt;- lm(Sales ~ TV + Radio + Newspaper, data = subset_data)\n  print(paste(\"Product\", p, \"model:\"))\n  print(summary(product_models[[p]]))\n}\n\n# 互动效应模型（产品与广告渠道的交互）\ninteraction_model &lt;- lm(Sales ~ product * (TV + Radio + Newspaper), \n                        data = product_data)\nsummary(interaction_model)\n\n# 营销预算优化：基于边际回报率\n# 根据回归系数计算每个渠道的投资回报率，优化预算分配\n\n案例3：市场细分分析\n\n# 不同市场细分的回归分析\nsegment_data &lt;- data.frame(\n  customer_segment = rep(c(\"高收入\", \"中收入\", \"低收入\"), each = 30),\n  price = runif(90, 50, 200),\n  promotion = runif(90, 0, 1),\n  store_quality = runif(90, 1, 5)\n)\n# 不同细分市场的消费者对价格和促销的敏感度不同\nsegment_data$purchase &lt;- 10 +\n  ifelse(segment_data$customer_segment == \"高收入\", -0.01, \n         ifelse(segment_data$customer_segment == \"中收入\", -0.03, -0.05)) * segment_data$price +\n  ifelse(segment_data$customer_segment == \"高收入\", 1, \n         ifelse(segment_data$customer_segment == \"中收入\", 2, 3)) * segment_data$promotion +\n  0.5 * segment_data$store_quality +\n  rnorm(90, 0, 1)\n\n# 分析不同细分市场的价格敏感度\nsegment_models &lt;- list()\nfor(s in unique(segment_data$customer_segment)) {\n  subset_data &lt;- segment_data[segment_data$customer_segment == s, ]\n  segment_models[[s]] &lt;- lm(purchase ~ price + promotion + store_quality, \n                           data = subset_data)\n  print(paste(\"Segment\", s, \"model:\"))\n  print(summary(segment_models[[s]]))\n}\n\n# 差异化定价策略建议\nprice_sensitivity &lt;- data.frame(\n  segment = names(segment_models),\n  price_effect = sapply(segment_models, function(model) coef(model)[\"price\"])\n)\nprint(price_sensitivity)\n\n\n\n\n\n\n\nAI辅助学习建议（第六周）\n\n\n\n\n回归分析理解与解释\n\n请AI解释回归系数的含义：要求AI使用通俗易懂的语言解释回归系数的实际意义\n让AI比较相关分析与回归分析：理解两者的区别和各自适用场景\n要求AI解释拟合优度(R²)：深入理解R²的含义、局限性和在商业分析中的解读方式\n\n\n\nR代码编写与模型构建\n\n请AI生成完整的回归分析流程代码：从数据探索、模型构建到诊断和解释的全流程代码\n让AI帮助进行变量选择：生成向前、向后或逐步回归代码，并解释选择逻辑\n要求AI编写回归结果可视化代码：创建更专业和直观的回归结果展示图\n\n\n\n回归模型诊断与优化\n\n请AI检查回归模型假设：生成检验线性性、同方差性、独立性和正态性的代码和解释\n让AI解释多重共线性问题：诊断和处理多重共线性的方法\n要求AI优化模型预测性能：提供提高模型预测准确性的建议\n\n\n\n回归分析应用场景\n\n请AI推荐适合项目主题的回归应用问题：根据选择的项目主题获取具体的研究问题建议\n让AI设计商业分析方案：设计从数据收集到分析解释的完整方案\n要求AI解释回归分析在不同行业的应用：了解回归分析在市场营销、金融、人力资源等领域的典型应用案例\n\n\n\n\n\n\n参考文献与扩展阅读\n\nJames, G., Witten, D., Hastie, T., & Tibshirani, R. (2013). An Introduction to Statistical Learning. Springer.\nKutner, M. H., Nachtsheim, C. J., Neter, J., & Li, W. (2005). Applied Linear Statistical Models (5th ed.). McGraw-Hill.\nFox, J. (2016). Applied Regression Analysis and Generalized Linear Models (3rd ed.). SAGE Publications.\nFaraway, J. J. (2014). Linear Models with R (2nd ed.). Chapman and Hall/CRC.\n李惠莲. (2018). 回归分析在商业决策中的应用. 统计与决策, 34(15), 82-85.",
    "crumbs": [
      "项目二：商业数据分析与统计推断",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>第六周：回归分析初步</span>"
    ]
  },
  {
    "objectID": "week7.html",
    "href": "week7.html",
    "title": "第七周：分类数据分析",
    "section": "",
    "text": "第十三次课：卡方检验-拟合优度检验",
    "crumbs": [
      "项目二：商业数据分析与统计推断",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>第七周：分类数据分析</span>"
    ]
  },
  {
    "objectID": "week7.html#第十三次课卡方检验-拟合优度检验",
    "href": "week7.html#第十三次课卡方检验-拟合优度检验",
    "title": "第七周：分类数据分析",
    "section": "",
    "text": "分类数据分析概述\n分类数据的特点： - 取值是离散的类别，而非连续的数值 - 例如：性别（男/女）、颜色（红/绿/蓝）、学历（本科/硕士/博士）等 - 分类数据可分为名义变量（无序类别）和有序变量（有顺序等级）\n分类数据分析的目的： - 描述分类数据的分布特征（频率、比例） - 检验分类变量之间的关系（独立性、关联性） - 比较不同组别在分类变量上的分布差异 - 构建模型预测分类变量的取值\n常用分析方法： - 频数分布表和条形图：描述单个分类变量的分布 - 列联表和卡方检验：检验两个分类变量之间是否独立 - 相关分析：衡量有序分类变量之间的相关程度 - 对数线性模型：分析复杂的分类数据关系 - 逻辑回归和判别分析：预测分类变量\n数据展示方式：\n\n# 创建示例数据\nsurvey_data &lt;- data.frame(\n  gender = sample(c(\"男\", \"女\"), 200, replace = TRUE, prob = c(0.45, 0.55)),\n  education = sample(c(\"高中\", \"本科\", \"硕士\", \"博士\"), 200, replace = TRUE, \n                    prob = c(0.25, 0.45, 0.20, 0.10)),\n  satisfaction = sample(c(\"非常不满意\", \"不满意\", \"一般\", \"满意\", \"非常满意\"), \n                      200, replace = TRUE)\n)\n\n# 频数分布表\ntable(survey_data$gender)\ntable(survey_data$education)\nprop.table(table(survey_data$education)) # 比例\n\n# 图形展示\nlibrary(ggplot2)\n\n# 条形图\nggplot(survey_data, aes(x = education, fill = education)) +\n  geom_bar() +\n  labs(title = \"受访者教育水平分布\",\n       x = \"教育水平\", y = \"频数\") +\n  theme_minimal()\n\n# 饼图\npie_data &lt;- data.frame(\n  education = names(table(survey_data$education)),\n  count = as.numeric(table(survey_data$education))\n)\n\nggplot(pie_data, aes(x = \"\", y = count, fill = education)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(\"y\", start = 0) +\n  labs(title = \"受访者教育水平分布\") +\n  theme_void() +\n  theme(legend.title = element_blank())\n\n# 马赛克图（两个分类变量的联合分布）\nlibrary(ggmosaic)\nggplot(survey_data) +\n  geom_mosaic(aes(x = product(gender), fill = education)) +\n  labs(title = \"性别与教育水平的联合分布\") +\n  theme_minimal()\n\n\n\n卡方检验：拟合优度检验\n拟合优度检验的目的： - 检验观察频数分布与期望频数分布是否一致 - 评估样本是否来自某个特定的理论分布 - 判断数据是否符合预期的理论模型\n应用场景： - 检验观察数据是否符合均匀分布（如骰子是否公平） - 检验观察数据是否符合某个理论分布（如泊松分布） - 验证市场份额分布是否发生变化（如品牌偏好） - 产品质量控制（检验缺陷分布是否符合预期） - 消费者偏好测试（检验不同口味的受欢迎程度）\n假设检验： - 原假设(H0)：观察频数分布与期望频数分布一致 - 备择假设(H1)：观察频数分布与期望频数分布不一致\n检验统计量：卡方统计量 (\\(\\chi^2\\)) \\(\\chi^2 = \\sum_{i=1}^{k} \\frac{(O_i - E_i)^2}{E_i}\\)\n\n\\(O_i\\)：第\\(i\\)个类别的观察频数\n\\(E_i\\)：第\\(i\\)个类别的期望频数\n\\(k\\)：类别个数\n\n自由度: df = 类别个数 - 1 = k - 1\n决策规则： - 如果\\(p值 &lt; \\alpha\\)（通常\\(\\alpha = 0.05\\)），则拒绝原假设 - 如果\\(p值 \\geq \\alpha\\)，则不拒绝原假设\n检验步骤： 1. 收集观察频数数据 2. 确定期望频数分布（基于理论模型或历史数据） 3. 计算卡方统计量 4. 确定自由度并查找临界值或计算p值 5. 做出统计决策并进行业务解释\n\n\nR语言实现拟合优度检验\n基本语法：\n\n# 语法结构\nchisq.test(x, p = NULL)\n\n# 参数说明\n# x：观察频率向量\n# p：期望概率向量（可选，默认为均匀分布）\n\n示例1：检验糖果颜色分布是否均匀\n\n# 假设某品牌糖果有5种颜色，收集样本统计各颜色数量\ncandy_colors &lt;- c(\"红色\", \"黄色\", \"绿色\", \"蓝色\", \"紫色\")\nobserved_counts &lt;- c(30, 25, 28, 32, 35)  # 观察频数\n\n# 创建数据框用于可视化\ncandy_data &lt;- data.frame(\n  color = candy_colors,\n  count = observed_counts\n)\n\n# 可视化观察频数\nggplot(candy_data, aes(x = color, y = count, fill = color)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"糖果颜色分布\",\n       x = \"颜色\", y = \"频数\") +\n  theme_minimal()\n\n# 执行卡方拟合优度检验（检验是否符合均匀分布）\nchi_result &lt;- chisq.test(observed_counts)\nprint(chi_result)\n\n# 解读结果\n# 如果p值小于0.05，则拒绝原假设，认为糖果颜色分布不均匀\n# 如果p值大于等于0.05，则不拒绝原假设，认为糖果颜色分布均匀\n\n示例2：检验销售数据是否符合预期分布\n\n# 某公司四款产品的实际销售量（观察频数）\nproducts &lt;- c(\"产品A\", \"产品B\", \"产品C\", \"产品D\")\nobserved_sales &lt;- c(320, 210, 240, 130)\n\n# 根据历史数据或市场预测的期望销售比例\nexpected_proportions &lt;- c(0.35, 0.25, 0.25, 0.15)\n\n# 可视化观察与期望的比较\nsales_data &lt;- data.frame(\n  product = rep(products, 2),\n  type = rep(c(\"观察销量\", \"期望销量\"), each = 4),\n  count = c(observed_sales, expected_proportions * sum(observed_sales))\n)\n\nggplot(sales_data, aes(x = product, y = count, fill = type)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"产品销售量：观察值vs期望值\",\n       x = \"产品\", y = \"销售量\") +\n  theme_minimal()\n\n# 执行卡方拟合优度检验\nchi_sales &lt;- chisq.test(observed_sales, p = expected_proportions)\nprint(chi_sales)\n\n# 计算残差（可识别哪些类别与期望差异显著）\nchi_sales$residuals\n\n示例3：问卷调查数据分析\n\n# 某问卷调查对某商品的评价结果\nratings &lt;- c(\"非常好\", \"好\", \"一般\", \"差\", \"非常差\")\nobserved_ratings &lt;- c(45, 80, 60, 25, 10)\n\n# 假设评价应该呈正态分布（公司期望）\nexpected_prop &lt;- c(0.15, 0.35, 0.30, 0.15, 0.05)\n\n# 创建数据框并可视化\nrating_data &lt;- data.frame(\n  rating = ratings,\n  observed = observed_ratings,\n  expected = expected_prop * sum(observed_ratings)\n)\n\n# 转换为长格式进行可视化\nrating_long &lt;- reshape2::melt(rating_data, id.vars = \"rating\", \n                             variable.name = \"type\", value.name = \"count\")\n\n# 创建条形图比较观察值与期望值\nggplot(rating_long, aes(x = rating, y = count, fill = type)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"产品评价：观察值vs期望值\",\n       x = \"评价\", y = \"频数\") +\n  scale_fill_manual(values = c(\"observed\" = \"steelblue\", \"expected\" = \"coral\"),\n                   labels = c(\"观察值\", \"期望值\")) +\n  theme_minimal()\n\n# 执行卡方拟合优度检验\nchi_rating &lt;- chisq.test(observed_ratings, p = expected_prop)\nprint(chi_rating)\n\n# 标准化残差（&gt;1.96或&lt;-1.96表示在5%水平上显著）\nround(chi_rating$residuals, 2)\n\n\n\n拟合优度检验的注意事项\n\n样本量要求：\n\n期望频数不应太小，通常要求所有类别的期望频数都大于等于5\n如果有类别的期望频数小于5，可考虑合并类别或使用精确方法\n\n类别选择：\n\n类别划分需合理，不应人为操纵以适应检验需要\n类别间应互斥且完备（覆盖所有可能情况）\n\n期望分布的确定：\n\n期望分布应基于合理的理论假设或历史数据\n如果期望分布是从数据估计得出，则自由度需要相应调整\n\n结果解释：\n\n拒绝原假设只能说明观察分布与期望分布存在显著差异\n需要结合实际问题背景解释差异的实际意义和重要性\n\n\n\n\n商业案例分析：市场调研中的应用\n案例背景： 某快餐连锁店通过市场调研收集了顾客对其五种主要产品的偏好数据。该公司希望验证实际消费者偏好是否与其市场定位一致。\n\n# 五种产品的实际偏好计数\nproducts &lt;- c(\"汉堡\", \"炸鸡\", \"沙拉\", \"三明治\", \"披萨\")\nobserved_preferences &lt;- c(250, 180, 120, 150, 300)\n\n# 公司的市场定位预期比例\nexpected_proportions &lt;- c(0.3, 0.2, 0.1, 0.15, 0.25)\n\n# 创建数据框用于分析和可视化\npreference_data &lt;- data.frame(\n  product = products,\n  observed = observed_preferences,\n  expected = expected_proportions * sum(observed_preferences),\n  difference = observed_preferences - expected_proportions * sum(observed_preferences)\n)\n\n# 可视化比较\nggplot(preference_data, aes(x = product, y = observed, fill = product)) +\n  geom_bar(stat = \"identity\") +\n  geom_point(aes(y = expected), shape = 18, size = 5, color = \"red\") +\n  geom_text(aes(label = paste0(\"+\", round(difference))), \n            position = position_dodge(width = 0.9), vjust = -0.5) +\n  labs(title = \"消费者产品偏好: 观察vs期望\",\n       subtitle = \"红点表示期望频数，数字显示差异\",\n       x = \"产品\", y = \"偏好次数\") +\n  theme_minimal()\n\n# 执行卡方拟合优度检验\nchi_preference &lt;- chisq.test(observed_preferences, p = expected_proportions)\nprint(chi_preference)\n\n# 分析结果\nif(chi_preference$p.value &lt; 0.05) {\n  cat(\"消费者实际偏好与公司的市场定位存在显著差异。\\n\")\n  \n  # 找出差异最大的产品\n  largest_diff_idx &lt;- which.max(abs(preference_data$difference))\n  if(preference_data$difference[largest_diff_idx] &gt; 0) {\n    cat(paste0(\"产品 '\", products[largest_diff_idx], \n               \"' 的实际偏好显著高于预期，可考虑增加投入。\\n\"))\n  } else {\n    cat(paste0(\"产品 '\", products[largest_diff_idx], \n               \"' 的实际偏好显著低于预期，需要重新评估市场策略。\\n\"))\n  }\n} else {\n  cat(\"消费者实际偏好与公司的市场定位基本一致，当前营销策略有效。\\n\")\n}\n\n商业决策建议： - 如果检验显示实际偏好与预期有显著差异，公司可能需要调整产品策略和市场营销计划 - 对于偏好显著高于预期的产品，可考虑增加供应和营销资源 - 对于偏好显著低于预期的产品，需要研究原因并改进产品或调整定位 - 使用残差分析识别具体哪些产品与预期差异最大，优先处理这些产品",
    "crumbs": [
      "项目二：商业数据分析与统计推断",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>第七周：分类数据分析</span>"
    ]
  },
  {
    "objectID": "week7.html#第十四次课卡方检验-独立性检验与相关分析",
    "href": "week7.html#第十四次课卡方检验-独立性检验与相关分析",
    "title": "第七周：分类数据分析",
    "section": "第十四次课：卡方检验-独立性检验与相关分析",
    "text": "第十四次课：卡方检验-独立性检验与相关分析\n\n卡方检验：独立性检验\n独立性检验的目的： - 检验两个分类变量之间是否独立 - 评估一个分类变量的分布是否受另一个分类变量的影响 - 判断两个分类变量是否存在关联关系\n应用场景： - 检验性别与购买偏好是否独立 - 分析学历与收入水平是否相关 - 评估地区与产品销量是否有关联 - 研究营销渠道与转化率之间的关系 - 分析产品特性与客户满意度之间的关系\n假设检验： - 原假设(H0)：两个分类变量之间独立 - 备择假设(H1)：两个分类变量之间不独立（存在关联）\n列联表：用于展示两个分类变量频率分布的表格，又称为交叉表或者交互频数表\n期望频率计算： \\(E_{ij} = \\frac{(\\text{第 } i \\text{ 行总和}) \\times (\\text{第 } j \\text{ 列总和})}{\\text{总样本量}}\\)\n卡方统计量： \\(\\chi^2 = \\sum_{i=1}^{r}\\sum_{j=1}^{c} \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\\)\n\n\\(O_{ij}\\)：第\\(i\\)行第\\(j\\)列的观察频数\n\\(E_{ij}\\)：第\\(i\\)行第\\(j\\)列的期望频数\n\\(r\\)：行数\n\\(c\\)：列数\n\n自由度: df = (行数 - 1) × (列数 - 1)\n决策规则： - 如果\\(p值 &lt; \\alpha\\)（通常\\(\\alpha = 0.05\\)），则拒绝原假设，认为两个变量不独立 - 如果\\(p值 \\geq \\alpha\\)，则不拒绝原假设，认为两个变量独立\n\n\nR语言实现独立性检验\n基本实现步骤：\n\n# 创建列联表\ncontingency_table &lt;- table(data$var1, data$var2)\n\n# 查看列联表\ncontingency_table\n\n# 执行卡方独立性检验\nchi_result &lt;- chisq.test(contingency_table)\nprint(chi_result)\n\n# 查看卡方检验的详细结果\nchi_result$expected  # 期望频数\nchi_result$observed  # 观察频数\nchi_result$residuals  # 残差\nchi_result$stdres  # 标准化残差（&gt;1.96或&lt;-1.96表示在5%水平上显著）\n\n示例1：性别与产品偏好的关系\n\n# 创建示例数据\nset.seed(123)\nn &lt;- 500\ngender &lt;- sample(c(\"男\", \"女\"), n, replace = TRUE, prob = c(0.45, 0.55))\nproduct &lt;- sample(c(\"A\", \"B\", \"C\"), n, replace = TRUE)\n\n# 使偏好有一定关联性（非独立）\nproduct[gender == \"男\" & product == \"A\"] &lt;- sample(\n  c(\"A\", \"B\", \"C\"), sum(gender == \"男\" & product == \"A\"), \n  replace = TRUE, prob = c(0.6, 0.3, 0.1))\nproduct[gender == \"女\" & product == \"B\"] &lt;- sample(\n  c(\"A\", \"B\", \"C\"), sum(gender == \"女\" & product == \"B\"), \n  replace = TRUE, prob = c(0.3, 0.2, 0.5))\n\n# 创建数据框\npreference_data &lt;- data.frame(gender = gender, product = product)\n\n# 创建列联表\ngender_product_table &lt;- table(preference_data$gender, preference_data$product)\nprint(gender_product_table)\n\n# 计算比例\nprop.table(gender_product_table, margin = 1)  # 行比例（按性别）\nprop.table(gender_product_table, margin = 2)  # 列比例（按产品）\n\n# 可视化列联表\nlibrary(ggplot2)\n\n# 转换成数据框\ntable_df &lt;- as.data.frame(gender_product_table)\nnames(table_df) &lt;- c(\"gender\", \"product\", \"frequency\")\n\n# 条形图\nggplot(table_df, aes(x = product, y = frequency, fill = gender)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"性别与产品偏好的关系\",\n       x = \"产品\", y = \"频数\") +\n  theme_minimal()\n\n# 马赛克图\nlibrary(vcd)\nmosaic(gender_product_table, shade = TRUE, legend = TRUE)\n\n# 执行卡方独立性检验\nchi_gender_product &lt;- chisq.test(gender_product_table)\nprint(chi_gender_product)\n\n# 分析残差以确定哪些单元格对卡方统计量贡献最大\nround(chi_gender_product$stdres, 2)  # 标准化残差\n\n示例2：教育水平与收入等级的关系\n\n# 创建更实际的示例数据\nset.seed(456)\nn &lt;- 600\n\n# 教育水平与收入有一定关联（高教育水平对应高收入概率更大）\neducation &lt;- sample(c(\"高中\", \"本科\", \"硕士\", \"博士\"), n, replace = TRUE, \n                    prob = c(0.3, 0.4, 0.2, 0.1))\n\n# 基于教育水平生成收入水平\nincome &lt;- character(n)\nfor(i in 1:n) {\n  if(education[i] == \"高中\") {\n    income[i] &lt;- sample(c(\"低\", \"中\", \"高\"), 1, prob = c(0.6, 0.3, 0.1))\n  } else if(education[i] == \"本科\") {\n    income[i] &lt;- sample(c(\"低\", \"中\", \"高\"), 1, prob = c(0.3, 0.5, 0.2))\n  } else if(education[i] == \"硕士\") {\n    income[i] &lt;- sample(c(\"低\", \"中\", \"高\"), 1, prob = c(0.1, 0.4, 0.5))\n  } else {  # 博士\n    income[i] &lt;- sample(c(\"低\", \"中\", \"高\"), 1, prob = c(0.05, 0.25, 0.7))\n  }\n}\n\neducation_income_data &lt;- data.frame(education = education, income = income)\n\n# 创建列联表\neducation_income_table &lt;- table(education_income_data$education, \n                               education_income_data$income)\nprint(education_income_table)\n\n# 转换教育水平和收入为有序因子\neducation_income_data$education &lt;- factor(education_income_data$education, \n                                        levels = c(\"高中\", \"本科\", \"硕士\", \"博士\"))\neducation_income_data$income &lt;- factor(education_income_data$income, \n                                     levels = c(\"低\", \"中\", \"高\"))\n\n# 创建堆叠条形图\nedu_inc_prop &lt;- prop.table(table(education_income_data$education, \n                               education_income_data$income), margin = 1)\nedu_inc_df &lt;- as.data.frame(edu_inc_prop)\nnames(edu_inc_df) &lt;- c(\"education\", \"income\", \"proportion\")\n\nggplot(edu_inc_df, aes(x = education, y = proportion, fill = income)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"教育水平与收入等级的关系\",\n       x = \"教育水平\", y = \"比例\") +\n  scale_fill_brewer(palette = \"Blues\") +\n  theme_minimal()\n\n# 执行卡方独立性检验\nchi_edu_income &lt;- chisq.test(education_income_table)\nprint(chi_edu_income)\n\n# 标准化残差分析\nround(chi_edu_income$stdres, 2)\n\n# 计算关联强度指标 - Cramer's V\n# Cramer's V取值范围为[0,1]，越接近1表示关联越强\nlibrary(vcd)\nassocstats(education_income_table)\n\n示例3：营销渠道与转化率的关系\n\n# 创建营销渠道与转化结果的数据\nchannels &lt;- c(\"社交媒体\", \"电子邮件\", \"搜索引擎\", \"展示广告\", \"推荐\")\nconversions &lt;- c(\"是\", \"否\")\n\n# 创建有一定关联性的数据\nconversion_data &lt;- data.frame(\n  channel = rep(channels, c(150, 200, 180, 120, 100)),\n  converted = c(\n    sample(conversions, 150, replace = TRUE, prob = c(0.15, 0.85)),  # 社交媒体\n    sample(conversions, 200, replace = TRUE, prob = c(0.25, 0.75)),  # 电子邮件\n    sample(conversions, 180, replace = TRUE, prob = c(0.20, 0.80)),  # 搜索引擎\n    sample(conversions, 120, replace = TRUE, prob = c(0.10, 0.90)),  # 展示广告\n    sample(conversions, 100, replace = TRUE, prob = c(0.30, 0.70))   # 推荐\n  )\n)\n\n# 创建列联表\nchannel_conversion_table &lt;- table(conversion_data$channel, conversion_data$converted)\nprint(channel_conversion_table)\n\n# 计算转化率\nconversion_rates &lt;- prop.table(channel_conversion_table, margin = 1)[, \"是\"]\nconversion_rates_df &lt;- data.frame(\n  channel = names(conversion_rates),\n  rate = as.numeric(conversion_rates)\n)\n\n# 可视化转化率\nggplot(conversion_rates_df, aes(x = channel, y = rate, fill = channel)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = sprintf(\"%.1f%%\", rate * 100)), vjust = -0.5) +\n  labs(title = \"不同营销渠道的转化率\",\n       x = \"营销渠道\", y = \"转化率\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n# 执行卡方独立性检验\nchi_channel_conversion &lt;- chisq.test(channel_conversion_table)\nprint(chi_channel_conversion)\n\n# 标准化残差分析\nstd_res &lt;- round(chi_channel_conversion$stdres, 2)\nprint(std_res)\n\n# 商业分析解读\nif(chi_channel_conversion$p.value &lt; 0.05) {\n  cat(\"不同营销渠道的转化率存在显著差异。\\n\")\n  \n  # 找出转化率最高的渠道\n  best_channel &lt;- conversion_rates_df$channel[which.max(conversion_rates_df$rate)]\n  cat(paste0(\"'\", best_channel, \"' 渠道有最高的转化率，应考虑增加在该渠道的投入。\\n\"))\n  \n  # 找出转化率最低的渠道\n  worst_channel &lt;- conversion_rates_df$channel[which.min(conversion_rates_df$rate)]\n  cat(paste0(\"'\", worst_channel, \"' 渠道有最低的转化率，应重新评估或优化该渠道的营销策略。\\n\"))\n} else {\n  cat(\"不同营销渠道的转化率没有显著差异，可能需要检查其他因素。\\n\")\n}\n\n\n\n独立性检验的注意事项\n\n样本大小和期望频数：\n\n所有期望频数最好大于5\n如果期望频数较小，可使用Fisher精确检验替代卡方检验\n\n多重比较问题：\n\n进行多个独立卡方检验时，应考虑多重比较问题\n可使用Bonferroni校正等方法调整显著性水平\n\n因果关系推断限制：\n\n卡方检验只能说明变量间是否存在关联，不能确定因果关系\n关联不等于因果，需要结合专业知识和其他研究方法确定因果关系\n\n关联强度的衡量：\n\n卡方检验只能说明变量间是否存在关联，不能量化关联强度\n可使用其他指标如Cramer’s V、Phi系数、列联系数等量化关联强度\n\n\n\n\n相关分析（针对有序分类变量）\n相关分析的目的： - 衡量两个变量之间线性关系的强度和方向 - 量化两个变量一起变化的程度和方式\nPearson相关系数： - 适用于数值型变量（等距或比例尺度） - 衡量线性关系的强度和方向 - 取值范围[-1, 1] - 1表示完全正相关 - -1表示完全负相关 - 0表示无线性相关\nSpearman相关系数： - 适用于有序分类变量或非正态分布的数值型变量 - 基于变量的秩（rank）计算相关系数，对异常值不敏感 - 衡量单调关系（而非线性关系） - 取值范围与Pearson相关系数相同\nKendall’s tau相关系数： - 适用于有序变量，尤其是存在大量并列秩的情况 - 测量配对观测值的一致性 - 在小样本或存在并列值时比Spearman更稳健\n\n\nR语言实现相关分析\n基本实现方法：\n\n# Pearson相关系数\ncor(x, y, method = \"pearson\")\n\n# Spearman相关系数\ncor(x, y, method = \"spearman\")\n\n# Kendall's tau相关系数\ncor(x, y, method = \"kendall\")\n\n# 相关性检验\ncor.test(x, y, method = \"pearson\")  # 也可以是\"spearman\"或\"kendall\"\n\n示例1：顾客满意度与购买金额的相关性\n\n# 创建示例数据\nset.seed(789)\nn &lt;- 100\n\n# 创建有序变量和连续变量\nsatisfaction &lt;- sample(1:5, n, replace = TRUE,\n                      prob = c(0.05, 0.15, 0.30, 0.35, 0.15))  # 1-5的满意度等级\npurchase_amount &lt;- numeric(n)\n\n# 创建相关数据（满意度高的客户购买金额倾向于高）\nfor(i in 1:n) {\n  base_amount &lt;- 50 + satisfaction[i] * 10  # 基础金额随满意度增加\n  variation &lt;- rnorm(1, 0, 15)  # 随机变异\n  purchase_amount[i] &lt;- max(0, base_amount + variation)  # 确保金额为正\n}\n\ncustomer_data &lt;- data.frame(\n  satisfaction = satisfaction,\n  purchase_amount = purchase_amount\n)\n\n# 可视化数据\nggplot(customer_data, aes(x = factor(satisfaction), y = purchase_amount)) +\n  geom_boxplot(fill = \"skyblue\") +\n  labs(title = \"不同满意度等级的购买金额分布\",\n       x = \"满意度等级\", y = \"购买金额\") +\n  theme_minimal()\n\n# 散点图（加上抖动以显示相同等级的点）\nggplot(customer_data, aes(x = satisfaction, y = purchase_amount)) +\n  geom_point(position = position_jitter(width = 0.2), alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"满意度与购买金额的关系\",\n       x = \"满意度等级\", y = \"购买金额\") +\n  theme_minimal()\n\n# 计算Spearman相关系数（适用于有序变量）\nspearman_corr &lt;- cor(customer_data$satisfaction, \n                    customer_data$purchase_amount, \n                    method = \"spearman\")\nprint(paste(\"Spearman相关系数:\", round(spearman_corr, 3)))\n\n# 相关性显著性检验\nspearman_test &lt;- cor.test(customer_data$satisfaction, \n                         customer_data$purchase_amount, \n                         method = \"spearman\")\nprint(spearman_test)\n\n# 如果满意度编码为因子，可以先转换为数值\n# customer_data$satisfaction_num &lt;- as.numeric(as.character(customer_data$satisfaction))\n\n示例2：多变量相关性分析\n\n# 创建包含多个变量的示例数据集\nset.seed(101)\nn &lt;- 150\n\n# 创建变量\nage &lt;- sample(18:65, n, replace = TRUE)\nincome &lt;- 20000 + age * 500 + rnorm(n, 0, 5000)  # 收入与年龄正相关\neducation_years &lt;- 9 + sample(0:12, n, replace = TRUE, \n                            prob = c(0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05))\nspending &lt;- income * 0.2 + rnorm(n, 0, 2000)  # 支出与收入正相关\nsatisfaction &lt;- sample(1:10, n, replace = TRUE)  # 1-10的产品满意度\nloyalty_score &lt;- satisfaction * 0.8 + rnorm(n, 0, 1.5)  # 忠诚度与满意度正相关\nloyalty_score &lt;- pmax(1, pmin(10, round(loyalty_score)))  # 限制在1-10范围\n\nmulti_var_data &lt;- data.frame(\n  age = age,\n  income = income,\n  education_years = education_years,\n  spending = spending,\n  satisfaction = satisfaction,\n  loyalty_score = loyalty_score\n)\n\n# 计算相关矩阵\ncorrelation_matrix &lt;- cor(multi_var_data, method = \"spearman\")\nprint(round(correlation_matrix, 2))\n\n# 可视化相关矩阵\nlibrary(corrplot)\ncorrplot(correlation_matrix, method = \"circle\", type = \"upper\", \n         order = \"hclust\", tl.col = \"black\", tl.srt = 45)\n\n# 另一种可视化方式\nlibrary(ggcorrplot)\nggcorrplot(correlation_matrix, hc.order = TRUE, type = \"lower\",\n           lab = TRUE, lab_size = 3,\n           colors = c(\"#6D9EC1\", \"white\", \"#E46726\"))\n\n# 检验相关系数的显著性\ncorr_test_matrix &lt;- matrix(NA, nrow = ncol(multi_var_data), \n                         ncol = ncol(multi_var_data))\nfor(i in 1:ncol(multi_var_data)) {\n  for(j in 1:ncol(multi_var_data)) {\n    if(i != j) {\n      test_result &lt;- cor.test(multi_var_data[,i], multi_var_data[,j], \n                             method = \"spearman\")\n      corr_test_matrix[i,j] &lt;- test_result$p.value\n    }\n  }\n}\ncolnames(corr_test_matrix) &lt;- rownames(corr_test_matrix) &lt;- names(multi_var_data)\nprint(corr_test_matrix &lt; 0.05)  # TRUE表示相关性显著（p &lt; 0.05）\n\n示例3：有序分类变量的相关分析\n\n# 创建两个有序分类变量的示例数据\nset.seed(123)\nn &lt;- 120\n\n# 教育水平（1=高中, 2=本科, 3=硕士, 4=博士）\neducation_level &lt;- sample(1:4, n, replace = TRUE, prob = c(0.3, 0.4, 0.2, 0.1))\n\n# 职业等级（1=初级, 2=中级, 3=高级, 4=管理）- 与教育水平存在相关性\njob_level &lt;- numeric(n)\nfor(i in 1:n) {\n  if(education_level[i] == 1) {\n    job_level[i] &lt;- sample(1:4, 1, prob = c(0.6, 0.3, 0.08, 0.02))\n  } else if(education_level[i] == 2) {\n    job_level[i] &lt;- sample(1:4, 1, prob = c(0.3, 0.4, 0.25, 0.05))\n  } else if(education_level[i] == 3) {\n    job_level[i] &lt;- sample(1:4, 1, prob = c(0.1, 0.3, 0.4, 0.2))\n  } else { # education_level = 4\n    job_level[i] &lt;- sample(1:4, 1, prob = c(0.05, 0.15, 0.4, 0.4))\n  }\n}\n\nordinal_data &lt;- data.frame(\n  education_level = factor(education_level, levels = 1:4,\n                          labels = c(\"高中\", \"本科\", \"硕士\", \"博士\")),\n  job_level = factor(job_level, levels = 1:4,\n                    labels = c(\"初级\", \"中级\", \"高级\", \"管理\"))\n)\n\n# 创建列联表\nordinal_table &lt;- table(ordinal_data$education_level, ordinal_data$job_level)\nprint(ordinal_table)\n\n# 可视化\nggplot(ordinal_data, aes(x = education_level, fill = job_level)) +\n  geom_bar(position = \"fill\") +\n  labs(title = \"教育水平与职业等级的关系\",\n       x = \"教育水平\", y = \"比例\",\n       fill = \"职业等级\") +\n  theme_minimal()\n\n# 将有序因子转换为数值以进行相关分析\neducation_num &lt;- as.numeric(ordinal_data$education_level)\njob_num &lt;- as.numeric(ordinal_data$job_level)\n\n# 计算Spearman相关系数\nspearman_ordinal &lt;- cor.test(education_num, job_num, method = \"spearman\")\nprint(paste(\"Spearman相关系数:\", round(spearman_ordinal$estimate, 3)))\nprint(paste(\"p值:\", spearman_ordinal$p.value))\n\n# 计算Kendall's tau相关系数\nkendall_ordinal &lt;- cor.test(education_num, job_num, method = \"kendall\")\nprint(paste(\"Kendall's tau相关系数:\", round(kendall_ordinal$estimate, 3)))\nprint(paste(\"p值:\", kendall_ordinal$p.value))\n\n# 解释结果\nif(spearman_ordinal$p.value &lt; 0.05) {\n  if(spearman_ordinal$estimate &gt; 0) {\n    cat(\"教育水平与职业等级存在显著的正相关关系。教育水平越高，获得高职业等级的可能性越大。\\n\")\n  } else {\n    cat(\"教育水平与职业等级存在显著的负相关关系。这一发现可能需要进一步调查。\\n\")\n  }\n  \n  # 相关强度解释\n  corr_strength &lt;- abs(spearman_ordinal$estimate)\n  if(corr_strength &lt; 0.3) {\n    cat(\"相关强度弱。\\n\")\n  } else if(corr_strength &lt; 0.7) {\n    cat(\"相关强度中等。\\n\")\n  } else {\n    cat(\"相关强度强。\\n\")\n  }\n} else {\n  cat(\"教育水平与职业等级之间没有显著的相关关系。\\n\")\n}\n\n\n\n分类数据分析在商业中的实际应用\n市场研究案例：\n\n# 市场细分分析 - 检验年龄段与购买渠道的关系\nage_groups &lt;- c(\"18-24岁\", \"25-34岁\", \"35-44岁\", \"45-54岁\", \"55岁以上\")\nchannels &lt;- c(\"实体店\", \"官方网站\", \"电商平台\", \"社交媒体\")\n\n# 创建观察数据（基于真实市场研究）\nmarket_data &lt;- matrix(c(\n  45, 80, 65, 30,    # 18-24岁各渠道购买人数\n  70, 120, 90, 50,   # 25-34岁各渠道购买人数\n  90, 85, 70, 25,    # 35-44岁各渠道购买人数\n  75, 45, 40, 10,    # 45-54岁各渠道购买人数\n  60, 20, 15, 5      # 55岁以上各渠道购买人数\n), nrow = 5, byrow = TRUE)\n\nrownames(market_data) &lt;- age_groups\ncolnames(market_data) &lt;- channels\n\n# 转换为数据框用于可视化\nmarket_df &lt;- as.data.frame.table(market_data)\nnames(market_df) &lt;- c(\"age_group\", \"channel\", \"frequency\")\n\n# 各年龄段的渠道偏好可视化\nggplot(market_df, aes(x = age_group, y = frequency, fill = channel)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"不同年龄段的购买渠道偏好\",\n       x = \"年龄段\", y = \"购买人数\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n# 各年龄段的渠道比例可视化\nggplot(market_df, aes(x = age_group, y = frequency, fill = channel)) +\n  geom_bar(stat = \"identity\", position = \"fill\") +\n  labs(title = \"不同年龄段的购买渠道比例\",\n       x = \"年龄段\", y = \"比例\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n# 执行卡方独立性检验\nchi_market &lt;- chisq.test(market_data)\nprint(chi_market)\n\n# 分析残差\nround(chi_market$stdres, 2)\n\n# 可视化标准化残差\nresidual_df &lt;- as.data.frame.table(chi_market$stdres)\nnames(residual_df) &lt;- c(\"age_group\", \"channel\", \"stdres\")\n\nggplot(residual_df, aes(x = age_group, y = channel, fill = stdres)) +\n  geom_tile() +\n  scale_fill_gradient2(low = \"blue\", high = \"red\", mid = \"white\", \n                      midpoint = 0, limit = c(-4, 4)) +\n  geom_text(aes(label = round(stdres, 1))) +\n  labs(title = \"年龄段与购买渠道关系的标准化残差\",\n       subtitle = \"正值(红色)表示频率高于期望，负值(蓝色)表示频率低于期望\",\n       x = \"年龄段\", y = \"购买渠道\") +\n  theme_minimal()\n\n# 基于分析结果的营销策略建议\ncat(\"市场细分分析结果与营销策略建议：\\n\\n\")\n\nif(chi_market$p.value &lt; 0.05) {\n  cat(\"年龄段与购买渠道之间存在显著关联。\\n\")\n  \n  # 分析每个年龄段的主要渠道\n  for(i in 1:length(age_groups)) {\n    preferred_channel &lt;- channels[which.max(market_data[i,])]\n    cat(paste0(age_groups[i], \"顾客更偏好通过\", preferred_channel, \n              \"购买，应针对性地在该渠道增加对应年龄段的营销投入。\\n\"))\n  }\n  \n  # 分析每个渠道的主要年龄段\n  for(j in 1:length(channels)) {\n    main_age &lt;- age_groups[which.max(market_data[,j])]\n    cat(paste0(channels[j], \"渠道主要吸引\", main_age, \n              \"顾客，可针对这一年龄段特点优化该渠道的用户体验和产品展示。\\n\"))\n  }\n  \n  # 发现潜在机会\n  neg_res &lt;- which(chi_market$stdres &lt; -2, arr.ind = TRUE)\n  if(nrow(neg_res) &gt; 0) {\n    for(k in 1:nrow(neg_res)) {\n      cat(paste0(age_groups[neg_res[k,1]], \"在\", channels[neg_res[k,2]], \n                \"渠道的使用显著低于预期，这可能是一个需要探索的市场机会。\\n\"))\n    }\n  }\n} else {\n  cat(\"年龄段与购买渠道之间没有显著关联，可能需要考虑其他因素进行市场细分。\\n\")\n}\n\n\n\n综合练习\n练习1：拟合优度检验 分析某地区人口不同年龄段的分布是否符合历史数据\n练习2：独立性检验 分析用户学历与对某品牌产品满意度是否独立\n练习3：相关分析 分析有序变量（如满意度等级、教育水平、收入水平）之间的关系\n\n\n\n\n\n\nAI辅助学习建议（第七周）\n\n\n\n\n分类数据理解与解释\n\n请AI解释分类数据特点：要求AI比较分类数据与连续数据的区别及分析方法差异\n让AI解释卡方检验原理：通过通俗易懂的例子理解卡方检验的统计思想\n要求AI解释统计显著性与业务显著性：理解p值小于0.05但实际业务影响可能不大的情况\n\n\n\nR代码编写与应用\n\n请AI生成完整的卡方检验分析流程：从数据探索、检验假设到结果解释的全流程代码\n让AI编写更高级的可视化代码：创建更专业的分类数据可视化图表\n要求AI编写残差分析代码：通过残差分析找出对总体关系贡献最大的类别组合\n\n\n\n结果解读与决策支持\n\n请AI解释卡方检验结果：将统计输出转化为业务语言和建议\n让AI分析相关系数的实际意义：解释不同强度相关系数的业务含义\n要求AI提供基于分析结果的具体行动建议：将统计分析转化为可执行的商业决策\n\n\n\n分类数据分析应用场景\n\n请AI推荐适合的业务问题：根据项目主题获取适合应用分类数据分析的问题建议\n让AI设计市场调研问卷：针对特定业务问题设计合适的分类数据收集方案\n要求AI解释分类数据分析的局限性：了解何时需要补充其他分析方法\n\n\n\n\n\n\n参考文献与扩展阅读\n\nAgresti, A. (2018). An Introduction to Categorical Data Analysis (3rd ed.). Wiley.\nFriendly, M. (2000). Visualizing Categorical Data. SAS Institute.\nR Core Team. (2021). R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing.\nMeyer, D., Zeileis, A., & Hornik, K. (2006). The Strucplot Framework: Visualizing Multi-way Contingency Tables with vcd. Journal of Statistical Software.\n张敏杰. (2019). 分类数据分析在市场研究中的应用. 统计与信息论坛, 34(8), 102-107.",
    "crumbs": [
      "项目二：商业数据分析与统计推断",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>第七周：分类数据分析</span>"
    ]
  },
  {
    "objectID": "week8.html",
    "href": "week8.html",
    "title": "第八周：项目二总结与汇报",
    "section": "",
    "text": "第十五次课：非参数检验方法简介",
    "crumbs": [
      "项目二：商业数据分析与统计推断",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>第八周：项目二总结与汇报</span>"
    ]
  },
  {
    "objectID": "week8.html#第十五次课非参数检验方法简介",
    "href": "week8.html#第十五次课非参数检验方法简介",
    "title": "第八周：项目二总结与汇报",
    "section": "",
    "text": "非参数检验方法概述\n参数检验与非参数检验比较： - 参数检验：基于总体分布类型的假设（通常是正态分布），对总体参数（如均值、方差等）进行推断，数据需满足严格的分布假设 - 非参数检验：不依赖于总体分布类型的假设，适用范围更广，对数据分布的要求较低，更加稳健 - 比较优势： - 参数检验优势：当数据满足假设条件时，参数检验通常具有更高的统计效能（检验力） - 非参数检验优势：对异常值不敏感，适用于有序数据，无需满足正态性假设，应用更广泛\n非参数检验的应用场景： - 数据不符合正态分布假设 - 数据是等级数据或顺序数据（有序分类变量） - 样本量较小（n &lt; 30） - 存在异常值或偏态分布 - 需要检验中位数而非均值 - 数据测量尺度为等级尺度或名义尺度\n常用的非参数检验方法： - Wilcoxon符号秩检验：单样本或配对样本中位数检验 - Wilcoxon秩和检验（Mann-Whitney U检验）：独立样本中位数检验 - Kruskal-Wallis检验：多组独立样本中位数检验 - Friedman检验：多组配对样本比较 - Spearman秩相关系数：非参数相关分析 - 符号检验：中位数检验的简单方法\n\n\nWilcoxon符号秩检验\n适用场景： - 单样本中位数检验：检验样本是否来自中位数等于某个特定值的总体 - 配对样本中位数差检验：检验配对样本的差值中位数是否为0 - 替代：单样本t检验和配对样本t检验的非参数替代方法\n检验原理： 1. 对于单样本检验，计算每个观测值与假设中位数的差值 2. 对于配对样本检验，计算每对观测值的差值 3. 忽略差值为0的观测 4. 对非零差值的绝对值进行排序并赋予秩次 5. 计算带符号秩和作为检验统计量\n假设检验： - 原假设(H0)：中位数等于指定值（单样本）或差值的中位数为0（配对样本） - 备择假设(H1)：中位数不等于指定值或差值的中位数不为0（也可设置单侧检验）\nR语言实现：\n\n# 单样本Wilcoxon符号秩检验\nwilcox.test(x, mu = 0)\n\n# 配对样本Wilcoxon符号秩检验\nwilcox.test(x, y, paired = TRUE)\n\n# 可设置替代假设类型\nwilcox.test(x, y, paired = TRUE, alternative = \"less\") # 单侧检验H1: 差值中位数&lt;0\nwilcox.test(x, y, paired = TRUE, alternative = \"greater\") # 单侧检验H1: 差值中位数&gt;0\n\n实例：消费者满意度评价\n\n# 假设数据：新产品满意度评分（1-10分）\nset.seed(123)\nnew_product_ratings &lt;- c(7, 8, 9, 6, 8, 7, 9, 8, 10, 7, 8, 9, 7, 8, 6)\n\n# 检验中位数是否高于行业标准7.5分\nwilcox.test(new_product_ratings, mu = 7.5, alternative = \"greater\")\n\n# 假设另一组数据：产品改进前后满意度对比\nbefore_improvement &lt;- c(6, 7, 5, 8, 6, 7, 5, 6, 7, 8, 6, 5, 7, 6, 7)\nafter_improvement &lt;- c(7, 8, 7, 9, 8, 8, 6, 7, 8, 9, 7, 6, 8, 7, 8)\n\n# 检验产品改进是否提高了满意度\nwilcox.test(before_improvement, after_improvement, paired = TRUE, \n            alternative = \"less\") # H1: 改进前&lt;改进后\n\n# 解释结果\n# p-value &lt; 0.05表示拒绝H0，即改进确实提高了满意度\n\n\n\nWilcoxon秩和检验（Mann-Whitney U检验）\n适用场景： - 独立样本中位数检验：检验两个独立样本是否来自中位数相等的总体 - 替代：独立样本t检验的非参数替代方法 - 适用于样本量较小或数据不符合正态性假设的情况\n检验原理： 1. 将两组样本合并后进行排序 2. 给每个观测值赋予秩次 3. 计算各组的秩和 4. 基于秩和计算检验统计量U值\n假设检验： - 原假设(H0)：两组样本来自相同分布（具有相等的中位数） - 备择假设(H1)：两组样本来自不同分布（中位数不等）\nR语言实现：\n\n# Wilcoxon秩和检验/Mann-Whitney U检验\nwilcox.test(x, y)\n\n# 单侧检验\nwilcox.test(x, y, alternative = \"less\") # H1: x分布&lt;y分布\nwilcox.test(x, y, alternative = \"greater\") # H1: x分布&gt;y分布\n\n实例：不同市场策略效果比较\n\n# 假设数据：两种市场策略的转化率（%）\nstrategyA &lt;- c(5.2, 4.8, 6.3, 5.5, 4.9, 5.8, 5.1, 6.0, 5.3, 4.7)\nstrategyB &lt;- c(6.5, 7.2, 5.9, 6.8, 7.5, 6.2, 7.1, 6.7, 7.3, 6.9)\n\n# 检验策略B是否比策略A效果更好\nresult &lt;- wilcox.test(strategyA, strategyB, alternative = \"less\")\nprint(result)\n\n# 可视化比较\nboxplot(strategyA, strategyB, names = c(\"策略A\", \"策略B\"),\n        col = c(\"lightblue\", \"lightgreen\"),\n        main = \"两种市场策略转化率对比\",\n        ylab = \"转化率(%)\")\n\n# 如果p值&lt;0.05，可得出结论：策略B的转化率显著高于策略A\nif(result$p.value &lt; 0.05) {\n  cat(\"统计结果显示：策略B的转化率显著高于策略A，建议采用策略B\")\n} else {\n  cat(\"统计结果显示：未能证明策略B的转化率显著高于策略A，需要进一步研究\")\n}\n\n\n\nKruskal-Wallis检验\n适用场景： - 多组独立样本中位数检验：检验多组独立样本是否来自中位数相等的总体 - 可视为Wilcoxon秩和检验的扩展，用于多组比较 - 替代：单因素方差分析(ANOVA)的非参数替代方法\n检验原理： 1. 将所有样本合并后进行排序 2. 给每个观测值赋予秩次 3. 计算各组的平均秩次 4. 基于组间平均秩次的差异计算H统计量（近似卡方分布）\n假设检验： - 原假设(H0)：所有组别样本来自相同分布（具有相等的中位数） - 备择假设(H1)：至少有一对组别样本来自不同分布（中位数不等）\nR语言实现：\n\n# Kruskal-Wallis检验\nkruskal.test(y ~ group)\n\n# 事后多重比较（如果Kruskal-Wallis检验显著）\n# 需要安装dunn.test包\n# install.packages(\"dunn.test\")\nlibrary(dunn.test)\ndunn.test(y, group, method = \"bonferroni\")\n\n实例：不同广告渠道效果比较\n\n# 假设数据：四种广告渠道的点击率(%)\nsocial_media &lt;- c(2.8, 3.2, 2.5, 3.0, 2.9, 3.1, 2.7, 3.3)\nemail &lt;- c(3.5, 4.0, 3.8, 3.6, 4.2, 3.9, 3.7, 4.1)\nsearch_ads &lt;- c(4.5, 5.0, 4.8, 4.6, 5.2, 4.9, 4.7, 5.1)\ndisplay_ads &lt;- c(1.8, 2.1, 1.7, 2.0, 1.9, 2.2, 1.6, 2.3)\n\n# 合并数据\nclick_rates &lt;- c(social_media, email, search_ads, display_ads)\nchannels &lt;- factor(rep(c(\"社交媒体\", \"电子邮件\", \"搜索广告\", \"展示广告\"), \n                       each = length(social_media)))\n\n# 执行Kruskal-Wallis检验\nkw_result &lt;- kruskal.test(click_rates ~ channels)\nprint(kw_result)\n\n# 可视化比较\nboxplot(click_rates ~ channels, col = rainbow(4),\n        main = \"不同广告渠道点击率对比\",\n        xlab = \"广告渠道\", ylab = \"点击率(%)\")\n\n# 若Kruskal-Wallis检验显著，进行多重比较\nif(kw_result$p.value &lt; 0.05) {\n  # install.packages(\"dunn.test\") # 若未安装\n  library(dunn.test)\n  dunn_result &lt;- dunn.test(click_rates, channels, method = \"bonferroni\")\n  \n  # 解释结果\n  cat(\"统计结果显示：不同广告渠道的点击率存在显著差异\\n\")\n  # 确定性能最佳的渠道\n  means &lt;- tapply(click_rates, channels, mean)\n  best_channel &lt;- names(means)[which.max(means)]\n  cat(\"其中，\", best_channel, \"的平均点击率最高，建议增加该渠道的投入\\n\")\n}\n\n\n\n非参数相关分析：Spearman秩相关系数\n适用场景： - 衡量两个变量之间单调关系（不一定是线性）的强度 - 适用于等级数据或不符合正态分布的数值数据 - 替代：Pearson相关系数的非参数替代方法 - 对异常值不敏感\n计算原理： 1. 将两个变量分别转换为秩次 2. 计算秩次之间的Pearson相关系数\n假设检验： - 原假设(H0)：两个变量之间不存在单调关系（相关系数为0） - 备择假设(H1)：两个变量之间存在单调关系（相关系数不为0）\nR语言实现：\n\n# 计算Spearman相关系数\ncor(x, y, method = \"spearman\")\n\n# 相关性显著性检验\ncor.test(x, y, method = \"spearman\")\n\n实例：品牌认知度与购买意愿的关系\n\n# 假设数据：消费者对10个品牌的认知度评分和购买意愿评分（1-10分）\nset.seed(123)\nbrand_awareness &lt;- c(8, 6, 9, 7, 5, 4, 8, 9, 6, 7)\npurchase_intention &lt;- c(7, 5, 9, 6, 4, 3, 7, 8, 6, 8)\n\n# 计算Spearman相关系数并检验显著性\nspearman_result &lt;- cor.test(brand_awareness, purchase_intention, method = \"spearman\")\nprint(spearman_result)\n\n# 可视化相关关系\nlibrary(ggplot2)\nbrand_data &lt;- data.frame(awareness = brand_awareness, intention = purchase_intention)\nggplot(brand_data, aes(x = awareness, y = intention)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"loess\", se = FALSE, color = \"blue\") +\n  labs(title = \"品牌认知度与购买意愿的关系\",\n       x = \"品牌认知度评分\", y = \"购买意愿评分\") +\n  theme_minimal()\n\n# 解释结果\nrho &lt;- round(spearman_result$estimate, 2)\np_value &lt;- spearman_result$p.value\n\ncat(paste0(\"Spearman相关系数: \", rho, \"\\n\"))\ncat(paste0(\"p值: \", p_value, \"\\n\"))\n\nif(p_value &lt; 0.05) {\n  if(rho &gt; 0) {\n    cat(\"统计结果显示：品牌认知度与购买意愿存在显著的正相关关系\\n\")\n    cat(\"营销建议：提高品牌认知度有望提升消费者购买意愿，应加强品牌推广\\n\")\n  } else {\n    cat(\"统计结果显示：品牌认知度与购买意愿存在显著的负相关关系，这是意外发现\\n\")\n    cat(\"需要进一步调查这一现象的原因\\n\")\n  }\n} else {\n  cat(\"统计结果显示：品牌认知度与购买意愿之间没有发现显著的相关关系\\n\")\n  cat(\"营销建议：需要探索其他可能影响购买意愿的因素\\n\")\n}\n\n\n\n非参数检验在商业分析中的应用\n市场研究： - 评估不同市场细分的客户满意度差异 - 比较不同群体对新产品的接受度 - 分析不同区域的消费者行为模式 - 评估营销活动前后的品牌态度变化\n金融分析： - 比较不同投资策略的收益率表现 - 评估异常市场条件下的投资组合表现 - 分析市场波动性与其他经济指标的关系 - 研究股票价格走势与行业指数的关联\n人力资源： - 比较不同培训方法对员工绩效的影响 - 分析薪资水平与工作满意度的关系 - 评估不同领导风格对团队效率的影响 - 研究工作环境变化对员工士气的影响\n运营管理： - 比较不同供应商的产品质量 - 评估流程改进前后的效率变化 - 分析客户服务满意度与响应时间的关系 - 研究不同库存管理策略的效果\n\n\n非参数检验方法选择指南\n单样本分析： - 检验中位数是否等于特定值：Wilcoxon符号秩检验或符号检验\n两组样本比较： - 配对样本比较（前后测试）：Wilcoxon符号秩检验 - 独立样本比较（两组对比）：Wilcoxon秩和检验（Mann-Whitney U检验）\n多组样本比较： - 独立多组比较：Kruskal-Wallis检验（通常后跟Dunn检验进行多重比较） - 配对多组比较：Friedman检验\n相关分析： - 有序变量或非正态分布变量：Spearman秩相关系数 - 二元变量（2×2表）：Phi系数 - 基于等级的关联度量：Kendall’s tau系数\n\n\nR语言实现非参数检验的注意事项\n\n数据准备：\n\n确保数据格式正确，特别是因子变量的水平设置\n处理缺失值（NA）\n检查异常值对结果的潜在影响\n\n解释统计结果：\n\np值显著性判断（通常α=0.05）\n考虑效应大小，而不仅仅是统计显著性\n理解非参数检验的统计功效\n\n多重比较问题：\n\n当进行多次检验时，考虑多重比较校正\n使用Bonferroni、Holm或FDR等方法调整p值\n避免第一类错误累积\n\n可视化辅助：\n\n使用箱线图、小提琴图等直观展示数据分布\n通过图形验证结果的实际意义\n结合描述性统计解释检验结果\n\n\n\n\n\n\n\n\nAI辅助学习建议（第八周：非参数检验）\n\n\n\n\n概念理解与方法选择\n\n请AI解释非参数检验的核心思想：要求AI使用简单易懂的比喻解释非参数检验与参数检验的区别\n让AI创建决策树：基于数据特征和研究问题，帮助选择合适的非参数检验方法\n要求AI比较检验效能：在不同样本大小和分布条件下，比较参数检验和对应的非参数检验的效能\n\n\n\nR代码编写与结果解释\n\n请AI生成完整的非参数检验分析流程：从数据探索、异常值检测、检验方法选择到结果解释的R代码\n让AI解释复杂的检验结果：将统计输出转化为商业语言，解释结果的实际意义\n要求AI编写多组比较的代码：针对Kruskal-Wallis检验后的事后多重比较分析\n\n\n\n案例分析与商业应用\n\n请AI提供行业特定案例：生成符合你项目主题的非参数检验应用示例\n让AI提出商业建议：基于非参数检验结果，提供具体的商业决策建议\n要求AI评估决策风险：解释在不同显著性水平下做决策的风险与收益\n\n\n\n数据可视化提升\n\n请AI优化非参数检验结果的可视化：生成更专业、更有说服力的图表代码\n让AI创建交互式可视化代码：使用plotly等包创建可交互的检验结果展示\n要求AI设计结果报告模板：创建一个专业的非参数检验结果报告框架",
    "crumbs": [
      "项目二：商业数据分析与统计推断",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>第八周：项目二总结与汇报</span>"
    ]
  },
  {
    "objectID": "week8.html#第十六次课项目二成果汇报与展示",
    "href": "week8.html#第十六次课项目二成果汇报与展示",
    "title": "第八周：项目二总结与汇报",
    "section": "第十六次课：项目二成果汇报与展示",
    "text": "第十六次课：项目二成果汇报与展示\n\n项目汇报流程\n小组汇报： - 每组15分钟汇报时间（包括展示和答辩） - 所有组员共同参与\n汇报内容要求： 1. 项目背景与目标 - 清晰说明项目主题和研究问题 - 阐述项目的商业意义\n\n数据来源与描述\n\n介绍数据的收集方式\n描述数据特征（样本量、变量类型、基本统计量等）\n展示数据清洗与预处理的过程\n\n研究方法\n\n描述所选择的统计分析方法\n解释模型建立的过程与原理\n说明方法选择的合理性\n\n结果展示与分析\n\n呈现关键的统计结果\n使用图表直观展示分析发现\n解释结果的统计和商业意义\n\n结论与建议\n\n总结主要发现\n提出基于数据分析的商业建议\n分析结论的可靠性和局限性\n\n项目总结\n\n项目亮点与创新点\n遇到的挑战及解决方法\n项目经验与反思\n\n\n\n\n评分标准\n内容（50%）： - 问题定义的清晰度和相关性 - 数据分析方法的适当性 - 结论的合理性和洞察性 - 商业建议的实用性\n技术（30%）： - 统计方法应用的准确性 - 数据处理的规范性 - 结果呈现的清晰度和专业性\n展示（20%）： - 演讲的组织性和清晰度 - 展示材料的设计和品质 - 回答问题的能力 - 团队协作表现\n\n\n项目成果要求\n分析报告： - 完整记录分析过程和结果 - 包含所有相关代码和图表 - 格式规范，逻辑清晰\n演示文稿： - 重点突出，内容精炼 - 图表专业，设计美观 - 符合学术报告规范\n代码文件： - 提交完整、可运行的代码 - 代码注释充分，结构清晰 - 实现数据分析的全流程\n\n\n项目反思与总结\n学习收获： - 统计理论知识的实践应用 - 数据分析能力的提升 - 团队协作经验\n挑战与解决方案： - 数据获取与处理的挑战 - 统计模型选择与优化 - 结果解释与商业转化\n未来提升方向： - 深入学习高级统计方法 - 提升数据可视化技能 - 加强商业问题理解能力",
    "crumbs": [
      "项目二：商业数据分析与统计推断",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>第八周：项目二总结与汇报</span>"
    ]
  }
]