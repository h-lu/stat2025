---
title: "第二周：R语言数据导入与数据初步理解"
---

::: {.callout-tip appearance="simple"}
## 本周学习目标

*   学习**R语言数据导入**，掌握 `readr` 包常用函数
*   学会用 R **初步查看和理解数据**
*   了解**数据类型**和**数据质量**的概念，能发现一些常见的数据问题
*   学习计算**描述性统计量**，初步认识数据
*   初步掌握 `dplyr` 包的**列选择**和**行筛选**技能
:::

## 第三次课：数据获取与R语言数据导入

::: {.callout-note}
### 项目小组讨论：确定数据来源和获取方案

**小组交流**：  大家分享上周找到的数据资源，互相看看有什么好的数据集或者 API。

**一起讨论**：
*   看看大家找的数据怎么样，靠不靠谱。
*   **重点是确定怎么拿到数据**：
    *   如果是公开数据集，怎么下载，数据长什么样。
    *   如果是 API，怎么注册账号，API 怎么用，先简单了解一下。
*   **选数据的时候，要考虑能不能快速拿到数据**，别选太难搞的。
*   **互相学习**：  大家可以互相交流经验，看看别人是怎么找数据、拿数据的。
:::

### 数据获取实践：常用方法

#### 公开数据集
*   **常用网站**：
    *   **综合数据平台**：
        *   **Kaggle**:  [https://www.kaggle.com/datasets](https://www.kaggle.com/datasets) (全球综合性数据竞赛和数据集平台，需要注册账号)
        *   **阿里云天池**: [https://tianchi.aliyun.com/dataset](https://tianchi.aliyun.com/dataset) (阿里巴巴旗下数据竞赛和数据集平台，中文，需要注册账号)
        *   **DataFountain (DF 平台)**: [https://www.datafountain.cn/datasets](https://www.datafountain.cn/datasets) (中国的数据竞赛和数据集平台，中文)
    *   **政府开放数据平台**：
        *   **中国政府数据开放平台**: [http://data.gov.cn/](http://data.gov.cn/) (国家级政府数据开放平台，覆盖多领域)
        *   **北京市政府数据开放平台**: [https://data.beijing.gov.cn/](https://data.beijing.gov.cn/) (省级/市级政府数据平台示例，中文)
        *   **中国政府信息公开**:  [https://www.gov.cn/zhengce/xxgk/](https://www.gov.cn/zhengce/xxgk/) (国务院政策文件等，政府信息公开)
        *   **美国政府开放数据**: [https://www.data.gov/](https://www.data.gov/) (政府公开数据示例，英文，可对比参考)
    *   **机构/组织数据平台**：
        *   **世界银行公开数据**: [https://data.worldbank.org/](https://data.worldbank.org/) (国际组织数据，多领域)
        *   **联合国数据**: [http://data.un.org/](http://data.un.org/) (国际组织数据，全球统计数据)
        *   **国家统计局**: [http://www.stats.gov.cn/](http://www.stats.gov.cn/) (中国国家统计数据，权威统计信息)
        *   **中国人民银行**: [http://www.pbc.gov.cn/](http://www.pbc.gov.cn/) (中国金融数据，金融统计信息)
    *   **特定领域数据平台**:
        *   **UCI Machine Learning Repository**: [https://archive.ics.uci.edu/datasets](https://archive.ics.uci.edu/datasets) (机器学习领域常用数据集，英文)
        *   **豆瓣电影、读书、音乐**:  [https://www.douban.com/](https://www.douban.com/) (中文电影、图书、音乐评分、评论等数据，可能需要爬虫或API)
        *   **Steam 游戏数据**: [https://store.steampowered.com/](https://store.steampowered.com/) (Steam 平台游戏信息，例如用户评价、游戏类型等，可能需要爬虫或API)

#### API (应用程序编程接口)
*   **API 是什么？**  API 可以理解为**网站或平台提供的数据接口**。通过 API，我们可以用**程序**（比如 R 代码）直接从网站服务器获取数据，而不需要手动下载文件。
*   **常用 API 平台**：
    *   **娱乐内容 API (音乐/电影/图书/游戏)**：
        *   **Spotify API**: [https://developer.spotify.com/documentation/web-api/](https://developer.spotify.com/documentation/web-api/) (获取 Spotify 音乐数据)
        *   **豆瓣 API** (非官方，但常用):  [https://developers.douban.com/wiki/?title=api_v2](https://developers.douban.com/wiki/?title=api_v2) (获取电影、图书、音乐数据)
        *   **OMDb API (电影)**: [http://www.omdbapi.com/](http://www.omdbapi.com/) (获取电影信息，免费 API，但有访问限制)
        *   **Steam API**: [https://steamapi.xpaw.me/](https://steamapi.xpaw.me/) (非官方 Steam API, 获取游戏信息和玩家数据)
        *   **RAWG API**: [https://rawg.io/apidocs](https://rawg.io/apidocs) (游戏数据库 API, 包含游戏信息、评测等)
    *   **金融数据 API**：
        *   **Yahoo Finance API** (非官方，但常用):  [https://finance.yahoo.com/quote/AAPL/history/](https://finance.yahoo.com/quote/AAPL/history/)  (获取股票市场数据)
        *   **Tushare**: [https://tushare.pro/](https://tushare.pro/) (中国股票、期货、宏观经济数据，需要注册账号)
        *   **Quandl (Nasdaq Data Link)**: [https://www.nasdaq.com/solutions/nasdaq-datalink](https://www.nasdaq.com/solutions/nasdaq-datalink) (各种金融和经济数据，部分免费，部分收费)
    *   **通用数据 API 平台**：
        *   **聚合数据**: [https://www.juhe.cn/](https://www.juhe.cn/) (提供各种生活、出行等 API，部分免费，部分收费)
        *   **Apipost**: [https://www.apipost.cn/api-store](https://www.apipost.cn/api-store) (API 商店，提供各种类型的 API)
    *   **实用工具 API**：
        *   **天气 API**：
            *   **OpenWeatherMap**: [https://openweathermap.org/api](https://openweathermap.org/api) (全球天气数据)
            *   **和风天气**: [https://dev.qweather.com/](https://dev.qweather.com/) (中国及全球天气数据)
        *   **地理编码 API (Geocoding API)**：
            *   **高德地图API**: [https://lbs.amap.com/api/webservice/guide/api/georegeo](https://lbs.amap.com/api/webservice/guide/api/georegeo) (地址和坐标转换，中国常用)
*   **如何使用 API 获取数据？**
    *   **注册 API 账号 (如果需要)**：  很多 API 平台需要注册账号并获取 API 密钥 (API Key) 才能使用。
    *   **阅读 API 文档**：  API 文档会告诉你如何发送 API 请求，需要哪些参数，以及 API 返回的数据格式。
    *   **使用 API 请求工具**：  可以使用 Postman 等工具测试 API 请求，或者在 R 中使用 `httr` 包发送 API 请求 (本周课不深入 `httr` 包的具体用法)。
    *   **AI 辅助**：  可以使用 Cursor, ChatGPT 等 AI 工具辅助理解 API 文档，生成 API 请求代码。 例如，让 AI 总结 API 文档的关键信息，或者解释 API 请求的参数含义。


### R语言数据导入进阶

在R语言中，`readr` 包提供了一系列高效读取各种文本数据文件的函数。最常用的包括：

*   `read_csv()` 函数：用于读取逗号分隔的 `.csv` 文件。这是最常见的数据文件格式。
*   `read_tsv()` 函数：用于读取制表符分隔的 `.tsv` 文件。
*   `read_delim()` 函数：更通用的读取文本文件的函数，可以自定义分隔符。

这些函数都属于 `readr` 包，通常在RStudio等环境中已经默认安装，如果没有，可以使用 `install.packages("readr")` 安装，并使用 `library(readr)` 加载。

下面是一些基本用法示例：


#### `read_excel()` 函数： 读取 Excel 文件

*   可以读取 `.xls` 和 `.xlsx` 格式的 Excel 文件。
*   需要先安装和加载 `readxl` 包 (`install.packages("readxl")`, `library(readxl)`).

```R
# 安装 readxl 包 (如果还没安装)
install.packages("readxl")
# 加载 readxl 包
library(readxl)
# 读取 Excel 文件
excel_data <- read_excel("你的Excel文件.xlsx")
```

#### `read_json()` 函数： 读取 JSON 文件

*   可以读取 JSON 格式的文件。
*   需要安装和加载 `jsonlite` 包 (`install.packages("jsonlite")`, `library(jsonlite)`).

```


# 安装 jsonlite 包 (如果还没安装)
install.packages("jsonlite")
# 加载 jsonlite 包
library(jsonlite)
# 读取 JSON 文件
json_data <- read_json("你的JSON文件.json")
```

#### `read_html()` 函数： 读取 HTML 表格

*   可以读取网页上的表格数据。
*   需要安装和加载 `rvest` 包 (`install.packages("rvest")`, `library(rvest)`).
*   **注意**： 网页数据抓取比较复杂，这里只是简单了解一下。

```


# 安装 rvest 包 (如果还没安装)
install.packages("rvest")
# 加载 rvest 包
library(rvest)
# 读取 HTML 页面
webpage <- read_html("你的网页地址")
# 提取 HTML 表格 (假设表格在页面中是第一个表格)
html_table <- html_table(html_nodes(webpage, "table")[[1]])
```

#### `fread()` 函数 (`data.table` 包)：  快速读取大型数据文件

*   `fread()` 函数读取大文件速度很快，可以用来替代 `read_csv()`。
*   `data.table` 包功能很强大，但我们这门课初期主要用 `readr` 包。

```


# 安装 data.table 包 (如果还没安装)
if(!requireNamespace("data.table", quietly = TRUE)){
    install.packages("data.table")
}
# 加载 data.table 包
library(data.table)
# 使用 fread 读取 CSV 文件
large_csv_data <- fread("你的大型CSV文件.csv")
```


## 第四次课：数据初步理解与描述性统计


### 初步认识数据：常用R函数

在拿到数据之后，我们通常需要先快速了解数据的大致情况。R 语言提供了一系列函数，可以帮助我们快速查看数据的基本信息，例如数据的维度、列名、数据类型、以及数据的前几行和后几行等等。下面介绍一些常用的 R 函数。

#### 常用 R 函数

*   **`head()` 和 `tail()`**:  看数据的前几行和后几行。

```R
head(你的数据框) # 默认看前 6 行
head(你的数据框, 10) # 看前 10 行
tail(你的数据框) # 默认看后 6 行
```

*   **`glimpse()` (`dplyr` 包)**:  更清楚地展示数据结构，包括列名、数据类型和数据预览。

```
library(dplyr) # 确保加载 dplyr 包
glimpse(你的数据框)
```

*   **`summary()`**:  看每列数据的描述性统计信息 (平均值、中位数、最小值、最大值等等)。

```
summary(你的数据框)
```

*   **`str()`**:  查看数据框的结构，包括数据类型和维度。

```
str(你的数据框)
```

*   **`names()`**:  查看列名。

```
names(你的数据框)
```

::: {.callout-tip appearance="simple"}
#### 练习

*   **练习任务**：  用上面这些函数，查看你导入的数据，初步了解数据大概是什么样的。
:::


### 数据类型与数据质量

在进行数据分析之前，理解数据的类型和质量至关重要。不同的数据类型决定了我们可以对数据进行的操作，而数据质量则直接影响分析结果的可靠性。本节将简要介绍常见的数据类型和数据质量问题。


#### 常见数据类型

*   **数值型 (numeric, integer)**:  数字，可以用来计算。
*   **字符型 (character)**:  文本，字符串。
*   **逻辑型 (logical)**:  TRUE (真) / FALSE (假)。
*   **因子型 (factor)**:  分类数据，比如学历 (小学，初中，高中)。
*   **日期型 (Date, POSIXct)**:  日期和时间。

#### 数据质量问题

*   **缺失值 (NA)**:  数据不见了，不知道是什么值。
*   **重复值**:  数据重复出现。
*   **异常值 (Outliers)**:  不正常的数据，和大部分数据差别很大。
*   **数据不一致**:  比如单位不一样，格式不统一。
*   **数据质量很重要**，如果数据有问题，分析结果可能也会错 ("Garbage in, garbage out")。


### 描述性统计量

在拿到数据之后，我们首先需要对数据有一个初步的认识。**描述性统计量**就是帮助我们**概括和描述数据基本特征**的统计方法。通过学习和计算**描述性统计量**，例如**均值**、**中位数**、**标准差**等等，我们可以快速了解数据的**集中趋势**、**离散程度**和**大致分布**，为后续的数据分析和建模打下基础。


#### 集中趋势

*   **均值 (Mean)**:  平均数，用 `mean()` 函数计算。

```
mean(你的数据框$列名)
```

:::callout-note
*   **优点**： 均值是**最常用**的集中趋势度量，**易于理解和计算**。它利用了数据集中的所有数值信息，能够**充分反映数据的中心位置**。在**数据分布对称**的情况下，均值能够很好地代表数据的典型水平。
*   **缺点**： 均值对**异常值（outliers）非常敏感**。如果数据集中存在极端值，均值会受到很大影响，**不能准确反映大多数数据的集中趋势**。例如，如果一组收入数据中存在极少数高收入人群，均值会被显著拉高，无法代表普通收入水平。
*   **使用技巧**： 当数据分布**接近对称且没有明显异常值**时，均值是衡量集中趋势的良好选择。在**需要考虑所有数据点**的情况下，也应优先考虑均值。但当数据存在**偏斜分布或异常值**时，均值可能会产生误导，此时应结合其他统计量一起使用。
:::

*   **中位数 (Median)**:  把数据排序后，最中间的那个数，用 `median()` 函数计算。

```
median(你的数据框$列名)
```

:::callout-note
*   **优点**： 中位数**不受异常值的影响**，对数据分布的形状**不敏感**。即使数据集中存在极端值，中位数仍然能够**稳健地反映数据的中心位置**。因此，中位数是衡量**偏斜分布数据**集中趋势的良好指标。
*   **缺点**： 中位数**没有充分利用数据集中的所有数值信息**，因为它只关注排序后中间位置的数值，而忽略了其他数值的大小。在**数据分布对称**的情况下，中位数可能不如均值那样精确地反映数据的中心位置。
*   **使用技巧**： 当数据分布**偏斜或存在异常值**时，中位数是比均值更稳健的集中趋势度量。在**关注数据集中间水平**，而**不希望受到极端值干扰**时，应优先考虑中位数。可以**结合均值和中位数一起使用**，比较它们之间的差异，判断数据分布的偏斜程度。
:::

*   **众数 (Mode)**:  出现次数最多的数 (R 没有直接计算众数的函数，可以自己写代码或者用包，这里先不深入)。

:::callout-note
*   **优点**： 众数**易于理解**，直接反映了数据集中**出现频率最高的数值**。众数**不受极端值的影响**，并且**适用于任何类型的数据**，包括数值型和类别型数据。对于**类别数据**，众数是唯一可用的集中趋势度量。
*   **缺点**： 众数可能**不存在**或**不唯一**。当数据集分布**均匀**或**有多个数值出现频率相近**时，众数可能无法明确指示数据的集中趋势。众数**没有利用数据集中数值大小的信息**，仅仅关注频率，因此**信息量较少**。
*   **使用技巧**： 众数**主要用于描述类别数据的集中趋势**，例如，调查学生最喜欢的颜色，众数可以告诉我们哪个颜色最受欢迎。对于**数值数据**，当**数据集中存在明显的峰值**，且**关注最常见的数值**时，可以使用众数。但当众数不唯一或不存在时，或者需要更精确地描述数据的中心位置时，应结合其他集中趋势度量。
:::

#### 离散程度

*   **标准差 (Standard Deviation)**:  数据离散程度的一种度量，用 `sd()` 函数计算。

```
sd(你的数据框$列名)
```

:::callout-note
*   **优点**： 标准差是**最常用**的离散程度度量，**易于理解和计算**。它**考虑了数据集中所有数值与均值的偏差**，能够**全面反映数据的离散程度**。标准差具有**明确的数学意义**，可以用于**正态分布**数据的分析和**参数估计**。
*   **缺点**： 标准差**对异常值敏感**。当数据集中存在极端值时，标准差会被放大，**不能准确反映大多数数据的离散程度**。标准差只能用于**数值型数据**，不能用于类别型数据。
*   **使用技巧**： 当数据分布**接近对称且没有明显异常值**时，标准差是衡量离散程度的良好选择。在**需要全面考虑数据波动情况**，并进行**进一步统计分析**时，应优先考虑标准差。但当数据存在**偏斜分布或异常值**时，标准差可能会产生误导，此时应结合其他离散程度度量一起使用，例如四分位距。
:::

*   **方差 (Variance)**:  也是数据离散程度的度量，用 `var()` 函数计算。

```
var(你的数据框$列名)
```

:::callout-note
*   **优点**： 方差与标准差类似，也**考虑了数据集中所有数值与均值的偏差**，能够**反映数据的离散程度**。方差具有**良好的数学性质**，在统计理论中有很多应用，例如**方差分析**。
*   **缺点**： 方差的**单位是原始数据单位的平方**，**解释性不如标准差直观**。例如，如果身高单位是厘米，方差的单位就是平方厘米，不符合日常理解习惯。方差也**对异常值敏感**，与标准差类似。
*   **使用技巧**： 方差和标准差在实际应用中**常常一起使用**，它们反映的离散程度信息基本一致。在**需要进行统计推断或理论分析**时，方差可能更常用。但在**描述性统计和结果解释**时，标准差通常更直观易懂。
:::

*   **四分位距 (IQR)**:  第三四分位数减去第一四分位数，用 `IQR()` 函数计算。

```
IQR(你的数据框$列名)
```

:::callout-note
*   **优点**： 四分位距**不受异常值的影响**，对数据分布的形状**不敏感**。它**只关注数据中间 50% 的离散程度**，能够**稳健地反映数据的变异性**。四分位距**易于计算和理解**，常用于**箱线图**的绘制。
*   **缺点**： 四分位距**只利用了数据集中间部分的信息**，**忽略了数据两端的变化**，信息量不如标准差丰富。四分位距**不能充分反映数据的整体分布**情况。
*   **使用技巧**： 当数据分布**偏斜或存在异常值**时，四分位距是比标准差更稳健的离散程度度量。在**关注数据中间 50% 的波动范围**，而**不希望受到极端值干扰**时，应优先考虑四分位距。可以**结合标准差和四分位距一起使用**，从不同角度理解数据的离散程度。
:::

*   **极差 (Range)**:  最大值减去最小值，用 `range()` 函数计算，然后自己算一下。

```
data_range <- range(你的数据框$列名)
range_value <- data_range[2] - data_range[1] # 最大值 - 最小值
```

:::callout-note
*   **优点**： 极差**非常容易计算和理解**，直接反映了数据的**最大波动范围**。
*   **缺点**： 极差**只利用了最大值和最小值两个极端值的信息**，**忽略了中间数据的分布**，**不能全面反映数据的离散程度**。极差**非常容易受到异常值的影响**，如果数据集中存在极端值，极差会被显著放大，**无法准确反映大多数数据的波动范围**。
*   **使用技巧**： 极差**通常只作为对数据波动范围的粗略估计**，或者在**数据量较小**的情况下使用。在**需要快速了解数据大致范围**时，可以使用极差。但由于其对异常值敏感且信息量少，**不宜作为主要的离散程度度量**。在实际应用中，更常用标准差或四分位距来描述数据的离散程度。
:::


### `dplyr` 包：数据清洗入门

数据清洗 (Data Cleaning) 是数据分析中非常重要的一个环节。真实世界的数据往往是“脏乱”的，可能包含缺失值、重复值、格式错误、异常值等等问题。**数据清洗的目的**就是**处理这些数据质量问题**，让数据变得更加**干净、规范、可用**，为后续的分析和建模打下良好的基础。

`dplyr` 包是 R 语言中一个非常流行和强大的**数据处理包**，它提供了一系列简洁高效的函数，可以帮助我们**快速完成各种数据清洗和转换任务**。接下来我们来学习 `dplyr` 包的一些常用函数。


::: {.callout-tip appearance="simple"}
#### `dplyr` 包的核心动词

*   `select()`:  **选择列**
*   `filter()`:  **筛选行**
*   `mutate()`:  **创建新列或修改列**
*   `arrange()`:  **排序**
*   `summarise()`:  **汇总统计**
*   `group_by()`:  **分组**
*   `%>%` (管道操作符):  **把上一步的结果传给下一步**
:::

#### `select()` 函数： 选择需要的列

```language:R
# 选择单列
select(你的数据框, 列名)

# 选择多列
select(你的数据框, 列1, 列2, 列3)

# 选择列名以特定字符开头的列
select(你的数据框, starts_with("前缀"))

# 选择列名以特定字符结尾的列
select(你的数据框, ends_with("后缀"))

# 选择列名包含特定字符的列
select(你的数据框, contains("字符串"))

# 排除特定列
select(你的数据框, -要排除的列名)
```

:::callout-note
## 使用技巧
*   **灵活组合选择方法**:  `select()` 可以灵活组合各种选择列的方法，例如 `starts_with()`, `ends_with()`, `contains()` 等，以及 `-` 排除列，来快速选择需要的列。
*   **配合管道操作符 `%>%`**:  `select()` 经常和管道操作符 `%>%` 结合使用，作为数据清洗的第一步，先选择需要的列，再进行后续的数据处理。
*   **保持代码简洁易读**:  合理使用 `select()` 可以让代码更简洁易读，只保留分析需要的列，减少干扰信息。
*   **在数据探索阶段使用**:  在数据探索的初期，可以使用 `select()` 快速查看不同列的数据，了解数据的大致结构和内容。
:::

#### `filter()` 函数： 筛选符合条件的行

```language:R
# 筛选单条件
filter(你的数据框, 列名 > 值)

# 筛选多条件 (AND，并且)
filter(你的数据框, 列1 == 值1 & 列2 < 值2)

# 筛选多条件 (OR，或者)
filter(你的数据框, 列1 == 值1 | 列2 < 值2)

# 使用 %in% 筛选多个值
filter(你的数据框, 列名 %in% c("值1", "值2", "值3"))

# 筛选缺失值 (NA)
filter(你的数据框, is.na(列名))

# 筛选非缺失值
filter(你的数据框, !is.na(列名))
```


:::callout-note
## 使用技巧
*   **多条件灵活组合**:  `filter()` 可以使用 `&` (AND) 和 `|` (OR) 组合多个筛选条件，构建复杂的筛选逻辑。
*   **使用 `%in%` 简化多值筛选**:  当需要筛选某一列的多个特定值时，使用 `%in%` 操作符可以使代码更简洁。
*   **处理缺失值**:  `is.na()` 和 `!is.na()` 可以方便地筛选缺失值和非缺失值，用于数据清洗中处理缺失值的情况。
*   **在数据清洗和预处理阶段使用**:  `filter()` 是数据清洗和预处理中非常常用的函数，用于筛选出符合特定条件的子数据集，为后续分析做准备。
*   **结合其他 `dplyr` 函数**:  `filter()` 经常与其他 `dplyr` 函数 (如 `group_by()`, `summarise()`, `mutate()`) 结合使用，完成更复杂的数据处理任务。
:::

#### 演示

*   **演示**：  用 `dplyr` 函数对示例数据做一些简单的列选择和行筛选。

### 描述性统计和数据清洗练习

*   **练习任务**：  计算示例数据的描述性统计量，用 `dplyr` 的 `select()` 和 `filter()` 函数做简单的数据清洗。
*   **可以用 AI 工具 (Cursor) 帮忙**，比如让 AI 解释 `select()` 和 `filter()` 函数怎么用。

::: {.callout-important}
## 课后作业 (第二周)

1.  **完成数据获取**：  下载数据集，或者尝试用 API 获取数据 (API 这周主要是尝试，不要求成功拿到完整数据)。
2.  **用 `readr` (或其他包) 把数据导入到 R**。
3.  **用 `head()`, `glimpse()`, `summary()`, `str()` 等函数看看数据**。
4.  **计算数据中重要变量的描述性统计量** (平均值、中位数、标准差等)。
5.  **尝试用 `dplyr` 的 `select()` 和 `filter()` 函数做简单的数据清洗**。
6.  **思考题**：  你现在拿到的数据有什么质量问题吗？ 比如有没有缺失值、异常值、重复值？  想想可以怎么处理这些问题 (可以查资料或者用 AI 搜索)。
:::

::: {.callout-tip appearance="simple"}
## AI 辅助学习建议 (第二周)

*   **数据获取**：  用 AI 帮你看 API 文档，找数据集，总结数据信息。
*   **R 数据导入**：  用 AI 帮你写和调试数据导入代码，解决导入问题。
*   **数据理解和描述性统计**：  用 AI 帮你写代码，理解数据查看和描述性统计的代码，学习各种统计量的意思。
*   **`dplyr` 数据清洗**：  用 AI 帮你学习 `dplyr` 的 `select()` 和 `filter()` 函数，生成 `dplyr` 代码，完成数据清洗练习。
:::