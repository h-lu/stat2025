[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "统计学与R语言",
    "section": "",
    "text": "课程目标\n本课程旨在帮助你掌握统计学的基础知识，并使用R语言进行数据分析。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>课程介绍</span>"
    ]
  },
  {
    "objectID": "index.html#课程内容",
    "href": "index.html#课程内容",
    "title": "统计学与R语言",
    "section": "课程内容",
    "text": "课程内容",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>课程介绍</span>"
    ]
  },
  {
    "objectID": "index.html#考核方式",
    "href": "index.html#考核方式",
    "title": "统计学与R语言",
    "section": "考核方式",
    "text": "考核方式\n\n课堂参与 (20%)： 出勤、课堂互动、课堂表现\n小组项目1次 (10%)： 包括项目选题、数据收集、统计分析、结果解释和结论。\n最终项目1次 (20%)： 包括项目选题、数据收集、统计分析、结果解释和结论。\n期末考试 (50%)： 闭卷考试，考察学生对统计学基本概念、原理和方法的掌握程度。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>课程介绍</span>"
    ]
  },
  {
    "objectID": "week1_lecture.html",
    "href": "week1_lecture.html",
    "title": "第一周：启程：统计思维、R与数据世界",
    "section": "",
    "text": "1. 欢迎来到统计学与R的世界！\n本周我们将开启一段探索数据奥秘的旅程。统计学不仅仅是数学公式，更是一种理解世界、做出明智决策的思维方式。而 R 语言，则是我们探索数据、实践统计思维的强大工具。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>第一周：启程：统计思维、R与数据世界</span>"
    ]
  },
  {
    "objectID": "week1_lecture.html#欢迎来到统计学与r的世界",
    "href": "week1_lecture.html#欢迎来到统计学与r的世界",
    "title": "第一周：启程：统计思维、R与数据世界",
    "section": "",
    "text": "本周目标\n\n\n\n\n理解统计学的基本概念和重要性。\n熟悉 R 和 RStudio 的基本操作环境。\n掌握 R 的基础语法，为后续学习打下基础。\n初步了解 AI 助手在学习和数据分析中的潜力。\n明确课程目标、学习方式和最终项目要求。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>第一周：启程：统计思维、R与数据世界</span>"
    ]
  },
  {
    "objectID": "week1_lecture.html#统计思维超越直觉",
    "href": "week1_lecture.html#统计思维超越直觉",
    "title": "第一周：启程：统计思维、R与数据世界",
    "section": "2. 统计思维：超越直觉",
    "text": "2. 统计思维：超越直觉\n\n什么是统计学？\n\n收集、处理、分析、解释数据，并从中得出结论的科学。\n在不确定性中寻找规律，量化证据。\n\n为何学习统计学？\n\n培养数据驱动的决策能力。\n批判性地评估信息和研究。\n解决现实世界中的复杂问题（商业、科研、医疗等）。\n\n统计思维的核心：\n\n变异性 (Variation): 认识到数据总是存在差异。\n随机性 (Randomness): 理解概率在抽样和推断中的作用。\n模型 (Models): 使用简化的数学表示来理解复杂现象。\n推断 (Inference): 从样本信息推广到总体特征。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>第一周：启程：统计思维、R与数据世界</span>"
    ]
  },
  {
    "objectID": "week1_lecture.html#r-与-rstudio你的数据科学工作台",
    "href": "week1_lecture.html#r-与-rstudio你的数据科学工作台",
    "title": "第一周：启程：统计思维、R与数据世界",
    "section": "3. R 与 RStudio：你的数据科学工作台",
    "text": "3. R 与 RStudio：你的数据科学工作台\n\nR 语言简介:\n\n开源、免费、强大的统计计算和图形绘制语言。\n拥有庞大的社区和丰富的扩展包 (Packages)。\n\nRStudio IDE:\n\n集成开发环境 (Integrated Development Environment)，让 R 的使用更便捷。\n主要窗口：脚本编辑器、控制台、环境/历史记录、文件/图形/包/帮助。\n\n环境搭建:\n\n安装 R: https://cran.r-project.org/\n安装 RStudio Desktop: https://posit.co/download/rstudio-desktop/\n\ntidyverse 包介绍与安装:\n\ntidyverse 是一个包含了一系列用于数据科学的 R 包的集合（如 ggplot2, dplyr, tidyr, readr 等），它们共享一致的设计哲学、语法和数据结构。\n安装命令：\n\n# install.packages(\"tidyverse\") # 如果尚未安装，取消注释并运行\nlibrary(tidyverse) # 加载包",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>第一周：启程：统计思维、R与数据世界</span>"
    ]
  },
  {
    "objectID": "week1_lecture.html#r-基础语法入门",
    "href": "week1_lecture.html#r-基础语法入门",
    "title": "第一周：启程：统计思维、R与数据世界",
    "section": "4. R 基础语法入门",
    "text": "4. R 基础语法入门\n\nR 作为计算器:\n1 + 1\n5 * 3\n10 / 2\n2 ^ 3 # 幂运算\n变量赋值: 使用 &lt;- 或 = (推荐 &lt;-)\nx &lt;- 5\ny &lt;- x * 2\nx\ny\n数据类型初识:\n\nnumeric: 数值型 (包括整数和浮点数)\ncharacter: 字符型 (文本，用引号括起来)\nlogical: 逻辑型 (TRUE 或 FALSE)\n\na &lt;- 10.5\nb &lt;- \"Hello, R!\"\nc &lt;- TRUE\nclass(a) # 查看变量类型\nclass(b)\nclass(c)\n向量 (Vector): R中最基本的数据结构，存储相同类型元素的序列。使用 c() 函数创建。\nnumeric_vector &lt;- c(1, 3, 5, 7)\nchar_vector &lt;- c(\"apple\", \"banana\", \"cherry\")\nlogical_vector &lt;- c(TRUE, FALSE, TRUE, TRUE)\n\nnumeric_vector\nchar_vector[1] # 访问第一个元素 (R的索引从1开始)\nlength(numeric_vector) # 查看向量长度\n\n\n\n\n\n\n向量类型一致性\n\n\n\n一个向量中的所有元素必须是相同的数据类型。如果混合不同类型，R 会进行强制类型转换（通常转换为字符型）。\nmixed_vector &lt;- c(1, \"two\", TRUE)\nmixed_vector # 查看结果\nclass(mixed_vector)",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>第一周：启程：统计思维、R与数据世界</span>"
    ]
  },
  {
    "objectID": "week1_lecture.html#ai-助手初识你的智能学习伙伴",
    "href": "week1_lecture.html#ai-助手初识你的智能学习伙伴",
    "title": "第一周：启程：统计思维、R与数据世界",
    "section": "5. AI 助手初识：你的智能学习伙伴",
    "text": "5. AI 助手初识：你的智能学习伙伴\n现代 AI 工具（如 ChatGPT、Copilot 等）可以在学习 R 和统计学过程中提供巨大帮助。\n\n\n\n\n\n\nAI 辅助演示\n\n\n\n\n查询 R 语法: “如何在 R 中创建数值向量？” 或 “解释 R 中 class() 函数的作用。”\n解释统计概念: “请解释统计学中变异的概念” 或 “平均数和中位数有什么区别？”\n代码调试: (后续会涉及) 粘贴错误信息，询问可能的错误原因。\n生成示例代码: “请给我一个在 R 中使用 dplyr 包 filter() 函数的示例。”\n\n重要提示: AI 是强大的助手，但并非绝对权威。务必批判性地看待 AI 的回答，并通过官方文档、书籍或老师进行验证。 它的主要价值在于快速获取信息、启发思路和辅助编程，而非替代独立思考和深入理解。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>第一周：启程：统计思维、R与数据世界</span>"
    ]
  },
  {
    "objectID": "week1_lecture.html#课程与项目介绍",
    "href": "week1_lecture.html#课程与项目介绍",
    "title": "第一周：启程：统计思维、R与数据世界",
    "section": "6. 课程与项目介绍",
    "text": "6. 课程与项目介绍\n\n课程目标: 掌握数据处理、可视化和常用统计推断方法，能够使用 R 语言独立完成基本的数据分析任务。\n教学方式: 理论讲解 + R 代码演示 + 案例分析 + 动手练习 + Capstone 项目。\n评估方式: 平时作业、期中/期末考试、Capstone 项目。\nCapstone 项目: (后续详细介绍) 一个综合性的数据分析项目，要求应用课程所学知识解决一个实际或模拟的问题。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>第一周：启程：统计思维、R与数据世界</span>"
    ]
  },
  {
    "objectID": "week1_lecture.html#本周小结与预告",
    "href": "week1_lecture.html#本周小结与预告",
    "title": "第一周：启程：统计思维、R与数据世界",
    "section": "7. 本周小结与预告",
    "text": "7. 本周小结与预告\n本周我们了解了统计学的基本思想，安装并熟悉了 R 和 RStudio 环境，掌握了 R 的基础语法，并认识了 AI 助手。下周我们将深入学习如何获取和导入数据，并开始进行数据的初步描述性分析。\n思考题:\n\n尝试使用 R 进行一些基本的数学运算。\n创建不同类型的向量（数值、字符、逻辑），并尝试访问其中的元素。\n思考一个你感兴趣的、可以用数据来回答的问题。这个问题可能涉及哪些变量？",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>第一周：启程：统计思维、R与数据世界</span>"
    ]
  },
  {
    "objectID": "week2_lecture.html",
    "href": "week2_lecture.html",
    "title": "第二周：数据的语言：获取、导入与初步描述",
    "section": "",
    "text": "1. 数据从何而来？\n数据分析的第一步是获取数据。数据可以来自各种来源，并以不同的格式存储。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>第二周：数据的语言：获取、导入与初步描述</span>"
    ]
  },
  {
    "objectID": "week2_lecture.html#数据从何而来",
    "href": "week2_lecture.html#数据从何而来",
    "title": "第二周：数据的语言：获取、导入与初步描述",
    "section": "",
    "text": "常见数据来源:\n\n文件: CSV (逗号分隔值), Excel (.xlsx), TXT (纯文本), JSON, XML 等。这是最常见的形式。\n数据库: SQL 数据库 (如 PostgreSQL, MySQL), NoSQL 数据库。\nAPI (应用程序编程接口): 从网站或服务（如社交媒体、天气服务）获取实时数据。\n网页抓取: 从网页 HTML 中提取数据（需要注意合法性和道德规范）。\n\n常见数据格式:\n\n表格数据 (Tabular Data): 行代表观测 (Observations)，列代表变量 (Variables)。这是我们本课程主要处理的格式。CSV 和 Excel 文件通常存储表格数据。\n非结构化数据: 文本、图像、音频等。\n半结构化数据: JSON, XML 等，具有一定的结构但不如表格数据规整。\n\n\n\n\n\n\n\n\n本周目标\n\n\n\n\n了解常见的数据来源和格式。\n使用 readr 包高效导入 CSV 等文本文件。\n理解 R 中核心的表格数据结构：数据框 (Data Frame) 和 Tibble。\n认识并处理一种重要的变量类型：因子 (Factor)。\n计算并解释描述性统计量，包括集中趋势和离散趋势。\n初步掌握 dplyr 包中的数据筛选和选择功能。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>第二周：数据的语言：获取、导入与初步描述</span>"
    ]
  },
  {
    "objectID": "week2_lecture.html#readr高效导入数据",
    "href": "week2_lecture.html#readr高效导入数据",
    "title": "第二周：数据的语言：获取、导入与初步描述",
    "section": "2. readr：高效导入数据",
    "text": "2. readr：高效导入数据\ntidyverse 中的 readr 包提供了快速、友好的函数来读取矩形数据（如 CSV 和 TSV）。\n\n核心函数:\n\nread_csv(): 读取逗号分隔的文件。\nread_tsv(): 读取制表符分隔的文件。\nread_delim(): 读取使用任意分隔符的文件。\nread_fwf(): 读取固定宽度文件。\nread_log(): 读取 Apache 风格的日志文件。\nread_excel(): (来自 readxl 包，通常与 tidyverse 一起使用) 读取 Excel 文件。\n\nread_csv() 示例: 假设我们有一个名为 students.csv 的文件：\n    Name,Age,Major,GPA\n    Alice,21,Statistics,3.8\n    Bob,22,Computer Science,3.5\n    Charlie,20,Mathematics,3.9\n    David,21,Statistics,3.6\n在 R 中读取：\n\nlibrary(tidyverse) # 加载tidyverse通常也会加载readr\n\n# 假设 students.csv 在当前工作目录下\n# 如果不在，需要提供完整或相对路径\n# students_data &lt;- read_csv(\"path/to/your/students.csv\")\n\n# 为了演示，我们直接用文本创建数据\ncsv_text &lt;- \"Name,Age,Major,GPA\\nAlice,21,Statistics,3.8\\nBob,22,Computer Science,3.5\\nCharlie,20,Mathematics,3.9\\nDavid,21,Statistics,3.6\"\n\nstudents_data &lt;- read_csv(csv_text)\n\nprint(students_data)\n\n#&gt; # A tibble: 4 × 4\n#&gt;   Name      Age Major              GPA\n#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n#&gt; 1 Alice      21 Statistics         3.8\n#&gt; 2 Bob        22 Computer Science   3.5\n#&gt; 3 Charlie    20 Mathematics        3.9\n#&gt; 4 David      21 Statistics         3.6\n\n\nread_csv() 会自动猜测列的类型，并返回一个 Tibble 对象。\n常用参数:\n\nfile: 文件路径或 URL。\ncol_names: 是否包含列名 (默认为 TRUE)。如果文件没有列名，设为 FALSE，readr 会自动生成 X1, X2…\ncol_types: 手动指定列类型，提高稳定性和速度。\nna: 指定哪些字符串应被视作缺失值 (默认识别 “NA”)。\nskip: 跳过文件开头的行数。\nn_max: 最多读取的行数。\n\n# 示例：指定列类型，将 \"N/A\" 视作缺失值\nstudents_data_spec &lt;- read_csv(\n  \"students.csv\",\n  col_types = cols(\n    Name = col_character(),\n    Age = col_integer(),\n    Major = col_character(),\n    GPA = col_double()\n  ),\n  na = c(\"NA\", \"N/A\")\n)",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>第二周：数据的语言：获取、导入与初步描述</span>"
    ]
  },
  {
    "objectID": "week2_lecture.html#数据框-data-frame-与-tibble",
    "href": "week2_lecture.html#数据框-data-frame-与-tibble",
    "title": "第二周：数据的语言：获取、导入与初步描述",
    "section": "3. 数据框 (Data Frame) 与 Tibble",
    "text": "3. 数据框 (Data Frame) 与 Tibble\n\n数据框 (Data Frame): R 中存储表格数据的标准结构。\n\n本质上是一个等长向量的列表。\n每一列是一个向量，必须包含相同类型的数据。\n不同列可以包含不同类型的数据。\n创建示例：\n\n\ndf &lt;- data.frame(\n  ID = c(101, 102, 103),\n  Product = c(\"A\", \"B\", \"A\"),\n  Price = c(15.5, 20.0, 16.0),\n  InStock = c(TRUE, FALSE, TRUE)\n)\n\nprint(df)\n\n#&gt;    ID Product Price InStock\n#&gt; 1 101       A  15.5    TRUE\n#&gt; 2 102       B  20.0   FALSE\n#&gt; 3 103       A  16.0    TRUE\n\nstr(df) # 查看数据框结构\n\n#&gt; 'data.frame':    3 obs. of  4 variables:\n#&gt;  $ ID     : num  101 102 103\n#&gt;  $ Product: chr  \"A\" \"B\" \"A\"\n#&gt;  $ Price  : num  15.5 20 16\n#&gt;  $ InStock: logi  TRUE FALSE TRUE\n\n\nTibble: tidyverse 对数据框的现代优化版本。\n\nreadr 函数默认返回 Tibble。\n优点:\n\n打印更友好：只显示前 10 行和适合屏幕的列。\n不会自动将字符串转换为因子 (Factor)。\n不会改变列名（例如，不允许非法字符）。\n子集提取 ([) 行为更一致。\n\n大多数情况下，可以像使用数据框一样使用 Tibble。\ntibble() 函数创建 Tibble，as_tibble() 将数据框转换为 Tibble。\n\n\nlibrary(tibble)\n\ntb &lt;- tibble(\n  ID = c(101, 102, 103),\n  Product = c(\"A\", \"B\", \"A\"),\n  Price = c(15.5, 20.0, 16.0),\n  InStock = c(TRUE, FALSE, TRUE)\n)\n\nprint(tb)\n\n#&gt; # A tibble: 3 × 4\n#&gt;      ID Product Price InStock\n#&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;lgl&gt;  \n#&gt; 1   101 A        15.5 TRUE   \n#&gt; 2   102 B        20   FALSE  \n#&gt; 3   103 A        16   TRUE\n\nstr(tb)\n\n#&gt; tibble [3 × 4] (S3: tbl_df/tbl/data.frame)\n#&gt;  $ ID     : num [1:3] 101 102 103\n#&gt;  $ Product: chr [1:3] \"A\" \"B\" \"A\"\n#&gt;  $ Price  : num [1:3] 15.5 20 16\n#&gt;  $ InStock: logi [1:3] TRUE FALSE TRUE",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>第二周：数据的语言：获取、导入与初步描述</span>"
    ]
  },
  {
    "objectID": "week2_lecture.html#变量类型因子-factor",
    "href": "week2_lecture.html#变量类型因子-factor",
    "title": "第二周：数据的语言：获取、导入与初步描述",
    "section": "4. 变量类型：因子 (Factor)",
    "text": "4. 变量类型：因子 (Factor)\n因子是 R 中用来表示分类变量 (Categorical Variable) 的特殊数据类型。分类变量的值来自一个固定的、已知的集合，称为水平 (Levels)。\n\n应用场景: 性别 (男/女)、学历 (本科/硕士/博士)、产品类别 (A/B/C) 等。\n为何使用因子？\n\n节省内存（内部存储为整数）。\n在统计建模和绘图中（如 ggplot2）通常需要因子类型来正确处理分类变量。\n可以指定水平的顺序（例如，教育程度：小学 &lt; 中学 &lt; 大学）。\n\n创建和使用:\n\n# 假设有一个字符向量表示教育程度\neducation_char &lt;- c(\"Bachelor\", \"Master\", \"Bachelor\", \"PhD\", \"Master\")\n\n# 将其转换为因子\neducation_factor &lt;- factor(education_char)\nprint(education_factor)\n\n#&gt; [1] Bachelor Master   Bachelor PhD      Master  \n#&gt; Levels: Bachelor Master PhD\n\nlevels(education_factor) # 查看水平\n\n#&gt; [1] \"Bachelor\" \"Master\"   \"PhD\"\n\n# 查看内部存储 (整数)\nas.numeric(education_factor)\n\n#&gt; [1] 1 2 1 3 2\n\n# 创建有序因子 (指定水平顺序)\neducation_ordered &lt;- factor(\n  education_char,\n  levels = c(\"Bachelor\", \"Master\", \"PhD\"), # 指定顺序\n  ordered = TRUE\n)\n\nprint(education_ordered)\n\n#&gt; [1] Bachelor Master   Bachelor PhD      Master  \n#&gt; Levels: Bachelor &lt; Master &lt; PhD\n\neducation_ordered[1] &lt; education_ordered[2] # 可以比较顺序\n\n#&gt; [1] TRUE\n\n\n\n\n\n\n\n\nstringsAsFactors\n\n\n\n在旧版本的 R (&lt; 4.0) 中，data.frame() 默认会将字符向量转换为因子。tidyverse (包括 readr 和 tibble) 不会自动这样做，这通常是更期望的行为。如果需要因子，请显式转换。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>第二周：数据的语言：获取、导入与初步描述</span>"
    ]
  },
  {
    "objectID": "week2_lecture.html#描述性统计-i数据的中心在哪里集中趋势",
    "href": "week2_lecture.html#描述性统计-i数据的中心在哪里集中趋势",
    "title": "第二周：数据的语言：获取、导入与初步描述",
    "section": "5. 描述性统计 I：数据的”中心”在哪里？(集中趋势)",
    "text": "5. 描述性统计 I：数据的”中心”在哪里？(集中趋势)\n描述性统计用于总结和描述数据集的主要特征。集中趋势度量了数据的中心位置。\n\n均值 (Mean): 数据的算术平均值。对异常值敏感。\n\n公式: \\(\\bar{x} = \\frac{\\sum_{i=1}^{n} x_i}{n}\\)\nR 实现: mean()\n\nscores &lt;- c(85, 92, 78, 88, 95, 72)\nmean(scores)\n\n#&gt; [1] 85\n\n# 处理缺失值 (NA)\nscores_na &lt;- c(85, 92, NA, 88, 95, 72)\nmean(scores_na) # 结果是 NA\n\n#&gt; [1] NA\n\nmean(scores_na, na.rm = TRUE) # 移除 NA 后计算\n\n#&gt; [1] 86.4\n\n\n\n中位数 (Median): 将数据排序后位于中间位置的值。对异常值不敏感（稳健）。\n\n如果 n 为奇数，中位数是第 \\(\\frac{n+1}{2}\\) 个值。\n如果 n 为偶数，中位数是第 \\(\\frac{n}{2}\\) 和第 \\(\\frac{n}{2}+1\\) 个值的平均值。\nR 实现: median()\n\nmedian(scores)\n\n#&gt; [1] 86.5\n\nmedian(scores_na, na.rm = TRUE)\n\n#&gt; [1] 88\n\n# 比较均值和中位数 (异常值影响)\nscores_outlier &lt;- c(85, 92, 78, 88, 95, 72, 200)\nmean(scores_outlier)\n\n#&gt; [1] 101\n\nmedian(scores_outlier)\n\n#&gt; [1] 88\n\n\n\n众数 (Mode): 数据集中出现次数最多的值。适用于分类数据，也可用于数值数据。R 基础包没有直接计算众数的函数，通常需要自定义或使用其他包。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>第二周：数据的语言：获取、导入与初步描述</span>"
    ]
  },
  {
    "objectID": "week2_lecture.html#描述性统计-ii数据的散布程度如何离散趋势",
    "href": "week2_lecture.html#描述性统计-ii数据的散布程度如何离散趋势",
    "title": "第二周：数据的语言：获取、导入与初步描述",
    "section": "6. 描述性统计 II：数据的”散布”程度如何？(离散趋势)",
    "text": "6. 描述性统计 II：数据的”散布”程度如何？(离散趋势)\n离散趋势度量了数据围绕中心值的散布或变异程度。\n\n极差 (Range): 最大值与最小值的差。简单但易受异常值影响。\n\nR 实现: range() 返回最小值和最大值，diff(range(x)) 计算极差。\n\n\nrange(scores)\n\n#&gt; [1] 72 95\n\ndiff(range(scores))\n\n#&gt; [1] 23\n\n\n分位数 (Quantiles): 将数据排序后，按特定比例分割数据的值。\n\n四分位数 (Quartiles): 将数据分为四等份的点。\n\nQ1 (第一四分位数): 25% 的数据小于该值。\nQ2 (第二四分位数): 50% 的数据小于该值，即中位数。\nQ3 (第三四分位数): 75% 的数据小于该值。\n\n四分位距 (Interquartile Range, IQR): Q3 与 Q1 的差 (\\(IQR = Q3 - Q1\\))。衡量数据中间 50% 的散布范围，对异常值稳健。\nR 实现: quantile(), IQR()\n\n\nquantile(scores) # 默认计算 0%, 25%, 50%, 75%, 100% 分位数\n\n#&gt;   0%  25%  50%  75% 100% \n#&gt; 72.0 79.8 86.5 91.0 95.0\n\nquantile(scores, probs = c(0.1, 0.9)) # 计算 10% 和 90% 分位数\n\n#&gt;  10%  90% \n#&gt; 75.0 93.5\n\nIQR(scores)\n\n#&gt; [1] 11.2\n\n\n方差 (Variance): 数据点与其均值之差的平方的平均值。度量数据偏离均值的平均程度。单位是原始数据的平方。\n\n样本方差公式: \\(s^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}\\) (注意分母是 n-1，无偏估计)\nR 实现: var()\n\n\nvar(scores)\n\n#&gt; [1] 75.2\n\n\n标准差 (Standard Deviation): 方差的平方根。与原始数据具有相同的单位，更易于解释。\n\n样本标准差公式: \\(s = \\sqrt{s^2} = \\sqrt{\\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}}\\)\nR 实现: sd()\n\n\nsd(scores)\n\n#&gt; [1] 8.67\n\nsqrt(var(scores)) # 结果与 sd(scores) 相同\n\n#&gt; [1] 8.67\n\n\n\n\n\n集中趋势:\n\n数据对称且无极端异常值：均值。\n数据偏斜或有异常值：中位数。\n\n离散趋势:\n\n数据对称且无极端异常值：标准差（结合均值）。\n数据偏斜或有异常值：IQR（结合中位数）。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>第二周：数据的语言：获取、导入与初步描述</span>"
    ]
  },
  {
    "objectID": "week2_lecture.html#dplyr-初步数据操作的瑞士军刀",
    "href": "week2_lecture.html#dplyr-初步数据操作的瑞士军刀",
    "title": "第二周：数据的语言：获取、导入与初步描述",
    "section": "7. dplyr 初步：数据操作的瑞士军刀",
    "text": "7. dplyr 初步：数据操作的瑞士军刀\ndplyr 是 tidyverse 的核心包之一，提供了用于数据操作（筛选、选择、变换、汇总、排序）的一致且高效的函数（称为 “verbs”）。\n\n核心思想: 每个函数只做一件事，通过管道 (%&gt;%) 连接起来完成复杂操作。\n管道操作符 (%&gt;%): 将左侧对象作为右侧函数的第一个参数传递。读作 “then”。\n\nx %&gt;% f(y) 等价于 f(x, y)\nx %&gt;% f(y) %&gt;% g(z) 等价于 g(f(x, y), z)\n\n本周学习的 dplyr 动词:\n\nselect(): 按名称选择列。\nfilter(): 根据条件筛选行。\n\nselect() 示例: (使用之前创建的 students_data Tibble)\n\nlibrary(dplyr)\n\n# 选择 Name 和 GPA 列\nselect(students_data, Name, GPA)\n\n#&gt; # A tibble: 4 × 2\n#&gt;   Name      GPA\n#&gt;   &lt;chr&gt;   &lt;dbl&gt;\n#&gt; 1 Alice     3.8\n#&gt; 2 Bob       3.5\n#&gt; 3 Charlie   3.9\n#&gt; 4 David     3.6\n\n# 选择除 Major 之外的所有列\nselect(students_data, -Major)\n\n#&gt; # A tibble: 4 × 3\n#&gt;   Name      Age   GPA\n#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 Alice      21   3.8\n#&gt; 2 Bob        22   3.5\n#&gt; 3 Charlie    20   3.9\n#&gt; 4 David      21   3.6\n\n# 选择从 Name 到 Major 的所有列\nselect(students_data, Name:Major)\n\n#&gt; # A tibble: 4 × 3\n#&gt;   Name      Age Major           \n#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;           \n#&gt; 1 Alice      21 Statistics      \n#&gt; 2 Bob        22 Computer Science\n#&gt; 3 Charlie    20 Mathematics     \n#&gt; 4 David      21 Statistics\n\n# 使用管道\nstudents_data %&gt;% select(Name, Age)\n\n#&gt; # A tibble: 4 × 2\n#&gt;   Name      Age\n#&gt;   &lt;chr&gt;   &lt;dbl&gt;\n#&gt; 1 Alice      21\n#&gt; 2 Bob        22\n#&gt; 3 Charlie    20\n#&gt; 4 David      21\n\n\nfilter() 示例:\n\n# 筛选 Major 为 Statistics 的学生\nfilter(students_data, Major == \"Statistics\")\n\n#&gt; # A tibble: 2 × 4\n#&gt;   Name    Age Major        GPA\n#&gt;   &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n#&gt; 1 Alice    21 Statistics   3.8\n#&gt; 2 David    21 Statistics   3.6\n\n# 筛选 Age 大于 20 的学生\nfilter(students_data, Age &gt; 20)\n\n#&gt; # A tibble: 3 × 4\n#&gt;   Name    Age Major              GPA\n#&gt;   &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n#&gt; 1 Alice    21 Statistics         3.8\n#&gt; 2 Bob      22 Computer Science   3.5\n#&gt; 3 David    21 Statistics         3.6\n\n# 筛选 Major 为 Statistics 且 GPA 大于 3.7 的学生\nfilter(students_data, Major == \"Statistics\", GPA &gt; 3.7) # 逗号表示 \"与\"\n\n#&gt; # A tibble: 1 × 4\n#&gt;   Name    Age Major        GPA\n#&gt;   &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n#&gt; 1 Alice    21 Statistics   3.8\n\n# 或者使用 &\nfilter(students_data, Major == \"Statistics\" & GPA &gt; 3.7)\n\n#&gt; # A tibble: 1 × 4\n#&gt;   Name    Age Major        GPA\n#&gt;   &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n#&gt; 1 Alice    21 Statistics   3.8\n\n# 筛选 Major 为 Statistics 或 Mathematics 的学生\nfilter(students_data, Major == \"Statistics\" | Major == \"Mathematics\")\n\n#&gt; # A tibble: 3 × 4\n#&gt;   Name      Age Major         GPA\n#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;\n#&gt; 1 Alice      21 Statistics    3.8\n#&gt; 2 Charlie    20 Mathematics   3.9\n#&gt; 3 David      21 Statistics    3.6\n\n# 或者使用 %in%\nfilter(students_data, Major %in% c(\"Statistics\", \"Mathematics\"))\n\n#&gt; # A tibble: 3 × 4\n#&gt;   Name      Age Major         GPA\n#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;\n#&gt; 1 Alice      21 Statistics    3.8\n#&gt; 2 Charlie    20 Mathematics   3.9\n#&gt; 3 David      21 Statistics    3.6\n\n# 结合管道\nstudents_data %&gt;%\n  filter(Age &gt;= 21) %&gt;%\n  select(Name, GPA)\n\n#&gt; # A tibble: 3 × 2\n#&gt;   Name    GPA\n#&gt;   &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 Alice   3.8\n#&gt; 2 Bob     3.5\n#&gt; 3 David   3.6",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>第二周：数据的语言：获取、导入与初步描述</span>"
    ]
  },
  {
    "objectID": "week2_lecture.html#项目相关与本周总结",
    "href": "week2_lecture.html#项目相关与本周总结",
    "title": "第二周：数据的语言：获取、导入与初步描述",
    "section": "8. 项目相关与本周总结",
    "text": "8. 项目相关与本周总结\n\n项目任务: 尝试使用 readr 函数导入一份真实数据（如果是 CSV 或类似格式）。检查导入后的数据结构 (str(), glimpse())，看看列类型是否符合预期。\n本周回顾: 我们学习了如何将数据读入 R，理解了数据框和 Tibble，认识了因子类型，并掌握了计算基本描述性统计量和使用 dplyr 进行初步筛选和选择的方法。这些是进行任何数据分析的基础。\n\n下周预告: 我们将深入学习 dplyr 和 tidyr，掌握更多数据整理和变形的强大技术，为更复杂的数据分析和可视化做准备。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>第二周：数据的语言：获取、导入与初步描述</span>"
    ]
  },
  {
    "objectID": "week3_lecture.html",
    "href": "week3_lecture.html",
    "title": "第三周：数据整形：tidyverse 的核心技艺",
    "section": "",
    "text": "1. dplyr 进阶：更强大的数据操作\n上周我们学习了 dplyr 的 select() 和 filter()。本周我们将学习更多核心动词，让数据操作如虎添翼。\n我们将继续使用上周创建的 students_data Tibble，并可能引入新的示例数据。\nlibrary(tidyverse)\n\n# 回顾上周数据 (或重新创建)\ncsv_text &lt;- \"Name,Age,Major,GPA\\nAlice,21,Statistics,3.8\\nBob,22,Computer Science,3.5\\nCharlie,20,Mathematics,3.9\\nDavid,21,Statistics,3.6\"\nstudents_data &lt;- read_csv(csv_text)\n\n# 引入一个更复杂的数据集用于演示 group_by 和 summarise\nexam_scores &lt;- tibble(\n  StudentID = c(101, 102, 101, 103, 102, 103, 101),\n  Exam = c(\"Midterm\", \"Midterm\", \"Final\", \"Midterm\", \"Final\", \"Final\", \"Quiz1\"),\n  Score = c(85, 90, 88, 75, 92, 80, 95)\n)\n\nprint(students_data)\n\n#&gt; # A tibble: 4 × 4\n#&gt;   Name      Age Major              GPA\n#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n#&gt; 1 Alice      21 Statistics         3.8\n#&gt; 2 Bob        22 Computer Science   3.5\n#&gt; 3 Charlie    20 Mathematics        3.9\n#&gt; 4 David      21 Statistics         3.6\n\nprint(exam_scores)\n\n#&gt; # A tibble: 7 × 3\n#&gt;   StudentID Exam    Score\n#&gt;       &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;\n#&gt; 1       101 Midterm    85\n#&gt; 2       102 Midterm    90\n#&gt; 3       101 Final      88\n#&gt; 4       103 Midterm    75\n#&gt; 5       102 Final      92\n#&gt; 6       103 Final      80\n#&gt; 7       101 Quiz1      95",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>第三周：数据整形：`tidyverse` 的核心技艺</span>"
    ]
  },
  {
    "objectID": "week3_lecture.html#dplyr-进阶更强大的数据操作",
    "href": "week3_lecture.html#dplyr-进阶更强大的数据操作",
    "title": "第三周：数据整形：tidyverse 的核心技艺",
    "section": "",
    "text": "本周目标\n\n\n\n\n掌握 dplyr 的核心数据转换动词：mutate(), arrange(), group_by(), summarise()。\n理解并应用 tidyr 进行数据长宽格式转换：pivot_longer(), pivot_wider()。\n掌握”整洁数据” (Tidy Data) 的核心原则。\n学习处理数据中的缺失值 (NA)。\n熟练运用管道 (%&gt;%) 连接多步数据处理操作。\n\n\n\n\n\n\nmutate(): 创建或修改列\n\n基于现有列计算新列，或修改现有列。\n新列会添加到数据框的末尾。\n\n\n# 示例1: 计算 GPA 相对于 4.0 的差距\nstudents_data %&gt;%\n  mutate(GPA_diff = 4.0 - GPA)\n\n#&gt; # A tibble: 4 × 5\n#&gt;   Name      Age Major              GPA GPA_diff\n#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 Alice      21 Statistics         3.8    0.200\n#&gt; 2 Bob        22 Computer Science   3.5    0.5  \n#&gt; 3 Charlie    20 Mathematics        3.9    0.100\n#&gt; 4 David      21 Statistics         3.6    0.4\n\n# 示例2: 创建一个表示年龄是否大于21岁的逻辑列\nstudents_data %&gt;%\n  mutate(Is_Over_21 = Age &gt; 21)\n\n#&gt; # A tibble: 4 × 5\n#&gt;   Name      Age Major              GPA Is_Over_21\n#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt; &lt;lgl&gt;     \n#&gt; 1 Alice      21 Statistics         3.8 FALSE     \n#&gt; 2 Bob        22 Computer Science   3.5 TRUE      \n#&gt; 3 Charlie    20 Mathematics        3.9 FALSE     \n#&gt; 4 David      21 Statistics         3.6 FALSE\n\n# 示例3: 同时创建多个列\nstudents_data %&gt;%\n  mutate(\n    GPA_diff = 4.0 - GPA,\n    Birth_Year = 2024 - Age # 假设当前是2024年\n  )\n\n#&gt; # A tibble: 4 × 6\n#&gt;   Name      Age Major              GPA GPA_diff Birth_Year\n#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n#&gt; 1 Alice      21 Statistics         3.8    0.200       2003\n#&gt; 2 Bob        22 Computer Science   3.5    0.5         2002\n#&gt; 3 Charlie    20 Mathematics        3.9    0.100       2004\n#&gt; 4 David      21 Statistics         3.6    0.4         2003\n\n# 示例4: 修改现有列 (例如，将 GPA 乘以 25 得到百分制)\nstudents_data %&gt;%\n  mutate(GPA_percent = GPA * 25) # 创建新列\n\n#&gt; # A tibble: 4 × 5\n#&gt;   Name      Age Major              GPA GPA_percent\n#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1 Alice      21 Statistics         3.8        95  \n#&gt; 2 Bob        22 Computer Science   3.5        87.5\n#&gt; 3 Charlie    20 Mathematics        3.9        97.5\n#&gt; 4 David      21 Statistics         3.6        90\n\n# 示例5: 直接修改原列 (需谨慎)\nstudents_data %&gt;%\n  mutate(GPA = GPA * 25)\n\n#&gt; # A tibble: 4 × 4\n#&gt;   Name      Age Major              GPA\n#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n#&gt; 1 Alice      21 Statistics        95  \n#&gt; 2 Bob        22 Computer Science  87.5\n#&gt; 3 Charlie    20 Mathematics       97.5\n#&gt; 4 David      21 Statistics        90\n\n\narrange(): 按列排序行\n\n默认升序排列。\n使用 desc() 进行降序排列。\n可以按多个列排序。\n\n\n# 按年龄升序排序\nstudents_data %&gt;% arrange(Age)\n\n#&gt; # A tibble: 4 × 4\n#&gt;   Name      Age Major              GPA\n#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n#&gt; 1 Charlie    20 Mathematics        3.9\n#&gt; 2 Alice      21 Statistics         3.8\n#&gt; 3 David      21 Statistics         3.6\n#&gt; 4 Bob        22 Computer Science   3.5\n\n# 按 GPA 降序排序\nstudents_data %&gt;% arrange(desc(GPA))\n\n#&gt; # A tibble: 4 × 4\n#&gt;   Name      Age Major              GPA\n#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n#&gt; 1 Charlie    20 Mathematics        3.9\n#&gt; 2 Alice      21 Statistics         3.8\n#&gt; 3 David      21 Statistics         3.6\n#&gt; 4 Bob        22 Computer Science   3.5\n\n# 先按专业升序，再按 GPA 降序\nstudents_data %&gt;% arrange(Major, desc(GPA))\n\n#&gt; # A tibble: 4 × 4\n#&gt;   Name      Age Major              GPA\n#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n#&gt; 1 Bob        22 Computer Science   3.5\n#&gt; 2 Charlie    20 Mathematics        3.9\n#&gt; 3 Alice      21 Statistics         3.8\n#&gt; 4 David      21 Statistics         3.6\n\n\ngroup_by(): 按分类变量分组\n\n本身不改变数据外观，但会为后续操作（主要是 summarise()）添加分组信息。\n后续操作将在每个分组内部独立进行。\n\n\n# 按专业分组 (输出看起来没变，但内部结构变了)\nstudents_data %&gt;% group_by(Major)\n\n#&gt; # A tibble: 4 × 4\n#&gt; # Groups:   Major [3]\n#&gt;   Name      Age Major              GPA\n#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n#&gt; 1 Alice      21 Statistics         3.8\n#&gt; 2 Bob        22 Computer Science   3.5\n#&gt; 3 Charlie    20 Mathematics        3.9\n#&gt; 4 David      21 Statistics         3.6\n\n# 按学生ID分组 exam_scores 数据\nexam_scores %&gt;% group_by(StudentID)\n\n#&gt; # A tibble: 7 × 3\n#&gt; # Groups:   StudentID [3]\n#&gt;   StudentID Exam    Score\n#&gt;       &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;\n#&gt; 1       101 Midterm    85\n#&gt; 2       102 Midterm    90\n#&gt; 3       101 Final      88\n#&gt; 4       103 Midterm    75\n#&gt; 5       102 Final      92\n#&gt; 6       103 Final      80\n#&gt; 7       101 Quiz1      95\n\n\nsummarise() (或 summarize()): 数据汇总\n\n通常与 group_by() 结合使用，对每个分组进行汇总计算。\n创建包含汇总统计量的新数据框。\n常用的汇总函数：mean(), median(), sd(), var(), min(), max(), n() (计算行数/观测数), n_distinct() (计算唯一值数量)。\n\n\n# 计算所有学生的平均年龄和最高 GPA (没有 group_by)\nstudents_data %&gt;%\n  summarise(\n    Avg_Age = mean(Age),\n    Max_GPA = max(GPA)\n  )\n\n#&gt; # A tibble: 1 × 2\n#&gt;   Avg_Age Max_GPA\n#&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1      21     3.9\n\n# 计算每个专业的学生人数和平均 GPA\nstudents_data %&gt;%\n  group_by(Major) %&gt;%\n  summarise(\n    Num_Students = n(), # n() 计算当前分组的行数\n    Avg_GPA = mean(GPA, na.rm = TRUE) # 好习惯：处理可能的NA\n  )\n\n#&gt; # A tibble: 3 × 3\n#&gt;   Major            Num_Students Avg_GPA\n#&gt;   &lt;chr&gt;                   &lt;int&gt;   &lt;dbl&gt;\n#&gt; 1 Computer Science            1     3.5\n#&gt; 2 Mathematics                 1     3.9\n#&gt; 3 Statistics                  2     3.7\n\n# 计算每个学生的考试次数和平均分\nexam_scores %&gt;%\n  group_by(StudentID) %&gt;%\n  summarise(\n    Num_Exams = n(),\n    Avg_Score = mean(Score),\n    Min_Score = min(Score),\n    Max_Score = max(Score)\n  )\n\n#&gt; # A tibble: 3 × 5\n#&gt;   StudentID Num_Exams Avg_Score Min_Score Max_Score\n#&gt;       &lt;dbl&gt;     &lt;int&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1       101         3      89.3        85        95\n#&gt; 2       102         2      91          90        92\n#&gt; 3       103         2      77.5        75        80\n\n# 计算每门考试的参加人数和最高分\nexam_scores %&gt;%\n  group_by(Exam) %&gt;%\n  summarise(\n    Num_Participants = n_distinct(StudentID), # 统计不重复的学生ID数\n    Highest_Score = max(Score)\n  )\n\n#&gt; # A tibble: 3 × 3\n#&gt;   Exam    Num_Participants Highest_Score\n#&gt;   &lt;chr&gt;              &lt;int&gt;         &lt;dbl&gt;\n#&gt; 1 Final                  3            92\n#&gt; 2 Midterm                3            90\n#&gt; 3 Quiz1                  1            95\n\n\n\n\n\n\n\n\nungroup()\n\n\n\n使用 group_by() 后，数据会保持分组状态。如果后续操作希望在整个数据集上进行，而不是分组进行，需要使用 ungroup() 取消分组。\n\nstudents_data %&gt;%\n  group_by(Major) %&gt;%\n  mutate(Major_Avg_GPA = mean(GPA)) %&gt;% # 在分组内计算平均GPA\n  ungroup() %&gt;% # 取消分组\n  mutate(Overall_Avg_GPA = mean(GPA)) # 在全体数据上计算总平均GPA\n\n#&gt; # A tibble: 4 × 6\n#&gt;   Name      Age Major              GPA Major_Avg_GPA Overall_Avg_GPA\n#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;         &lt;dbl&gt;           &lt;dbl&gt;\n#&gt; 1 Alice      21 Statistics         3.8           3.7             3.7\n#&gt; 2 Bob        22 Computer Science   3.5           3.5             3.7\n#&gt; 3 Charlie    20 Mathematics        3.9           3.9             3.7\n#&gt; 4 David      21 Statistics         3.6           3.7             3.7",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>第三周：数据整形：`tidyverse` 的核心技艺</span>"
    ]
  },
  {
    "objectID": "week3_lecture.html#整洁数据-tidy-data-的理念",
    "href": "week3_lecture.html#整洁数据-tidy-data-的理念",
    "title": "第三周：数据整形：tidyverse 的核心技艺",
    "section": "2. 整洁数据 (Tidy Data) 的理念",
    "text": "2. 整洁数据 (Tidy Data) 的理念\n“整洁数据” 是由 Hadley Wickham 提出的数据组织标准，旨在简化数据分析流程。遵循整洁数据原则的数据更易于使用 tidyverse 工具进行处理和可视化。\n\n三条核心原则:\n\n每个变量构成一列 (Each variable forms a column)。\n每个观测构成一行 (Each observation forms a row)。\n每种类型的观测单元构成一个表格 (Each type of observational unit forms a table)。\n\n为何重要？\n\ntidyverse 中的函数（dplyr, ggplot2 等）都设计为处理整洁数据。\n使数据结构标准化，便于理解和协作。\n简化数据清理和转换步骤。\n\n不整洁数据的常见形式:\n\n列名是变量值，而不是变量名 (例如，年份作为列名)。\n一个单元格中存储了多个值。\n变量同时存储在行和列中。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>第三周：数据整形：`tidyverse` 的核心技艺</span>"
    ]
  },
  {
    "objectID": "week3_lecture.html#tidyr-让数据更整洁",
    "href": "week3_lecture.html#tidyr-让数据更整洁",
    "title": "第三周：数据整形：tidyverse 的核心技艺",
    "section": "3. tidyr: 让数据更整洁",
    "text": "3. tidyr: 让数据更整洁\ntidyr 包提供了将数据在”宽”格式和”长”格式之间转换的函数，帮助我们将数据整理成”整洁”的形式。\n\n宽数据 (Wide Data): 通常人类阅读更友好，但不利于计算。变量值可能作为列名。\n长数据 (Long Data): 通常更符合整洁数据原则，便于 tidyverse 处理。每个观测的关键信息都在行内，变量名在列中。\n核心函数:\n\npivot_longer(): 将宽数据变长。将多个列”融合”成键-值对的两列。\npivot_wider(): 将长数据变宽。根据键-值对将数据”展开”到多个列。\n\npivot_longer() 示例: 假设我们有如下”宽”格式数据，记录了不同季度销售额：\n\nsales_wide &lt;- tibble(\n  Product = c(\"A\", \"B\"),\n  Qtr1 = c(100, 150),\n  Qtr2 = c(110, 160),\n  Qtr3 = c(120, 170),\n  Qtr4 = c(130, 180)\n  )\n\n  print(sales_wide)\n\n#&gt; # A tibble: 2 × 5\n#&gt;   Product  Qtr1  Qtr2  Qtr3  Qtr4\n#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 A         100   110   120   130\n#&gt; 2 B         150   160   170   180\n\n\n这里的列名 Qtr1 到 Qtr4 实际上是”季度”这个变量的值。我们希望将其转换为整洁的长格式：\n\nsales_long &lt;- sales_wide %&gt;%\n  pivot_longer(\n    cols = Qtr1:Qtr4, # 指定哪些列需要被转换 (这里是 Qtr1 到 Qtr4) \n    names_to = \"Quarter\",  # 新列名，用于存储原来的列名 (Qtr1, Qtr2...)\n    values_to = \"Sales\"    # 新列名，用于存储原来的单元格值\n  )\n\nprint(sales_long)\n\n#&gt; # A tibble: 8 × 3\n#&gt;   Product Quarter Sales\n#&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;\n#&gt; 1 A       Qtr1      100\n#&gt; 2 A       Qtr2      110\n#&gt; 3 A       Qtr3      120\n#&gt; 4 A       Qtr4      130\n#&gt; 5 B       Qtr1      150\n#&gt; 6 B       Qtr2      160\n#&gt; 7 B       Qtr3      170\n#&gt; 8 B       Qtr4      180\n\n\n现在，每个观测（某个产品在某个季度的销售额）都独占一行，变量（产品、季度、销售额）各自成列。\npivot_wider() 示例: 将刚才的长数据 sales_long 转换回宽数据：\n\nsales_regained_wide &lt;- sales_long %&gt;%\n  pivot_wider(\n    names_from = Quarter, # 指定包含新列名的列 (Quarter)\n    values_from = Sales   # 指定包含新单元格值的列 (Sales)\n    )\n\nprint(sales_regained_wide)\n\n#&gt; # A tibble: 2 × 5\n#&gt;   Product  Qtr1  Qtr2  Qtr3  Qtr4\n#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 A         100   110   120   130\n#&gt; 2 B         150   160   170   180",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>第三周：数据整形：`tidyverse` 的核心技艺</span>"
    ]
  },
  {
    "objectID": "week3_lecture.html#处理缺失值-na",
    "href": "week3_lecture.html#处理缺失值-na",
    "title": "第三周：数据整形：tidyverse 的核心技艺",
    "section": "4. 处理缺失值 (NA)",
    "text": "4. 处理缺失值 (NA)\n缺失值 (NA, Not Available) 在真实数据中非常常见。dplyr 和 tidyr 以及 R 基础函数提供了处理它们的方法。\n\n识别缺失值: is.na() 函数返回一个逻辑向量，TRUE 表示对应位置是 NA。\n\nx &lt;- c(1, 2, NA, 4, NA)\nis.na(x)\n\n#&gt; [1] FALSE FALSE  TRUE FALSE  TRUE\n\n# 在数据框中使用 (例如，检查 exam_scores 中是否有 NA)\nis.na(exam_scores) # 返回一个与数据框同样大小的逻辑矩阵\n\n#&gt;      StudentID  Exam Score\n#&gt; [1,]     FALSE FALSE FALSE\n#&gt; [2,]     FALSE FALSE FALSE\n#&gt; [3,]     FALSE FALSE FALSE\n#&gt; [4,]     FALSE FALSE FALSE\n#&gt; [5,]     FALSE FALSE FALSE\n#&gt; [6,]     FALSE FALSE FALSE\n#&gt; [7,]     FALSE FALSE FALSE\n\nany(is.na(exam_scores)) # 检查整个数据框是否有任何 NA\n\n#&gt; [1] FALSE\n\ncolSums(is.na(exam_scores)) # 计算每列的 NA 数量\n\n#&gt; StudentID      Exam     Score \n#&gt;         0         0         0\n\n\n处理策略:\n\n删除:\n\nna.omit() (基础 R): 删除任何列包含 NA 的整行。简单粗暴，可能丢失过多信息。\ndrop_na() (tidyr): 功能类似 na.omit(), 但可以指定只检查某些列的 NA。\n\n\n\nscores_na_df &lt;- tibble(ID = 1:6, Score = c(85, 92, NA, 88, 95, 72))\nprint(scores_na_df)\n\n#&gt; # A tibble: 6 × 2\n#&gt;      ID Score\n#&gt;   &lt;int&gt; &lt;dbl&gt;\n#&gt; 1     1    85\n#&gt; 2     2    92\n#&gt; 3     3    NA\n#&gt; 4     4    88\n#&gt; 5     5    95\n#&gt; 6     6    72\n\nna.omit(scores_na_df) # 删除包含 NA 的行\n\n#&gt; # A tibble: 5 × 2\n#&gt;      ID Score\n#&gt;   &lt;int&gt; &lt;dbl&gt;\n#&gt; 1     1    85\n#&gt; 2     2    92\n#&gt; 3     4    88\n#&gt; 4     5    95\n#&gt; 5     6    72\n\nlibrary(tidyr)\nscores_na_df %&gt;% drop_na() # 同上\n\n#&gt; # A tibble: 5 × 2\n#&gt;      ID Score\n#&gt;   &lt;int&gt; &lt;dbl&gt;\n#&gt; 1     1    85\n#&gt; 2     2    92\n#&gt; 3     4    88\n#&gt; 4     5    95\n#&gt; 5     6    72\n\n# 假设有另一列，我们只想删除 Score 为 NA 的行\nscores_na_df2 &lt;- tibble(\n  ID = 1:6,\n  Score = c(85, 92, NA, 88, 95, 72),\n  Group = c(\"A\", \"B\", \"A\", NA, \"B\", \"A\")\n  )\nprint(scores_na_df2)\n\n#&gt; # A tibble: 6 × 3\n#&gt;      ID Score Group\n#&gt;   &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;\n#&gt; 1     1    85 A    \n#&gt; 2     2    92 B    \n#&gt; 3     3    NA A    \n#&gt; 4     4    88 &lt;NA&gt; \n#&gt; 5     5    95 B    \n#&gt; 6     6    72 A\n\nscores_na_df2 %&gt;% drop_na(Score) # 只检查 Score 列的 NA\n\n#&gt; # A tibble: 5 × 3\n#&gt;      ID Score Group\n#&gt;   &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;\n#&gt; 1     1    85 A    \n#&gt; 2     2    92 B    \n#&gt; 3     4    88 &lt;NA&gt; \n#&gt; 4     5    95 B    \n#&gt; 5     6    72 A\n\n\n\n填充/插补 (Imputation): 用某个值（如均值、中位数、众数或模型预测值）替换 NA。这更复杂，需要根据具体情况选择合适的方法（后续课程可能涉及）。\n\n\nreplace_na() (tidyr): 用指定值替换 NA。\n\n\nscores_na_df %&gt;%\n  mutate(Score_filled = replace_na(Score, mean(Score, na.rm = TRUE))) # 用均值填充\n\n#&gt; # A tibble: 6 × 3\n#&gt;      ID Score Score_filled\n#&gt;   &lt;int&gt; &lt;dbl&gt;        &lt;dbl&gt;\n#&gt; 1     1    85         85  \n#&gt; 2     2    92         92  \n#&gt; 3     3    NA         86.4\n#&gt; 4     4    88         88  \n#&gt; 5     5    95         95  \n#&gt; 6     6    72         72\n\n\n\n在计算中忽略: 许多函数（如 mean(), sum(), sd() 等）有 na.rm = TRUE 参数。\n\n\nmean(scores_na_df$Score) # NA\n\n#&gt; [1] NA\n\nmean(scores_na_df$Score, na.rm = TRUE) # 正确计算\n\n#&gt; [1] 86.4\n\n\n\n\n\n\n\n\n\n处理 NA 的重要性\n\n\n\n不恰当处理 NA 会导致分析结果偏差甚至错误。选择哪种策略取决于数据的性质、缺失的原因以及分析的目标。删除是最简单的方法，但只有在 NA 占比很小或确定该观测无效时才推荐。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>第三周：数据整形：`tidyverse` 的核心技艺</span>"
    ]
  },
  {
    "objectID": "week3_lecture.html#管道-连接多步操作",
    "href": "week3_lecture.html#管道-连接多步操作",
    "title": "第三周：数据整形：tidyverse 的核心技艺",
    "section": "5. 管道 (%>%) 连接多步操作",
    "text": "5. 管道 (%&gt;%) 连接多步操作\n管道使得复杂的数据处理流程清晰易读。\n\n示例： 从 exam_scores 数据中，找出每个学生（StudentID）的最高分（Max_Score），并按最高分降序排列，最后只显示 StudentID 和 Max_Score。\n\nexam_scores %&gt;%\n  group_by(StudentID) %&gt;% # 按学生分组\n  summarise(Max_Score = max(Score)) %&gt;% # 计算每个学生的最高分\n  arrange(desc(Max_Score)) %&gt;% # 按最高分降序排列\n  ungroup() # 最好取消分组（虽然这里影响不大）\n\n#&gt; # A tibble: 3 × 2\n#&gt;   StudentID Max_Score\n#&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1       101        95\n#&gt; 2       102        92\n#&gt; 3       103        80\n\n\n对比不使用管道的代码：\n\ngrouped_data &lt;- group_by(exam_scores, StudentID)\nsummary_data &lt;- summarise(grouped_data, Max_Score = max(Score))\narranged_data &lt;- arrange(summary_data, desc(Max_Score))\nungroup(arranged_data)\n\n#&gt; # A tibble: 3 × 2\n#&gt;   StudentID Max_Score\n#&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1       101        95\n#&gt; 2       102        92\n#&gt; 3       103        80\n\n\n\n管道显然更简洁、更符合思维流程。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>第三周：数据整形：`tidyverse` 的核心技艺</span>"
    ]
  },
  {
    "objectID": "week3_lecture.html#项目相关与本周总结",
    "href": "week3_lecture.html#项目相关与本周总结",
    "title": "第三周：数据整形：tidyverse 的核心技艺",
    "section": "6. 项目相关与本周总结",
    "text": "6. 项目相关与本周总结\n\n项目任务:\n\n应用本周学到的 dplyr 动词（mutate, arrange, group_by, summarise）对你的项目数据进行初步的探索性分析。例如，计算分组统计量，创建新变量，按特定条件排序。\n检查你的项目数据是否符合”整洁数据”原则。如果不符合，思考如何使用 pivot_longer 或 pivot_wider 进行转换（如果适用）。\n检查项目数据中的缺失值 (is.na(), colSums(is.na()))。思考初步的处理策略（暂时可以先记录下来，不一定立即处理）。\n\n本周回顾: 我们掌握了 dplyr 的核心转换函数和 tidyr 的长宽格式转换，理解了整洁数据的重要性，并学习了处理缺失值的基本方法。通过管道，我们可以将这些操作流畅地组合起来，高效地完成数据整形任务。\n\n下周预告: 数据准备就绪，是时候让数据”说话”了！我们将学习强大的可视化工具 ggplot2，探索如何通过图形发现数据中的模式和洞见，并初步接触推断统计的思想。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>第三周：数据整形：`tidyverse` 的核心技艺</span>"
    ]
  },
  {
    "objectID": "week4_lecture.html",
    "href": "week4_lecture.html",
    "title": "第四周：眼见为实：ggplot2 可视化探索与推断初步",
    "section": "",
    "text": "1. 为何需要数据可视化？\n我们已经学会了如何整理数据和计算描述性统计量，但数字往往难以直观地揭示数据背后的模式、趋势和异常。数据可视化通过图形将数据呈现出来，帮助我们：",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>第四周：眼见为实：`ggplot2` 可视化探索与推断初步</span>"
    ]
  },
  {
    "objectID": "week4_lecture.html#为何需要数据可视化",
    "href": "week4_lecture.html#为何需要数据可视化",
    "title": "第四周：眼见为实：ggplot2 可视化探索与推断初步",
    "section": "",
    "text": "探索性数据分析 (Exploratory Data Analysis, EDA): 快速理解数据分布、变量间关系、发现异常点。\n沟通发现: 清晰有效地向他人展示数据洞见。\n模型诊断: (后续课程) 检查统计模型的假设是否成立。\n\n\n\n\n\n\n\n本周目标\n\n\n\n\n理解数据可视化的基本原则。\n掌握 ggplot2 的核心语法和图层叠加思想。\n能够绘制常用的单变量和双变量图形。\n对图形进行基本的定制（标签、主题）。\n初步理解推断统计的核心思想：从样本推断总体。\n理解点估计和区间估计的概念。\n掌握置信区间的概念和正确解释。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>第四周：眼见为实：`ggplot2` 可视化探索与推断初步</span>"
    ]
  },
  {
    "objectID": "week4_lecture.html#数据可视化原则",
    "href": "week4_lecture.html#数据可视化原则",
    "title": "第四周：眼见为实：ggplot2 可视化探索与推断初步",
    "section": "2. 数据可视化原则",
    "text": "2. 数据可视化原则\n有效的可视化不仅仅是绘制图形，更要遵循一定的原则，确保图形清晰、准确、不误导。\n\n清晰性: 图形元素（点、线、条）易于区分，标签、坐标轴清晰明了。\n准确性: 图形真实反映数据特征，避免扭曲（如不恰当的坐标轴范围）。\n简洁性: 避免不必要的图形元素（“图表垃圾”），突出核心信息。\n目的性: 图形应服务于特定的分析或沟通目的。选择合适的图形类型。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>第四周：眼见为实：`ggplot2` 可视化探索与推断初步</span>"
    ]
  },
  {
    "objectID": "week4_lecture.html#ggplot2图形的语法",
    "href": "week4_lecture.html#ggplot2图形的语法",
    "title": "第四周：眼见为实：ggplot2 可视化探索与推断初步",
    "section": "3. ggplot2：图形的语法",
    "text": "3. ggplot2：图形的语法\nggplot2 是 tidyverse 中的旗舰级可视化包，它基于“图形语法”(Grammar of Graphics) 的理念，提供了一种强大而灵活的方式来创建各种复杂的图形。\n\n核心理念：图层叠加 (Layers) 一个 ggplot2 图形由若干图层叠加而成，每个图层包含：\n\n数据 (Data): 要可视化的数据框或 Tibble。\n映射 (Aesthetic Mappings, aes()): 将数据中的变量映射到图形的视觉属性（如 x 轴位置、y 轴位置、颜色、形状、大小等）。\n几何对象 (Geometric Objects, geom_...): 定义了使用哪种图形来表示数据（如点、线、条形、箱线等）。\n统计变换 (Statistical Transformations, stat_...): 对数据进行统计汇总（如计算频数、密度、均值等），geom 通常有默认的 stat。\n位置调整 (Position Adjustments, position_...): 处理图形元素重叠问题（如堆叠、并列）。\n坐标系 (Coordinate System, coord_...): 控制坐标轴（如笛卡尔坐标、极坐标）。\n分面 (Faceting, facet_...): 将数据按某个分类变量分割成多个子图。\n\n基本语法模板:\nggplot(data = &lt;DATA_FRAME&gt;) +\n  geom_xxx(mapping = aes(&lt;MAPPINGS&gt;)) +       # 其他图层、设定...\n示例数据准备: 我们将使用 ggplot2 内置的 mpg 数据集（关于不同汽车型号燃油效率等信息）。\n\nlibrary(tidyverse)     \nglimpse(mpg) # 快速查看数据结构\n\n#&gt; Rows: 234\n#&gt; Columns: 11\n#&gt; $ manufacturer &lt;chr&gt; \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"audi\", \"…\n#&gt; $ model        &lt;chr&gt; \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4\", \"a4 quattro\", \"…\n#&gt; $ displ        &lt;dbl&gt; 1.8, 1.8, 2.0, 2.0, 2.8, 2.8, 3.1, 1.8, 1.8, 2.0, 2.0, 2.…\n#&gt; $ year         &lt;int&gt; 1999, 1999, 2008, 2008, 1999, 1999, 2008, 1999, 1999, 200…\n#&gt; $ cyl          &lt;int&gt; 4, 4, 4, 4, 6, 6, 6, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, …\n#&gt; $ trans        &lt;chr&gt; \"auto(l5)\", \"manual(m5)\", \"manual(m6)\", \"auto(av)\", \"auto…\n#&gt; $ drv          &lt;chr&gt; \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"f\", \"4\", \"4\", \"4\", \"4\", \"4…\n#&gt; $ cty          &lt;int&gt; 18, 21, 20, 21, 16, 18, 18, 18, 16, 20, 19, 15, 17, 17, 1…\n#&gt; $ hwy          &lt;int&gt; 29, 29, 31, 30, 26, 26, 27, 26, 25, 28, 27, 25, 25, 25, 2…\n#&gt; $ fl           &lt;chr&gt; \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p\", \"p…\n#&gt; $ class        &lt;chr&gt; \"compact\", \"compact\", \"compact\", \"compact\", \"compact\", \"c…\n\n# ?mpg # 查看数据集帮助文档",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>第四周：眼见为实：`ggplot2` 可视化探索与推断初步</span>"
    ]
  },
  {
    "objectID": "week4_lecture.html#常用单变量图形",
    "href": "week4_lecture.html#常用单变量图形",
    "title": "第四周：眼见为实：ggplot2 可视化探索与推断初步",
    "section": "4. 常用单变量图形",
    "text": "4. 常用单变量图形\n用于探索单个变量的分布特征。\n\n直方图 (Histogram): geom_histogram()\n\n展示连续变量的分布情况。将变量范围分成若干区间 (bins)，计算落在每个区间的观测数量。\naes(): 通常只需要映射 x 轴。\n\n\n# 探索发动机排量 (displ) 的分布\nggplot(data = mpg) +\n  geom_histogram(mapping = aes(x = displ), binwidth = 0.5, fill = \"skyblue\", color = \"black\")\n\n\n\n\n\n\n\n  # binwidth 控制区间的宽度，可以调整以观察不同粒度的分布\n  # fill 设置填充色, color 设置边框色\n\n密度图 (Density Plot): geom_density()\n\n直方图的平滑版本，更清晰地展示分布形状。\naes(): 通常只需要映射 x 轴。\n\n\n# 探索发动机排量 (displ) 的分布\nggplot(data = mpg) +\n  geom_density(mapping = aes(x = displ), fill = \"lightgreen\", alpha = 0.7)\n\n\n\n\n\n\n\n  # alpha 控制填充透明度\n\n箱线图 (Boxplot): geom_boxplot()\n\n展示连续变量的分布概要（中位数、四分位数、异常值）。\naes(): 通常映射 y 轴（或 x 轴，如果想画水平箱线图）。可以映射 x 轴为分类变量来分组比较。\n\n\n# 探索每加仑高速公路行驶英里数 (hwy) 的分布\nggplot(data = mpg) +\n  geom_boxplot(mapping = aes(y = hwy), fill = \"orange\")\n\n\n\n\n\n\n\n# 查看不同驱动方式 (drv: f=前驱, r=后驱, 4=四驱) 的 hwy 分布\nggplot(data = mpg) +\n  geom_boxplot(mapping = aes(x = drv, y = hwy, fill = drv)) # 按 drv 分组并用颜色区分\n\n\n\n\n\n\n\n\n\n\n箱体：覆盖 IQR (Q1 到 Q3)。\n箱内粗线：中位数 (Q2)。\n触须 (Whiskers)：通常延伸到距离箱体 1.5 倍 IQR 范围内的最远点。\n点：超出触须范围的潜在异常值。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>第四周：眼见为实：`ggplot2` 可视化探索与推断初步</span>"
    ]
  },
  {
    "objectID": "week4_lecture.html#常用双变量图形",
    "href": "week4_lecture.html#常用双变量图形",
    "title": "第四周：眼见为实：ggplot2 可视化探索与推断初步",
    "section": "5. 常用双变量图形",
    "text": "5. 常用双变量图形\n用于探索两个变量之间的关系。\n\n散点图 (Scatter Plot): geom_point()\n\n展示两个连续变量之间的关系。\naes(): 映射 x 和 y 轴。可以映射其他属性（如 color, shape, size）到第三个变量。\n\n\n# 探索发动机排量 (displ) 与高速公路里程 (hwy) 的关系\nggplot(data = mpg) +\n  geom_point(mapping = aes(x = displ, y = hwy))\n\n\n\n\n\n\n\n# 将颜色映射到车辆类别 (class)\nggplot(data = mpg) +\n  geom_point(mapping = aes(x = displ, y = hwy, color = class))\n\n\n\n\n\n\n\n# 将点的大小映射到气缸数 (cyl)\nggplot(data = mpg) +\n  geom_point(mapping = aes(x = displ, y = hwy, size = cyl, color = class), alpha = 0.6)\n\n\n\n\n\n\n\n\n分组箱线图/小提琴图 (Grouped Boxplot/Violin Plot)\n\n比较一个连续变量在不同分类变量组别下的分布。\ngeom_boxplot() 或 geom_violin() (小提琴图结合了箱线图和密度图)。\naes(): 映射 x 到分类变量，y 到连续变量。\n\n\n# 比较不同车辆类别 (class) 的高速公路里程 (hwy) 分布 (箱线图)\nggplot(data = mpg) +\n  geom_boxplot(mapping = aes(x = class, y = hwy, fill = class)) +\n  coord_flip() # 翻转坐标轴，让类别标签更易读\n\n\n\n\n\n\n\n# 比较不同车辆类别 (class) 的高速公路里程 (hwy) 分布 (小提琴图)\nggplot(data = mpg) +\n  geom_violin(mapping = aes(x = class, y = hwy, fill = class)) +\n  geom_boxplot(mapping = aes(x = class, y = hwy), width = 0.1, fill = \"white\", alpha = 0.5) + # 叠加箱线图\n  coord_flip()\n\n\n\n\n\n\n\n\n条形图 (Bar Plot): geom_bar() / geom_col()\n\ngeom_bar(): 统计分类变量的频数。aes() 只需要映射 x。\ngeom_col(): 直接绘制已计算好的高度值。aes() 需要映射 x 和 y。\n\n\n# 统计不同车辆类别 (class) 的数量\nggplot(data = mpg) +\n  geom_bar(mapping = aes(x = class, fill = class)) +\n  coord_flip()\n\n\n\n\n\n\n\n# 统计不同类型车辆的平均油耗 (hwy)\nvehicle_summary &lt;- mpg %&gt;%\n  group_by(class) %&gt;%\n  summarise(Avg_hwy = mean(hwy))\n\n# 绘制每个车辆类别的平均油耗 (hwy)\nggplot(data = vehicle_summary) +\n  geom_col(mapping = aes(x = class, y = Avg_hwy, fill = class))",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>第四周：眼见为实：`ggplot2` 可视化探索与推断初步</span>"
    ]
  },
  {
    "objectID": "week4_lecture.html#图形定制初步",
    "href": "week4_lecture.html#图形定制初步",
    "title": "第四周：眼见为实：ggplot2 可视化探索与推断初步",
    "section": "6. 图形定制初步",
    "text": "6. 图形定制初步\nggplot2 提供了丰富的定制选项。\n\n标签 (Labels): labs()\n\n修改标题、副标题、坐标轴标签、图例标题等。\n\n\np &lt;- ggplot(data = mpg) +\n  geom_point(mapping = aes(x = displ, y = hwy, color = class))\n\np + labs(\n  title = \"发动机排量与高速公路里程关系\",\n  subtitle = \"数据来源：mpg 数据集\",\n  x = \"发动机排量 (升)\",\n  y = \"高速公路里程 (英里/加仑)\",\n  color = \"车辆类别\",\n  caption = \"图形由 ggplot2 生成\"\n)\n\n\n\n\n\n\n\n\n主题 (Themes): theme_...()\n\n快速改变图形的整体外观（背景、网格线、字体等）。\n内置主题：theme_bw(), theme_minimal(), theme_classic(), theme_light(), theme_dark() 等。\ntheme() 函数可以进行更细致的调整。\n\n\np + labs(\n  title = \"发动机排量与高速公路里程关系\",\n  x = \"发动机排量 (升)\",\n  y = \"高速公路里程 (英里/加仑)\",\n  color = \"车辆类别\"\n) +\ntheme_minimal() # 应用 minimal 主题",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>第四周：眼见为实：`ggplot2` 可视化探索与推断初步</span>"
    ]
  },
  {
    "objectID": "week4_lecture.html#推断统计思想初步",
    "href": "week4_lecture.html#推断统计思想初步",
    "title": "第四周：眼见为实：ggplot2 可视化探索与推断初步",
    "section": "7. 推断统计思想初步",
    "text": "7. 推断统计思想初步\n到目前为止，我们主要关注描述统计（描述已有数据的特征）和探索性分析（发现数据中的模式）。推断统计则更进一步，试图从样本 (Sample) 数据推断总体 (Population) 的特征。\n\n总体 vs 样本:\n\n总体: 我们感兴趣的所有个体或对象的集合（例如，所有中国大学生的身高）。总体通常太大而无法完全测量。\n样本: 从总体中抽取的一部分个体或对象的集合（例如，随机抽取 1000 名中国大学生的身高）。我们通过分析样本来了解总体。\n\n抽样分布 (Sampling Distribution):\n\n想象一下，我们反复从同一个总体中抽取多个大小相同的样本，并计算每个样本的某个统计量（如样本均值 \\(\\bar{x}\\)）。\n这些样本统计量的分布就称为该统计量的抽样分布。\n抽样分布描述了样本统计量本身的不确定性或变异性。\n\n中心极限定理 (Central Limit Theorem, CLT) 直观理解:\n\nCLT 是统计学中最重要的定理之一。\n核心思想: 无论总体本身的分布形状如何（只要不是太极端），当样本量 \\(n\\) 足够大时，样本均值 \\(\\bar{x}\\) 的抽样分布近似服从正态分布。\n这个正态分布的均值等于总体均值 \\(\\mu\\)，标准差（称为标准误 Standard Error, SE）等于总体标准差 \\(\\sigma\\) 除以 \\(\\sqrt{n}\\) (\\(SE = \\frac{\\sigma}{\\sqrt{n}}\\))。\n意义: 使得我们可以利用正态分布的性质来对总体均值进行推断，即使我们不知道总体的具体分布。\n\n\n\nCLT 是许多统计推断方法（如 t 检验、置信区间）的理论基础。它告诉我们，即使原始数据不是正态的，样本均值在多次抽样下也会趋向于正态分布，这极大地简化了推断过程。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>第四周：眼见为实：`ggplot2` 可视化探索与推断初步</span>"
    ]
  },
  {
    "objectID": "week4_lecture.html#参数估计点估计-vs-区间估计",
    "href": "week4_lecture.html#参数估计点估计-vs-区间估计",
    "title": "第四周：眼见为实：ggplot2 可视化探索与推断初步",
    "section": "8. 参数估计：点估计 vs 区间估计",
    "text": "8. 参数估计：点估计 vs 区间估计\n我们通常希望估计总体的某个参数（如总体均值 \\(\\mu\\)、总体比例 \\(p\\)）。\n\n点估计 (Point Estimate): 用样本统计量直接作为总体参数的估计值。\n\n例如，用样本均值 \\(\\bar{x}\\) 估计总体均值 \\(\\mu\\)。\n用样本比例 \\(\\hat{p}\\) 估计总体比例 \\(p\\)。\n优点: 简单直观。\n缺点: 几乎不可能精确等于总体参数，且没有提供估计的不确定性信息。由于抽样误差，每次抽样的点估计值都会有所不同。\n\n区间估计 (Interval Estimate): 给出一个包含总体参数真实值的可能范围，并附带一定的置信水平 (Confidence Level)。\n\n最常见的区间估计是置信区间 (Confidence Interval, CI)。\n优点: 提供了估计的不确定性度量。\n缺点: 理解和解释比点估计复杂。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>第四周：眼见为实：`ggplot2` 可视化探索与推断初步</span>"
    ]
  },
  {
    "objectID": "week4_lecture.html#置信区间-confidence-interval",
    "href": "week4_lecture.html#置信区间-confidence-interval",
    "title": "第四周：眼见为实：ggplot2 可视化探索与推断初步",
    "section": "9. 置信区间 (Confidence Interval)",
    "text": "9. 置信区间 (Confidence Interval)\n\n概念: 基于样本数据构造的一个区间，我们有一定程度的信心（由置信水平决定）认为该区间包含了未知的总体参数。\n置信水平 (Confidence Level): 通常表示为 \\((1-\\alpha) \\times 100\\%\\)，常用 95%。\n\n95% 置信区间的含义 (重要！): 如果我们反复从总体中抽取无数个相同大小的样本，并为每个样本构造一个 95% 置信区间，那么大约有 95% 的这些区间会包含真实的总体参数。\n错误理解: 不能说“总体参数有 95% 的概率落在这个具体的区间内”。总体参数是一个固定的值，它要么在区间内，要么不在。置信水平描述的是构造区间这个方法的长期可靠性。\n\n置信区间的构成 (以总体均值 \\(\\mu\\) 为例，假设 \\(\\sigma\\) 已知或 \\(n\\) 很大):\n\n置信区间 = 点估计 \\(\\pm\\) 边际误差 (Margin of Error, MOE)\n\\(CI = \\bar{x} \\pm Z_{\\alpha/2} \\times SE = \\bar{x} \\pm Z_{\\alpha/2} \\times \\frac{\\sigma}{\\sqrt{n}}\\)\n\\(Z_{\\alpha/2}\\) 是标准正态分布上侧 \\(\\alpha/2\\) 分位数（例如，95% 置信水平对应 \\(\\alpha=0.05\\), \\(Z_{0.025} \\approx 1.96\\)）。\n边际误差取决于：\n\n置信水平: 水平越高，区间越宽。\n数据变异性 (\\(\\sigma\\)): 变异性越大，区间越宽。\n样本量 (\\(n\\)): 样本量越大，区间越窄（估计越精确）。\n\n\n解释示例: 假设我们计算出某产品用户满意度的 95% 置信区间为 [8.2, 8.8]。\n\n正确解释: 我们有 95% 的信心认为，该产品用户的真实平均满意度介于 8.2 和 8.8 之间。或者说，如果我们重复抽样并构造区间，预计 95% 的区间会包含真实的平均满意度。\n错误解释:\n\n“用户的满意度有 95% 的概率在 8.2 到 8.8 之间。” (概率是针对区间的构造方法，不是针对具体区间或参数)\n“95% 的用户满意度在 8.2 到 8.8 之间。” (置信区间是关于总体均值，不是关于个体数据)",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>第四周：眼见为实：`ggplot2` 可视化探索与推断初步</span>"
    ]
  },
  {
    "objectID": "week4_lecture.html#项目相关与本周总结",
    "href": "week4_lecture.html#项目相关与本周总结",
    "title": "第四周：眼见为实：ggplot2 可视化探索与推断初步",
    "section": "10. 项目相关与本周总结",
    "text": "10. 项目相关与本周总结\n\n项目任务:\n\n使用 ggplot2 对你的项目数据进行深入的探索性数据分析 (EDA)。尝试绘制各种单变量和双变量图形，探索变量分布和关系。\n思考你的项目中可能需要进行参数估计的问题。例如，你想估计某个群体的平均值、比例或两个变量间的关系强度吗？这些估计是点估计还是区间估计更有意义？\n\n本周回顾: 我们学习了数据可视化的重要性和 ggplot2 的强大功能，能够绘制和定制常见的统计图形。同时，我们初步踏入了推断统计的大门，理解了从样本推断总体的基本思想、抽样分布、CLT 的直观意义，以及点估计和置信区间的概念与解释。\n\n下周预告: 我们将正式学习假设检验，这是推断统计的另一个核心工具，用于基于样本证据对关于总体的某个断言（假设）做出决策。我们将学习单样本和双样本 t 检验，以及方差分析 (ANOVA)。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>第四周：眼见为实：`ggplot2` 可视化探索与推断初步</span>"
    ]
  },
  {
    "objectID": "week5_lecture.html",
    "href": "week5_lecture.html",
    "title": "第五周：做出判断：假设检验 (单/双样本) 与 ANOVA 应用",
    "section": "",
    "text": "1. 假设检验：基于证据做决策\n上周我们学习了如何用置信区间来估计总体参数的范围。假设检验 (Hypothesis Testing) 是推断统计的另一个核心工具，它提供了一个正式的框架，用于利用样本数据来判断关于总体的某个断言（假设）是否可信。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>第五周：做出判断：假设检验 (单/双样本) 与 ANOVA 应用</span>"
    ]
  },
  {
    "objectID": "week5_lecture.html#假设检验基于证据做决策",
    "href": "week5_lecture.html#假设检验基于证据做决策",
    "title": "第五周：做出判断：假设检验 (单/双样本) 与 ANOVA 应用",
    "section": "",
    "text": "核心思想: 我们想检验一个关于总体的原假设 (Null Hypothesis, \\(H_0\\))。我们收集样本数据，看样本证据在多大程度上反对 \\(H_0\\)。如果证据足够强（即样本结果在 \\(H_0\\) 成立的条件下非常罕见），我们就拒绝 \\(H_0\\)，并接受与之对立的备择假设 (Alternative Hypothesis, \\(H_1\\) 或 \\(H_a\\))。\n\n\n\n\n\n\n\n本周目标\n\n\n\n\n理解假设检验的基本逻辑：原假设、备择假设、P 值、显著性水平、决策规则。\n区分并理解两类错误。\n掌握单样本 t 检验的应用场景、假设、R 实现和结果解读。\n掌握双独立样本 t 检验的应用场景、假设（特别是方差齐性）、R 实现和结果解读。\n掌握配对样本 t 检验的应用场景、与独立样本的区别、R 实现和结果解读。\n理解为何需要方差分析 (ANOVA) 来比较多组均值。\n掌握单因素 ANOVA 的应用场景、假设、R 实现和结果解读（ANOVA 表）。\n理解事后检验的必要性，并掌握 Tukey’s HSD 的 R 实现和解读。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>第五周：做出判断：假设检验 (单/双样本) 与 ANOVA 应用</span>"
    ]
  },
  {
    "objectID": "week5_lecture.html#假设检验的逻辑步骤",
    "href": "week5_lecture.html#假设检验的逻辑步骤",
    "title": "第五周：做出判断：假设检验 (单/双样本) 与 ANOVA 应用",
    "section": "2. 假设检验的逻辑步骤",
    "text": "2. 假设检验的逻辑步骤\n一个典型的假设检验包含以下步骤：\n\n陈述假设:\n\n原假设 (\\(H_0\\)): 通常是表示“没有效应”、“没有差异”或维持现状的陈述。它包含等号（=, ≤, ≥）。我们总是假设 \\(H_0\\) 为真开始分析。\n\n例：新药无效 (\\(μ_{新药} = μ_{安慰剂}\\))。\n例：产品合格率不低于 95% (\\(p \\ge 0.95\\))。\n\n备择假设 (\\(H_1\\) 或 \\(H_a\\)): 我们希望找到证据支持的陈述，通常是表示“有效应”、“有差异”或我们怀疑的情况。它不包含等号（≠, &lt;, &gt;）。\n\n例：新药有效 (\\(μ_{新药} \\ne μ_{安慰剂}\\)，双侧检验；或 \\(μ_{新药} &gt; μ_{安慰剂}\\)，单侧检验)。\n例：产品合格率低于 95% (\\(p &lt; 0.95\\))。\n\n\n选择显著性水平 (\\(\\alpha\\)):\n\n\\(\\alpha\\) 是我们愿意承担的犯第一类错误的概率（见下文）。\n它代表了我们拒绝 \\(H_0\\) 所需的证据强度阈值。\n常用值：0.05 (5%)，有时也用 0.01 或 0.10。需要在分析前确定。\n\n计算检验统计量 (Test Statistic):\n\n根据样本数据计算一个值，该值衡量了样本结果与 \\(H_0\\) 预期结果之间的差异程度（考虑了抽样变异性）。\n不同的检验方法有不同的检验统计量（如 t 值, F 值, \\(\\chi^2\\) 值）。\n\n计算 P 值 (P-value):\n\n核心概念: P 值是在假设 \\(H_0\\) 为真的前提下，观察到当前样本结果或更极端结果的概率。\nP 值越小，表示样本结果在 \\(H_0\\) 下越不可能发生，反对 \\(H_0\\) 的证据越强。\n\n做出决策:\n\n将 P 值与显著性水平 \\(\\alpha\\) 进行比较：\n\n如果 P 值 ≤ \\(\\alpha\\): 结果具有统计显著性 (Statistically Significant)。我们拒绝 \\(H_0\\)，接受 \\(H_1\\)。有足够证据反对原假设。\n如果 P 值 &gt; \\(\\alpha\\): 结果不具有统计显著性。我们未能拒绝 (Fail to Reject) \\(H_0\\)。没有足够证据反对原假设。\n\n注意: 未能拒绝 \\(H_0\\) 不等于 证明 \\(H_0\\) 为真，只是证据不足以推翻它。\n\n解释结果: 结合具体问题情境，用通俗语言解释决策的含义。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>第五周：做出判断：假设检验 (单/双样本) 与 ANOVA 应用</span>"
    ]
  },
  {
    "objectID": "week5_lecture.html#两类错误",
    "href": "week5_lecture.html#两类错误",
    "title": "第五周：做出判断：假设检验 (单/双样本) 与 ANOVA 应用",
    "section": "3. 两类错误",
    "text": "3. 两类错误\n在假设检验中，我们可能做出错误的决策：\n\n第一类错误 (Type I Error, \\(\\alpha\\) 错误, 弃真错误):\n\n当 \\(H_0\\) 实际上为真时，我们却拒绝了它。\n发生概率为 \\(\\alpha\\) (显著性水平)。\n后果：错误地认为有效应或差异（例如，认为无效药有效）。\n\n第二类错误 (Type II Error, \\(\\beta\\) 错误, 取伪错误):\n\n当 \\(H_0\\) 实际上为假（\\(H_1\\) 为真）时，我们却未能拒绝它。\n发生概率为 \\(\\beta\\)。\n统计功效 (Power) = \\(1 - \\beta\\)，即当 \\(H_1\\) 为真时，正确拒绝 \\(H_0\\) 的概率。\n后果：未能发现存在的效应或差异（例如，未能发现有效药物的效果）。\n\n\n\n\n\n\n\n\n错误权衡\n\n\n\n\\(\\alpha\\) 和 \\(\\beta\\) 通常是相互制约的。降低 \\(\\alpha\\)（减少犯第一类错误的风险）通常会增加 \\(\\beta\\)（增加犯第二类错误的风险），反之亦然。选择 \\(\\alpha\\) 需要权衡两类错误的相对严重性。统计功效受样本量、效应大小、\\(\\alpha\\) 水平和数据变异性影响。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>第五周：做出判断：假设检验 (单/双样本) 与 ANOVA 应用</span>"
    ]
  },
  {
    "objectID": "week5_lecture.html#单样本-t-检验-one-sample-t-test",
    "href": "week5_lecture.html#单样本-t-检验-one-sample-t-test",
    "title": "第五周：做出判断：假设检验 (单/双样本) 与 ANOVA 应用",
    "section": "4. 单样本 t 检验 (One-Sample t-test)",
    "text": "4. 单样本 t 检验 (One-Sample t-test)\n\n目的: 检验单个总体的均值 \\(\\mu\\) 是否等于某个已知的特定值 \\(\\mu_0\\)。\n应用场景:\n\n某品牌矿泉水声称每瓶含钠量为 20mg，检验是否属实？(\\(H_0: \\mu = 20\\))\n某地区去年人均收入为 50000 元，今年是否有显著变化？(\\(H_0: \\mu = 50000\\))\n\n假设条件:\n\n样本是随机从总体中抽取的。\n总体分布近似正态，或者样本量足够大（通常 n ≥ 30，中心极限定理保证样本均值的抽样分布近似正态）。可以通过 QQ 图或 Shapiro-Wilk 检验来检查正态性。\n\n检验统计量 (t 值): \\[ t = \\frac{\\bar{x} - \\mu_0}{s / \\sqrt{n}} \\] 其中 \\(\\bar{x}\\) 是样本均值，\\(\\mu_0\\) 是假设的总体均值， \\(s\\) 是样本标准差， \\(n\\) 是样本量。该统计量服从自由度为 \\(df = n-1\\) 的 t 分布。\nR 实现: t.test()\n\nlibrary(tidyverse)\n\n# 示例：检验一批灯泡的平均寿命是否显著不等于 1000 小时\nlifespan &lt;- c(980, 1020, 1010, 995, 970, 1035, 1005, 960, 1015, 990)\nsample_mean &lt;- mean(lifespan)\nsample_sd &lt;- sd(lifespan)\nn &lt;- length(lifespan)\nprint(paste(\"Sample Mean:\", sample_mean, \"Sample SD:\", sample_sd, \"n:\", n))\n\n#&gt; [1] \"Sample Mean: 998 Sample SD: 23.4757558155453 n: 10\"\n\n# H0: mu = 1000\n# H1: mu != 1000 (双侧检验)\nt_test_result &lt;- t.test(lifespan, mu = 1000)\nprint(t_test_result)\n\n#&gt; \n#&gt;  One Sample t-test\n#&gt; \n#&gt; data:  lifespan\n#&gt; t = -0.26941, df = 9, p-value = 0.7937\n#&gt; alternative hypothesis: true mean is not equal to 1000\n#&gt; 95 percent confidence interval:\n#&gt;   981.2065 1014.7935\n#&gt; sample estimates:\n#&gt; mean of x \n#&gt;       998\n\n# 访问结果的关键信息\nt_test_result$statistic # t 值\n\n#&gt;         t \n#&gt; -0.269408\n\nt_test_result$parameter # 自由度 (df)\n\n#&gt; df \n#&gt;  9\n\nt_test_result$p.value   # P 值\n\n#&gt; [1] 0.7936906\n\nt_test_result$conf.int  # 总体均值的置信区间 (默认 95%)\n\n#&gt; [1]  981.2065 1014.7935\n#&gt; attr(,\"conf.level\")\n#&gt; [1] 0.95\n\nt_test_result$estimate  # 样本均值\n\n#&gt; mean of x \n#&gt;       998\n\n\n结果解读:\n\n查看 P 值。如果 P 值 &lt; \\(\\alpha\\) (例如 0.05)，则拒绝 \\(H_0\\)。\n在上面的例子中，如果 P 值 &lt; 0.05，我们可以说：有统计学证据表明这批灯泡的平均寿命显著不等于 1000 小时 (在 \\(\\alpha=0.05\\) 水平下)。\n查看置信区间。如果 \\(\\mu_0\\) (这里是 1000) 不包含在置信区间内，也支持拒绝 \\(H_0\\)。置信区间给出了总体均值可能的范围。\n单侧检验: 如果想检验平均寿命是否大于 1000 (\\(H_1: \\mu &gt; 1000\\))，使用 alternative = \"greater\"；如果想检验是否小于 1000 (\\(H_1: \\mu &lt; 1000\\))，使用 alternative = \"less\"。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>第五周：做出判断：假设检验 (单/双样本) 与 ANOVA 应用</span>"
    ]
  },
  {
    "objectID": "week5_lecture.html#双独立样本-t-检验-two-independent-samples-t-test",
    "href": "week5_lecture.html#双独立样本-t-检验-two-independent-samples-t-test",
    "title": "第五周：做出判断：假设检验 (单/双样本) 与 ANOVA 应用",
    "section": "5. 双独立样本 t 检验 (Two-Independent-Samples t-test)",
    "text": "5. 双独立样本 t 检验 (Two-Independent-Samples t-test)\n\n目的: 比较两个独立总体的均值 \\(\\mu_1\\) 和 \\(\\mu_2\\) 是否相等。\n应用场景:\n\n比较两种不同教学方法下学生的平均成绩是否有差异？(\\(H_0: \\mu_1 = \\mu_2\\))\n比较男性和女性的平均工资是否有差异？(\\(H_0: \\mu_{male} = \\mu_{female}\\))\n\n假设条件:\n\n两个样本是独立随机抽取的。\n两个总体都近似正态分布，或者两个样本量都足够大 (n1 ≥ 30, n2 ≥ 30)。\n方差齐性 (Homogeneity of Variances): 两个总体的方差 \\(\\sigma_1^2\\) 和 \\(\\sigma_2^2\\) 相等。这是传统 Student’s t-test 的要求。\n\n检验方差齐性: 可以使用 Levene’s test 或 F 检验 (var.test())。\\(H_0\\): 方差相等。如果 P 值 &gt; \\(\\alpha\\) (如 0.05)，则不能拒绝方差齐性的假设。\n方差不齐怎么办？ R 中的 t.test() 默认使用 Welch’s t-test，它不要求方差齐性，是对自由度进行了调整的 t 检验，通常更推荐使用。\n\n\nR 实现: t.test() (使用公式语法或分别传入两个向量)\n\n# 示例：比较两种肥料对作物产量的影响\nyield_A &lt;- c(25, 28, 22, 30, 26)\nyield_B &lt;- c(32, 35, 29, 38, 31, 33)\n\n# 1. (可选但推荐) 检查方差齐性\nvar_test_result &lt;- var.test(yield_A, yield_B)\nprint(var_test_result) # 查看 P 值\n\n#&gt; \n#&gt;  F test to compare two variances\n#&gt; \n#&gt; data:  yield_A and yield_B\n#&gt; F = 0.92, num df = 4, denom df = 5, p-value = 0.9625\n#&gt; alternative hypothesis: true ratio of variances is not equal to 1\n#&gt; 95 percent confidence interval:\n#&gt;  0.1245282 8.6153132\n#&gt; sample estimates:\n#&gt; ratio of variances \n#&gt;               0.92\n\n# 2. 执行 t 检验\n# H0: mu_A = mu_B (或 mu_A - mu_B = 0)\n# H1: mu_A != mu_B\n# 默认使用 Welch's t-test (var.equal = FALSE)\nt_test_ind_welch &lt;- t.test(yield_A, yield_B)\nprint(t_test_ind_welch)\n\n#&gt; \n#&gt;  Welch Two Sample t-test\n#&gt; \n#&gt; data:  yield_A and yield_B\n#&gt; t = -3.6313, df = 8.7711, p-value = 0.005715\n#&gt; alternative hypothesis: true difference in means is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -11.053048  -2.546952\n#&gt; sample estimates:\n#&gt; mean of x mean of y \n#&gt;      26.2      33.0\n\n# 如果方差齐性检验 P 值很大 (如 &gt; 0.1 或 0.05)，且你坚持使用 Student's t-test\n# t_test_ind_student &lt;- t.test(yield_A, yield_B, var.equal = TRUE)\n# print(t_test_ind_student)\n\n# 使用公式语法 (数据需要是长格式)\nyield_data &lt;- tibble(\n  Yield = c(yield_A, yield_B),\n  Fertilizer = factor(rep(c(\"A\", \"B\"), times = c(length(yield_A), length(yield_B))))\n)\nprint(yield_data)\n\n#&gt; # A tibble: 11 × 2\n#&gt;    Yield Fertilizer\n#&gt;    &lt;dbl&gt; &lt;fct&gt;     \n#&gt;  1    25 A         \n#&gt;  2    28 A         \n#&gt;  3    22 A         \n#&gt;  4    30 A         \n#&gt;  5    26 A         \n#&gt;  6    32 B         \n#&gt;  7    35 B         \n#&gt;  8    29 B         \n#&gt;  9    38 B         \n#&gt; 10    31 B         \n#&gt; 11    33 B\n\nt.test(Yield ~ Fertilizer, data = yield_data) # 默认 Welch\n\n#&gt; \n#&gt;  Welch Two Sample t-test\n#&gt; \n#&gt; data:  Yield by Fertilizer\n#&gt; t = -3.6313, df = 8.7711, p-value = 0.005715\n#&gt; alternative hypothesis: true difference in means between group A and group B is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -11.053048  -2.546952\n#&gt; sample estimates:\n#&gt; mean in group A mean in group B \n#&gt;            26.2            33.0\n\n# t.test(Yield ~ Fertilizer, data = yield_data, var.equal = TRUE) # Student's\n\n结果解读:\n\n同样关注 P 值。如果 P 值 &lt; \\(\\alpha\\)，拒绝 \\(H_0\\)，认为两个总体的均值有显著差异。\n查看置信区间 (针对均值差 \\(\\mu_1 - \\mu_2\\))。如果区间不包含 0，也支持拒绝 \\(H_0\\)。区间给出了两个总体均值差异的可能范围。\n同样可以进行单侧检验 (alternative = \"greater\" 或 \"less\")。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>第五周：做出判断：假设检验 (单/双样本) 与 ANOVA 应用</span>"
    ]
  },
  {
    "objectID": "week5_lecture.html#配对样本-t-检验-paired-samples-t-test",
    "href": "week5_lecture.html#配对样本-t-检验-paired-samples-t-test",
    "title": "第五周：做出判断：假设检验 (单/双样本) 与 ANOVA 应用",
    "section": "6. 配对样本 t 检验 (Paired-Samples t-test)",
    "text": "6. 配对样本 t 检验 (Paired-Samples t-test)\n\n目的: 比较同一个对象在两种不同条件下或两个不同时间点的均值是否存在差异。本质上是检验差值的均值是否等于 0。\n应用场景:\n\n比较同一批患者服药前后的血压平均值是否有变化？\n比较同一组学生使用两种不同学习方法后的测试成绩是否有差异？\n比较同一块土地使用两种不同肥料的产量是否有差异（需要配对设计）？\n\n与独立样本的区别: 独立样本是比较两个不同组的对象；配对样本是比较同一组对象的两次测量。配对设计可以有效控制个体差异。\n假设条件:\n\n样本是配对的。\n配对差值 (Differences) 来自的总体近似正态分布，或者配对数量足够大 (n_pairs ≥ 30)。\n\n检验统计量: 对差值进行单样本 t 检验，检验差值的均值 \\(\\mu_d\\) 是否等于 0。 \\[ t = \\frac{\\bar{d} - 0}{s_d / \\sqrt{n_{pairs}}} \\] 其中 \\(\\bar{d}\\) 是差值的样本均值，\\(s_d\\) 是差值的样本标准差，\\(n_{pairs}\\) 是配对数量。自由度 \\(df = n_{pairs}-1\\)。\nR 实现: t.test() (设置 paired = TRUE)\n\n# 示例：比较 10 名学生使用新旧两种教学方法后的测试得分\nscore_old &lt;- c(75, 82, 68, 79, 88, 72, 90, 85, 77, 81)\nscore_new &lt;- c(80, 85, 75, 81, 92, 78, 93, 88, 80, 84)\n\n# H0: mu_diff = 0 (两种方法得分均值无差异)\n# H1: mu_diff != 0\nt_test_paired &lt;- t.test(score_new, score_old, paired = TRUE)\nprint(t_test_paired)\n\n#&gt; \n#&gt;  Paired t-test\n#&gt; \n#&gt; data:  score_new and score_old\n#&gt; t = 7.7316, df = 9, p-value = 2.904e-05\n#&gt; alternative hypothesis: true mean difference is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  2.758912 5.041088\n#&gt; sample estimates:\n#&gt; mean difference \n#&gt;             3.9\n\n# 也可以先计算差值，再做单样本 t 检验\n# differences &lt;- score_new - score_old\n# t.test(differences, mu = 0) # 结果与上面相同\n\n结果解读:\n\n关注 P 值。如果 P 值 &lt; \\(\\alpha\\)，拒绝 \\(H_0\\)，认为两种条件下或两个时间点的均值存在显著差异。\n查看置信区间 (针对差值的均值 \\(\\mu_d\\))。如果区间不包含 0，也支持拒绝 \\(H_0\\)。区间给出了均值差异的可能范围。\n同样可以进行单侧检验。例如，检验新方法是否优于旧方法 (\\(H_1: \\mu_d &gt; 0\\))，使用 alternative = \"greater\"。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>第五周：做出判断：假设检验 (单/双样本) 与 ANOVA 应用</span>"
    ]
  },
  {
    "objectID": "week5_lecture.html#单因素方差分析-one-way-anova",
    "href": "week5_lecture.html#单因素方差分析-one-way-anova",
    "title": "第五周：做出判断：假设检验 (单/双样本) 与 ANOVA 应用",
    "section": "7. 单因素方差分析 (One-Way ANOVA)",
    "text": "7. 单因素方差分析 (One-Way ANOVA)\n\n动机: 当我们要比较三个或更多独立组的均值时，如果两两进行 t 检验，会增加犯第一类错误的概率（多重比较问题）。例如，比较 3 组，需要做 3 次 t 检验，总体 \\(\\alpha\\) 会膨胀。ANOVA 提供了一种一次性检验所有组均值是否完全相等的方法。\n目的: 检验三个或更多独立总体的均值是否全部相等。\n应用场景:\n\n比较三种不同肥料对作物产量的平均影响是否相同？\n比较四种不同教学方法下学生的平均成绩是否都一样？\n比较不同地区（≥3个）的平均房价是否相同？\n\n基本思想: 比较组间变异 (Between-group Variation) 与组内变异 (Within-group Variation)。\n\n如果组间变异显著大于组内变异，则说明各组均值之间可能存在显著差异。\n\n假设条件:\n\n各样本是独立随机抽取的。\n各总体都近似正态分布。\n方差齐性: 各总体的方差相等。这对 ANOVA 比较重要，可以用 Levene’s test 检验。\n\n假设陈述:\n\n\\(H_0: \\mu_1 = \\mu_2 = ... = \\mu_k\\) (所有 k 个总体的均值都相等)\n\\(H_1:\\) 至少有一个总体的均值与其他总体不相等 (注意：不是所有均值都不等)。\n\n检验统计量 (F 值): \\[ F = \\frac{\\text{组间均方 (Mean Square Between, MSB)}}{\\text{组内均方 (Mean Square Within, MSW)}} \\]\n\nMSB 度量了各样本均值相对于总均值的变异。\nMSW 度量了每个样本内部数据的变异（是总体方差的估计）。\nF 值服从 F 分布，具有两个自由度：\\(df_1 = k-1\\) (组间自由度) 和 \\(df_2 = N-k\\) (组内自由度)，其中 k 是组数，N 是总样本量。\n\nR 实现: aov() (Analysis of Variance)\n\n# 示例：比较三种不同教学方法 (A, B, C) 的学生成绩\nscores_methodA &lt;- c(78, 85, 82, 79, 88)\nscores_methodB &lt;- c(88, 92, 90, 86, 94)\nscores_methodC &lt;- c(72, 78, 75, 80, 70)\n\n# 准备长格式数据\nanova_data &lt;- tibble(\n  Score = c(scores_methodA, scores_methodB, scores_methodC),\n  Method = factor(rep(c(\"A\", \"B\", \"C\"), each = 5))\n)\nprint(anova_data)\n\n#&gt; # A tibble: 15 × 2\n#&gt;    Score Method\n#&gt;    &lt;dbl&gt; &lt;fct&gt; \n#&gt;  1    78 A     \n#&gt;  2    85 A     \n#&gt;  3    82 A     \n#&gt;  4    79 A     \n#&gt;  5    88 A     \n#&gt;  6    88 B     \n#&gt;  7    92 B     \n#&gt;  8    90 B     \n#&gt;  9    86 B     \n#&gt; 10    94 B     \n#&gt; 11    72 C     \n#&gt; 12    78 C     \n#&gt; 13    75 C     \n#&gt; 14    80 C     \n#&gt; 15    70 C\n\n# (可选) 检查方差齐性 (例如使用 car 包的 leveneTest)\n# library(car)\n# leveneTest(Score ~ Method, data = anova_data)\n\n# 执行 ANOVA\n# H0: mu_A = mu_B = mu_C\n# H1: 至少有一个 mu 不相等\nanova_result &lt;- aov(Score ~ Method, data = anova_data)\n\n# 查看 ANOVA 表\nsummary(anova_result)\n\n#&gt;             Df Sum Sq Mean Sq F value   Pr(&gt;F)    \n#&gt; Method       2  562.5  281.27   19.05 0.000189 ***\n#&gt; Residuals   12  177.2   14.77                     \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n解读 ANOVA 表 (summary(anova_result))\n\nDf: 自由度 (\\(k-1\\) 和 \\(N-k\\))。\nSum Sq: 平方和 (组间 SSb, 组内 SSw)。\nMean Sq: 均方 (MSB = SSb/df1, MSW = SSw/df2)。\nF value: F 统计量 (\\(F = MSB / MSW\\))。\nPr(&gt;F): P 值。\n决策: 查看 P 值。如果 P 值 &lt; \\(\\alpha\\) (如 0.05)，则拒绝 \\(H_0\\)。\n结论: 在上面的例子中，P 值 (0.000311) 远小于 0.05，因此我们拒绝 \\(H_0\\)，认为至少有一种教学方法的平均成绩与其他方法存在显著差异。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>第五周：做出判断：假设检验 (单/双样本) 与 ANOVA 应用</span>"
    ]
  },
  {
    "objectID": "week5_lecture.html#事后检验-post-hoc-tests",
    "href": "week5_lecture.html#事后检验-post-hoc-tests",
    "title": "第五周：做出判断：假设检验 (单/双样本) 与 ANOVA 应用",
    "section": "8. 事后检验 (Post-hoc Tests)",
    "text": "8. 事后检验 (Post-hoc Tests)\n\n为何需要？ ANOVA 检验的 P 值 &lt; \\(\\alpha\\) 只能告诉我们至少有一组均值不同，但不能告诉我们具体是哪些组之间存在差异。\n目的: 在 ANOVA 拒绝 \\(H_0\\) 后，进行两两比较，找出具体哪些组的均值存在显著差异。\n常用方法：Tukey’s Honest Significant Difference (HSD)\n\n控制了进行所有可能两两比较时的总体第一类错误率。\n计算每对组均值差的置信区间和调整后的 P 值。\n\nR 实现: TukeyHSD() (需要先运行 aov())\n\n# 对之前的 anova_result 进行 Tukey HSD 检验\ntukey_result &lt;- TukeyHSD(anova_result)\nprint(tukey_result)\n\n#&gt;   Tukey multiple comparisons of means\n#&gt;     95% family-wise confidence level\n#&gt; \n#&gt; Fit: aov(formula = Score ~ Method, data = anova_data)\n#&gt; \n#&gt; $Method\n#&gt;      diff        lwr        upr     p adj\n#&gt; B-A   7.6   1.116122 14.0838784 0.0220746\n#&gt; C-A  -7.4 -13.883878 -0.9161216 0.0255847\n#&gt; C-B -15.0 -21.483878 -8.5161216 0.0001311\n\n# 绘制置信区间图\nplot(tukey_result)\n\n\n\n\n\n\n\n\n解读 TukeyHSD() 结果:\n\ndiff: 两组样本均值的差。\nlwr, upr: 均值差的 95% 置信区间下限和上限。\np adj: 调整后的 P 值 (Adjusted P-value)。\n决策: 查看 p adj。如果 p adj &lt; \\(\\alpha\\) (如 0.05)，则认为该对组的均值存在显著差异。\n结论: 从上面的结果看，方法 B 的平均成绩显著高于方法 A 和方法 C；方法 C 和方法 A 之间没有显著差异 (在 \\(\\alpha=0.05\\) 水平下)。\n置信区间图：如果区间不包含 0，则表示差异显著。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>第五周：做出判断：假设检验 (单/双样本) 与 ANOVA 应用</span>"
    ]
  },
  {
    "objectID": "week5_lecture.html#项目相关与本周总结",
    "href": "week5_lecture.html#项目相关与本周总结",
    "title": "第五周：做出判断：假设检验 (单/双样本) 与 ANOVA 应用",
    "section": "9. 项目相关与本周总结",
    "text": "9. 项目相关与本周总结\n\n项目任务:\n\n根据你的项目问题和数据类型，判断是否需要进行 t 检验或 ANOVA。\n如果需要比较两组（独立或配对），选择合适的 t 检验，执行并解释结果。\n如果需要比较三组或更多组，执行 ANOVA。如果 ANOVA 结果显著，进行 Tukey’s HSD 事后检验，并解释具体哪些组之间存在差异。\n注意检查相应检验的假设条件（特别是正态性和方差齐性），可以在报告中提及检查结果或局限性。\n\n本周回顾: 本周内容非常关键且密集。我们系统学习了假设检验的完整逻辑，并掌握了应用最广泛的几种检验方法：单样本 t 检验、双独立样本 t 检验、配对样本 t 检验和单因素方差分析 (ANOVA) 及其事后检验。理解每种检验的应用场景、假设条件、R 实现和结果解读至关重要。\n\n下周预告: 我们将转向探索变量之间的关系，学习相关分析和简单线性回归，了解如何量化和描述两个连续变量之间的线性关联程度。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>第五周：做出判断：假设检验 (单/双样本) 与 ANOVA 应用</span>"
    ]
  },
  {
    "objectID": "week6_lecture.html",
    "href": "week6_lecture.html",
    "title": "第六周：探索关系：相关与简单线性回归入门",
    "section": "",
    "text": "1. 变量之间的关系\n前几周我们关注于描述单个变量的特征（分布）或比较不同组别在某个变量上的差异（均值比较）。本周我们将开始探索两个或多个变量之间是否存在关联，以及如何量化和描述这种关联。\n我们将继续使用 mpg 数据集，并可能引入其他示例。\nlibrary(tidyverse)\n\n# glimpse(mpg)",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>第六周：探索关系：相关与简单线性回归入门</span>"
    ]
  },
  {
    "objectID": "week6_lecture.html#变量之间的关系",
    "href": "week6_lecture.html#变量之间的关系",
    "title": "第六周：探索关系：相关与简单线性回归入门",
    "section": "",
    "text": "本周目标\n\n\n\n\n理解相关性分析的目的和局限性（相关不等于因果）。\n掌握 Pearson 和 Spearman 相关系数的适用场景、计算和显著性检验。\n能够结合散点图直观理解相关性。\n理解简单线性回归 (SLR) 的基本概念、模型形式和系数含义。\n了解最小二乘法 (OLS) 的基本思想。\n能够使用 R 的 lm() 函数拟合 SLR 模型并解读基本输出（系数、R²）。\n初步了解多元线性回归 (MLR) 的动机和“偏回归系数”的概念。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>第六周：探索关系：相关与简单线性回归入门</span>"
    ]
  },
  {
    "objectID": "week6_lecture.html#相关分析-correlation-analysis",
    "href": "week6_lecture.html#相关分析-correlation-analysis",
    "title": "第六周：探索关系：相关与简单线性回归入门",
    "section": "2. 相关分析 (Correlation Analysis)",
    "text": "2. 相关分析 (Correlation Analysis)\n相关分析用于衡量两个连续变量之间线性关联的强度和方向。\n\n相关不等于因果 (Correlation does not imply causation!)\n\n\n\n\n\n\n\n相关不等于因果\n\n\n\n在统计分析中，相关关系与因果关系是截然不同的概念。当我们观察到两个变量之间存在相关性时，可能有以下四种解释：\n\n直接因果：X 直接导致 Y 的变化。\n反向因果：Y 的变化反过来影响 X。\n共同原因：存在第三方变量 Z 同时影响 X 和 Y。\n随机巧合：变量间的关联纯属偶然。\n\n需要特别注意的是，相关分析仅能揭示变量是否共同变化，而无法证明因果关系。要确定因果关系，通常需要借助更严谨的研究设计（如随机对照实验）或坚实的理论依据。\n\n\n\n\n\n\n\n\n相关不等于因果的典型案例\n\n\n\n\n冰淇淋与溺水：冰淇淋销量与溺水人数高度相关。但这并非因为吃冰淇淋导致溺水，而是因为两者都与夏天/高温这个混淆变量相关。\n雨伞与感冒：雨伞销量与感冒人数呈正相关。这并不意味着使用雨伞会导致感冒，而是因为两者都与雨天这个共同因素相关。\n鞋子尺寸与阅读能力：儿童的鞋子尺寸与其阅读能力呈正相关。这显然不是因果关系，而是因为两者都与年龄这个变量相关。\n医院数量与犯罪率：一个城市的医院数量与犯罪率呈正相关。这并不意味着医院导致犯罪，而是因为两者都与城市人口规模相关。\n\n\n\n\n相关系数 (Correlation Coefficient, \\(r\\)):\n\n衡量线性关联强度和方向的数值，范围在 \\(-1\\) 到 \\(+1\\) 之间。\n符号表示方向：\n\n\\(r &gt; 0\\): 正相关 (一个变量增加，另一个变量倾向于增加)。\n\\(r &lt; 0\\): 负相关 (一个变量增加，另一个变量倾向于减少)。\n\\(r = 0\\): 无线性相关 (注意：可能存在非线性关系)。\n\n绝对值表示强度：\n\n\\(|r|\\) 接近 1: 强线性相关。\n\\(|r|\\) 接近 0: 弱线性相关或无线性相关。\n强度划分没有绝对标准，通常：0.1-0.3 (弱), 0.4-0.6 (中), 0.7-1.0 (强)。\n\n\n常用相关系数:\n\n皮尔逊积矩相关系数 (Pearson Product-Moment Correlation Coefficient, \\(r\\)):\n\n最常用的相关系数。\n衡量两个连续变量之间线性关联的强度和方向。\n假设条件:\n\n变量是连续的。\n变量之间存在线性关系（可通过散点图初步判断）。\n数据近似服从二元正态分布（或样本量足够大）。对异常值比较敏感。\n\n公式: \\(r = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n}(x_i - \\bar{x})^2 \\sum_{i=1}^{n}(y_i - \\bar{y})^2}}\\)\n\n斯皮尔曼等级相关系数 (Spearman Rank Correlation Coefficient, \\(\\rho\\) 或 \\(r_s\\)):\n\n基于变量值的秩次 (Rank) 计算的相关系数。\n衡量两个变量之间单调关系 (Monotonic Relationship) 的强度和方向（即一个变量增加，另一个变量也倾向于增加或减少，但不一定是直线）。\n适用场景:\n\n变量是有序分类变量 (Ordinal)。\n连续变量不满足 Pearson 相关系数的正态性或线性假设。\n数据中存在异常值（对异常值不敏感）。\n\n计算方法：先将两个变量的数据分别排序并转换为秩次，然后计算秩次的 Pearson 相关系数。\n\n\n可视化：散点图 (Scatter Plot) 散点图是判断两个连续变量关系类型（线性、非线性、无关系）和观察异常值的最佳工具。\n\n# 探索发动机排量 (displ) 与高速公路里程 (hwy) 的关系\nggplot(mpg, aes(x = displ, y = hwy)) +\n    geom_point(aes(color = class)) + # 用颜色区分车辆类别\n    geom_smooth(method = \"lm\", se = FALSE, color = \"red\") + # 添加线性拟合线 (后面会讲)\n    geom_smooth(se = FALSE, color = \"blue\", linetype = \"dashed\") + # 添加非线性平滑曲线 (LOESS)\n    labs(title = \"发动机排量 vs 高速公路里程\", x = \"排量 (升)\", y = \"里程 (MPG)\") +       theme_minimal()     # 从图中可以看出，两者大致呈负相关关系，可能略带曲线。\n\n\n\n\n\n\n\n\nR 实现:\n\ncor(x, y, method = ...): 计算相关系数。\n\nmethod: “pearson” (默认), “spearman”, “kendall”。\n\ncor.test(x, y, method = ...): 计算相关系数，并进行显著性检验。\n\n显著性检验的原假设 \\(H_0\\): 两个变量之间没有相关性 (总体相关系数 \\(\\rho = 0\\))。\n备择假设 \\(H_1\\): 两个变量之间存在相关性 (\\(\\rho \\ne 0\\))。\n返回结果包括相关系数估计值、P 值和置信区间。\n\n\n\n# 计算 displ 和 hwy 的 Pearson 相关系数\ncor(mpg$displ, mpg$hwy, method = \"pearson\")\n\n#&gt; [1] -0.76602\n\n# 进行 Pearson 相关性检验\npearson_test &lt;- cor.test(mpg$displ, mpg$hwy, method = \"pearson\")\nprint(pearson_test)\n\n#&gt; \n#&gt;  Pearson's product-moment correlation\n#&gt; \n#&gt; data:  mpg$displ and mpg$hwy\n#&gt; t = -18.151, df = 232, p-value &lt; 2.2e-16\n#&gt; alternative hypothesis: true correlation is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  -0.8142727 -0.7072539\n#&gt; sample estimates:\n#&gt;      cor \n#&gt; -0.76602\n\n# 解读:\n# r 约 -0.76 (强负相关)\n# P 值非常小 (&lt; 2.2e-16)，远小于 0.05，拒绝 H0，认为 displ 和 hwy 之间存在显著的线性相关性。\n# 95% 置信区间 [-0.81, -0.71]，不包含 0，也支持拒绝 H0。\n\n# 计算 displ 和 hwy 的 Spearman 相关系数 (对非线性关系和异常值更稳健)\ncor(mpg$displ, mpg$hwy, method = \"spearman\")\n\n#&gt; [1] -0.8266576\n\n# 进行 Spearman 相关性检验\nspearman_test &lt;- cor.test(mpg$displ, mpg$hwy, method = \"spearman\")\nprint(spearman_test)\n\n#&gt; \n#&gt;  Spearman's rank correlation rho\n#&gt; \n#&gt; data:  mpg$displ and mpg$hwy\n#&gt; S = 3900727, p-value &lt; 2.2e-16\n#&gt; alternative hypothesis: true rho is not equal to 0\n#&gt; sample estimates:\n#&gt;        rho \n#&gt; -0.8266576\n\n# 解读:\n# rho 约 -0.83 (强负单调关系)\n# P 值也非常小，拒绝 H0，认为存在显著的单调关系。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>第六周：探索关系：相关与简单线性回归入门</span>"
    ]
  },
  {
    "objectID": "week6_lecture.html#简单线性回归-simple-linear-regression-slr",
    "href": "week6_lecture.html#简单线性回归-simple-linear-regression-slr",
    "title": "第六周：探索关系：相关与简单线性回归入门",
    "section": "3. 简单线性回归 (Simple Linear Regression, SLR)",
    "text": "3. 简单线性回归 (Simple Linear Regression, SLR)\n相关分析告诉我们变量间关联的强度和方向，而回归分析 (Regression Analysis) 则更进一步，试图建立一个数学模型来描述一个或多个自变量 (Independent Variable / Predictor) 如何影响一个因变量 (Dependent Variable / Response)。\n简单线性回归是其中最基础的形式，用于描述一个连续自变量 X 如何线性地影响一个连续因变量 Y。\n\n概念引入: 我们试图找到一条最佳拟合直线，来概括散点图中两个连续变量 (X, Y) 之间的关系。这条直线可以用来：\n\n描述 X 对 Y 的影响程度（斜率）。\n基于 X 的值来预测 Y 的值。\n\n模型形式: \\[ Y = \\beta_0 + \\beta_1 X + \\epsilon \\]\n\n\\(Y\\): 因变量 (Response)。\n\\(X\\): 自变量 (Predictor)。\n\\(\\beta_0\\): 截距 (Intercept)。当 \\(X=0\\) 时，Y 的期望值。有时没有实际意义（例如 X 不能取 0）。\n\\(\\beta_1\\): 斜率 (Slope)。X 每增加一个单位时，Y 的期望平均变化量。这是衡量 X 对 Y 线性影响的关键系数。\n\\(\\epsilon\\): 误差项 (Error Term) / 残差 (Residual)。代表了除 X 之外所有其他影响 Y 的因素，以及模型本身的随机性。假设误差项是独立的，且服从均值为 0，方差为 \\(\\sigma^2\\) 的正态分布 (\\(N(0, \\sigma^2)\\))。\n\n系数含义解释 (重要！):\n\n\\(\\beta_0\\) (截距): 当自变量 X 为 0 时，因变量 Y 的预测值。\n\\(\\beta_1\\) (斜率): 自变量 X 每变化一个单位，因变量 Y 平均变化 \\(\\beta_1\\) 个单位。\n\n最小二乘法 (Ordinary Least Squares, OLS) 思想:\n\n如何找到“最佳”拟合直线？OLS 的目标是找到一条直线，使得所有实际观测值 \\(y_i\\) 与直线上预测值 \\(\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i\\) 之间的纵向距离（残差 \\(e_i = y_i - \\hat{y}_i\\)）的平方和最小。\n即最小化：\\(\\sum_{i=1}^{n} e_i^2 = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 = \\sum_{i=1}^{n} (y_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i))^2\\)\n通过微积分可以推导出 \\(\\hat{\\beta}_0\\) 和 \\(\\hat{\\beta}_1\\) 的估计公式。\n\nR 实现: lm() (Linear Model)\n\n使用公式语法 Y ~ X。\n\n\n# 拟合一个用 displ 预测 hwy 的简单线性回归模型\n# hwy = beta0 + beta1 * displ + epsilon\nslr_model &lt;- lm(hwy ~ displ, data = mpg)\n\n# 查看模型基本信息\nprint(slr_model)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = hwy ~ displ, data = mpg)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)        displ  \n#&gt;      35.698       -3.531\n\n# 查看详细的汇总统计信息 (最常用)\nsummary_slr &lt;- summary(slr_model)\nprint(summary_slr)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = hwy ~ displ, data = mpg)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -7.1039 -2.1646 -0.2242  2.0589 15.0105 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  35.6977     0.7204   49.55   &lt;2e-16 ***\n#&gt; displ        -3.5306     0.1945  -18.15   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 3.836 on 232 degrees of freedom\n#&gt; Multiple R-squared:  0.5868, Adjusted R-squared:  0.585 \n#&gt; F-statistic: 329.5 on 1 and 232 DF,  p-value: &lt; 2.2e-16\n\n\n基本输出解读 (summary(slr_model))\n\nCoefficients 表:\n\nEstimate: 系数的点估计值 (\\(\\hat{\\beta}_0\\) 和 \\(\\hat{\\beta}_1\\))。\n\n\\(\\hat{\\beta}_0 \\approx 35.70\\): 当发动机排量为 0 时，预测的高速公路里程约为 35.7 MPG (这里截距可能没有实际意义)。\n\\(\\hat{\\beta}_1 \\approx -3.53\\): 发动机排量每增加 1 升，高速公路里程平均减少约 3.53 MPG。\n\nStd. Error: 系数估计值的标准误，衡量估计的不确定性。\nt value: 检验系数是否显著不为 0 的 t 统计量 (\\(t = \\frac{\\hat{\\beta}}{\\text{Std. Error}}\\))。\\(H_0: \\beta = 0\\) vs \\(H_1: \\beta \\ne 0\\)。\nPr(&gt;|t|): 对应 t 检验的 P 值。如果 P 值 &lt; \\(\\alpha\\)，则认为该系数显著不为 0，即该自变量对因变量有显著的线性影响。在本例中，displ 的 P 值远小于 0.05，说明排量对高速里程有显著的负向影响。\n\nR-squared (\\(R^2\\)) (决定系数 Coefficient of Determination):\n\n表示因变量 Y 的总变异中，能被自变量 X (模型) 解释的比例。范围在 0 到 1 之间。\n\\(R^2 = 1 - \\frac{\\sum e_i^2}{\\sum (y_i - \\bar{y})^2} = \\frac{\\text{模型解释的平方和}}{\\text{总平方和}}\\)\n这里的 Multiple R-squared: 0.5868 意味着发动机排量 (displ) 解释了高速公路里程 (hwy) 变异的约 58.7%。\nAdjusted R-squared: 对自变量个数进行惩罚的 R²，在多元回归中更有用，用于模型比较。\n\nF-statistic 和 p-value: 对整个模型整体显著性的检验。\\(H_0\\): 所有回归系数（除截距外）都为 0。在 SLR 中，它等价于对 \\(\\beta_1\\) 的 t 检验。如果 P 值 &lt; \\(\\alpha\\)，则认为模型整体是显著的。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>第六周：探索关系：相关与简单线性回归入门</span>"
    ]
  },
  {
    "objectID": "week6_lecture.html#多元线性回归-multiple-linear-regression-mlr-概念初步引入",
    "href": "week6_lecture.html#多元线性回归-multiple-linear-regression-mlr-概念初步引入",
    "title": "第六周：探索关系：相关与简单线性回归入门",
    "section": "4. 多元线性回归 (Multiple Linear Regression, MLR) 概念初步引入",
    "text": "4. 多元线性回归 (Multiple Linear Regression, MLR) 概念初步引入\n现实世界中，一个因变量往往受到多个自变量的影响。MLR 将 SLR 扩展到包含两个或更多自变量的情况。\n\n动机:\n\n更准确地预测 Y（包含更多相关信息）。\n控制其他变量的影响，估计某个特定自变量对 Y 的独立效应 (Independent Effect)。\n\n模型形式: \\[ Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_k X_k + \\epsilon \\]\n\n\\(X_1, X_2, ..., X_k\\): k 个自变量。\n\\(\\beta_0\\): 截距。当所有自变量都为 0 时，Y 的期望值。\n\\(\\beta_1, \\beta_2, ..., \\beta_k\\): 偏回归系数 (Partial Regression Coefficients)。\n\n核心概念：偏回归系数 \\(\\beta_j\\)\n\n\\(\\beta_j\\) 表示在控制住模型中所有其他自变量 (\\(X_1, ..., X_{j-1}, X_{j+1}, ..., X_k\\)) 不变的情况下，自变量 \\(X_j\\) 每增加一个单位时，因变量 Y 的期望平均变化量。\n重要区别: MLR 中的 \\(\\beta_j\\) 不等于 单独做 Y 对 \\(X_j\\) 的 SLR 时的斜率！因为它考虑并剔除了其他自变量的影响。这使得我们能更准确地评估 \\(X_j\\) 对 Y 的独立贡献。\n\nR 实现: 仍然使用 lm() 函数，在公式中加入更多自变量。 (我们将在后续课程中深入学习 MLR 的模型构建、诊断和选择。)\n后续重要性: 拟合 MLR 模型只是第一步。后续需要进行模型诊断（检查假设是否满足）、模型选择（选择最佳的自变量组合）等，这些是阶段二的核心内容。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>第六周：探索关系：相关与简单线性回归入门</span>"
    ]
  },
  {
    "objectID": "week6_lecture.html#项目相关与本周总结",
    "href": "week6_lecture.html#项目相关与本周总结",
    "title": "第六周：探索关系：相关与简单线性回归入门",
    "section": "5. 项目相关与本周总结",
    "text": "5. 项目相关与本周总结\n\n项目任务:\n\n计算你项目中连续变量之间的相关系数（Pearson 或 Spearman，根据情况选择），并进行显著性检验。结合散点图进行解释。\n如果你的项目问题涉及用一个连续变量预测另一个连续变量，尝试构建一个简单线性回归模型。解释模型的系数 (\\(\\hat{\\beta}_0, \\hat{\\beta}_1\\)) 和 R²。\n思考你的项目中，是否需要考虑多个自变量来预测因变量？如果是，初步设想一个 MLR 模型（写下公式即可），并思考每个自变量的偏效应可能是什么含义。\n\n本周回顾: 我们学习了如何使用相关分析来量化两个连续变量的线性关联强度，并强调了相关不等于因果。接着，我们入门了简单线性回归，学习了如何用一条直线来建模和预测，理解了 OLS 原理、模型系数的含义以及 R² 的解释。最后，我们初步接触了多元线性回归的核心思想——控制变量和偏效应，为后续更复杂的模型学习打下了基础。\n\n下周预告: 我们将回到分类数据，学习如何分析两个或多个分类变量之间的关联性，主要工具是卡方检验 (Chi-squared Test)。同时，我们将对第一阶段（第 1-7 周）所学知识进行小结，梳理各种统计方法的适用场景。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>第六周：探索关系：相关与简单线性回归入门</span>"
    ]
  },
  {
    "objectID": "week7_lecture.html",
    "href": "week7_lecture.html",
    "title": "第七周：分类数据的智慧：卡方检验与阶段总结",
    "section": "",
    "text": "1. 回顾分类变量与列联表\n前几周我们主要关注连续变量的分析（描述统计、t 检验、ANOVA、相关、回归）。本周我们将重点转向分类变量 (Categorical Variables)，特别是分析两个或多个分类变量之间是否存在关联。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>第七周：分类数据的智慧：卡方检验与阶段总结</span>"
    ]
  },
  {
    "objectID": "week7_lecture.html#回顾分类变量与列联表",
    "href": "week7_lecture.html#回顾分类变量与列联表",
    "title": "第七周：分类数据的智慧：卡方检验与阶段总结",
    "section": "",
    "text": "分类变量: 其值表示类别或标签，而不是数值大小（尽管有时用数字编码）。\n\n名义变量 (Nominal): 类别之间没有内在顺序（如性别、血型、产品颜色）。\n有序变量 (Ordinal): 类别之间存在逻辑顺序（如教育程度、满意度评分、衣服尺码）。我们在第二周学习的因子 (Factor) 类型常用于表示分类变量，特别是需要指定顺序时。\n\n列联表 (Contingency Table) / 交叉表 (Cross-Tabulation):\n\n用于展示两个或多个分类变量频数分布的表格。\n行代表一个变量的类别，列代表另一个变量的类别，单元格中的数值是对应组合的频数 (Frequency) 或计数。\n是分析分类变量关系的基础。\n\nR 实现: table() (基础 R 函数)\n\nlibrary(tidyverse)\n\n# 使用 ggplot2 内置的 diamonds 数据集的部分数据\n# (为了简化，只选 GIA 评级和切割质量)\nset.seed(123) # 为了结果可重复\ndiamonds_sample &lt;- diamonds %&gt;% \n  sample_n(500) %&gt;%\n  select(cut, color)\n\n# 创建两个分类变量的列联表\ncontingency_table &lt;- table(diamonds_sample$cut, diamonds_sample$color)\nprint(contingency_table)\n\n#&gt;            \n#&gt;              D  E  F  G  H  I  J\n#&gt;   Fair       2  1  5  2  6  1  1\n#&gt;   Good       8  7 12  9  3  3  1\n#&gt;   Very Good 14 22 24 16 17 12  7\n#&gt;   Premium    8 17 26 26 27 11 10\n#&gt;   Ideal     21 40 31 50 36 17  7\n\n# 也可以使用 dplyr 的 count() 来创建类似的表格 (长格式)\ndiamonds_sample %&gt;% \n  count(cut, color) %&gt;%\npivot_wider(names_from = color, values_from = n, values_fill = 0)\n\n#&gt; # A tibble: 5 × 8\n#&gt;   cut           D     E     F     G     H     I     J\n#&gt;   &lt;ord&gt;     &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n#&gt; 1 Fair          2     1     5     2     6     1     1\n#&gt; 2 Good          8     7    12     9     3     3     1\n#&gt; 3 Very Good    14    22    24    16    17    12     7\n#&gt; 4 Premium       8    17    26    26    27    11    10\n#&gt; 5 Ideal        21    40    31    50    36    17     7\n\n# 计算行百分比、列百分比或总百分比 (使用 prop.table())\nprop.table(contingency_table) # 占总数的百分比\n\n#&gt;            \n#&gt;                 D     E     F     G     H     I     J\n#&gt;   Fair      0.004 0.002 0.010 0.004 0.012 0.002 0.002\n#&gt;   Good      0.016 0.014 0.024 0.018 0.006 0.006 0.002\n#&gt;   Very Good 0.028 0.044 0.048 0.032 0.034 0.024 0.014\n#&gt;   Premium   0.016 0.034 0.052 0.052 0.054 0.022 0.020\n#&gt;   Ideal     0.042 0.080 0.062 0.100 0.072 0.034 0.014\n\nprop.table(contingency_table, margin = 1) # 行百分比 (每行和为 1)\n\n#&gt;            \n#&gt;                      D          E          F          G          H          I\n#&gt;   Fair      0.11111111 0.05555556 0.27777778 0.11111111 0.33333333 0.05555556\n#&gt;   Good      0.18604651 0.16279070 0.27906977 0.20930233 0.06976744 0.06976744\n#&gt;   Very Good 0.12500000 0.19642857 0.21428571 0.14285714 0.15178571 0.10714286\n#&gt;   Premium   0.06400000 0.13600000 0.20800000 0.20800000 0.21600000 0.08800000\n#&gt;   Ideal     0.10396040 0.19801980 0.15346535 0.24752475 0.17821782 0.08415842\n#&gt;            \n#&gt;                      J\n#&gt;   Fair      0.05555556\n#&gt;   Good      0.02325581\n#&gt;   Very Good 0.06250000\n#&gt;   Premium   0.08000000\n#&gt;   Ideal     0.03465347\n\nprop.table(contingency_table, margin = 2) # 列百分比 (每列和为 1)\n\n#&gt;            \n#&gt;                      D          E          F          G          H          I\n#&gt;   Fair      0.03773585 0.01149425 0.05102041 0.01941748 0.06741573 0.02272727\n#&gt;   Good      0.15094340 0.08045977 0.12244898 0.08737864 0.03370787 0.06818182\n#&gt;   Very Good 0.26415094 0.25287356 0.24489796 0.15533981 0.19101124 0.27272727\n#&gt;   Premium   0.15094340 0.19540230 0.26530612 0.25242718 0.30337079 0.25000000\n#&gt;   Ideal     0.39622642 0.45977011 0.31632653 0.48543689 0.40449438 0.38636364\n#&gt;            \n#&gt;                      J\n#&gt;   Fair      0.03846154\n#&gt;   Good      0.03846154\n#&gt;   Very Good 0.26923077\n#&gt;   Premium   0.38461538\n#&gt;   Ideal     0.26923077\n\n\n\n\n\n\n\n\n\n本周目标\n\n\n\n\n熟练创建和解读列联表。\n理解卡方检验（特别是独立性检验）的原理、目的和应用场景。\n掌握卡方独立性检验的 R 实现 (chisq.test())、假设条件和结果解读。\n（可选）了解卡方拟合优度检验。\n能够根据问题选择合适的统计检验方法（t 检验、ANOVA、卡方、相关/回归）。\n对第一阶段所学的数据处理、可视化和推断统计知识进行系统性总结。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>第七周：分类数据的智慧：卡方检验与阶段总结</span>"
    ]
  },
  {
    "objectID": "week7_lecture.html#卡方检验-chi2-test",
    "href": "week7_lecture.html#卡方检验-chi2-test",
    "title": "第七周：分类数据的智慧：卡方检验与阶段总结",
    "section": "2. 卡方检验 (\\(\\chi^2\\) Test)",
    "text": "2. 卡方检验 (\\(\\chi^2\\) Test)\n卡方检验是一类用于分析分类数据的非参数检验方法。它比较观测频数 (Observed Frequencies) 与基于某个假设计算出的期望频数 (Expected Frequencies) 之间的差异。差异越大，越倾向于拒绝原假设。\n本周我们重点关注卡方独立性检验。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>第七周：分类数据的智慧：卡方检验与阶段总结</span>"
    ]
  },
  {
    "objectID": "week7_lecture.html#卡方独立性检验-chi-squared-test-of-independence",
    "href": "week7_lecture.html#卡方独立性检验-chi-squared-test-of-independence",
    "title": "第七周：分类数据的智慧：卡方检验与阶段总结",
    "section": "3. 卡方独立性检验 (Chi-squared Test of Independence)",
    "text": "3. 卡方独立性检验 (Chi-squared Test of Independence)\n\n目的: 判断两个分类变量是否相互独立 (Independent)。换句话说，一个变量的取值是否与另一个变量的取值无关。\n应用场景:\n\n吸烟状况（是/否）与是否患有某种呼吸系统疾病（是/否）之间是否存在关联？\n不同教育水平（小学/中学/大学）的人群在对某项政策的支持度（支持/反对/中立）上是否存在差异？\n产品颜色（红/蓝/绿）的选择是否与消费者性别（男/女）有关？\n\n假设陈述:\n\n\\(H_0\\): 两个变量相互独立 (没有关联)。\n\\(H_1\\): 两个变量不独立 (存在关联)。\n\n期望频数 (Expected Frequency, E) 的思想:\n\n如果 \\(H_0\\) 为真（即两个变量独立），那么某个单元格 \\((i, j)\\)（第 i 行, 第 j 列）的期望频数可以通过以下方式计算： \\[ E_{ij} = \\frac{(\\text{第 } i \\text{ 行的总频数}) \\times (\\text{第 } j \\text{ 列的总频数})}{\\text{总样本量 } N} \\]\n期望频数代表了在变量独立的假设下，我们期望在每个单元格中看到的频数。\n\n检验统计量 (\\(\\chi^2\\) 值):\n\n衡量所有单元格的观测频数 (Observed Frequency, O) 与期望频数 (Expected Frequency, E) 之间总差异的度量。 \\[ \\chi^2 = \\sum_{\\text{所有单元格}} \\frac{(O_{ij} - E_{ij})^2}{E_{ij}} \\]\n\\(\\chi^2\\) 值越大，表示观测频数与独立假设下的期望频数差异越大，越倾向于拒绝 \\(H_0\\)。\n该统计量近似服从卡方分布，自由度 \\(df = (\\text{行数} - 1) \\times (\\text{列数} - 1)\\)。\n\n假设条件 (重要！):\n\n数据是频数数据（计数）。\n样本是随机抽取的。\n期望频数的要求:\n\n所有单元格的期望频数 \\(E_{ij}\\) 通常要求大于等于 5。这是卡方分布近似有效的关键条件。\n如果期望频数过小（例如，小于 5 的单元格超过 20%），卡方检验的结果可能不可靠。可以考虑：\n\n合并类别: 将频数较少的行或列合并。\n使用 Fisher 精确检验 (Fisher’s Exact Test): 特别适用于 2x2 列联表，或者当期望频数很小时。fisher.test() 在 R 中实现。\n增加样本量。\n\n\n\nR 实现: chisq.test()\n\n# 使用之前的 diamonds 列联表 contingency_table\nprint(contingency_table)\n\n#&gt;            \n#&gt;              D  E  F  G  H  I  J\n#&gt;   Fair       2  1  5  2  6  1  1\n#&gt;   Good       8  7 12  9  3  3  1\n#&gt;   Very Good 14 22 24 16 17 12  7\n#&gt;   Premium    8 17 26 26 27 11 10\n#&gt;   Ideal     21 40 31 50 36 17  7\n\n# 执行卡方独立性检验\n# H0: 切割质量 (cut) 与 颜色 (color) 相互独立\n# H1: 切割质量 (cut) 与 颜色 (color) 不独立 (存在关联)\nchisq_result &lt;- chisq.test(contingency_table)\nprint(chisq_result)\n\n#&gt; \n#&gt;  Pearson's Chi-squared test\n#&gt; \n#&gt; data:  contingency_table\n#&gt; X-squared = 29.085, df = 24, p-value = 0.217\n\n# 查看期望频数 (如果需要检查假设条件)\nchisq_result$expected\n\n#&gt;            \n#&gt;                  D      E      F      G      H      I      J\n#&gt;   Fair       1.908  3.132  3.528  3.708  3.204  1.584  0.936\n#&gt;   Good       4.558  7.482  8.428  8.858  7.654  3.784  2.236\n#&gt;   Very Good 11.872 19.488 21.952 23.072 19.936  9.856  5.824\n#&gt;   Premium   13.250 21.750 24.500 25.750 22.250 11.000  6.500\n#&gt;   Ideal     21.412 35.148 39.592 41.612 35.956 17.776 10.504\n\n\n结果解读:\n\nX-squared: 计算得到的 \\(\\chi^2\\) 统计量值 (29.085)。\ndf: 自由度 (df = (5-1) * (7-1) = 4 * 6 = 24)。\np-value: P 值 (0.217)。\n决策: 将 P 值与 \\(\\alpha\\) (例如 0.05) 比较。\n\n在这个例子中，P 值 (0.217) &gt; 0.05。\n\n结论: 我们未能拒绝原假设 \\(H_0\\)。没有足够的统计证据表明钻石的切割质量和颜色之间存在显著关联 (在 \\(\\alpha=0.05\\) 水平下)。\n注意: 如果 P 值小于 \\(\\alpha\\)，我们会拒绝 \\(H_0\\)，结论是两个变量之间存在显著关联。但卡方检验本身不能告诉我们关联的具体模式（哪些类别组合的差异最大）或强度。需要结合观察列联表的百分比或计算其他关联度量（如 Cramer’s V）。\n\nFisher 精确检验 (Fisher’s Exact Test): fisher.test()\n\n当期望频数过小时，Fisher 检验是更准确的选择，尤其对于 2x2 表。\n\n\n# 假设有一个 2x2 表，期望频数可能较小\ntreatment_data &lt;- matrix(c(3, 1, 8, 7), nrow = 2, byrow = TRUE)\nrownames(treatment_data) &lt;- c(\"Treatment\", \"Control\")\ncolnames(treatment_data) &lt;- c(\"Improved\", \"Not Improved\")\nprint(treatment_data)\n\n#&gt;           Improved Not Improved\n#&gt; Treatment        3            1\n#&gt; Control          8            7\n\n# chisq.test(treatment_data) # 可能会有警告关于近似无效\n\nfisher_result &lt;- fisher.test(treatment_data)\nprint(fisher_result) # P 值通常更可靠\n\n#&gt; \n#&gt;  Fisher's Exact Test for Count Data\n#&gt; \n#&gt; data:  treatment_data\n#&gt; p-value = 0.6027\n#&gt; alternative hypothesis: true odds ratio is not equal to 1\n#&gt; 95 percent confidence interval:\n#&gt;    0.1561786 156.9964265\n#&gt; sample estimates:\n#&gt; odds ratio \n#&gt;   2.502087",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>第七周：分类数据的智慧：卡方检验与阶段总结</span>"
    ]
  },
  {
    "objectID": "week7_lecture.html#可选-卡方拟合优度检验-chi-squared-goodness-of-fit-test",
    "href": "week7_lecture.html#可选-卡方拟合优度检验-chi-squared-goodness-of-fit-test",
    "title": "第七周：分类数据的智慧：卡方检验与阶段总结",
    "section": "4. (可选) 卡方拟合优度检验 (Chi-squared Goodness-of-Fit Test)",
    "text": "4. (可选) 卡方拟合优度检验 (Chi-squared Goodness-of-Fit Test)\n\n目的: 检验单个分类变量的观测频数分布是否与某个理论或期望的分布相符。\n应用场景:\n\n掷一个骰子 120 次，检验骰子是否均匀（即每个点数出现的期望频数都是 120/6 = 20）？\n某地区人口普查的民族构成比例是否与全国的民族构成比例一致？\n\n假设陈述:\n\n\\(H_0\\): 观测频数分布符合期望分布。\n\\(H_1\\): 观测频数分布不符合期望分布。\n\nR 实现: chisq.test() (传入观测频数向量 x 和期望概率向量 p)\n\n# 示例：掷骰子 120 次的观测结果\nobserved_counts &lt;- c(18, 22, 19, 21, 23, 17) # 各点数出现次数\n# 期望概率 (均匀骰子)\nexpected_probs &lt;- rep(1/6, 6)\n\n# H0: 骰子是均匀的 (观测分布符合期望概率)\n# H1: 骰子不均匀\ngof_result &lt;- chisq.test(x = observed_counts, p = expected_probs)\nprint(gof_result)\n\n#&gt; \n#&gt;  Chi-squared test for given probabilities\n#&gt; \n#&gt; data:  observed_counts\n#&gt; X-squared = 1.4, df = 5, p-value = 0.9243\n\n# 解读: P 值很大 (0.92)，未能拒绝 H0，没有证据表明骰子不均匀。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>第七周：分类数据的智慧：卡方检验与阶段总结</span>"
    ]
  },
  {
    "objectID": "week7_lecture.html#实践应用选择合适的检验方法",
    "href": "week7_lecture.html#实践应用选择合适的检验方法",
    "title": "第七周：分类数据的智慧：卡方检验与阶段总结",
    "section": "5. 实践应用：选择合适的检验方法",
    "text": "5. 实践应用：选择合适的检验方法\n现在我们已经学习了多种推断统计方法，关键在于根据研究问题和数据类型选择合适的方法。\n\n\n\n\n\n\n方法选择总结\n\n\n\n\n比较单个总体的均值 vs 已知值:\n\n单样本 t 检验 (总体近似正态或 n≥30)\n\n比较两个独立总体的均值:\n\n双独立样本 t 检验 (总体近似正态或 n1,n2≥30；Welch’s test 默认，不要求方差齐性)\n\n比较同一个对象两次测量的均值 (配对数据):\n\n配对样本 t 检验 (差值近似正态或 n_pairs≥30)\n\n比较三个或更多独立总体的均值:\n\n单因素 ANOVA (总体近似正态，方差齐性)\n如果 ANOVA 显著，用 Tukey’s HSD 等事后检验看具体差异。\n\n检验两个分类变量是否独立/关联:\n\n卡方独立性检验 (期望频数 E≥5)\n(期望频数小或 2x2 表: Fisher 精确检验)\n\n检验单个分类变量的分布 vs 期望分布:\n\n卡方拟合优度检验 (期望频数 E≥5)\n\n衡量两个连续变量的线性关联强度:\n\nPearson 相关系数 (线性关系，近似二元正态)\n\n衡量两个变量的单调关联强度 (含定序变量或非正态连续变量):\n\nSpearman 相关系数\n\n用一个连续变量预测另一个连续变量 (线性关系):\n\n简单线性回归 (SLR)\n\n用多个变量预测一个连续变量:\n\n多元线性回归 (MLR) (阶段二内容)\n\n用多个变量预测一个分类变量:\n\nLogistic 回归 等分类模型 (阶段二内容)\n\n\n\n\n思考流程:\n\n你的研究问题是什么？（比较均值？检验关联？预测？）\n涉及几个变量？变量是什么类型？（连续？分类？名义？有序？）\n数据是独立的还是配对的？\n满足哪些统计假设？（正态性？方差齐性？线性关系？期望频数？）",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>第七周：分类数据的智慧：卡方检验与阶段总结</span>"
    ]
  },
  {
    "objectID": "week7_lecture.html#阶段一知识小结",
    "href": "week7_lecture.html#阶段一知识小结",
    "title": "第七周：分类数据的智慧：卡方检验与阶段总结",
    "section": "6. 阶段一知识小结",
    "text": "6. 阶段一知识小结\n恭喜你完成了统计学与 R 语言学习的第一阶段！让我们回顾一下核心技能和知识点：\n\n数据处理与整形 (tidyverse: dplyr, tidyr):\n\n数据导入 (readr)\n数据框与 Tibble\n选择列 (select)\n筛选行 (filter)\n创建/修改列 (mutate)\n排序 (arrange)\n分组计算 (group_by, summarise, n())\n长宽格式转换 (pivot_longer, pivot_wider)\n处理缺失值 (is.na, drop_na, replace_na, na.rm=TRUE)\n管道操作 (%&gt;%)\n整洁数据原则\n\n数据可视化 (ggplot2):\n\n图形语法核心：数据、映射 (aes)、几何对象 (geom_...)\n常用图形：直方图、密度图、箱线图、散点图、条形图、小提琴图\n图形定制：标签 (labs)、主题 (theme_...)\n\n描述性统计:\n\n集中趋势：均值 (mean)、中位数 (median)\n离散趋势：极差 (range)、分位数/IQR (quantile, IQR)、方差 (var)、标准差 (sd)\n\n推断统计基础:\n\n总体与样本\n抽样分布与中心极限定理 (CLT)\n参数估计：点估计 vs 区间估计 (置信区间 conf.int)\n假设检验逻辑：\\(H_0\\)/\\(H_1\\), \\(\\alpha\\), P 值, 决策规则, 两类错误\n\n常用推断检验方法:\n\nt 检验 (t.test: 单样本, 双独立样本, 配对样本)\n方差分析 (aov, summary, TukeyHSD)\n卡方检验 (chisq.test, fisher.test)\n相关性检验 (cor.test)\n简单线性回归 (lm, summary)\n\n\n掌握这些基础知识，你已经具备了进行基本数据分析的能力！",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>第七周：分类数据的智慧：卡方检验与阶段总结</span>"
    ]
  },
  {
    "objectID": "week7_lecture.html#项目相关与本周总结",
    "href": "week7_lecture.html#项目相关与本周总结",
    "title": "第七周：分类数据的智慧：卡方检验与阶段总结",
    "section": "7. 项目相关与本周总结",
    "text": "7. 项目相关与本周总结\n\n项目任务:\n\n分析你项目中分类变量之间的关系。使用列联表和卡方独立性检验（或 Fisher 检验）来判断它们之间是否存在显著关联。\n开始整合阶段一所学的所有知识，构建你的项目的整体分析框架。建议从以下几个方面进行思考：\n\n数据预处理：需要进行哪些数据清理和转换？（如处理缺失值、异常值、数据类型转换等）\n探索性分析：哪些描述性统计量（如均值、中位数、标准差等）和可视化图表（如直方图、散点图、箱线图等）最能揭示数据特征？\n推断分析：根据研究问题，需要采用哪些统计推断方法？（如 t 检验、方差分析、卡方检验、回归分析等）\n结果呈现：如何清晰有效地展示分析结果？（如使用表格、图形、统计报告等） （以上内容可先进行初步构思，后续逐步完善）\n\n\n本周回顾: 我们学习了如何使用列联表和卡方检验来分析分类变量之间的关系，并重点掌握了独立性检验。同时，我们对第一阶段的核心内容进行了梳理和总结，强调了根据问题选择合适统计方法的重要性。\n\n阶段二预告: 下周我们将进入课程的第二阶段。首先会系统回顾第一阶段的核心内容，然后深入探讨多元线性回归，学习如何构建、诊断和解释包含多个自变量的模型，这是统计建模中非常重要的一环。准备好迎接更复杂的模型世界吧！",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>第七周：分类数据的智慧：卡方检验与阶段总结</span>"
    ]
  },
  {
    "objectID": "week8_lecture.html",
    "href": "week8_lecture.html",
    "title": "第八周：承前启后：阶段回顾与多元回归再探",
    "section": "",
    "text": "1. 欢迎来到第二阶段！\n本周我们正式进入课程的第二阶段。在深入学习更高级的统计模型之前，我们需要系统地回顾和巩固第一阶段（第 1-7 周）的核心知识，并在此基础上，重新审视和深入理解多元线性回归 (Multiple Linear Regression, MLR)。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>第八周：承前启后：阶段回顾与多元回归再探</span>"
    ]
  },
  {
    "objectID": "week8_lecture.html#欢迎来到第二阶段",
    "href": "week8_lecture.html#欢迎来到第二阶段",
    "title": "第八周：承前启后：阶段回顾与多元回归再探",
    "section": "",
    "text": "本周目标\n\n\n\n\n系统回顾第一阶段核心内容：数据处理与可视化 (tidyverse, ggplot2)；描述统计；参数估计（点估计与置信区间）；假设检验逻辑；常用检验方法 (t 检验, ANOVA, 卡方检验)；相关分析；简单线性回归 (SLR) 基础与多元线性回归 (MLR) 初步概念。\n深入理解 MLR 中偏回归系数的意义：控制变量与独立效应。\n反复练习对 lm() 输出中 MLR 系数的业务含义解释。\n区分统计显著性与实际重要性。\n回顾线性回归的 L.I.N.E. 假设，理解其重要性及违背后果。\n（演示）利用 AI 辅助回顾概念、解释 MLR 系数，并强调验证其准确性。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>第八周：承前启后：阶段回顾与多元回归再探</span>"
    ]
  },
  {
    "objectID": "week8_lecture.html#阶段一知识回顾-重点环节",
    "href": "week8_lecture.html#阶段一知识回顾-重点环节",
    "title": "第八周：承前启后：阶段回顾与多元回归再探",
    "section": "2. 阶段一知识回顾 (重点环节)",
    "text": "2. 阶段一知识回顾 (重点环节)\n让我们通过互动问答、知识点串讲和快速练习，快速回顾一下前七周的核心内容。\n\n数据处理与可视化描述统计与参数估计假设检验逻辑与常用方法\n\n\n\ntidyverse 核心包: dplyr, tidyr, readr, ggplot2 等。\ndplyr 动词:\n\nselect(): 选择列。\nfilter(): 筛选行。\nmutate(): 创建/修改列。\narrange(): 排序。\ngroup_by() + summarise(): 分组汇总 (常用 n(), mean(), sd(), min(), max(), n_distinct())。\n管道 %&gt;%: 连接操作。\n\ntidyr 动词:\n\npivot_longer(): 宽数据变长。\npivot_wider(): 长数据变宽。\ndrop_na(): 删除含 NA 的行。\nreplace_na(): 替换 NA。\n\n整洁数据原则: 每个变量一列，每个观测一行，每种观测一个表。\nggplot2 图形语法:\n\nggplot(data, aes(x=..., y=..., color=...)) + geom_xxx(...)\n常用 geom: geom_point, geom_line, geom_histogram, geom_density, geom_boxplot, geom_violin, geom_bar, geom_col, geom_smooth。\n定制: labs(), theme_...(), coord_flip()。\n\n\n快速练习:\n\n如何筛选 mpg 数据集中 manufacturer 为 “audi” 且 year 为 2008 的车辆？\n如何计算 mpg 数据集中每个 manufacturer 的平均城市里程 (cty)？\n如何用 ggplot2 绘制 mpg 数据集中 cty (城市里程) 与 hwy (高速里程) 的散点图，并按 drv (驱动方式) 区分颜色？\n\n\n\n\n描述统计:\n\n集中趋势: 均值 (mean), 中位数 (median)。\n离散趋势: 标准差 (sd), 方差 (var), IQR (IQR), 范围 (range)。\n\n参数估计:\n\n点估计: 用样本统计量估计总体参数 (如 \\(\\bar{x}\\) 估计 \\(\\mu\\))。\n区间估计: 置信区间 (CI)。\n\n置信区间:\n\n提供总体参数可能范围的估计，并附带置信水平。\n95% CI 含义：重复抽样构造区间，约 95% 的区间会包含真值。\n解读：我们有 XX% 的信心认为总体参数落在 [下限, 上限] 之间。\n影响因素：置信水平、样本量、数据变异性。\n\n\n快速思考:\n\n什么时候应该使用中位数而不是均值来描述数据的中心？\n99% 置信区间与 95% 置信区间相比，哪个更宽？为什么？\n增加样本量会对置信区间的宽度产生什么影响？\n\n\n\n\n假设检验逻辑:\n\n\\(H_0\\) (原假设) vs \\(H_1\\) (备择假设)。\n\\(\\alpha\\) (显著性水平，第一类错误概率)。\n检验统计量。\nP 值 (在 \\(H_0\\) 为真的条件下，观测到当前或更极端结果的概率)。\n决策：P ≤ \\(\\alpha\\) -&gt; 拒绝 \\(H_0\\)；P &gt; \\(\\alpha\\) -&gt; 未能拒绝 \\(H_0\\)。\n两类错误：Type I (\\(\\alpha\\)) vs Type II (\\(\\beta\\))；Power = \\(1-\\beta\\)。\n\n常用检验方法回顾 (见第七周总结):\n\nt 检验 (t.test): 比较 1 或 2 组均值 (单样本, 双独立样本, 配对样本)。\nANOVA (aov, TukeyHSD): 比较 3+ 组均值。\n卡方检验 (chisq.test, fisher.test): 分析分类变量关联性 (独立性检验) 或分布拟合 (拟合优度检验)。\n相关检验 (cor.test): 检验两个连续 (或有序) 变量的相关性是否显著。\nSLR (lm): 检验单个自变量对因变量的线性影响是否显著 (看系数的 P 值)。\n\n\n快速判断:\n\n想比较两种不同减肥方法的效果（体重减少量），应使用哪种检验？(假设满足条件)\n想调查某大学男女生对食堂满意度（满意/不满意）是否存在差异，应使用哪种检验？\n想研究广告投入（连续变量）与产品销量（连续变量）之间是否存在线性关系，应使用哪种分析？\n想比较三种不同品牌灯泡的平均寿命是否有差异，应使用哪种检验？如果结果显著，下一步该做什么？",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>第八周：承前启后：阶段回顾与多元回归再探</span>"
    ]
  },
  {
    "objectID": "week8_lecture.html#多元回归再认识深入理解偏回归系数",
    "href": "week8_lecture.html#多元回归再认识深入理解偏回归系数",
    "title": "第八周：承前启后：阶段回顾与多元回归再探",
    "section": "3. 多元回归“再认识”：深入理解偏回归系数",
    "text": "3. 多元回归“再认识”：深入理解偏回归系数\n我们在第六周初步接触了 MLR。现在，我们要深入理解其核心——偏回归系数 (Partial Regression Coefficient)。\n\n回顾模型形式: \\(Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_k X_k + \\epsilon\\)\n偏回归系数 \\(\\beta_j\\) 的意义 (核心！):\n\n\\(\\beta_j\\) 衡量的是，在保持模型中所有其他自变量 (\\(X_1, ..., X_{j-1}, X_{j+1}, ..., X_k\\)) 数值不变 (或称“控制住” Control For) 的条件下，自变量 \\(X_j\\) 每增加一个单位时，因变量 Y 的期望**平均变化量。\n它反映了 \\(X_j\\) 对 Y 的独立效应 (Independent Effect) 或调整后效应 (Adjusted Effect)。\n\n为何重要？\n\n现实世界中变量往往相互关联（存在混淆 Confounding）。如果不控制其他相关变量，我们可能会错误地估计某个变量的真实影响（遗漏变量偏误 Omitted Variable Bias）。\nMLR 通过将多个相关变量纳入模型，可以分离出每个自变量在控制了其他变量影响后的净效应 (Net Effect)。\n\n示例：预测汽车高速里程 (hwy)\n\nSLR: lm(hwy ~ displ, data = mpg)\n\ndispl 的系数 \\(\\hat{\\beta}_1 \\approx -3.53\\)。这表示排量每增加 1 升，hwy 平均减少 3.53 MPG，但这个估计可能混杂了其他与排量相关的因素（如气缸数、车重等）的影响。\n\nMLR: lm(hwy ~ displ + cyl + drv, data = mpg) (加入气缸数 cyl 和驱动方式 drv)\n\nlibrary(tidyverse)\nmlr_model_mpg &lt;- lm(hwy ~ displ + cyl + drv, data = mpg)\nsummary(mlr_model_mpg)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = hwy ~ displ + cyl + drv, data = mpg)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.7095 -2.0282 -0.1297  1.3760 13.8110 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  33.0915     1.0306  32.108  &lt; 2e-16 ***\n#&gt; displ        -1.1245     0.4614  -2.437   0.0156 *  \n#&gt; cyl          -1.4526     0.3334  -4.357 1.99e-05 ***\n#&gt; drvf          5.0446     0.5134   9.826  &lt; 2e-16 ***\n#&gt; drvr          4.8851     0.7116   6.864 6.20e-11 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2.968 on 229 degrees of freedom\n#&gt; Multiple R-squared:  0.7559, Adjusted R-squared:  0.7516 \n#&gt; F-statistic: 177.2 on 4 and 229 DF,  p-value: &lt; 2.2e-16\n\n\n\n解读 displ 的偏回归系数 \\(\\hat{\\beta}_{displ} \\approx -1.1245\\):\n\n在保持气缸数 (cyl) 和驱动方式 (drv) 不变的情况下，发动机排量 (displ) 每增加 1 升，高速公路里程 (hwy) 平均减少约 1.12 MPG。\n对比 SLR: 这个系数 (-1.1245) 的绝对值小于 SLR 中的系数 (-3.53)。这表明，排量对里程的部分负面影响实际上是通过气缸数等其他因素体现的。控制了这些因素后，排量本身的独立负面影响变小了。\n\n解读 cyl 的偏回归系数 \\(\\hat{\\beta}_{cyl} \\approx -1.4509\\):\n\n在保持排量 (displ) 和驱动方式 (drv) 不变的情况下，气缸数 (cyl) 每增加 1 个，高速公路里程 (hwy) 平均减少约 1.45 MPG。\n\n解读分类变量 drv (因子): R 自动进行了虚拟编码 (Dummy Coding)。它选择一个参照组（这里是 drv = '4' 四驱），其他组别的系数表示相对于参照组的平均差异。\n\ndrvf (\\(\\hat{\\beta}_{drvf} \\approx 5.04\\)): 在保持排量和气缸数不变的情况下，前驱 (drv='f') 车辆的平均高速里程比四驱 (drv='4') 车辆高约 5.04 MPG (且 P &lt; 0.05，差异显著)。\ndrvr (\\(\\hat{\\beta}_{drvr} \\approx 4.9\\)): 在保持排量和气缸数不变的情况下，后驱 (drv='r') 车辆的平均高速里程比四驱 (drv='4') 车辆高约 4.9 MPG (且 P &lt; 0.05，差异显著)。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>第八周：承前启后：阶段回顾与多元回归再探</span>"
    ]
  },
  {
    "objectID": "week8_lecture.html#统计显著性-vs-实际重要性",
    "href": "week8_lecture.html#统计显著性-vs-实际重要性",
    "title": "第八周：承前启后：阶段回顾与多元回归再探",
    "section": "4. 统计显著性 vs 实际重要性",
    "text": "4. 统计显著性 vs 实际重要性\n\n统计显著性 (Statistical Significance): 由 P 值决定。P 值 &lt; \\(\\alpha\\) 意味着我们有足够证据拒绝 \\(H_0\\)（例如，系数不为 0，或组间均值有差异）。它表明观察到的效应不太可能仅仅由随机抽样误差引起。\n实际重要性 (Practical Significance / Effect Size): 指效应的大小或幅度在现实世界中是否有意义或值得关注。\n区分:\n\n大样本量可能导致非常小的效应也具有统计显著性（P 值很小），但这个效应在实际应用中可能微不足道。\n小样本量可能导致很大的效应却不具有统计显著性（P 值较大），因为证据不足。\n\n评估实际重要性:\n\n回归系数的大小: \\(\\beta_j\\) 的值本身有多大？结合业务背景判断这个变化量是否有意义。\nR²: 模型解释了多少变异？(虽然 R² 高不代表模型一定好或有因果关系)。\n置信区间: 系数的置信区间宽度和位置提供了效应大小不确定性的信息。\n标准化系数 (Standardized Coefficients, Betas): (后续可能涉及) 将所有变量标准化后进行回归，得到的系数可以比较不同自变量的相对重要性（因为它们在同一尺度上）。\n领域知识 (Domain Knowledge): 结合专业背景判断效应是否重要。\n\n\n\n\n\n\n\n\n警惕 P 值崇拜\n\n\n\n不要仅仅根据 P 值 &lt; 0.05 就认为结果一定重要。要结合效应大小、置信区间、研究背景和实际影响来综合判断。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>第八周：承前启后：阶段回顾与多元回归再探</span>"
    ]
  },
  {
    "objectID": "week8_lecture.html#回归模型的假设-l.i.n.e.",
    "href": "week8_lecture.html#回归模型的假设-l.i.n.e.",
    "title": "第八周：承前启后：阶段回顾与多元回归再探",
    "section": "5. 回归模型的假设 (L.I.N.E.)",
    "text": "5. 回归模型的假设 (L.I.N.E.)\n线性回归模型（包括 SLR 和 MLR）的有效性依赖于一些关键假设。如果这些假设严重违背，模型的预测和推断结果可能不可靠。\n\n线性性 (Linearity): 因变量 \\(Y\\) 与每个自变量 \\(X_j\\) 之间的关系是线性的（在控制其他变量后）。\n\n检查: 残差图 (Residuals vs Fitted plot)，残差应该随机散布在 0 附近，没有明显模式（如曲线）。也可以绘制部分残差图 (Partial Residual Plots)。\n后果: 如果关系是非线性的，线性模型拟合会很差，预测不准。\n处理: 变量变换（如 \\(\\log(Y)\\), \\(X^2\\)），加入非线性项，使用非线性模型。\n\n独立性 (Independence): 误差项 \\(\\epsilon_i\\) (或观测值 \\(Y_i\\)) 之间相互独立。\n\n检查: 通常根据研究设计判断（如时间序列数据、聚类数据可能违背）。也可以检查残差的自相关性 (Durbin-Watson test)。\n后果: 标准误估计偏低，导致 P 值偏小，容易犯第一类错误。\n处理: 使用考虑了依赖性的模型（如时间序列模型、多层模型）。\n\n正态性 (Normality): 误差项 \\(\\epsilon\\) 服从正态分布。注意：是误差项，不是 \\(Y\\) 或 \\(X\\) 本身！\n\n检查: 残差的正态 QQ 图 (Normal Q-Q plot)，点应大致落在直线上；残差的直方图；Shapiro-Wilk 检验。\n后果: 在小样本下，系数的置信区间和 P 值可能不准确。但在大样本下（CLT），t 检验和 F 检验对轻微偏离正态性比较稳健。\n处理: 变量变换，使用稳健回归方法。\n\n等方差性 (Equal Variance / Homoscedasticity): 误差项 \\(\\epsilon\\) 的方差对于所有自变量的取值水平都是恒定的 (\\(\\sigma^2\\))。\n\n检查: 残差图 (Residuals vs Fitted plot)，点的散布宽度应该大致均匀，没有喇叭形或扇形。也可以用 Breusch-Pagan 检验等。\n后果: OLS 估计仍然是无偏的，但标准误和 P 值不准确。\n处理: 变量变换（如 \\(\\log(Y)\\)），使用加权最小二乘法 (WLS) 或稳健标准误。\n\n\n\nLinearity, Independence, Normality, Equal Variance. 这些是经典 OLS 回归的核心假设。我们将在下一周学习如何通过模型诊断来检查这些假设。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>第八周：承前启后：阶段回顾与多元回归再探</span>"
    ]
  },
  {
    "objectID": "week8_lecture.html#ai-辅助理解与验证",
    "href": "week8_lecture.html#ai-辅助理解与验证",
    "title": "第八周：承前启后：阶段回顾与多元回归再探",
    "section": "6. AI 辅助理解与验证",
    "text": "6. AI 辅助理解与验证\nAI 工具可以帮助我们回顾概念和解释结果，但务必谨慎使用。\n\n\n\n\n\n\nAI 辅助演示 (需验证！)\n\n\n\n\n回顾概念: “请解释多元线性回归中偏回归系数的概念” 或 “线性回归的假设(LINE)有哪些？”\n解释 MLR 系数: (提供 summary() 输出) “请解释这个 R 回归输出中 ‘displ’ 的系数，并考虑模型中的其他变量”\n比较 SLR 和 MLR 系数: “为什么在简单线性回归(hwy ~ displ)和多元线性回归(hwy ~ displ + cyl + drv)中，‘displ’ 的系数会不同？”\n\n特别提醒： AI生成的内容可能存在不准确或不够细致的问题。请务必结合课堂所学知识和教材内容进行批判性思考和验证。 切勿直接将AI的解释作为最终答案直接使用。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>第八周：承前启后：阶段回顾与多元回归再探</span>"
    ]
  },
  {
    "objectID": "week8_lecture.html#本周总结与预告",
    "href": "week8_lecture.html#本周总结与预告",
    "title": "第八周：承前启后：阶段回顾与多元回归再探",
    "section": "7. 本周总结与预告",
    "text": "7. 本周总结与预告\n本周我们系统回顾了第一阶段的知识体系，并深入探讨了多元线性回归的核心——偏回归系数的意义和解释，以及统计显著性与实际重要性的区别。我们还重温了线性回归的关键假设 (L.I.N.E.)，为下周的模型诊断打下基础。\n下周预告: 模型拟合好了，但它可靠吗？下周我们将学习回归模型诊断的实战技术，利用各种图形和检验方法来检查 L.I.N.E. 假设是否满足，并识别模型中可能存在的问题（如异常值、强影响点、多重共线性）。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>第八周：承前启后：阶段回顾与多元回归再探</span>"
    ]
  },
  {
    "objectID": "week9_lecture.html",
    "href": "week9_lecture.html",
    "title": "第九周：模型诊断实战：发现模型的问题",
    "section": "",
    "text": "1. 为何需要模型诊断？\n上周我们学习了如何拟合多元线性回归模型 (MLR) 并解释其系数。然而，仅仅拟合模型是不够的。我们需要诊断 (Diagnose) 模型，以确保其结果是可靠和有效的。模型诊断主要关注：\n我们将使用上周拟合的 MLR 模型作为示例，并可能引入其他数据。\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(car) # 需要 car 包提供 VIF 和其他诊断功能\n# install.packages(\"car\") # 如果尚未安装\nlibrary(broom) # 需要 broom 包的 augment 函数\n\n# 回顾上周的 MLR 模型\n# mpg 数据集已在 tidyverse 中\nmlr_model_mpg &lt;- lm(hwy ~ displ + cyl + drv, data = mpg)\nsummary(mlr_model_mpg)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = hwy ~ displ + cyl + drv, data = mpg)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -8.7095 -2.0282 -0.1297  1.3760 13.8110 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  33.0915     1.0306  32.108  &lt; 2e-16 ***\n#&gt; displ        -1.1245     0.4614  -2.437   0.0156 *  \n#&gt; cyl          -1.4526     0.3334  -4.357 1.99e-05 ***\n#&gt; drvf          5.0446     0.5134   9.826  &lt; 2e-16 ***\n#&gt; drvr          4.8851     0.7116   6.864 6.20e-11 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2.968 on 229 degrees of freedom\n#&gt; Multiple R-squared:  0.7559, Adjusted R-squared:  0.7516 \n#&gt; F-statistic: 177.2 on 4 and 229 DF,  p-value: &lt; 2.2e-16\n\n# 为了演示，创建一个包含一些潜在问题的数据集\nset.seed(42)\nn_prob &lt;- 100\nx1_prob &lt;- rnorm(n_prob)\nx2_prob &lt;- x1_prob * 0.8 + rnorm(n_prob, 0, 0.1) # 引入共线性\nx3_prob &lt;- rnorm(n_prob)\ny_prob &lt;- 2 + 3*x1_prob + 1*x2_prob - 2*x3_prob + rnorm(n_prob, 0, 2)\n# 引入一个异常值/强影响点\ny_prob[1] &lt;- y_prob[1] + 15\nx1_prob[2] &lt;- x1_prob[2] + 4 # 引入一个高杠杆点\nprob_data &lt;- tibble(y = y_prob, x1 = x1_prob, x2 = x2_prob, x3 = x3_prob)\nprob_model &lt;- lm(y ~ x1 + x2 + x3, data = prob_data)\nsummary(prob_model)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y ~ x1 + x2 + x3, data = prob_data)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -4.0480 -1.2564 -0.2585  0.9413 13.2713 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)   2.2211     0.2293   9.685 7.06e-16 ***\n#&gt; x1            0.3627     0.5709   0.635    0.527    \n#&gt; x2            4.6080     0.7436   6.197 1.44e-08 ***\n#&gt; x3           -2.3616     0.2268 -10.413  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2.274 on 96 degrees of freedom\n#&gt; Multiple R-squared:  0.8412, Adjusted R-squared:  0.8363 \n#&gt; F-statistic: 169.6 on 3 and 96 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>第九周：模型诊断实战：发现模型的问题</span>"
    ]
  },
  {
    "objectID": "week9_lecture.html#为何需要模型诊断",
    "href": "week9_lecture.html#为何需要模型诊断",
    "title": "第九周：模型诊断实战：发现模型的问题",
    "section": "",
    "text": "检查线性回归的 L.I.N.E. 假设是否满足:\n\n线性性 (Linearity)\n独立性 (Independence) - 本课程较少涉及检验，主要靠研究设计保证\n正态性 (Normality of Residuals)\n等方差性 (Equal Variance / Homoscedasticity)\n\n识别可能对模型产生过大影响的数据点:\n\n异常值 (Outliers): Y 值远离模型预测值的点 (残差大)。\n高杠杆点 (High Leverage Points): X 值远离其他 X 值均值的点 (可能对回归线斜率有较大影响)。\n强影响点 (Influential Points): 对模型参数（系数）估计产生不成比例影响的点，通常既是异常值又是高杠杆点。\n\n\n\n\n\n\n\n\n本周目标\n\n\n\n\n理解模型诊断的重要性。\n掌握常用的模型诊断工具及其 R 实现：\n\n残差图 (Residual Plots): 检查线性性、等方差性。\n正态 QQ 图 (Normal Q-Q Plot): 检查残差正态性。\nShapiro-Wilk 检验: 对残差正态性进行统计检验。\n方差膨胀因子 (Variance Inflation Factor, VIF): 检查多重共线性。\nCook 距离 (Cook’s Distance): 识别强影响点。\n\n能够解读诊断图和指标，判断模型是否存在问题。\n通过实践工作坊应用诊断技术。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>第九周：模型诊断实战：发现模型的问题</span>"
    ]
  },
  {
    "objectID": "week9_lecture.html#诊断工具箱与-r-实现",
    "href": "week9_lecture.html#诊断工具箱与-r-实现",
    "title": "第九周：模型诊断实战：发现模型的问题",
    "section": "2. 诊断工具箱与 R 实现",
    "text": "2. 诊断工具箱与 R 实现\nR 的基础绘图功能和 car 等包提供了丰富的诊断工具。lm() 对象本身也包含了很多诊断信息。\n\n2.1 残差分析：检查线性性与等方差性\n残差 (Residuals, \\(e_i = y_i - \\hat{y}_i\\)) 是模型诊断的核心。它们代表了模型未能解释的部分。\n\n残差图 (Residuals vs Fitted Plot):\n\n横轴: 模型的拟合值 (\\(\\hat{y}_i\\))。\n纵轴: 残差 (\\(e_i\\))。\n理想模式: 点应该随机散布在 \\(y=0\\) 这条水平线上下，没有明显的模式（如曲线、喇叭形、扇形）。\n检查内容:\n\n线性性: 如果点呈现曲线模式，可能表示 Y 与某个 X 的关系不是线性的。\n等方差性: 如果点的散布宽度随着拟合值的变化而变化（例如，呈喇叭形或扇形），则违反了等方差性假设（异方差 Heteroscedasticity）。\n\nR 实现:\n\n# 方法1: 使用基础 plot() 函数 (推荐，一次生成多个诊断图)\npar(mfrow = c(2, 2)) # 设置绘图区域为 2x2\nplot(mlr_model_mpg)\n\n\n\n\n\n\n\npar(mfrow = c(1, 1)) # 恢复默认绘图区域\n\n# plot(prob_model) # 对另一个模型进行诊断\n\n# 方法2: 手动提取残差和拟合值绘图 (使用 ggplot2)\nmpg_diag &lt;- augment(mlr_model_mpg) # broom 包的 augment 函数提取诊断信息\n# glimpse(mpg_diag)\n\nggplot(mpg_diag, aes(x = .fitted, y = .resid)) +\n  geom_point(alpha = 0.6) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  geom_smooth(se = FALSE, color = \"blue\") + # 添加平滑曲线辅助观察模式\n  labs(title = \"Residuals vs Fitted\", x = \"Fitted values\", y = \"Residuals\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# 对 prob_model 绘图\nprob_diag &lt;- augment(prob_model)\nggplot(prob_diag, aes(x = .fitted, y = .resid)) +\n  geom_point(alpha = 0.6) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  geom_smooth(se = FALSE, color = \"blue\") +\n  labs(title = \"Residuals vs Fitted (Problematic Data)\", x = \"Fitted values\", y = \"Residuals\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# 这个图可能显示出一些非随机模式或异常点\n\n\n\n\n\n2.2 残差正态性检查\n\n正态 Q-Q 图 (Normal Q-Q Plot):\n\n横轴: 理论正态分布的分位数 (Theoretical Quantiles)。\n纵轴: 标准化残差 (Standardized Residuals) 的分位数。\n理想模式: 点应该大致落在对角线 (y=x) 上。\n检查内容: 如果点系统性地偏离对角线，特别是呈 S 形或弓形，则提示残差可能不正态。\nR 实现:\n\n# 方法1: 使用基础 plot() 函数 (第二个图)\n# plot(mlr_model_mpg)\n\n# 方法2: 使用 ggplot2\nggplot(mpg_diag, aes(sample = .std.resid)) + # .std.resid 是标准化残差\n  stat_qq() +\n  stat_qq_line(color = \"red\") +\n  labs(title = \"Normal Q-Q Plot\", x = \"Theoretical Quantiles\", y = \"Standardized Residuals\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# 对 prob_model 绘图\nggplot(augment(prob_model), aes(sample = .std.resid)) +\n  stat_qq() +\n  stat_qq_line(color = \"red\") +\n  labs(title = \"Normal Q-Q Plot (Problematic Data)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# 这个图可能显示出偏离直线的情况，特别是尾部\n\n\nShapiro-Wilk 正态性检验:\n\n一种常用的统计检验方法，用于检验数据是否来自正态分布总体。\n假设:\n\n\\(H_0\\): 数据服从正态分布。\n\\(H_1\\): 数据不服从正态分布。\n\nR 实现: shapiro.test() (作用于残差)\n\n# 提取模型残差\nresiduals_mpg &lt;- residuals(mlr_model_mpg)\nresiduals_prob &lt;- residuals(prob_model)\n\n# 执行 Shapiro-Wilk 检验\nshapiro.test(residuals_mpg)\n\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  residuals_mpg\n#&gt; W = 0.93763, p-value = 2e-08\n\nshapiro.test(residuals_prob)\n\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  residuals_prob\n#&gt; W = 0.86023, p-value = 2.886e-08\n\n# 解读:\n# 如果 P 值 &gt; alpha (如 0.05)，则未能拒绝 H0，没有足够证据表明残差不正态。\n# 如果 P 值 &lt; alpha，则拒绝 H0，认为残差不服从正态分布。\n# 注意：对于大样本量，即使轻微偏离正态，检验也可能显著 (P &lt; 0.05)。此时应更侧重于 Q-Q 图的视觉判断。\n\n\n\n\n\n2.3 检查多重共线性 (Multicollinearity)\n\n多重共线性: 指模型中的自变量之间存在高度相关关系。\n后果:\n\n系数估计值的标准误会增大，导致 t 检验的功效降低，难以判断系数的显著性（P 值变大）。\n系数估计值变得不稳定，对数据的微小变动非常敏感，甚至可能出现符号错误。\n难以解释单个自变量的独立效应。\n注意: 共线性不影响模型的整体拟合优度 (R²) 和预测能力（只要新数据的共线性模式与训练数据相似）。主要影响系数的解释和推断。\n\n诊断工具：方差膨胀因子 (Variance Inflation Factor, VIF)\n\nVIF 衡量每个自变量 \\(X_j\\) 的方差因其与其他自变量的相关性而“膨胀”了多少倍。\n计算方法：对每个 \\(X_j\\)，用它作为因变量，其他所有自变量作为预测变量，拟合一个辅助回归模型，得到 \\(R_j^2\\)。则 \\(VIF_j = \\frac{1}{1 - R_j^2}\\)。\n解读:\n\nVIF = 1: 表示该自变量与其他自变量完全不相关（理想情况）。\nVIF &gt; 1: 表示存在共线性。\n经验法则:\n\nVIF &gt; 5: 可能存在较强的共线性，需要关注。\nVIF &gt; 10: 通常认为存在严重的共线性，需要处理。\n\n\nR 实现: vif() (来自 car 包)\n\nlibrary(car)\n\n# 计算 mlr_model_mpg 的 VIF\nvif_mpg &lt;- vif(mlr_model_mpg)\nprint(vif_mpg)\n\n#&gt;           GVIF Df GVIF^(1/(2*Df))\n#&gt; displ 9.400685  1        3.066054\n#&gt; cyl   7.637266  1        2.763560\n#&gt; drv   2.006517  2        1.190175\n\n# 解读: displ 和 cyl 的 VIF 较高 (可能 &gt; 5)，提示它们之间存在较强相关性，这符合预期。\n# drv 的 VIF 通常较低，因为它是一个因子。\n\n# 计算 prob_model 的 VIF\nvif_prob &lt;- vif(prob_model)\nprint(vif_prob)\n\n#&gt;       x1       x2       x3 \n#&gt; 7.465051 7.485792 1.018794\n\n# 解读: x1 和 x2 的 VIF 可能非常高 (因为我们故意让它们相关)，提示严重共线性。\n\n\n\n\n\n2.4 识别强影响点\n\nCook 距离 (Cook’s Distance, \\(D_i\\))\n\n衡量第 \\(i\\) 个观测点对所有系数估计值的整体影响。\n它计算的是移除第 \\(i\\) 个点后，系数估计值的变化大小。\n解读:\n\nCook’s D 值越大，表示该点的影响越大。\n经验法则:\n\n\\(D_i &gt; 0.5\\): 可能是一个有影响的点。\n\\(D_i &gt; 1\\): 通常被认为是强影响点，需要仔细检查。\n也有建议用 \\(D_i &gt; 4/n\\) (n 为样本量) 作为阈值。\n\n\nR 实现:\n\n# 方法1: 使用基础 plot() 函数 (通常是第 5 个图，Residuals vs Leverage，点的大小与 Cook's D 相关)\n# plot(mlr_model_mpg)\n# plot(prob_model) # 观察是否有远离中心且 Cook's D 轮廓线较大的点\n\n# 方法2: 直接计算 Cook's D\ncooks_mpg &lt;- cooks.distance(mlr_model_mpg)\ncooks_prob &lt;- cooks.distance(prob_model)\n\n# 找出 Cook's D 较大的点\ncutoff_mpg &lt;- 4 / nrow(mpg)\ncutoff_prob &lt;- 4 / nrow(prob_data)\n\ninfluential_mpg_indices &lt;- which(cooks_mpg &gt; cutoff_mpg)\ninfluential_prob_indices &lt;- which(cooks_prob &gt; cutoff_prob) # 或者用 &gt; 0.5 或 &gt; 1\n\nprint(paste(\"Influential points in mpg model (indices):\", toString(influential_mpg_indices)))\n\n#&gt; [1] \"Influential points in mpg model (indices): 18, 20, 24, 26, 27, 28, 44, 75, 136, 159, 213, 222, 223\"\n\nprint(paste(\"Influential points in prob model (indices):\", toString(influential_prob_indices)))\n\n#&gt; [1] \"Influential points in prob model (indices): 1, 2, 81\"\n\n# 查看这些点的数据\n# mpg[influential_mpg_indices, ]\n# prob_data[influential_prob_indices, ]\n\n# 使用 ggplot2 可视化 Cook's D\nmpg_diag %&gt;%\n  mutate(obs_index = row_number()) %&gt;%\n  ggplot(aes(x = obs_index, y = .cooksd)) +\n  geom_col(fill = \"skyblue\") + # 用柱状图显示\n  geom_hline(yintercept = cutoff_mpg, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Cook's Distance Plot (mpg)\", x = \"Observation Index\", y = \"Cook's Distance\") +\n  theme_minimal()\n\n\n\n\n\n\n\naugment(prob_model) %&gt;%\n  mutate(obs_index = row_number()) %&gt;%\n  ggplot(aes(x = obs_index, y = .cooksd)) +\n  geom_col(fill = \"salmon\") +\n  geom_hline(yintercept = cutoff_prob, color = \"red\", linetype = \"dashed\") +\n  geom_hline(yintercept = 0.5, color = \"blue\", linetype = \"dotted\") + # 添加 0.5 阈值线\n  geom_hline(yintercept = 1, color = \"darkgreen\", linetype = \"dotted\") + # 添加 1 阈值线\n  labs(title = \"Cook's Distance Plot (Problematic Data)\", x = \"Observation Index\", y = \"Cook's Distance\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# 观察是否有柱子超过阈值线，特别是我们引入问题的第 1 个点。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>第九周：模型诊断实战：发现模型的问题</span>"
    ]
  },
  {
    "objectID": "week9_lecture.html#诊断实践工作坊",
    "href": "week9_lecture.html#诊断实践工作坊",
    "title": "第九周：模型诊断实战：发现模型的问题",
    "section": "3. 诊断实践工作坊",
    "text": "3. 诊断实践工作坊\n现在，让我们分组或独立地，对自己项目中的（或老师提供的）线性回归模型进行全面的诊断。\n步骤:\n\n拟合你的线性回归模型 (lm())。\n使用 plot(model) 或 ggplot2 绘制残差图 (Residuals vs Fitted)。检查是否有非线性模式或异方差（喇叭形）。\n绘制正态 Q-Q 图。检查点是否大致落在直线上。\n(可选) 使用 shapiro.test(residuals(model)) 进行正态性检验。\n如果模型有多个自变量，使用 vif(model) 检查多重共线性。是否有 VIF &gt; 5 或 10？\n绘制 Cook 距离图或计算 cooks.distance(model)。是否有 \\(D_i &gt; 4/n\\) 或 &gt; 0.5 或 &gt; 1 的点？识别这些强影响点。\n总结你的诊断结果：模型的主要问题是什么？（违反了哪些假设？是否存在共线性？是否有强影响点？）\n\n讨论:\n\n分享你的诊断结果。\n你的模型看起来可靠吗？哪些方面需要改进？\n对于发现的问题，你认为可能的原因是什么？",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>第九周：模型诊断实战：发现模型的问题</span>"
    ]
  },
  {
    "objectID": "week9_lecture.html#本周总结与预告",
    "href": "week9_lecture.html#本周总结与预告",
    "title": "第九周：模型诊断实战：发现模型的问题",
    "section": "4. 本周总结与预告",
    "text": "4. 本周总结与预告\n本周我们深入学习了线性回归模型诊断的关键技术。通过检查残差图、正态 Q-Q 图、VIF 和 Cook 距离等工具，我们能够评估模型是否满足基本假设，并识别出可能存在的问题，如非线性、异方差、残差非正态、多重共线性以及强影响点。模型诊断是确保回归结果可靠性和有效性的必要步骤。\n下周预告: 发现了模型的问题，该如何解决？下周我们将探讨模型改进与选择的策略，包括如何应对诊断中发现的问题（如变量变换、处理共线性/强影响点），如何引入交互项来捕捉更复杂的关系，以及在多个可能的模型中进行选择的原则和方法。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>第九周：模型诊断实战：发现模型的问题</span>"
    ]
  },
  {
    "objectID": "week10_lecture.html",
    "href": "week10_lecture.html",
    "title": "第十周：模型改进与选择的批判性视角",
    "section": "",
    "text": "1. 模型诊断之后：如何改进？\n上周我们学习了如何诊断线性回归模型，识别潜在的问题，如违反 L.I.N.E. 假设、多重共线性或存在强影响点。本周我们将探讨如何应对这些问题，改进我们的模型，并讨论如何在多个可能的模型中进行选择。\n我们将继续使用之前的模型和数据作为示例。\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(car)    # For vif()\nlibrary(broom)  # For augment()\n\n# 回顾模型\n# mpg 数据集\nmlr_model_mpg &lt;- lm(hwy ~ displ + cyl + drv, data = mpg)\n\n# 问题数据 (回顾创建过程)\nset.seed(42)\nn_prob &lt;- 100\nx1_prob &lt;- rnorm(n_prob)\nx2_prob &lt;- x1_prob * 0.8 + rnorm(n_prob, 0, 0.1) # 共线性\nx3_prob &lt;- rnorm(n_prob)\ny_prob &lt;- 2 + 3*x1_prob + 1*x2_prob - 2*x3_prob + rnorm(n_prob, 0, 2)\ny_prob[1] &lt;- y_prob[1] + 15 # 异常/强影响点\nx1_prob[2] &lt;- x1_prob[2] + 4 # 高杠杆点\nprob_data &lt;- tibble(y = y_prob, x1 = x1_prob, x2 = x2_prob, x3 = x3_prob)\nprob_model &lt;- lm(y ~ x1 + x2 + x3, data = prob_data)\n\n# 诊断回顾 (上一周内容)\n# plot(mlr_model_mpg)\n# plot(prob_model)\n# vif(mlr_model_mpg)\n# vif(prob_model)\n# cooks.distance(prob_model)",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>第十周：模型改进与选择的批判性视角</span>"
    ]
  },
  {
    "objectID": "week10_lecture.html#模型诊断之后如何改进",
    "href": "week10_lecture.html#模型诊断之后如何改进",
    "title": "第十周：模型改进与选择的批判性视角",
    "section": "",
    "text": "本周目标\n\n\n\n\n学习应对模型诊断问题的常用策略：\n\n变量变换 (Variable Transformation): 处理非线性、异方差、残差非正态。\n处理多重共线性: 移除变量、合并变量、岭回归/Lasso (概念介绍)。\n处理强影响点: 检查数据错误、移除点（需谨慎）、使用稳健回归。\n\n理解并应用交互项 (Interaction Terms) 来捕捉变量间的协同效应。\n批判性地看待自动模型选择方法（如 step()）。\n掌握基于理论、诊断结果和简洁性原则进行模型选择的思路。\n了解 AIC 和 BIC 作为模型选择的参考指标。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>第十周：模型改进与选择的批判性视角</span>"
    ]
  },
  {
    "objectID": "week10_lecture.html#应对诊断问题的策略",
    "href": "week10_lecture.html#应对诊断问题的策略",
    "title": "第十周：模型改进与选择的批判性视角",
    "section": "2. 应对诊断问题的策略",
    "text": "2. 应对诊断问题的策略\n\n2.1 变量变换 (Variable Transformation)\n当模型违反线性性、等方差性或残差正态性假设时，对因变量 Y 或某个自变量 X 进行数学变换（如取对数、平方根、倒数等）有时可以改善情况。\n\n常用变换:\n\n对数变换 (Log Transformation): log(Y) 或 log(X)。\n\n适用场景: 处理右偏 (Right-skewed) 数据、稳定随均值增大而增大的方差、将指数增长关系线性化。\n注意: 变量必须取正值。可考虑 log(Y + c)。\n系数解释变化: (见讲义详细说明)\n\n平方根变换 (Square Root Transformation): sqrt(Y) 或 sqrt(X)。适用于计数数据或轻微右偏/异方差。变量需非负。\n倒数变换 (Reciprocal Transformation): 1/Y 或 1/X。处理严重右偏。变量不能为 0。\n平方变换 (Square Transformation): \\(Y^2\\) 或 \\(X^2\\)。处理左偏 (Left-skewed) 数据。\nBox-Cox 变换: 自动寻找最佳幂变换 (\\(\\lambda\\)) (需要 MASS 包)。\n\n示例 (对数变换): 假设发现 hwy 的残差呈喇叭口（异方差）。\n\n# 尝试对 hwy 取对数\nmlr_model_log_hwy &lt;- lm(log(hwy) ~ displ + cyl + drv, data = mpg)\nsummary(mlr_model_log_hwy)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = log(hwy) ~ displ + cyl + drv, data = mpg)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -0.38326 -0.06832  0.00667  0.06868  0.36474 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  3.56292    0.04329  82.304  &lt; 2e-16 ***\n#&gt; displ       -0.04983    0.01938  -2.571   0.0108 *  \n#&gt; cyl         -0.06661    0.01400  -4.756 3.49e-06 ***\n#&gt; drvf         0.21762    0.02156  10.092  &lt; 2e-16 ***\n#&gt; drvr         0.23605    0.02989   7.897 1.18e-13 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.1247 on 229 degrees of freedom\n#&gt; Multiple R-squared:  0.7748, Adjusted R-squared:  0.7708 \n#&gt; F-statistic: 196.9 on 4 and 229 DF,  p-value: &lt; 2.2e-16\n\n# 诊断新模型\npar(mfrow=c(2,2))\nplot(mlr_model_log_hwy)\n\n\n\n\n\n\n\npar(mfrow=c(1,1))\n# 观察残差图和 QQ 图是否有改善\n\n选择变换的原则: 优先考虑 Y；基于理论或诊断图；注意系数解释变化；尝试比较。\n\n\n\n2.2 处理多重共线性 (VIF &gt; 5 或 10)\n\n策略:\n\n移除变量: 移除理论上不重要或 VIF 最高的变量之一 (可能引入遗漏偏误)。\n合并变量: 将高度相关的变量合并为综合指标 (如均值、PCA)。\n收集更多数据:。\n使用专门方法 (高级): 岭回归 (Ridge), Lasso 回归。\n\n示例 (移除变量): 在 prob_model 中，x1 和 x2 的 VIF 高。尝试移除 x2。\n\n\n\n2.3 处理强影响点 (Cook’s D &gt; 1 或 0.5 或 4/n)\n\n策略:\n\n检查数据错误: 修正或删除错误。\n检查是否代表特殊情况: 单独分析或分层建模。\n移除影响点 (需极其谨慎！): 仅在确认错误或不代表总体时考虑；必须报告；比较移除前后的模型。\n使用稳健回归 (Robust Regression): (高级) 如 rlm() from MASS。\n\n示例 (比较移除影响点): 在 prob_model 中，第一个点可能是强影响点。\n\n# 识别影响点索引 (假设 Cook's D &gt; 0.5)\ninfluential_prob_indices &lt;- which(cooks.distance(prob_model) &gt; 0.5)\n# print(influential_prob_indices) # 假设结果是 1\n\n# 拟合移除影响点后的模型\nif(length(influential_prob_indices) &gt; 0) {\n  prob_model_robust &lt;- lm(y ~ x1 + x2 + x3, data = prob_data[-influential_prob_indices, ])\n  # 比较摘要\n  summary(prob_model)\n  summary(prob_model_robust)\n} else {\n  print(\"No highly influential points found based on Cook's D &gt; 0.5\")\n}\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y ~ x1 + x2 + x3, data = prob_data[-influential_prob_indices, \n#&gt;     ])\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -3.6001 -1.1900 -0.2038  1.2253  4.6613 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)   2.0493     0.1818  11.272   &lt;2e-16 ***\n#&gt; x1            3.1105     1.6414   1.895   0.0612 .  \n#&gt; x2            1.0219     2.0328   0.503   0.6163    \n#&gt; x3           -2.0731     0.1823 -11.371   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.785 on 94 degrees of freedom\n#&gt; Multiple R-squared:  0.8823, Adjusted R-squared:  0.8786 \n#&gt; F-statistic: 234.9 on 3 and 94 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>第十周：模型改进与选择的批判性视角</span>"
    ]
  },
  {
    "objectID": "week10_lecture.html#交互项-interaction-terms",
    "href": "week10_lecture.html#交互项-interaction-terms",
    "title": "第十周：模型改进与选择的批判性视角",
    "section": "3. 交互项 (Interaction Terms)",
    "text": "3. 交互项 (Interaction Terms)\n当一个自变量的效果依赖于另一个自变量的水平时，引入交互项（变量乘积）。\n\n模型形式 (含交互项): \\[ Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 (X_1 \\times X_2) + \\epsilon \\]\n系数解释:\n\n\\(\\beta_1\\): \\(X_2=0\\) 时，\\(X_1\\) 的效应。\n\\(\\beta_2\\): \\(X_1=0\\) 时，\\(X_2\\) 的效应。\n\\(\\beta_3\\): \\(X_2\\) 每增加 1 单位，\\(X_1\\) 对 Y 的效应额外变化 \\(\\beta_3\\)。\n\\(X_1\\) 对 Y 的总效应: \\((\\beta_1 + \\beta_3 X_2)\\)，随 \\(X_2\\) 变化。\n\nR 实现: 使用 * 或 :。\n\nY ~ X1 * X2 (推荐) 或 Y ~ X1 + X2 + X1:X2\n\n\n# 示例：研究 displ 对 hwy 的影响是否因 drv 而异？\ninteraction_model_mpg &lt;- lm(hwy ~ displ * drv, data = mpg)\nsummary(interaction_model_mpg)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = hwy ~ displ * drv, data = mpg)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt; -8.489 -1.895 -0.191  1.797 13.467 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  30.6831     1.0961  27.994  &lt; 2e-16 ***\n#&gt; displ        -2.8785     0.2638 -10.913  &lt; 2e-16 ***\n#&gt; drvf          6.6950     1.5670   4.272 2.84e-05 ***\n#&gt; drvr         -4.9034     4.1821  -1.172   0.2422    \n#&gt; displ:drvf   -0.7243     0.4979  -1.455   0.1471    \n#&gt; displ:drvr    1.9550     0.8148   2.400   0.0172 *  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 3.034 on 228 degrees of freedom\n#&gt; Multiple R-squared:  0.746,  Adjusted R-squared:  0.7405 \n#&gt; F-statistic:   134 on 5 and 228 DF,  p-value: &lt; 2.2e-16\n\n# 解读交互项系数 (如 displ:drv4):\n# 相对于参照组 drv='f'，四驱 drv='4' 会使 displ 对 hwy 的负效应 (斜率) 发生多少变化。\n# 如果交互项显著 (P &lt; 0.05)，说明 displ 的影响依赖于驱动方式。\n\n# 可视化交互效应\n# install.packages(\"interactions\")\nlibrary(interactions)\ninteract_plot(interaction_model_mpg, pred = displ, modx = drv, plot.points = TRUE)\n\n\n\n\n\n\n\n# 如果线不平行，提示存在交互效应。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>第十周：模型改进与选择的批判性视角</span>"
    ]
  },
  {
    "objectID": "week10_lecture.html#模型选择的批判性视角",
    "href": "week10_lecture.html#模型选择的批判性视角",
    "title": "第十周：模型改进与选择的批判性视角",
    "section": "4. 模型选择的批判性视角",
    "text": "4. 模型选择的批判性视角\n选择“最佳”模型需要在简洁性和预测/解释能力之间权衡。\n\n常见策略与批判:\n\n自动逐步回归 (step()):\n\n方法: 自动增删变量优化 AIC 等标准。\n缺点: 结果不稳定、P 值失效、可能选出无意义模型。不推荐常规使用。\n\n基于理论和领域知识: 优先选择理论重要、可解释的变量。\n基于模型诊断: 移除导致严重问题的变量（如果合理）。\n基于简洁性原则 (Parsimony): 解释力相近时选更简单的。\n基于信息准则 (AIC/BIC):\n\n衡量拟合优度与复杂度的权衡。\n目标：选择 AIC 或 BIC 最小的模型。\nBIC 对复杂度惩罚更重，倾向于更简洁模型。\n可比较非嵌套模型。\n\n\n# 比较两个模型的 AIC/BIC\nmodel1 &lt;- lm(hwy ~ displ + cyl, data = mpg)\nmodel2 &lt;- lm(hwy ~ displ + drv, data = mpg)\nAIC(model1, model2)\n\n#&gt;        df      AIC\n#&gt; model1  4 1288.779\n#&gt; model2  5 1196.741\n\nBIC(model1, model2)\n\n#&gt;        df      BIC\n#&gt; model1  4 1302.601\n#&gt; model2  5 1214.018\n\n\n\n最佳实践: 结合理论、诊断、简洁性和信息准则进行综合判断。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>第十周：模型改进与选择的批判性视角</span>"
    ]
  },
  {
    "objectID": "week10_lecture.html#本周总结与预告",
    "href": "week10_lecture.html#本周总结与预告",
    "title": "第十周：模型改进与选择的批判性视角",
    "section": "5. 本周总结与预告",
    "text": "5. 本周总结与预告\n本周我们探讨了模型诊断后的改进策略（变量变换、处理共线性/影响点）和交互项的应用。我们还批判性地讨论了模型选择的方法，强调了综合判断的重要性。\n下周预告: 进入分类预测领域，学习Logistic 回归原理、系数解释（优势比 Odds Ratio）及 R 实现。Capstone 项目启动！",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>第十周：模型改进与选择的批判性视角</span>"
    ]
  },
  {
    "objectID": "week11_lecture.html",
    "href": "week11_lecture.html",
    "title": "第十一周：预测分类结果：Logistic 回归（一）",
    "section": "",
    "text": "1. 从线性回归到分类预测\n到目前为止，我们学习的回归模型（SLR, MLR）都是用于预测连续型因变量 Y。但很多时候，我们感兴趣的预测目标是分类变量，特别是二元分类 (Binary Classification) 变量，其结果只有两种可能（例如：是/否、成功/失败、购买/不购买、患病/未患病）。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>第十一周：预测分类结果：Logistic 回归（一）</span>"
    ]
  },
  {
    "objectID": "week11_lecture.html#从线性回归到分类预测",
    "href": "week11_lecture.html#从线性回归到分类预测",
    "title": "第十一周：预测分类结果：Logistic 回归（一）",
    "section": "",
    "text": "线性回归的局限性:\n\n如果直接用线性回归预测一个 0/1 的二元变量，预测值 \\(\\hat{y}\\) 可能会超出 [0, 1] 的合理范围。\n误差项不满足正态性和等方差性假设。\n因变量和自变量之间的关系通常不是线性的，而是 S 形的。\n\nLogistic 回归 (Logistic Regression):\n\n一种广泛用于处理二元或多元分类问题的广义线性模型 (Generalized Linear Model, GLM)。\n它不直接预测类别 (0 或 1)，而是预测属于某个类别（通常是 “成功” 或 “事件发生”，编码为 1）的概率 (Probability) \\(P(Y=1|X)\\)。\n然后可以设定一个阈值（如 0.5），将预测概率转换为类别预测。\n\n\n\n\n\n\n\n\n本周目标\n\n\n\n\n理解为何线性回归不适用于分类结果。\n掌握 Logistic 回归的基本原理：Sigmoid 函数和 Logit 变换。\n理解 Logistic 回归的模型形式。\n重点掌握 Logistic 回归系数的解释，特别是优势比 (Odds Ratio, OR)。\n能够使用 R 的 glm() 函数拟合二元 Logistic 回归模型。\n了解综合实践项目的要求、选题方向、时间安排和评分标准。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>第十一周：预测分类结果：Logistic 回归（一）</span>"
    ]
  },
  {
    "objectID": "week11_lecture.html#logistic-回归原理",
    "href": "week11_lecture.html#logistic-回归原理",
    "title": "第十一周：预测分类结果：Logistic 回归（一）",
    "section": "2. Logistic 回归原理",
    "text": "2. Logistic 回归原理\nLogistic 回归通过两个关键步骤将线性预测值与概率联系起来：\n\n线性预测器 (Linear Predictor): 与线性回归类似，计算自变量的线性组合： \\[ z = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_k X_k \\] 这个 \\(z\\) 的取值范围是 \\((-\\infty, +\\infty)\\)。\n连接函数 (Link Function) 的逆转换 / Sigmoid 函数: 为了将 \\(z\\) 映射到 (0, 1) 的概率区间，Logistic 回归使用了 Sigmoid 函数 (也称为 Logistic 函数)： \\[ P(Y=1|X) = p = \\frac{e^z}{1 + e^z} = \\frac{1}{1 + e^{-z}} \\]\n\nSigmoid 函数的图形呈 S 形，可以将任何实数 \\(z\\) 转换为 (0, 1) 之间的值。\n当 \\(z \\to +\\infty\\) 时，\\(p \\to 1\\)。\n当 \\(z \\to -\\infty\\) 时，\\(p \\to 0\\)。\n当 \\(z = 0\\) 时，\\(p = 0.5\\)。\n\n\n\n\nCode\nlibrary(tidyverse)\n# 生成一系列 z 值\nz &lt;- seq(-10, 10, length.out = 100)\n\n# 计算对应的概率 p\np &lt;- 1 / (1 + exp(-z))\n\n# 绘制 Sigmoid 函数图像\nggplot(data.frame(z = z, p = p), aes(x = z, y = p)) +\n  geom_line(color = \"blue\") +\n  labs(x = \"z\", y = \"p(z)\", title = \"Sigmoid Function\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n什么是连接函数 (Link Function)？\n\n\n\n连接函数（Link Function）是广义线性模型（GLM）中的一个重要概念。它的作用是将因变量的期望值（如概率 \\(p\\)）与自变量的线性组合（\\(z = \\beta_0 + \\beta_1 X_1 + ...\\)）联系起来。通过连接函数，可以将不同类型的因变量（如概率、计数等）与线性预测器相结合，实现灵活的建模。例如，Logistic 回归中用 Logit 连接函数将概率 \\(p\\) 映射到 \\((-\\infty, +\\infty)\\) 的对数优势（log-odds）空间。\n\n\n\n\n\n\n\n\n为什么会使用 Sigmoid 函数？\n\n\n\n在 Logistic 回归中，我们需要将线性预测器 \\(z\\)（取值范围为 \\((-\\infty, +\\infty)\\)）转换为概率 \\(p\\)（取值范围为 \\((0, 1)\\)）。Sigmoid 函数（Logistic 函数）正好具备这种特性：\\(p = \\frac{1}{1 + e^{-z}}\\)。它不仅保证输出在 \\((0, 1)\\) 区间，还能很好地描述概率随自变量变化的 S 形趋势。因此，Sigmoid 函数成为二元 Logistic 回归的标准选择。\n\n\n\n\n\n\n\n\n一定要使用 Sigmoid 函数吗？\n\n\n\n不一定。虽然 Logistic 回归通常使用 Sigmoid（Logit 连接函数），但在广义线性模型（GLM）框架下，连接函数是可以更换的。例如，Probit 回归使用正态分布的累积分布函数（CDF）作为连接函数，Cloglog 回归使用补对数-对数（complementary log-log）连接函数。不同的连接函数适用于不同的数据分布和建模需求。实际中，Sigmoid 最常用，但不是唯一选择。\n\n\n\nLogit 变换 (Logit Transformation) / 连接函数: 反过来，如果我们想将概率 \\(p\\) 转换回线性预测器 \\(z\\)，需要用到 Sigmoid 函数的反函数，即 Logit 变换：\n\n优势 (Odds): 事件发生的概率与不发生的概率之比。\\(Odds = \\frac{p}{1-p}\\)。取值范围是 \\((0, +\\infty)\\)。\n对数优势 (Log-odds) / Logit: 对优势取自然对数。\\(Logit(p) = \\log(\\frac{p}{1-p})\\)。取值范围是 \\((-\\infty, +\\infty)\\)。\n在 Logistic 回归中，Logit(p) 被假定为自变量的线性组合: \\[ \\log\\left(\\frac{p}{1-p}\\right) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_k X_k \\] 这里的 Logit 函数就是 Logistic 回归的连接函数，它将非线性的概率关系转换为了线性的对数优势关系。\n\n\n\n\n\n\n\n\n优势 (Odds) 的实际应用场景\n\n\n\n优势（Odds）及其对数优势（log-odds）在实际中有广泛应用，尤其是在医学、流行病学、社会科学等领域：\n\n医学/流行病学：用于比较暴露组与非暴露组某疾病发生的优势（如吸烟者与非吸烟者患肺癌的优势比）。\n社会科学：分析某因素（如教育水平、性别）对某事件（如就业、投票）的影响。\n金融风控：评估客户特征对违约概率的影响，优势比可量化某变量对违约风险的提升或降低。\n市场营销：衡量促销活动、广告等对购买行为发生的优势变化。\n心理学/行为科学：分析某干预措施对行为发生的优势提升。\n\n优势（Odds）和优势比（Odds Ratio, OR）为解释二元结局变量（如“是/否”）与自变量关系提供了直观的量化工具，尤其适用于事件发生率较低的场景。\n\n\n\n\n\n\n\n\n什么是相对风险（Relative Risk, RR）？\n\n\n\n相对风险（Relative Risk, RR），又称为风险比，是指暴露组事件发生的概率与非暴露组事件发生的概率之比。其计算公式为：\n\\[\nRR = \\frac{P(\\text{事件}| \\text{暴露})}{P(\\text{事件}| \\text{非暴露})}\n\\]\n\n若 \\(RR = 1\\)，表示暴露与事件发生无关；\n若 \\(RR &gt; 1\\)，表示暴露会增加事件发生的风险；\n若 \\(RR &lt; 1\\)，表示暴露会降低事件发生的风险。\n\n举例： 如果吸烟者患肺癌的概率为 0.10，非吸烟者为 0.02，则 \\(RR = 0.10 / 0.02 = 5\\)，即吸烟者患肺癌的风险是非吸烟者的 5 倍。\n实际解读时，很多情况下我们更关心的是相对风险（RR），因为它直接反映概率的倍数关系，更直观、更贴近实际意义。\n\n\n\n\n\n\n\n\n为什么优势比（OR）适用于事件发生概率较低的情况？\n\n\n\n当事件发生概率较低（即罕见事件）时，优势比（OR）与相对风险（RR）非常接近，二者数值差异很小，因此用 OR 近似 RR 是合理且常见的做法。例如，在流行病学中研究罕见疾病时，OR 可以很好地反映暴露与疾病之间的风险关系。\n数学说明：\n假设有两组（暴露组和非暴露组），事件发生概率分别为 \\(p_1\\) 和 \\(p_0\\)，则：\n\n相对风险（RR） 定义为： \\[\nRR = \\frac{p_1}{p_0}\n\\]\n优势比（OR） 定义为： \\[\nOR = \\frac{p_1/(1-p_1)}{p_0/(1-p_0)} = \\frac{p_1(1-p_0)}{p_0(1-p_1)}\n\\]\n\n当 \\(p_1\\) 和 \\(p_0\\) 都很小（即 \\(p_1, p_0 \\ll 1\\)），\\(1-p_1 \\approx 1\\)，\\(1-p_0 \\approx 1\\)，此时： \\[\nOR \\approx \\frac{p_1}{p_0} = RR\n\\] 因此在罕见事件（低发生率）情况下，OR 与 RR 数值非常接近。\n但当事件发生概率较高时，OR 会高估实际的风险比（RR），解释时容易产生误导。具体来说，随着 \\(p_1\\) 或 \\(p_0\\) 增大，\\(1-p_1\\) 和 \\(1-p_0\\) 不再接近 1，OR 的分母变小，导致 OR 明显大于 RR。例如：\n\n若 \\(p_0 = 0.5, p_1 = 0.75\\)，则 \\(RR = 0.75/0.5 = 1.5\\)，而 \\(OR = \\frac{0.75/0.25}{0.5/0.5} = 3\\)，OR 明显大于 RR。\n\n因此，优势比最适合用于低发生率（稀有事件）场景下的解释和比较；在高发生率场景下，需谨慎使用 OR，并建议同时报告 RR 以避免误导。\n\n\n\n\n\n\n\n\n那为什么 Logistic 回归要用优势（Odds）而不是直接用相对风险（RR）？\n\n\n\n实际上，在实际解读和政策建议时，我们更关心相对风险（RR），因为它直接反映概率的变化，对非专业人士也更容易理解。\n但在建模时，Logistic 回归选择用优势（Odds）和对数优势（log-odds）作为建模对象，主要原因有：\n\n概率的线性建模有限制：概率 \\(p\\) 的取值范围是 \\((0,1)\\)，直接用线性回归建模会导致预测值超出 \\([0,1]\\) 区间，不合理。\n优势（Odds）和对数优势（log-odds）可以取任意实数：对数优势 \\(log(\\frac{p}{1-p})\\) 的取值范围是 \\((-\\infty, +\\infty)\\)，适合用线性模型来建模。\nLogistic 回归的数学结构：Logistic 回归假定自变量的线性组合与对数优势（log-odds）成线性关系，即 \\[\n\\log\\left(\\frac{p}{1-p}\\right) = \\beta_0 + \\beta_1 X_1 + ... + \\beta_k X_k\n\\] 这样可以用最大似然法方便地估计参数。\n优势比（OR）易于解释和计算：对数优势的指数化（\\(e^{\\beta_j}\\)）就是优势比，能直观地反映自变量变化对事件发生“优势”的倍数影响。\n\n总结： Logistic 回归之所以用优势（Odds），主要是出于建模和数学推导的便利，而不是因为优势比本身比相对风险更有实际意义。实际解读时，尤其是向非专业人士汇报结果时，建议尽量补充相对风险（RR）的估算和解释。\n\n\n\n\n\n\n\n\n实际应用建议\n\n\n\n\n建模时：Logistic 回归只能直接输出优势比（OR），因为其数学结构决定了只能建模 log-odds。\n解读和报告时：如果事件发生率不高，可以用 OR 近似 RR；如果事件发生率较高，建议用其他方法（如风险回归模型、G-computation、marginal effect 等）估算和报告相对风险（RR），以便更贴近实际意义。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>第十一周：预测分类结果：Logistic 回归（一）</span>"
    ]
  },
  {
    "objectID": "week11_lecture.html#logistic-回归模型形式",
    "href": "week11_lecture.html#logistic-回归模型形式",
    "title": "第十一周：预测分类结果：Logistic 回归（一）",
    "section": "3. Logistic 回归模型形式",
    "text": "3. Logistic 回归模型形式\n核心模型是： \\[ \\log\\left(\\frac{P(Y=1|X)}{1-P(Y=1|X)}\\right) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_k X_k \\]\n或者等价地写成概率形式： \\[ P(Y=1|X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 X_1 + ... + \\beta_k X_k)}} \\]\n\n模型参数 \\(\\beta_0, \\beta_1, ..., \\beta_k\\) 通常使用最大似然估计 (Maximum Likelihood Estimation, MLE) 来获得，而不是 OLS。\n\n\n\n\n\n\n\n什么是最大似然估计 (Maximum Likelihood Estimation, MLE)？\n\n\n\n最大似然估计是一种常用的参数估计方法，其核心思想是：在已知观测数据的前提下，选择一组参数，使得在这些参数下，观测到的数据出现的“可能性”（即似然）最大。\n\n直观理解：假如你知道数据是某种分布（比如二项分布、正态分布等）生成的，但不知道具体参数（如均值、方差等），最大似然估计就是找到一组参数，使得“在这些参数下，实际观测到的数据最有可能出现”。\n数学表达：设观测数据为 \\(y_1, y_2, ..., y_n\\)，参数为 \\(\\theta\\)，则似然函数为 \\(L(\\theta) = P(\\text{数据}|\\theta)\\)。最大似然估计就是求使 \\(L(\\theta)\\) 最大的 \\(\\theta\\)。\n\n\n\n\n\n\n\n\n\nLogistic 回归中最大似然估计的计算方法\n\n\n\n在 Logistic 回归中，我们假设因变量 \\(Y_i\\) 服从伯努利分布（0/1），其概率由自变量 \\(X\\) 通过 logit 链接函数建模：\n\\[\nP(Y_i = 1|X_i) = p_i = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 X_{i1} + ... + \\beta_k X_{ik})}}\n\\]\n\n似然函数：所有观测的联合概率为 \\[\nL(\\beta) = \\prod_{i=1}^n p_i^{y_i} (1-p_i)^{1-y_i}\n\\]\n对数似然函数（便于计算）： \\[\n\\ell(\\beta) = \\sum_{i=1}^n \\left[ y_i \\log(p_i) + (1-y_i)\\log(1-p_i) \\right]\n\\]\n最大似然估计过程：\n\n写出对数似然函数 \\(\\ell(\\beta)\\)。\n对参数 \\(\\beta\\) 求偏导，令导数为 0，解方程组（通常无解析解）。\n用数值优化算法（如牛顿-拉夫森法）迭代求解最优参数 \\(\\hat{\\beta}\\)。\n\nR 中实现：glm() 函数自动完成最大似然估计，无需手动推导和优化。\n\n总结：Logistic 回归的系数估计本质上就是通过最大似然法，找到一组参数，使得在这些参数下，观测到的 0/1 结果最有可能出现。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>第十一周：预测分类结果：Logistic 回归（一）</span>"
    ]
  },
  {
    "objectID": "week11_lecture.html#系数解释优势比-odds-ratio-or---核心",
    "href": "week11_lecture.html#系数解释优势比-odds-ratio-or---核心",
    "title": "第十一周：预测分类结果：Logistic 回归（一）",
    "section": "4. 系数解释：优势比 (Odds Ratio, OR) - 核心！",
    "text": "4. 系数解释：优势比 (Odds Ratio, OR) - 核心！\n直接解释 Logistic 回归的系数 \\(\\beta_j\\) 比较困难，因为它表示自变量 \\(X_j\\) 每增加一个单位，对数优势 (Log-odds) 的变化量。为了更直观地理解，我们通常解释优势比 (Odds Ratio, OR)。\n\n优势比 (OR): 指自变量 \\(X_j\\) 增加一个单位时，事件发生的优势 (Odds) 变为原来的多少倍。 \\[ OR_j = \\frac{Odds(X_j+1)}{Odds(X_j)} = \\frac{e^{\\beta_0 + \\beta_1 X_1 + ... + \\beta_j(X_j+1) + ...}}{e^{\\beta_0 + \\beta_1 X_1 + ... + \\beta_j X_j + ...}} = e^{\\beta_j} \\]\n\n计算: \\(OR_j = \\exp(\\beta_j)\\)。\n\n解读 OR:\n\n\\(OR_j &gt; 1\\) (\\(\\beta_j &gt; 0\\)): \\(X_j\\) 增加一个单位，事件发生的优势增加 (变为原来的 \\(OR_j\\) 倍)。\\(X_j\\) 是风险因素/促进因素。\n\\(OR_j &lt; 1\\) (\\(\\beta_j &lt; 0\\)): \\(X_j\\) 增加一个单位，事件发生的优势减少 (变为原来的 \\(OR_j\\) 倍)。\\(X_j\\) 是保护因素。\n\\(OR_j = 1\\) (\\(\\beta_j = 0\\)): \\(X_j\\) 变化对事件发生的优势没有影响。\n\n示例解释:\n\n假设研究吸烟 (X=1 表示吸烟, X=0 表示不吸烟) 对患肺癌 (Y=1) 的影响，得到 \\(\\hat{\\beta}_{smoke} = 1.609\\)。\n计算 \\(OR_{smoke} = \\exp(1.609) \\approx 5.0\\)。\n解释: 吸烟者的患肺癌优势是不吸烟者的5 倍 (在控制其他变量后)。\n假设研究年龄 (X，连续变量) 对购买某产品 (Y=1) 的影响，得到 \\(\\hat{\\beta}_{age} = -0.05\\)。\n计算 \\(OR_{age} = \\exp(-0.05) \\approx 0.95\\)。\n解释: 年龄每增加 1 岁，购买该产品的优势变为原来的0.95 倍 (即降低了约 5%) (在控制其他变量后)。\n\n分类自变量的 OR: 如果 \\(X_j\\) 是一个分类变量（如用虚拟编码表示），\\(e^{\\beta_j}\\) 表示该类别相对于参照类别的优势比。\n\n\n\n\n\n\n\nOR vs RR\n\n\n\n优势比 (OR) 不等于 相对风险 (Relative Risk, RR = \\(P(Y=1|X_j+1) / P(Y=1|X_j)\\))。只有当事件发生率很低时，OR 才近似等于 RR。解释时要用“优势”而非“风险”或“概率”。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>第十一周：预测分类结果：Logistic 回归（一）</span>"
    ]
  },
  {
    "objectID": "week11_lecture.html#r-实现-glm-generalized-linear-model",
    "href": "week11_lecture.html#r-实现-glm-generalized-linear-model",
    "title": "第十一周：预测分类结果：Logistic 回归（一）",
    "section": "5. R 实现: glm() (Generalized Linear Model)",
    "text": "5. R 实现: glm() (Generalized Linear Model)\n使用 glm() 函数拟合 Logistic 回归模型。\n\n关键参数:\n\nformula: 与 lm() 类似，Y ~ X1 + X2 + ...。Y 应该是 0/1 编码或因子（R 会自动处理第一个水平为 0，第二个为 1）。\nfamily: 指定模型的分布族和连接函数。对于 Logistic 回归，使用 family = binomial(link = \"logit\") 或简写 family = binomial。\ndata: 数据框。\n\n示例： 使用 ISLR 包中的 Default 数据集，预测客户是否违约（default），基于信用卡余额（balance）和是否为学生（student）。\n\nlibrary(tidyverse)\nlibrary(ISLR)\nlibrary(broom)\n\n# 1. 数据准备：确保 default 是因子，student 也是因子\ndata(\"Default\")\nglimpse(Default)\n\n#&gt; Rows: 10,000\n#&gt; Columns: 4\n#&gt; $ default &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, No, No, No, No, No…\n#&gt; $ student &lt;fct&gt; No, Yes, No, No, No, Yes, No, Yes, No, No, Yes, Yes, No, No, N…\n#&gt; $ balance &lt;dbl&gt; 729.5265, 817.1804, 1073.5492, 529.2506, 785.6559, 919.5885, 8…\n#&gt; $ income  &lt;dbl&gt; 44361.625, 12106.135, 31767.139, 35704.494, 38463.496, 7491.55…\n\n# 默认 default 已为因子，student 也是因子\n\n# 2. 拟合 Logistic 回归模型\nlogistic_model &lt;- glm(default ~ balance + student, data = Default, family = binomial)\n\n# 3. 查看模型摘要（系数、标准误、z值、P值等）\ntidy_logistic &lt;- tidy(logistic_model)\nprint(tidy_logistic)\n\n#&gt; # A tibble: 3 × 5\n#&gt;   term         estimate std.error statistic   p.value\n#&gt;   &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 (Intercept) -10.7      0.369       -29.1  2.23e-186\n#&gt; 2 balance       0.00574  0.000232     24.7  3.14e-135\n#&gt; 3 studentYes   -0.715    0.148        -4.85 1.26e-  6\n\n# 4. 计算系数的优势比（OR）及其置信区间\n# 4.1 计算 OR\nor_table &lt;- tidy_logistic %&gt;%\n  mutate(OR = exp(estimate))\nprint(or_table)\n\n#&gt; # A tibble: 3 × 6\n#&gt;   term         estimate std.error statistic   p.value        OR\n#&gt;   &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 (Intercept) -10.7      0.369       -29.1  2.23e-186 0.0000215\n#&gt; 2 balance       0.00574  0.000232     24.7  3.14e-135 1.01     \n#&gt; 3 studentYes   -0.715    0.148        -4.85 1.26e-  6 0.489\n\n# 4.2 计算置信区间（对数优势尺度）\nconfint_logistic &lt;- confint(logistic_model)\nprint(confint_logistic)\n\n#&gt;                     2.5 %        97.5 %\n#&gt; (Intercept) -11.498144891 -10.049841998\n#&gt; balance       0.005296591   0.006206095\n#&gt; studentYes   -1.007777857  -0.429075610\n\n# 4.3 计算 OR 的置信区间\nor_ci &lt;- exp(confint_logistic)\nprint(or_ci)\n\n#&gt;                    2.5 %       97.5 %\n#&gt; (Intercept) 0.0000101489 4.319257e-05\n#&gt; balance     1.0053106429 1.006225e+00\n#&gt; studentYes  0.3650292262 6.511107e-01\n\n\n结果解读：\n\n系数表（tidy_logistic） 包含每个变量的估计值（Estimate）、标准误（Std. Error）、z值（z value）和P值（Pr(&gt;|z|)）。\n优势比（OR） 通过 exp(estimate) 计算，表示自变量每增加一个单位，违约的优势变化倍数。\n置信区间 通过 confint() 计算，exp(confint()) 得到 OR 的置信区间。\n如何解读：\n\n查看 or_table 和 or_ci 的输出，结合 P 值判断变量是否显著影响违约概率。\n例如，若 balance 的 OR &gt; 1 且 P 值显著，说明余额每增加 1 单位，违约的优势增加；若 student 的 OR &lt; 1，说明学生身份对违约的优势有保护作用（或相反，视结果而定）。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>第十一周：预测分类结果：Logistic 回归（一）</span>"
    ]
  },
  {
    "objectID": "week11_lecture.html#综合实践项目启动",
    "href": "week11_lecture.html#综合实践项目启动",
    "title": "第十一周：预测分类结果：Logistic 回归（一）",
    "section": "6. 综合实践项目启动",
    "text": "6. 综合实践项目启动\n本周，我们将正式启动课程的 综合实践项目！\n\n目标: 应用本课程（主要是第一阶段，后续会补充第二阶段知识）所学的数据处理、可视化和统计推断/建模技能，选择一个你感兴趣的数据集和研究问题，完成一次相对完整的数据分析过程，并撰写报告或进行展示。\n选题方向:\n\n可以使用课程提供的示例数据集。\n可以寻找公开数据集（如 Kaggle, UCI Machine Learning Repository, 政府公开数据平台等）。\n可以使用与你专业领域相关的数据（需确保可获取性）。\n关键： 选题范围要适中，问题要明确，数据应较为规整，或能够通过 tidyverse 工具进行清理。\n\n时间节点 (暂定，以老师最终通知为准):\n\n第 11-12 周: 确定选题、研究问题、获取数据、初步数据探索 (EDA)。\n第 13-14 周: 数据清理、模型构建（选择合适的统计方法）、模型诊断与改进。\n第 15 周: 结果解释、报告撰写、展示准备、预演与反馈。\n第 16 周: 最终项目展示与答辩 / 报告提交。\n\n评分标准 (大致方向):\n\n问题定义的清晰性与合理性。\n数据处理与准备的恰当性。\n探索性数据分析 (可视化) 的有效性。\n统计方法选择与应用的正确性。\n模型诊断与评估的完整性 (如适用)。\n结果解释的准确性与深入性。\n报告/展示的清晰度与专业性。\n\n\n本周任务: 开始思考你的综合实践项目选题！寻找可能的数据集，明确你想要通过数据分析回答什么问题。下周我们将讨论选题并进行初步的数据探索。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>第十一周：预测分类结果：Logistic 回归（一）</span>"
    ]
  },
  {
    "objectID": "week11_lecture.html#本周总结与预告",
    "href": "week11_lecture.html#本周总结与预告",
    "title": "第十一周：预测分类结果：Logistic 回归（一）",
    "section": "7. 本周总结与预告",
    "text": "7. 本周总结与预告\n本周我们开启了分类预测的大门，学习了 Logistic 回归的基本原理，包括 Sigmoid 函数、Logit 变换以及最重要的优势比 (Odds Ratio) 解释。我们还掌握了使用 glm() 函数在 R 中拟合模型的方法。同时，综合实践项目正式启动，请大家积极思考选题。\n下周预告: 拟合了 Logistic 回归模型，如何评估它的表现？下周我们将学习 Logistic 回归的评估指标，如混淆矩阵、准确率、精确率、召回率、F1 分数以及 ROC 曲线和 AUC 值，并探讨如何在不同模型间进行比较。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>第十一周：预测分类结果：Logistic 回归（一）</span>"
    ]
  },
  {
    "objectID": "week12_lecture.html",
    "href": "week12_lecture.html",
    "title": "第十二周：Logistic 回归评估 与 模型比较初步",
    "section": "",
    "text": "1. 模型好坏：如何评估分类模型？\n上周我们学习了如何拟合 Logistic 回归模型来预测分类结果的概率。本周我们将以 ISLR 包中的 Default 数据集为例，演示如何评估分类模型的预测性能 (Predictive Performance)，即模型在区分不同类别方面的表现如何。与线性回归使用 \\(R^2\\) 或 RMSE 不同，分类模型有其独特的评估指标。\n我们将以 ISLR 包中的 Default 数据集为例，拟合 default ~ balance + student 的 Logistic 回归模型。\nlibrary(tidyverse)\nlibrary(ISLR)\nlibrary(broom)\nlibrary(pROC) # 用于 ROC 曲线和 AUC 计算\n# install.packages(\"pROC\") # 如果尚未安装\nlibrary(yardstick) # tidyverse 风格的模型评估包 (可选)\n# install.packages(\"yardstick\") # 如果尚未安装\n\n# 加载 Default 数据集\ndata(Default)\nDefault &lt;- ISLR::Default %&gt;%\n  mutate(\n    default = factor(default, levels = c(\"No\", \"Yes\")),\n    student = factor(student)\n  )\n\n# 拟合 Logistic 回归模型\ndefault_model &lt;- glm(default ~ balance + student, data = Default, family = binomial)\n# summary(default_model)\n\n# 获取模型预测的概率 (预测为 \"Yes\" 的概率)\neval_data &lt;-augment(default_model, type.predict = \"response\") %&gt;%\n  mutate(predict_class = as.factor(ifelse(.fitted &gt; 0.5, \"Yes\", \"No\")))\n\n# glimpse(eval_data)",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>第十二周：Logistic 回归评估 与 模型比较初步</span>"
    ]
  },
  {
    "objectID": "week12_lecture.html#模型好坏如何评估分类模型",
    "href": "week12_lecture.html#模型好坏如何评估分类模型",
    "title": "第十二周：Logistic 回归评估 与 模型比较初步",
    "section": "",
    "text": "本周目标\n\n\n\n\n理解并能够计算混淆矩阵 (Confusion Matrix)。\n掌握常用的分类模型评估指标：准确率 (Accuracy)、精确率 (Precision)、召回率 (Recall / Sensitivity)、F1 分数 (F1-Score)、特异度 (Specificity)，并理解它们之间的权衡。\n理解 ROC 曲线 (Receiver Operating Characteristic Curve) 和 AUC 值 (Area Under the Curve) 的含义和作用。\n能够使用 R 实现上述评估指标和 ROC/AUC 的计算与可视化。\n了解使用 AIC/BIC 等信息准则比较广义线性模型 (GLM) 的思路。\n继续推进综合实践项目：选题讨论与初步数据探索。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>第十二周：Logistic 回归评估 与 模型比较初步</span>"
    ]
  },
  {
    "objectID": "week12_lecture.html#混淆矩阵-confusion-matrix",
    "href": "week12_lecture.html#混淆矩阵-confusion-matrix",
    "title": "第十二周：Logistic 回归评估 与 模型比较初步",
    "section": "2. 混淆矩阵 (Confusion Matrix)",
    "text": "2. 混淆矩阵 (Confusion Matrix)\n混淆矩阵是评估分类模型性能的基础。它是一个表格，总结了模型预测类别与实际类别之间的匹配情况。对于二元分类，它通常是一个 2x2 的矩阵。\n\n结构:\n\n\n\n\n\n\n\n\n\n预测为 Positive (1)\n预测为 Negative (0)\n\n\n\n\n实际为 Positive (1)\nTP (True Positive)\nFN (False Negative)\n\n\n实际为 Negative (0)\nFP (False Positive)\nTN (True Negative)\n\n\n\n\nTP (真正例): 实际为 Positive，预测也为 Positive (预测正确)。\nFN (假反例): 实际为 Positive，但预测为 Negative (预测错误，漏报，Type II Error)。\nFP (假正例): 实际为 Negative，但预测为 Positive (预测错误，误报，Type I Error)。\nTN (真反例): 实际为 Negative，预测也为 Negative (预测正确)。\n\nR 实现:\n\n# 方法1: 使用基础 table() 函数\n# 注意：第一个参数是实际值，第二个参数是预测值\nconfusion_matrix_base &lt;- table(Predicted = eval_data$predict_class, Observed = eval_data$default)\n\nprint(confusion_matrix_base)\n\n#&gt;          Observed\n#&gt; Predicted   No  Yes\n#&gt;       No  9628  228\n#&gt;       Yes   39  105\n\n# 方法2: 使用 yardstick 包 (更推荐，输出更规范)\nconf_mat_tbl &lt;- eval_data %&gt;%\n  conf_mat(truth = default, estimate = predict_class) # truth=真实值, estimate=预测值\n\nprint(conf_mat_tbl)\n\n#&gt;           Truth\n#&gt; Prediction   No  Yes\n#&gt;        No  9628  228\n#&gt;        Yes   39  105",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>第十二周：Logistic 回归评估 与 模型比较初步</span>"
    ]
  },
  {
    "objectID": "week12_lecture.html#基于混淆矩阵的评估指标",
    "href": "week12_lecture.html#基于混淆矩阵的评估指标",
    "title": "第十二周：Logistic 回归评估 与 模型比较初步",
    "section": "3. 基于混淆矩阵的评估指标",
    "text": "3. 基于混淆矩阵的评估指标\n从混淆矩阵可以衍生出多个评估指标，从不同角度衡量模型性能。\n\n准确率 (Accuracy):\n\n定义: 模型预测正确的样本占总样本的比例。\n公式: \\(Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}\\)\n解读: 最直观的指标，但在类别不平衡 (Imbalanced Classes) 的数据集中具有误导性。例如，如果 99% 的样本是 Negative，一个将所有样本都预测为 Negative 的模型也能达到 99% 的准确率，但这显然不是一个好模型。\nR 实现:\n\n# 手动计算\naccuracy_manual &lt;- (9628 + 105) / (9628 + 105 + 228 + 39)\nprint(accuracy_manual)\n\n#&gt; [1] 0.9733\n\n# 使用 yardstick\neval_data %&gt;% accuracy(truth = default, estimate = predict_class)\n\n#&gt; # A tibble: 1 × 3\n#&gt;   .metric  .estimator .estimate\n#&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 accuracy binary         0.973\n\n\n\n精确率 (Precision): (也叫查准率)\n\n定义: 在所有预测为 Positive 的样本中，实际也为 Positive 的比例。\n公式: \\(Precision = \\frac{TP}{TP + FP}\\)\n解读: 衡量模型预测 Positive 的准确性。高精确率表示模型预测为 Positive 的结果中，很少有误报 (FP)。关注”预测出来的 Positive 有多准？“。\n应用: 当误报 (FP) 的代价很高时很重要（例如，垃圾邮件检测，宁可漏掉一些垃圾邮件，也不想把正常邮件误判为垃圾邮件）。\nR 实现:\n\n# 手动计算 (预测为 Manual 的精确率)\nprecision_manual &lt;- 105 / (105 + 39)\nprint(precision_manual)\n\n#&gt; [1] 0.7291667\n\n# 使用 yardstick (需要指定 positive 类)\neval_data %&gt;% \n    precision(\n        truth = default,\n        estimate = predict_class,\n        event_level = \"second\" # \"second\" 表示第二个因子水平 \"Yes\" 是 positive 类\n        )\n\n#&gt; # A tibble: 1 × 3\n#&gt;   .metric   .estimator .estimate\n#&gt;   &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 precision binary         0.729\n\n\n\n召回率 (Recall / Sensitivity / True Positive Rate, TPR): (也叫查全率、敏感度)\n\n定义: 在所有实际为 Positive 的样本中，被模型成功预测为 Positive 的比例。\n公式: \\(Recall = Sensitivity = TPR = \\frac{TP}{TP + FN}\\)\n解读: 衡量模型找出所有 Positive 样本的能力。高召回率表示模型很少漏报 (FN)。关注”所有 Positive 的样本，找出来了多少？“。\n应用: 当漏报 (FN) 的代价很高时很重要（例如，疾病诊断，宁可误诊一些健康人，也不想漏掉真正的病人）。\nR 实现:\n\n# 手动计算 (Manual 类的召回率)\nrecall_manual &lt;- 105 / (105 + 228)\nprint(recall_manual)\n\n#&gt; [1] 0.3153153\n\n# 使用 yardstick\neval_data %&gt;% \n    recall(\n        truth = default,\n        estimate = predict_class,\n        event_level = \"second\" # \"second\" 表示第二个因子水平 \"Yes\" 是 positive 类\n        )\n\n#&gt; # A tibble: 1 × 3\n#&gt;   .metric .estimator .estimate\n#&gt;   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 recall  binary         0.315\n\n# 或者使用 sensitivity()\neval_data %&gt;% \n    sensitivity(\n        truth = default,\n        estimate = predict_class,\n        event_level = \"second\" # \"second\" 表示第二个因子水平 \"Yes\" 是 positive 类\n        )\n\n#&gt; # A tibble: 1 × 3\n#&gt;   .metric     .estimator .estimate\n#&gt;   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 sensitivity binary         0.315\n\n\n\nF1 分数 (F1-Score):\n\n定义: 精确率 (Precision) 和召回率 (Recall) 的调和平均数 (Harmonic Mean)。\n公式: \\(F1 = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall} = \\frac{2TP}{2TP + FP + FN}\\)\n解读: 综合考虑了精确率和召回率，当两者都较高时，F1 分数也较高。是评估模型综合性能的常用指标，尤其在类别不平衡时比准确率更可靠。\nR 实现:\n\n# 手动计算\nf1_manual &lt;- 2 * (precision_manual * recall_manual) / (precision_manual + recall_manual)\nprint(f1_manual)\n\n#&gt; [1] 0.4402516\n\n# 使用 yardstick\neval_data %&gt;% \n    f_meas(\n        truth = default,\n        estimate = predict_class,\n        event_level = \"second\" # \"second\" 表示第二个因子水平 \"Yes\" 是 positive 类\n        ) # f_meas 计算 F-beta score, 默认 beta=1 即 F1\n\n#&gt; # A tibble: 1 × 3\n#&gt;   .metric .estimator .estimate\n#&gt;   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 f_meas  binary         0.440\n\n\n\n特异度 (Specificity / True Negative Rate, TNR):\n\n定义: 在所有实际为 Negative 的样本中，被模型成功预测为 Negative 的比例。\n公式: \\(Specificity = TNR = \\frac{TN}{TN + FP}\\)\n解读: 衡量模型正确识别 Negative 样本的能力。与召回率 (Sensitivity) 对应。\n应用: 在疾病诊断中，表示正确识别健康人的能力。\nR 实现:\n\n# 手动计算\nspecificity_manual &lt;- 9628 / (9628 + 39)\nprint(specificity_manual)\n\n#&gt; [1] 0.9959657\n\n# 使用 yardstick\neval_data %&gt;% \n    specificity(\n        truth = default,\n        estimate = predict_class,\n        event_level = \"second\" # \"second\" 表示第二个因子水平 \"Yes\" 是 positive 类\n        )\n\n#&gt; # A tibble: 1 × 3\n#&gt;   .metric     .estimator .estimate\n#&gt;   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 specificity binary         0.996\n\n\n\n\n\n\n\n\n\n\n指标权衡 (Trade-off)\n\n\n\n\n精确率 vs 召回率: 通常存在权衡。提高精确率（减少 FP）可能会降低召回率（增加 FN），反之亦然。选择哪个更重要取决于具体应用场景和两类错误的代价。\n阈值选择: 改变分类阈值（默认 0.5）会影响预测类别，从而改变混淆矩阵和所有这些指标。ROC 曲线可以帮助我们理解不同阈值下的性能。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>第十二周：Logistic 回归评估 与 模型比较初步</span>"
    ]
  },
  {
    "objectID": "week12_lecture.html#roc-曲线-与-auc-值",
    "href": "week12_lecture.html#roc-曲线-与-auc-值",
    "title": "第十二周：Logistic 回归评估 与 模型比较初步",
    "section": "4. ROC 曲线 与 AUC 值",
    "text": "4. ROC 曲线 与 AUC 值\n\nROC 曲线 (Receiver Operating Characteristic Curve):\n\n一种可视化分类模型在所有可能阈值下性能表现的图形。\n横轴: 假正例率 (False Positive Rate, FPR) = \\(1 - Specificity = \\frac{FP}{FP + TN}\\)。\n纵轴: 真正例率 (True Positive Rate, TPR) = \\(Recall = Sensitivity = \\frac{TP}{TP + FN}\\)。\n绘制方法: 连续改变分类阈值，计算每个阈值下的 TPR 和 FPR，描点连接。\n解读: 曲线越靠近左上角 (TPR 高，FPR 低)，模型性能越好。对角线代表随机猜测。\n\nAUC 值 (Area Under the ROC Curve):\n\nROC 曲线下的面积，取值 0 到 1。\n解读: AUC 越大，模型区分 Positive 和 Negative 样本的整体能力越强。不依赖特定阈值。AUC=0.5 表示随机猜测。\n直观含义: 从 Positive 和 Negative 样本中各随机抽取一个，AUC 值等于模型将 Positive 样本预测概率排在 Negative 样本预测概率之前的概率。\n\nR 实现 (使用 yardstick 包):\n\n# 计算 AUC 值\nauc_value &lt;- eval_data %&gt;%\n  yardstick::roc_auc(\n    truth = default,\n    .fitted, # 预测为 \"Yes\" 的概率列\n    event_level = \"second\"\n  )\nprint(auc_value)\n\n#&gt; # A tibble: 1 × 3\n#&gt;   .metric .estimator .estimate\n#&gt;   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 roc_auc binary         0.950\n\n# 计算 ROC 曲线数据\nroc_curve_data &lt;- eval_data %&gt;%\n  yardstick::roc_curve(\n    truth = default,\n    .fitted, # 预测为 \"Yes\" 的概率列\n    event_level = \"second\"\n  )\n\n# 绘制 ROC 曲线\nggplot(roc_curve_data, aes(x = 1 - specificity, y = sensitivity)) +\n  geom_line(color = \"blue\", size = 1) +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"grey\") +\n  labs(\n    title = paste0(\"ROC Curve (AUC = \", round(auc_value$.estimate, 3), \")\"),\n    x = \"False Positive Rate (1 - Specificity)\",\n    y = \"True Positive Rate (Sensitivity)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n# 找到最佳阈值（例如，Youden's J 最大化）\nbest_threshold &lt;- roc_curve_data %&gt;%\n  mutate(youden_j = sensitivity + specificity - 1) %&gt;%\n  filter(youden_j == max(youden_j)) %&gt;%\n  select(.threshold, sensitivity, specificity, youden_j)\nprint(best_threshold)\n\n#&gt; # A tibble: 1 × 4\n#&gt;   .threshold sensitivity specificity youden_j\n#&gt;        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1     0.0317       0.904       0.863    0.767\n\n\n\n\n\n\n\n\n\n什么是 Youden’s J 最大化？\n\n\n\nYouden’s J 指数（又称 Youden’s J statistic）是评估二分类模型性能的一个指标，定义为：\n\\[\nJ = \\text{Sensitivity} + \\text{Specificity} - 1\n\\]\n其中，Sensitivity（灵敏度/召回率）和 Specificity（特异度）分别衡量模型对正例和负例的识别能力。J 值越大，模型在该阈值下的整体区分能力越强。\nYouden’s J 最大化方法有明确的理论依据。Youden’s J 指数最早由 W.J. Youden 在 1950 年的论文 “Index for rating diagnostic tests”（Biometrics, 1950, 6(3): 195-198）中提出。该指数衡量了诊断测试在不同阈值下对正例（灵敏度）和负例（特异度）识别能力的综合表现。最大化 J 值等价于在灵敏度和特异度之间取得最优平衡点，从而使模型整体区分能力最强。因此，选择使 J 值最大的阈值，理论上可以获得最佳的分类效果，尤其适用于正负样本重要性相当的场景。参考文献：Youden, W. J. (1950). Index for rating diagnostic tests. Biometrics, 6(3), 195-198.\n在 ROC 曲线分析中，常用 Youden’s J 最大化来确定最佳分类阈值，从而提升模型的实际应用效果。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>第十二周：Logistic 回归评估 与 模型比较初步</span>"
    ]
  },
  {
    "objectID": "week12_lecture.html#模型比较初步aic-与-bic",
    "href": "week12_lecture.html#模型比较初步aic-与-bic",
    "title": "第十二周：Logistic 回归评估 与 模型比较初步",
    "section": "5. 模型比较初步：AIC 与 BIC",
    "text": "5. 模型比较初步：AIC 与 BIC\n当我们有多个候选的 Logistic 回归模型时，如何比较它们？\n\n信息准则 (Information Criteria): AIC 和 BIC 同样适用于广义线性模型 (GLM)。\n\n权衡模型的拟合优度和模型复杂度。\n目标: 选择 AIC 或 BIC 最小的模型。\n只能用于比较使用相同因变量和相同数据集拟合的模型。\n\nR 实现:\n\n# 假设我们有另一个模型，只用 student 预测 default\ndefault_model_student_only &lt;- glm(default ~ student, data = Default, family = binomial)\n\n# 比较两个模型的 AIC 和 BIC\nAIC(default_model, default_model_student_only)\n\n#&gt;                            df      AIC\n#&gt; default_model               3 1577.682\n#&gt; default_model_student_only  2 2912.683\n\nBIC(default_model, default_model_student_only)\n\n#&gt;                            df      BIC\n#&gt; default_model               3 1599.313\n#&gt; default_model_student_only  2 2927.104\n\n# 结果显示 default_model (包含 student 和 balance) 的 AIC 和 BIC 都更小，\n# 表明在拟合优度和复杂度之间权衡后，它是相对更优的模型。\n\n其他比较方法:\n\n似然比检验 (LRT): 比较嵌套模型。anova(model1, model2, test=\"LRT\")。\n交叉验证 (Cross-Validation): (更高级) 在测试集上评估模型性能，更可靠。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>第十二周：Logistic 回归评估 与 模型比较初步</span>"
    ]
  },
  {
    "objectID": "week12_lecture.html#综合实践项目进展",
    "href": "week12_lecture.html#综合实践项目进展",
    "title": "第十二周：Logistic 回归评估 与 模型比较初步",
    "section": "6. 综合实践项目进展",
    "text": "6. 综合实践项目进展\n\n本周任务:\n\n确定选题和研究问题: 与老师或助教讨论你的初步想法，确保可行性。\n获取并初步检查数据: 使用 readr 导入数据，使用 glimpse(), summary(), skimr::skim() 等函数了解数据结构、变量类型、缺失值等。\n进行初步的 EDA: 使用 ggplot2 绘制关键变量的分布图（直方图、箱线图、条形图）和变量关系图（散点图、分组箱线图）。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>第十二周：Logistic 回归评估 与 模型比较初步</span>"
    ]
  },
  {
    "objectID": "week12_lecture.html#本周总结与预告",
    "href": "week12_lecture.html#本周总结与预告",
    "title": "第十二周：Logistic 回归评估 与 模型比较初步",
    "section": "7. 本周总结与预告",
    "text": "7. 本周总结与预告\n本周我们重点学习了如何评估分类模型（特别是 Logistic 回归）的性能。我们掌握了混淆矩阵及其衍生指标（准确率、精确率、召回率、F1、特异度），理解了它们的应用场景和权衡。我们还学习了 ROC 曲线和 AUC 值作为不依赖阈值的整体性能评估工具。最后，我们了解了使用 AIC/BIC 比较 GLM 的思路。\n下周预告: 我们将进一步探讨 AI 工具在数据分析中的应用，学习如何更有效地利用 AI 进行编程、调试、解释和报告写作，并强调批判性思维和验证的重要性。同时，我们将学习可重复报告的基础知识（R Markdown / Quarto），让我们的分析过程和结果更规范、更易于分享。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>第十二周：Logistic 回归评估 与 模型比较初步</span>"
    ]
  },
  {
    "objectID": "综合实践项目启动指南_五一假期.html",
    "href": "综合实践项目启动指南_五一假期.html",
    "title": "综合实践项目启动详细指南 (五一假期任务)",
    "section": "",
    "text": "大家好！\n综合实践项目是我们应用所学知识、深入探索数据分析过程的重要机会。这个”五一”假期是启动项目、奠定坚实基础的绝佳时机。本指南将详细分解假期内需要完成的核心任务，确保你能有效地开始你的数据分析之旅。\n假期核心目标： 完成项目选题、数据准备和初步探索性数据分析 (EDA)。\n\n\n任务一：最终确定选题与研究问题\n这是项目的起点和方向，至关重要。一个清晰、具体的问题将指导你后续所有的数据分析工作。\n\n从兴趣出发，聚焦具体问题：\n\n回顾你初步构思的 1-2 个主题。哪个最让你感兴趣？哪个的数据看起来更容易获取和处理？\n将宽泛的主题转化为一个或两个可以明确回答的问题。避免过于宏大或模糊不清的问题。\n检查问题是否”SMART”：\n\nSpecific (具体的): 问题明确指向特定的现象或关系吗？\nMeasurable (可衡量的): 你能用数据来量化和衡量问题中的关键概念吗？\nAchievable (可实现的): 你拥有的数据和当前掌握的技能足以回答这个问题吗？\nRelevant (相关的): 这个问题与你的兴趣、专业或课程内容相关吗？\nTime-bound (有时限的): (在项目整体框架下) 这个问题能在课程时间内完成分析吗？\n\n\n问题示例 (更通用):\n\n好问题 (具体、可衡量):\n\n描述性/比较性: “不同产品类别 (category) 的平均销售额 (sales) 是否存在差异？哪个类别平均销售额最高？” (适用于 EDA 的分组箱线图或后续的 ANOVA)\n描述性/比较性: “来自不同地区 (region) 的用户在网站停留时间 (session_duration) 上有何不同？” (适用于 EDA 的分组箱线图)\n关系探索: “广告支出 (ad_spend) 与网站访问量 (visits) 之间是否存在关联？它们的关系是怎样的？” (适用于 EDA 的散点图或后续的相关/简单回归分析)\n关系探索: “顾客年龄 (age) 与其购买金额 (purchase_amount) 之间有关系吗？” (适用于 EDA 的散点图)\n分类导向: “哪些用户特征（如 age, region, past_purchases）可以帮助区分高价值客户和普通客户？” (引向分类问题)\n\n待改进的问题 (过于宽泛):\n\n“分析销售数据。” (分析什么？目标是什么？)\n“研究用户行为。” (研究哪些行为？与什么相关？)\n\n\n最终确认： 写下你最终确定的 1-2 个核心研究问题。确保你理解这些问题，并相信你的数据能够帮助回答它们。\n\n\n\n\n任务二：确保数据到位：获取、导入与整理\n数据是分析的基础。你需要确保你的”原材料”已经准备就绪。\n\n获取数据：\n\n根据你的选题，下载所需的数据集。\n来源可能包括：老师提供的文件、Kaggle、UCI 机器学习库、天池、国家/地方政府数据开放平台、特定研究机构网站等。\n建议： 将下载的原始数据文件保存在你电脑上一个清晰、易于查找的位置。\n\n创建项目结构 (推荐)：\n\n在你的电脑上为这个项目创建一个总文件夹。\n在总文件夹内，建议创建子文件夹，例如：\n\ndata/: 存放原始数据文件和清理后的数据文件。\nscripts/ 或 code/: 存放你的 R 脚本文件 (.R 或 .qmd)。\nplots/: (可选) 存放生成的图表文件。\nreports/: (可选) 存放最终的报告文件。\n\n这样做有助于保持项目文件的整洁和有序。\n\n导入数据到 R 环境：\n\n启动 RStudio，建议创建一个新的 R 项目 (File -&gt; New Project…) 并将其设置在你创建的总文件夹中。这样可以更好地管理工作目录。\n使用 readr 包 (属于 tidyverse) 中的函数导入数据。最常用的是：\n\nread_csv(\"path/to/your/data.csv\"): 读取逗号分隔值文件 (.csv)。这是最常见的数据格式。\nread_tsv(\"path/to/your/data.tsv\"): 读取制表符分隔值文件 (.tsv)。\n(如果需要读取 Excel 文件，可能需要 readxl 包)：readxl::read_excel(\"path/to/your/data.xlsx\")。\n\n路径: \"path/to/your/data.csv\" 应替换为你数据文件的实际路径。如果 R 项目设置正确，且数据在 data/ 子文件夹下，路径通常是 \"data/your_data.csv\"。\n将读取的数据赋值给一个变量 (数据框)，例如：my_data &lt;- read_csv(\"data/your_data.csv\")。\n\n检查导入是否成功：\n\nhead(my_data): 查看数据框的前几行。\ntail(my_data): 查看数据框的后几行。\ndim(my_data): 查看数据框的维度 (行数和列数)。\ncolnames(my_data): 查看所有列名。\n确保数据看起来符合预期，没有明显的读取错误。\n\n\n\n\n\n任务三：完成初步探索性数据分析 (EDA)\nEDA 的目的是深入了解你的数据，发现其内在规律、异常情况以及变量间的潜在联系，为后续的建模和分析提供依据。\n\n数据整体检查 (使用 R 函数):\n\nglimpse(my_data): 必用！快速概览数据结构，每列的名称、数据类型 (如 dbl 双精度浮点数, int 整数, chr 字符, fct 因子) 和前几行的值。特别关注数据类型是否符合预期 (例如，分类变量是否应为因子 fct？)。\nsummary(my_data): 提供数值变量的五数概括 (最小值、第一四分位数、中位数、均值、第三四分位数、最大值) 和缺失值计数 (NA’s)，以及字符/因子变量的频数统计。有助于发现异常值和数据分布的初步印象。\nskimr::skim(my_data): (需要先安装和加载 skimr 包: install.packages(\"skimr\"); library(skimr)) 提供一个非常详尽的概览，包括缺失值比例、数值变量的迷你直方图、字符变量的独特性等。强烈推荐使用！\n重点检查:\n\n缺失值 (NA): 哪些列有缺失？缺失比例高吗？ (这会影响后续分析)\n数据类型: 是否有需要转换类型的列？(例如，代表类别的数字应转为因子)\n数值范围: 数值变量的范围是否合理？是否存在明显的极端值或异常值？\n分类变量水平: 如果有分类变量 (因子)，其水平 (levels) 是否正确？例如，对于 Logistic 回归的因变量，确保代表”成功”或”目标事件”的水平是第二个。\n\n\n单变量可视化 (ggplot2): 探索每个重要变量自身的分布特征。\n\n连续变量:\n\nggplot(my_data, aes(x = continuous_variable)) + geom_histogram(bins = 30): 直方图，观察分布形状 (对称、左偏、右偏)、峰值位置。bins 参数可以调整分组数量。\nggplot(my_data, aes(x = continuous_variable)) + geom_density(): 核密度图，平滑版的直方图，更清晰地展示分布形态。\nggplot(my_data, aes(y = continuous_variable)) + geom_boxplot(): 箱线图，展示中位数、四分位数范围 (IQR)、以及潜在的异常点。\n\n分类变量:\n\nggplot(my_data, aes(x = categorical_variable)) + geom_bar(): 条形图，展示每个类别的频数或计数。\n\n\n变量间关系可视化 (ggplot2): 探索变量之间可能存在的联系。\n\n连续 vs. 连续:\n\nggplot(my_data, aes(x = var1, y = var2)) + geom_point(): 散点图，观察是否存在线性关系、非线性关系、聚类或异常点。\n\n分类 vs. 连续:\n\nggplot(my_data, aes(x = categorical_var, y = continuous_var)) + geom_boxplot(): 分组箱线图，比较不同类别下连续变量的分布、中位数、离散程度和异常值。非常常用！\nggplot(my_data, aes(x = categorical_var, y = continuous_var)) + geom_violin(): 分组小提琴图，是箱线图和密度图的结合，能更详细地展示分布形态。\n(可选) ggplot(my_data, aes(x = continuous_var, fill = categorical_var)) + geom_density(alpha = 0.5): 分组密度图，比较不同类别下连续变量的分布曲线。\n\n分类 vs. 分类:\n\nggplot(my_data, aes(x = cat_var1, fill = cat_var2)) + geom_bar(position = \"fill\"): 填充条形图，展示在一个分类变量的每个类别中，另一个分类变量的相对比例。\nggplot(my_data, aes(x = cat_var1, fill = cat_var2)) + geom_bar(position = \"dodge\"): 并列条形图，比较不同类别组合的绝对频数。\nmy_data %&gt;% count(cat_var1, cat_var2) %&gt;% ggplot(aes(x = cat_var1, y = cat_var2, fill = n)) + geom_tile(): 热力图，用颜色深浅表示两个分类变量组合的频数。\n\n\n记录你的发现！: 这是 EDA 最重要的一步。\n\n在代码中添加注释: 对你的代码进行解释，说明你为什么进行某个检查或绘图。\n记录关键观察: 在脚本的注释中，或者单独的笔记文件中，记下你从检查和图表中获得的主要信息。例如：\n\n“变量 income 呈右偏分布，可能需要进行对数变换。”\n“变量 age 与 purchase_amount 似乎存在正相关。”\n“发现 location 列有 15% 的缺失值，需要后续处理。”\n“不同 education_level 组的平均 salary 有明显差异，boxplot 显示…”\n\n保存重要图表: 将具有启发性的图表保存下来 (可以使用 ggsave(\"plots/my_plot.png\"))，并给予有意义的文件名。\n\n\n\n\n\n假期结束时你应该拥有：\n\n一份明确的研究问题陈述。\n一个包含你的 R 项目、数据文件和初步 R 脚本的项目文件夹。\n一个可以成功运行的 R 脚本，该脚本能够：\n\n加载所需的库 (library(tidyverse), library(skimr) 等)。\n成功导入你的数据集。\n包含你进行数据整体检查的代码 (glimpse, summary, skim)。\n包含你绘制关键变量分布和变量关系图的 ggplot2 代码。\n\n一份记录了你 EDA 主要发现的笔记或代码注释。\n\n\n遇到困难怎么办？\n如果在假期中遇到难以解决的问题 (找不到数据、R 代码报错、不确定如何解释图表等)，请记录下问题，可以在假期后向老师、助教或同学请教。\n\n祝大家五一假期愉快，项目启动顺利！认真完成这三个任务将为你的综合实践项目打下坚实的基础。\n\n\n假期后工作坊：从探索到分析\n恭喜你完成了五一假期的项目启动初步任务！希望你已经成功迈出了项目的第一步，拥有了初步的选题、数据和一些 EDA 的发现。\n接下来的时间到第十三周课程开始前，你可以利用这段时间进行回顾和准备，更好地迎接后续更深入的分析、AI 辅助以及可重复报告的学习。\n\n回顾与思考 (为工作坊和后续学习做准备)：\n\n回顾假期成果： 看看你是否已经基本完成了指南中”五一假期建议任务”列出的三点要求。\n\n你的研究问题是否足够清晰和具体了？\n数据是否已成功导入，并且你对它的结构和内容有了初步了解？\n你是否通过 EDA 发现了一些有趣或异常的现象？将这些发现记录下来。\n\n梳理遇到的问题： 在选题、找数据、导入数据或初步 EDA 过程中，你遇到了哪些具体的困难或技术问题？例如：\n\n不确定选题的数据能否支持？\n找不到合适的数据集？\n数据导入时出现乱码或格式错误？\n不理解某些变量的含义？\n某种图表不知道如何绘制？\n绘制出的图表难以解读？\n数据中有很多缺失值不知道怎么办？ 将这些问题记录下来，在课堂上提问，或准备下周用 AI 工具尝试解决。\n\n思考下一步分析方向： 基于你的研究问题和 EDA 的初步发现，简单思考一下接下来可能需要进行哪些分析。例如：\n\n如果你的因变量是分类的，可能会用到 Logistic 回归。\n如果想比较几组的平均值，可能会用到 t 检验或 ANOVA。\n如果想预测一个连续变量，可能会用到线性回归。\n你可能还需要对数据进行清洗或转换（如处理缺失值、异常值，或进行变量变换）。\n\n\n\n\n为第十三周课程做准备：\n第十三周我们将学习如何利用 AI 工具辅助数据分析过程，以及如何创建可重复报告 (使用 Quarto)。为了充分利用课堂时间，你可以：\n\n准备 AI 提问素材： 从你梳理的问题中，挑选 2-3 个具体的、可以用技术手段解决的问题，准备在下周课堂上或课后尝试用 AI 辅助解决。\n初步了解 Quarto： 如果有时间，可以简单浏览一下 Quarto 的官方网站 (https://quarto.org/) 或相关介绍，了解它如何将代码、结果和文字结合起来。思考如何用 Quarto 来组织你已有的项目代码和 EDA 发现。\n\n\n\n项目时间表 (提醒)：\n\n第 13 周： 学习 AI 辅助分析技术和可重复报告制作；基于 EDA 结果，开始清理数据并构建初步统计模型。\n第 14 周： 深入模型评估与诊断；解释结果并进行讨论；开始撰写报告草稿。\n第 15-16 周： 完善分析并迭代模型；完成最终报告撰写和项目展示准备。\n\n\n通过本次课堂的实践指导，希望大家都能顺利启动项目，带着具体的问题和初步的发现迎接第十三周关于 AI 辅助分析和可重复报告的学习！",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>综合实践项目启动详细指南 (五一假期任务)</span>"
    ]
  },
  {
    "objectID": "week13_lecture.html",
    "href": "week13_lecture.html",
    "title": "第13周：AI赋能分析、可重复报告与项目实践",
    "section": "",
    "text": "欢迎来到第13周！",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>第13周：AI赋能分析、可重复报告与项目实践</span>"
    ]
  },
  {
    "objectID": "week13_lecture.html#本周议程",
    "href": "week13_lecture.html#本周议程",
    "title": "第13周：AI赋能分析、可重复报告与项目实践",
    "section": "本周议程",
    "text": "本周议程\n\n回顾与连接： 综合实践项目启动情况\n核心技能一：AI赋能数据分析\n\nAI在分析流程中的进阶应用\n有效Prompting技巧与批判性思维\n\n核心技能二：Quarto可重复报告\n\nQuarto基础：为何与如何\n创建你的第一个动态分析报告\n\n项目实践整合： 将AI与Quarto应用于你的综合项目\n\nAI辅助项目问题解决与分析深化\n用Quarto组织和呈现你的项目进展",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>第13周：AI赋能分析、可重复报告与项目实践</span>"
    ]
  },
  {
    "objectID": "week13_lecture.html#学习目标",
    "href": "week13_lecture.html#学习目标",
    "title": "第13周：AI赋能分析、可重复报告与项目实践",
    "section": "学习目标",
    "text": "学习目标\n\n完成本周学习后，你应该能够：\n\n\n运用AI工具辅助R编程、调试、结果解释和分析思路拓展。\n掌握构建有效AI Prompt的原则，并批判性评估AI输出。\n理解可重复报告的重要性，并使用Quarto创建包含文本、代码、图表的动态报告。\n将AI辅助和Quarto报告应用于你的综合实践项目，提升分析效率和成果质量。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>第13周：AI赋能分析、可重复报告与项目实践</span>"
    ]
  },
  {
    "objectID": "week13_lecture.html#ai在数据分析中的角色演进",
    "href": "week13_lecture.html#ai在数据分析中的角色演进",
    "title": "第13周：AI赋能分析、可重复报告与项目实践",
    "section": "AI在数据分析中的角色演进",
    "text": "AI在数据分析中的角色演进\n\nW1 初识： 我们曾学习过AI可以作为查询R语法、解释概念的助手。\nW13 进阶： 现在，我们将AI视为分析流程中的“智能副驾驶”，让它参与更复杂的任务。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>第13周：AI赋能分析、可重复报告与项目实践</span>"
    ]
  },
  {
    "objectID": "week13_lecture.html#ai工具进阶应用场景",
    "href": "week13_lecture.html#ai工具进阶应用场景",
    "title": "第13周：AI赋能分析、可重复报告与项目实践",
    "section": "1.1 AI工具进阶应用场景",
    "text": "1.1 AI工具进阶应用场景\n让我们通过实例来看看AI如何帮助我们。\n\n\na. 复杂代码生成与辅助编程\n\n场景描述Prompt示例AI可能输出 (示意)思考与练习\n\n\n假设你想用ggplot2为iris数据集绘制一个复杂的散点图：按Species上色，并为每个Species添加线性回归线。\n\n\n我正在使用R语言分析内置的`iris`数据集。\n请帮我写一段`ggplot2`代码，完成以下任务：\n1. 绘制一个散点图，x轴为`Sepal.Length`，y轴为`Sepal.Width`。\n2. 点的颜色根据`Species`列进行映射。\n3. 为每个`Species`分组添加一条平滑的线性回归线(不显示置信区间)。\n4. 添加合适的标题和轴标签，并使用`theme_minimal()`。\n\n\n# library(ggplot2)\n#\n# ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +\n#   geom_point() +\n#   geom_smooth(method = \"lm\", se = FALSE) + # 关键点\n#   labs(title = \"Sepal Length vs. Sepal Width by Species\",\n#        x = \"Sepal Length (cm)\",\n#        y = \"Sepal Width (cm)\") +\n#   theme_minimal()\n\n\n\n在你的R环境中运行AI生成的代码（或类似代码）。它是否直接可用？\n如果想修改回归线类型（例如，改为LOESS平滑），你该如何调整Prompt或代码？尝试一下。\n\n\n\n\n\n\n\nb. 代码调试与错误解释\n\n场景描述错误代码示例Prompt示例AI可能诊断思考与练习\n\n\n你写了一段R代码，但它报错了。\n\n\n# library(dplyr)\n# data_summary &lt;- mtcars %&gt;%\n#   group_by(cyl) %&gt;%\n#   summarise(mean_mpg = mean(MPG)) # 注意：mtcars中mpg是小写\n# print(data_sumary) # 注意：变量名拼写错误\n\n\n我在R中运行了以下代码：\n[粘贴上述错误代码]\n它给了我错误信息：[粘贴你实际遇到的错误信息，例如 \"Error: Problem with `summarise()` input `mean_mpg`. x object 'MPG' not found\"]\n然后，如果修复了第一个问题，又提示：[粘贴第二个错误信息，例如 \"Error: object 'data_sumary' not found\"]\n你能帮我看看问题出在哪里吗？并解释一下。\n\n\nAI通常能指出： 1. 列名 MPG 在 mtcars 数据集（或其他你使用的数据集）中可能是大小写错误或拼写错误。 2. 打印时变量名 data_sumary 与你之前定义的 data_summary 拼写不一致。\n\n\n\n尝试将你项目中遇到的一个代码错误信息输入AI，看看它的诊断和解释。\nAI提供的解释是否帮助你理解了错误的原因？\n\n\n\n\n\n\n\nc. 统计结果解释与概念深化\n\n场景描述假设的lm()输出片段Prompt示例思考与练习\n\n\n你运行了一个线性回归模型，得到了summary()输出，但不完全理解所有系数的含义。\n\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.5000     0.5000   7.000  1.2e-08 ***\nstudy_hours  0.8500     0.1000   8.500  2.5e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nResidual standard error: 1.2 on 48 degrees of freedom\nMultiple R-squared:  0.600, Adjusted R-squared:  0.591 \nF-statistic: 72.2 on 1 and 48 DF,  p-value: 2.5e-10\n\n\n这是我的线性回归模型（预测考试分数`score`，自变量为`study_hours`）的R `summary()`输出的一部分：\n[粘贴上述输出]\n请帮我解释：\n1. `study_hours`的Estimate (0.8500) 具体是什么意思？\n2. `study_hours`的Pr(&gt;|t|) (2.5e-10) 代表什么？\n3. Multiple R-squared (0.600) 告诉我关于模型什么信息？\n\n\n\n用你项目中的一个统计模型输出（如t检验、ANOVA、回归模型）尝试向AI提问，请求解释。\nAI的解释是否准确易懂？如果想向一个没有统计背景的人解释，你该如何再次提问AI或自己组织语言？\n\n\n\n\n\n\n\n重要：验证！\n\n\n\nAI对统计概念的解释通常是准确的，但对于特定情境下的细微差别或复杂假设，仍需结合你的专业知识和教材进行判断。不要盲目相信AI的每一个解释，尤其是涉及到研究结论时。\n\n\n\n\n\n\n\n\nd. 分析思路拓展与研究设计建议\n\n场景描述Prompt示例AI可能建议思考与练习\n\n\n你正在进行客户流失分析项目，已经完成了一些基础分析。\n\n\n我正在分析一个客户流失数据集，包含了客户的人口统计信息、购买行为、服务交互记录以及是否流失的标签。\n我已经做了：\n1. 描述性统计，了解各变量分布。\n2. EDA可视化，如流失与非流失客户在年龄、平均月消费上的箱线图比较。\n3. 初步的Logistic回归，用年龄和平均月消费预测流失。\n除了优化现有模型，AI你有什么建议，我还可以从哪些角度进一步分析数据以更深入理解客户流失原因或构建更好的预测模型？\n\n\n\n探索更多变量间的交互作用。\n尝试其他分类模型 (如决策树、随机森林)。\n进行客户分群，看不同群体的流失模式。\n分析流失客户在流失前的行为序列。\n\n\n\n\n针对你的项目，描述你已完成的分析，向AI征求下一步分析思路或研究设计的建议。\nAI的建议是否具有启发性？哪些建议是你当前阶段可以尝试的？\n\n\n\n\n\n\n\ne. (初步)辅助报告文本撰写/润色\n\n场景描述Prompt示例AI可能输出思考与练习\n\n\n你想将分析结果用专业的语言写入报告。\n\n\n我的R分析（双样本t检验）显示，实验组（接受新疗法）的平均康复时间 (25天) 显著短于对照组（接受标准疗法）的平均康复时间 (35天)，p值 &lt; 0.01。\n请帮我将这个发现用一段简洁、客观、适合写入研究报告“结果”部分的文字描述出来。\n\n\n“结果显示，接受新疗法的实验组其平均康复时间（M = 25天, SD = [需补充]）显著短于接受标准疗法的对照组（M = 35天, SD = [需补充]），t(df) = [需补充], p &lt; .01。” (AI可能会提醒你需要补充标准差和t检验的具体统计量)\n\n\n\n尝试将你项目中的一个分析发现描述给AI，让它帮你生成一段报告文本。\nAI生成的文本是否符合学术规范？你还需要补充哪些信息使其完整？",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>第13周：AI赋能分析、可重复报告与项目实践</span>"
    ]
  },
  {
    "objectID": "week13_lecture.html#有效-prompting-技巧",
    "href": "week13_lecture.html#有效-prompting-技巧",
    "title": "第13周：AI赋能分析、可重复报告与项目实践",
    "section": "1.2 有效 Prompting 技巧",
    "text": "1.2 有效 Prompting 技巧\n\n好的Prompt是获取高质量AI输出的关键。\n\n\n清晰性与具体性 (Clarity & Specificity):\n\n差: “帮我分析数据。”\n好: “我有一个名为sales_data的数据框，包含date, product_category, revenue三列。请帮我计算每个product_category的总revenue，并按降序排列。”\n\n提供上下文 (Provide Context): 你的目标、数据结构、已尝试的方法。\n指定角色 (Assign a Role): “假设你是一位资深的R语言统计分析师…”\n指定输出格式 (Specify Output Format): “请用R代码块给出答案。” / “请用项目符号列表的形式给出建议。”\n迭代与追问 (Iterate & Follow-up): 不要期望一次完美，通过追问优化。\n分解复杂任务 (Break Down Complex Tasks): 大问题拆成小问题。\n“思维链”提示 (Chain-of-Thought Prompting): 要求AI解释其思考过程：“请逐步解释你是如何得到这个结论的。”\n提供示例 (Few-shot Prompting): 如果期望特定风格，先给AI一两个例子。\n\n\n\n\n\n\n\n批判性评估是核心\n\n\n\nAI是副驾驶，你是主驾驶！\n\n事实核查: AI有时会“一本正经地胡说八道”（幻觉 Hallucination）。\n代码测试: AI生成的代码需要实际运行和测试。\n逻辑审查: AI的解释和建议是否符合统计学原理和你的研究背景？\n偏见警惕: AI的训练数据可能包含偏见。\n\n你是最终的决策者和责任人！",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>第13周：AI赋能分析、可重复报告与项目实践</span>"
    ]
  },
  {
    "objectID": "week13_lecture.html#为何需要可重复报告",
    "href": "week13_lecture.html#为何需要可重复报告",
    "title": "第13周：AI赋能分析、可重复报告与项目实践",
    "section": "2.1 为何需要可重复报告？",
    "text": "2.1 为何需要可重复报告？\n\n传统报告方式的痛点：\n\n\n手动复制粘贴易出错。\n数据或分析更新后，报告修改繁琐。\n分析过程不透明，难以复现。\n效率低下。\n\n可重复报告 (Reproducible Reporting): 将数据、代码、分析叙述和结果输出（图表、表格）整合在同一个文档中的实践。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>第13周：AI赋能分析、可重复报告与项目实践</span>"
    ]
  },
  {
    "objectID": "week13_lecture.html#quarto-简介",
    "href": "week13_lecture.html#quarto-简介",
    "title": "第13周：AI赋能分析、可重复报告与项目实践",
    "section": "2.2 Quarto 简介",
    "text": "2.2 Quarto 简介\n\nQuarto 是一个开源的科学和技术出版系统。\n\n使用 Markdown 编写文本。\n嵌入多种语言的 代码块 (R, Python, Julia等)。\n将代码执行结果直接插入最终文档。\n渲染输出为多种格式 (HTML, PDF, Word等)。\n\n\n\n\n\n\n\nNote\n\n\n\nQuarto 是 R Markdown 的“下一代”，功能更强大，体验更一致。如果你熟悉R Markdown，过渡到Quarto会非常平滑。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>第13周：AI赋能分析、可重复报告与项目实践</span>"
    ]
  },
  {
    "objectID": "week13_lecture.html#quarto-文档核心组成",
    "href": "week13_lecture.html#quarto-文档核心组成",
    "title": "第13周：AI赋能分析、可重复报告与项目实践",
    "section": "2.3 Quarto 文档核心组成",
    "text": "2.3 Quarto 文档核心组成\n一个典型的 .qmd 文件包含：\n\nYAML 头部 (YAML Header): 元数据和渲染选项。\n---\ntitle: \"我的分析报告\"\nauthor: \"张三\"\ndate: \"2023-10-27\"\nformat: html # 输出格式\neditor: visual # 或 source\n---\nMarkdown 文本: 叙述性内容。\n\n标题: # H1, ## H2\n格式: **粗体**, *斜体*, `代码`\n列表: * 项目, 1. 项目\n\n代码块 (Code Chunks): 嵌入和执行代码。\n\n```{r chunk-label, echo=TRUE, eval=TRUE, fig.cap=\"图表标题\"}\n# R code here\n# 例如:\n# plot(cars)\n```\n\nchunk-label: 唯一标识符 (推荐)。\n常用选项:\n\necho=TRUE/FALSE: 是否显示代码。\neval=TRUE/FALSE: 是否执行代码。\ninclude=TRUE/FALSE: 是否包含代码块所有输出。\nwarning=FALSE, message=FALSE: 隐藏警告/消息。\nresults='markup'/'hide'/'asis': 控制文本输出。\nfig.cap=\"图表标题\": 图表标题。\ntbl-cap=\"表格标题\": 表格标题 (配合knitr::kable())。\n\n\n\n行内代码 (Inline Code): `r R_expression`\n\n例如: “数据集有 `r nrow(iris)` 行。”",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>第13周：AI赋能分析、可重复报告与项目实践</span>"
    ]
  },
  {
    "objectID": "week13_lecture.html#动手创建你的第一个quarto报告",
    "href": "week13_lecture.html#动手创建你的第一个quarto报告",
    "title": "第13周：AI赋能分析、可重复报告与项目实践",
    "section": "2.4 动手：创建你的第一个Quarto报告",
    "text": "2.4 动手：创建你的第一个Quarto报告\n请打开RStudio，跟随以下步骤操作：\n\n新建 Quarto 文档:\n\nRStudio: File -&gt; New File -&gt; Quarto Document...\nTitle: “我的第一个Quarto报告”, Author: 你的名字, Format: HTML.\n保存为 my_first_report.qmd。\n\n观察YAML和默认内容。\n添加Markdown文本：\n\n写一个一级标题 # 引言。\n写一段介绍文字。\n\n添加R代码块：\n\n```{r setup, include=FALSE}\nlibrary(tidyverse)\n```\n\n```{r load-data, echo=TRUE}\ndata(iris)\nhead(iris)\n```\n\n添加行内代码： “Iris数据集包含 {r} ncol(iris) 个变量。”\n添加一个绘图代码块：\n\n```{r iris-plot, fig.cap=\"Iris花萼长度与宽度散点图 (按物种区分)\"}\nggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +\n    geom_point() +\n    labs(title = \"Iris Sepal Dimensions\", x = \"Sepal Length\", y = \"Sepal Width\")\n```\n\n渲染 (Render): 点击RStudio中的 “Render” 按钮。查看生成的HTML文件。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>第13周：AI赋能分析、可重复报告与项目实践</span>"
    ]
  },
  {
    "objectID": "week13_lecture.html#quarto的优势",
    "href": "week13_lecture.html#quarto的优势",
    "title": "第13周：AI赋能分析、可重复报告与项目实践",
    "section": "2.5 Quarto的优势",
    "text": "2.5 Quarto的优势\n\n透明性与可复现性\n一致性 (代码、结果、叙述一体)\n效率 (更新数据后一键重新生成)\n多种输出格式\n版本控制友好",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>第13周：AI赋能分析、可重复报告与项目实践</span>"
    ]
  },
  {
    "objectID": "week13_lecture.html#项目回顾与问题梳理",
    "href": "week13_lecture.html#项目回顾与问题梳理",
    "title": "第13周：AI赋能分析、可重复报告与项目实践",
    "section": "3.1 项目回顾与问题梳理",
    "text": "3.1 项目回顾与问题梳理\n请思考并回顾你的项目：\n\n你的研究问题是什么？\n数据准备和初步EDA进展如何？\n在项目启动阶段，你遇到了哪些具体问题？\n\n数据处理难题？\nR代码实现困难？\n分析思路不清晰？\n结果解读困惑？\n\n\n\n\n\n\n\n\n目标\n\n\n\n将这些实际问题作为练习AI辅助和构建Quarto报告的素材。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>第13周：AI赋能分析、可重复报告与项目实践</span>"
    ]
  },
  {
    "objectID": "week13_lecture.html#ai赋能你的项目",
    "href": "week13_lecture.html#ai赋能你的项目",
    "title": "第13周：AI赋能分析、可重复报告与项目实践",
    "section": "3.2 AI赋能你的项目",
    "text": "3.2 AI赋能你的项目\n针对你的项目问题，尝试使用AI获取帮助。\n场景1：用AI解决你项目中遇到的具体技术问题\n\n任务： 选择你梳理出的一个项目问题。\n构建Prompt： 运用本节课学到的Prompting技巧，向AI提问。\n\n示例 (数据清理)： “我的项目数据框df_project中，列age有15%的缺失值。age对我的分析很重要。我应该如何使用R处理这些缺失值？请给出至少两种方法的代码示例和它们的优缺点。”\n示例 (绘图)： “我想用ggplot2绘制一个分组箱线图，比较不同education_level (分类变量) 下income (连续变量) 的分布。但我希望箱线图按中位数排序，并且在每个箱子上显示样本量。请问如何实现？”\n\n与AI互动： 获取AI的回答，测试代码，评估建议。\n\n\n场景2：AI辅助项目数据清理与预处理\n\n思考你的项目数据：\n\n哪些列需要类型转换？\n哪些列有较多缺失值需要处理？\n是否存在明显的异常值？\n是否需要创建新的特征变量？\n\n向AI提问获取思路和代码建议：\n\nPrompt (特征工程)： “我的项目数据有start_time和end_time两列 (POSIXct格式)。我想计算每个记录的持续时长（例如分钟）。请给出R代码示例，最好使用lubridate包。”\n\n\n\n场景3：AI辅助初步模型选择与构建 (为下一阶段准备)\n\n基于你的研究问题和因变量类型，思考可能适用的模型。\nPrompt (模型建议)： “我的研究问题是判断哪些因素影响客户是否购买某产品 (因变量purchase: 0或1，二分类)。自变量有age (连续), gender (分类), income_level (有序分类)。你建议我初步尝试哪些统计模型？请给出模型名称和R中的主要实现函数。”\nPrompt (模型代码框架)： “我想用R构建一个简单的Logistic回归模型，因变量是purchase，自变量是age和income_level。请给我一个使用glm()函数的代码框架，并简要说明如何查看系数。”\n\n\n\n\n\n\n\nAI是起点，不是终点\n\n\n\nAI提供的模型建议和代码是初步的。模型的选择、构建、诊断和解释仍需你运用统计学知识主导完成。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>第13周：AI赋能分析、可重复报告与项目实践</span>"
    ]
  },
  {
    "objectID": "week13_lecture.html#用quarto组织和呈现你的项目",
    "href": "week13_lecture.html#用quarto组织和呈现你的项目",
    "title": "第13周：AI赋能分析、可重复报告与项目实践",
    "section": "3.3 用Quarto组织和呈现你的项目",
    "text": "3.3 用Quarto组织和呈现你的项目\n现在，将你的项目分析过程和初步发现，用Quarto文档记录下来。这将是你最终报告的雏形！\n任务：开始构建你的项目Quarto文档 (.qmd)\n\n创建新的Quarto文档 (或使用已有项目脚本改造)。\n\nYAML头部： 设置合适的 title, author, date, format (HTML, toc: true, code-fold: true, theme等)。\n在 execute 全局选项中设置 warning: false, message: false (如果需要)。\n\n规划文档结构 (大纲)：\n\n# 1. 引言与研究问题\n# 2. 数据准备与加载 (含R包加载、数据导入代码块)\n# 3. 探索性数据分析 (EDA)\n\n## 3.1 数据整体概览 (glimpse, summary, skimr::skim代码块及观察)\n## 3.2 单变量分析 (为每个重要变量创建绘图代码块及观察)\n## 3.3 双变量/多变量关系探索 (创建绘图代码块及观察)\n\n# 4. 数据清理 (基于EDA的清理计划和初步代码)\n# 5. 初步模型构建 (可选，或为下周准备)\n# 6. 初步结论与下一步计划\n\n迁移现有代码与发现：\n\n将你已有的R脚本中的代码块，复制到Quarto文档的相应位置。\n为代码块添加标签 (chunk-label) 和选项 (echo, eval, fig.cap等)。\n将你记录的EDA文字发现，用Markdown文本形式写在代码块下方或章节总结中。\n\n利用AI辅助撰写：\n\n尝试让AI帮你描述图表、解释代码逻辑、或润色段落。\n记住： 务必审核和修改AI生成的内容。\n\n频繁渲染 (Render)： 边写边渲染，及时发现问题并调整。\n\n\n\nQuarto项目文档示例片段\n---\ntitle: \"电商用户行为分析 - 初步探索\"\nauthor: \"你的名字\" # 替换为你的名字\ndate: \"today\"\nformat:\n  html:\n    toc: true\n    code-fold: true # 允许读者折叠/展开代码块\n    theme: lumen # 你可以选择一个喜欢的主题\nexecute:\n  warning: false # 不在报告中显示R的警告信息\n  message: false # 不在报告中显示R的普通消息\n---\n\n# 1. 引言与研究问题\n\n本项目旨在分析电商平台用户行为数据，以期发现...\n核心研究问题：\n1. 不同用户群体 (如按年龄、地区划分) 在购买频率和平均订单价值上是否存在显著差异？\n2. 哪些因素与用户的复购行为相关？\n\n# 2. 数据准备与加载\n\n```{r setup-libraries, echo=TRUE}\n# 加载本报告所需的R包\nlibrary(tidyverse) # 用于数据处理和可视化\nlibrary(skimr)     # 用于快速生成数据摘要\nlibrary(lubridate) # 用于日期时间处理 (如果需要)\n```\n\n```{r load-data, echo=TRUE}\n# 导入数据 (请确保路径正确)\n# 假设数据文件名为 \"ecommerce_user_data.csv\" 且位于项目下的 \"data\" 子文件夹中\n# user_data &lt;- read_csv(\"data/ecommerce_user_data.csv\") \n\n# 为了演示，我们使用R内置的iris数据集，并假装它是我们的项目数据\nuser_data &lt;- as_tibble(iris) \n# 请将上面一行替换为你实际导入数据的代码\n\nglimpse(user_data) # 快速查看数据结构\nhead(user_data)    # 查看数据前几行\n```\n*数据导入成功。初步查看，数据集包含 `r nrow(user_data)` 行和 `r ncol(user_data)` 列。变量类型基本符合预期。*\n\n# 3. 探索性数据分析 (EDA)\n\n## 3.1 数据整体概览\n\n```{r data-skim, echo=TRUE}\nskim(user_data) # 生成详细的数据摘要信息\n```\n**观察:** \n\n*   (根据`skim`的输出填写你的观察，例如：) `Sepal.Length` 变量没有缺失值，均值为X，标准差为Y。\n*   `Species` 是一个因子变量，有三个水平，每个水平均匀分布。\n*   ...\n\n## 3.2 单变量分析: 花萼长度 (`Sepal.Length`) 分布\n\n```{r eda-sepal-length-hist, fig.cap=\"花萼长度 (Sepal.Length) 分布直方图\", echo=TRUE}\nggplot(user_data, aes(x = Sepal.Length)) + \n  geom_histogram(bins = 15, fill = \"skyblue\", color = \"black\") + # 调整bins数量观察效果\n  labs(title = \"Sepal.Length Distribution\", x = \"Sepal Length\", y = \"Frequency\") +\n  theme_minimal() # 使用简洁主题\n```\n**观察:** 花萼长度的分布大致呈正态，峰值在X附近...\n\n# 4. 数据清理计划 (示例)\n\n基于EDA，下一步计划 (针对真实项目数据)：\n1.  (如果真实数据中有日期列) 将日期列转换为日期格式，并提取年份、月份等信息。\n2.  (如果真实数据中有缺失值) 处理`age`列的缺失值 (例如，使用中位数填充)。\n3.  (如果真实数据中有异常值) 检查并处理`order_value`中的潜在异常值。\n\n```{r data-cleaning-code-placeholder}\n# # 示例：转换日期 (假设有名为 'date_column' 的列)\n# user_data_cleaned &lt;- user_data %&gt;%\n#   mutate(date_column = ymd(date_column), # 假设是ymd格式\n#          purchase_year = year(date_column))\n\n# # 示例：填充年龄缺失值 (假设有名为 'age' 的列)\n# median_age &lt;- median(user_data$age, na.rm = TRUE) # 假设列名为 'age'\n# user_data_cleaned &lt;- user_data %&gt;% \n#   mutate(age = ifelse(is.na(age), median_age, age))\n```\n*后续将在这里完善数据清理步骤并验证。*\n\n...(后续内容)",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>第13周：AI赋能分析、可重复报告与项目实践</span>"
    ]
  },
  {
    "objectID": "week13_lecture.html#本周回顾",
    "href": "week13_lecture.html#本周回顾",
    "title": "第13周：AI赋能分析、可重复报告与项目实践",
    "section": "本周回顾",
    "text": "本周回顾\n\n我们学习了如何更智能地运用AI辅助数据分析。\n我们掌握了使用Quarto创建可重复、动态报告的基础。\n我们开始将这些技能应用于你的综合实践项目。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>第13周：AI赋能分析、可重复报告与项目实践</span>"
    ]
  },
  {
    "objectID": "week13_lecture.html#下一步为你的项目",
    "href": "week13_lecture.html#下一步为你的项目",
    "title": "第13周：AI赋能分析、可重复报告与项目实践",
    "section": "下一步为你的项目：",
    "text": "下一步为你的项目：\n\n完善Quarto项目文档：\n\n系统完成EDA部分的记录和图表整合。\n在Quarto文档中实际执行数据清理步骤，记录每一步的理由和结果。\n确保你的Quarto文档是一个“活的文档”，反映你分析的每一步。\n\n开始初步的统计模型构建：\n\n根据你的研究问题和清理后的数据，在Quarto中尝试构建第一个（或几个）统计模型。\n记录模型的代码、输出，并尝试用AI辅助初步解释结果。\n\n持续批判性地使用AI： 在后续所有分析环节中，让AI成为你的得力助手，但永远保持你的主导和判断。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>第13周：AI赋能分析、可重复报告与项目实践</span>"
    ]
  },
  {
    "objectID": "week13_lecture.html#为第14周做准备模型评估与诊断",
    "href": "week13_lecture.html#为第14周做准备模型评估与诊断",
    "title": "第13周：AI赋能分析、可重复报告与项目实践",
    "section": "为第14周做准备：模型评估与诊断",
    "text": "为第14周做准备：模型评估与诊断\n下周我们将深入探讨如何评估和诊断你构建的统计模型。请确保： * 你的数据已基本清理完毕。 * 你至少已经尝试构建了一个与你研究问题相关的初步模型。 * 你的Quarto文档已经包含了这些初步模型的结果。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>第13周：AI赋能分析、可重复报告与项目实践</span>"
    ]
  },
  {
    "objectID": "统计学与R语言期末复习指南.html",
    "href": "统计学与R语言期末复习指南.html",
    "title": "统计学与R语言期末复习指南",
    "section": "",
    "text": "前言\n本复习指南基于《统计学与R语言》期末试题内容，系统梳理了课程的核心知识点，并提供了相应的练习题。复习建议按照以下顺序进行：",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>统计学与R语言期末复习指南</span>"
    ]
  },
  {
    "objectID": "统计学与R语言期末复习指南.html#前言",
    "href": "统计学与R语言期末复习指南.html#前言",
    "title": "统计学与R语言期末复习指南",
    "section": "",
    "text": "R语言基础与数据处理\n描述性统计与数据可视化\n假设检验\n方差分析\n回归分析\n模型评估与诊断",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>统计学与R语言期末复习指南</span>"
    ]
  },
  {
    "objectID": "统计学与R语言期末复习指南.html#第一章r语言基础与数据处理",
    "href": "统计学与R语言期末复习指南.html#第一章r语言基础与数据处理",
    "title": "统计学与R语言期末复习指南",
    "section": "第一章：R语言基础与数据处理",
    "text": "第一章：R语言基础与数据处理\n\n1.1 核心知识点\n\n1.1.1 tidyverse生态系统\ntidyverse 是R语言中用于数据科学的核心包集合，包含以下主要包：\n\ndplyr：数据操作和变换\nggplot2：数据可视化\ntidyr：数据整理\nreadr：数据读取\npurrr：函数式编程\ntibble：现代化数据框\n\n整洁数据（Tidy Data）原则：\n\n每个变量自成一列\n每个观测自成一行\n\n每个值是一个单元格\n\n\n\n1.1.2 dplyr核心函数\nlibrary(tidyverse)\n\n# 主要数据操作函数\n# select()：选择列\n# filter()：筛选行\n# mutate()：创建/修改列\n# summarise()：汇总统计\n# group_by()：分组操作\n# arrange()：排序\n\n# 管道操作符 %&gt;% 的使用\ndata %&gt;%\n  filter(condition) %&gt;%\n  select(variables) %&gt;%\n  mutate(new_var = expression) %&gt;%\n  group_by(group_var) %&gt;%\n  summarise(stat = function(variable))\n\n\n1.1.3 数据导入与处理\n# CSV文件读取\nlibrary(readr)\ndata &lt;- read_csv(\"file.csv\")\n\n# 缺失值处理\nlibrary(tidyr)\n# 删除缺失值\nclean_data &lt;- data %&gt;% \n  drop_na()  # 或使用 na.omit()\n\n# 替换缺失值\ndata %&gt;% \n  replace_na(list(column_name = replacement_value))\n\n# 检查缺失值\nis.na(data)\n\n\n1.1.4 数据重塑\n# 宽格式转长格式\nlong_data &lt;- wide_data %&gt;%\n  pivot_longer(cols = c(col1, col2, col3), \n               names_to = \"variable\", \n               values_to = \"value\")\n\n# 长格式转宽格式\nwide_data &lt;- long_data %&gt;%\n  pivot_wider(names_from = variable, \n              values_from = value)\n\n\n\n1.2 练习题\n练习1： 使用 dplyr 完成以下操作\n# 假设有销售数据 sales_data，包含列：region, product, sales, date\n# 1. 计算每个地区的平均销售额\n# 2. 筛选销售额大于1000的记录\n# 3. 按地区分组，计算总销售额和记录数\n\n# 参考答案\nsales_summary &lt;- sales_data %&gt;%\n  filter(sales &gt; 1000) %&gt;%\n  group_by(region) %&gt;%\n  summarise(\n    avg_sales = mean(sales),\n    total_sales = sum(sales),\n    count = n()\n  )\n练习2： 数据读取与缺失值处理\n# 1. 读取CSV文件\n# 2. 检查并处理缺失值\n# 3. 创建数据质量报告\n\n# 参考代码\ndata_quality_check &lt;- function(data) {\n  missing_summary &lt;- data %&gt;%\n    summarise_all(~sum(is.na(.))) %&gt;%\n    pivot_longer(everything(), names_to = \"variable\", values_to = \"missing_count\") %&gt;%\n    mutate(missing_percent = missing_count / nrow(data) * 100)\n  \n  return(missing_summary)\n}",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>统计学与R语言期末复习指南</span>"
    ]
  },
  {
    "objectID": "统计学与R语言期末复习指南.html#第二章描述性统计与数据可视化",
    "href": "统计学与R语言期末复习指南.html#第二章描述性统计与数据可视化",
    "title": "统计学与R语言期末复习指南",
    "section": "第二章：描述性统计与数据可视化",
    "text": "第二章：描述性统计与数据可视化\n\n2.1 核心知识点\n\n2.1.1 描述性统计量\n集中趋势指标：\n\n均值（Mean）：对异常值敏感\n中位数（Median）：对异常值稳健\n众数（Mode）：最频繁出现的值\n\n离散程度指标：\n\n标准差（Standard Deviation）：衡量数据离散程度\n方差（Variance）：标准差的平方\n四分位距（IQR）：第75百分位数减去第25百分位数\n\n# R中的描述性统计函数\nmean(x, na.rm = TRUE)\nmedian(x, na.rm = TRUE)\nsd(x, na.rm = TRUE)\nvar(x, na.rm = TRUE)\nquantile(x, probs = c(0.25, 0.75), na.rm = TRUE)\nsummary(data)\n\n\n2.1.2 ggplot2数据可视化\nggplot2语法结构：\nggplot(data = dataset, aes(x = variable1, y = variable2)) +\n  geom_function() +\n  theme_function() +\n  labs()\n常用几何对象（geom）：\n\ngeom_point()：散点图\ngeom_line()：线图\ngeom_bar()：条形图（计算频数）\ngeom_col()：柱状图（使用原始值）\ngeom_histogram()：直方图\ngeom_boxplot()：箱线图\n\n美学映射（aes）：\n\nx, y：坐标轴\ncolor：颜色\nfill：填充色\nsize：大小\nshape：形状\n\n\n\n2.1.3 探索性数据分析（EDA）\nEDA的主要目的：\n\n理解数据分布\n发现数据中的模式和异常\n识别变量间的关系\n为后续建模提供依据\n\n\n\n\n2.2 练习题\n练习3： 创建综合的数据可视化\n# 使用 mtcars 数据集\nlibrary(ggplot2)\n\n# 1. 创建散点图显示 mpg 与 wt 的关系\n# 2. 按照 cyl 进行颜色分组\n# 3. 添加趋势线\n# 4. 设置图表标题和坐标轴标签\n\n# 参考答案\nggplot(mtcars, aes(x = wt, y = mpg, color = factor(cyl))) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(\n    title = \"汽车重量与油耗关系\",\n    x = \"重量 (1000 lbs)\",\n    y = \"油耗 (miles/gallon)\",\n    color = \"气缸数\"\n  ) +\n  theme_minimal()\n练习4： 描述性统计分析\n# 为数据集生成完整的描述性统计报告\ndescriptive_stats &lt;- function(data, numeric_vars) {\n  stats &lt;- data %&gt;%\n    select(all_of(numeric_vars)) %&gt;%\n    summarise_all(list(\n      mean = ~mean(., na.rm = TRUE),\n      median = ~median(., na.rm = TRUE),\n      sd = ~sd(., na.rm = TRUE),\n      min = ~min(., na.rm = TRUE),\n      max = ~max(., na.rm = TRUE),\n      q25 = ~quantile(., 0.25, na.rm = TRUE),\n      q75 = ~quantile(., 0.75, na.rm = TRUE)\n    )) %&gt;%\n    pivot_longer(everything(), names_to = \"stat\", values_to = \"value\") %&gt;%\n    separate(stat, into = c(\"variable\", \"statistic\"), sep = \"_(?=[^_]+$)\")\n  \n  return(stats)\n}",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>统计学与R语言期末复习指南</span>"
    ]
  },
  {
    "objectID": "统计学与R语言期末复习指南.html#第三章假设检验",
    "href": "统计学与R语言期末复习指南.html#第三章假设检验",
    "title": "统计学与R语言期末复习指南",
    "section": "第三章：假设检验",
    "text": "第三章：假设检验\n\n3.1 核心知识点\n\n3.1.1 假设检验基本概念\n假设检验步骤：\n\n建立原假设（H₀）和备择假设（H₁）\n选择显著性水平（α，通常为0.05）\n选择适当的检验统计量\n计算p值\n做出统计决策\n\n两类错误：\n\n第一类错误（Type I Error）：拒绝了实际为真的原假设，概率为α\n第二类错误（Type II Error）：接受了实际为伪的原假设，概率为β\n\np值的正确理解：\np值是在原假设为真的前提下，观察到当前样本结果或更极端结果的概率。\n\n\n3.1.2 t检验\n单样本t检验：\n# 检验样本均值是否等于某个值\nt.test(x, mu = hypothesized_mean)\n双独立样本t检验：\n# 比较两个独立样本的均值\nt.test(group1, group2, var.equal = TRUE)  # 等方差\nt.test(group1, group2, var.equal = FALSE) # 不等方差（Welch's t-test）\n\n# 或使用公式形式\nt.test(outcome ~ group, data = dataset, var.equal = TRUE)\n配对样本t检验：\n# 比较配对样本的均值差异\nt.test(before, after, paired = TRUE)\n前提假设：\n\n数据来自正态分布（或样本量足够大）\n对于双样本t检验，两样本相互独立\n对于等方差t检验，两总体方差相等\n\n\n\n3.1.3 方差齐性检验\n# Levene's 检验\nlibrary(car)\nleveneTest(outcome ~ group, data = dataset)\n\n# Bartlett's 检验\nbartlett.test(outcome ~ group, data = dataset)\n\n\n\n3.2 练习题\n练习5： 双独立样本t检验\n# 场景：比较两种教学方法对学生成绩的影响\n# 1. 进行方差齐性检验\n# 2. 选择适当的t检验\n# 3. 解释结果\n\n# 参考答案\n# 假设数据存储在 education_data 中，包含 score 和 method 列\n\n# 1. 方差齐性检验\nlevene_result &lt;- leveneTest(score ~ method, data = education_data)\nprint(levene_result)\n\n# 2. 根据方差齐性检验结果选择t检验\nif (levene_result$`Pr(&gt;F)`[1] &gt; 0.05) {\n  # 方差齐性，使用等方差t检验\n  t_result &lt;- t.test(score ~ method, data = education_data, var.equal = TRUE)\n} else {\n  # 方差不齐，使用Welch's t检验\n  t_result &lt;- t.test(score ~ method, data = education_data, var.equal = FALSE)\n}\n\n# 3. 结果解释\ncat(\"t统计量:\", t_result$statistic, \"\\n\")\ncat(\"p值:\", t_result$p.value, \"\\n\")\ncat(\"95%置信区间:\", t_result$conf.int, \"\\n\")\n\nif (t_result$p.value &lt; 0.05) {\n  cat(\"结论：两种教学方法的平均效果存在显著差异（p &lt; 0.05）\\n\")\n} else {\n  cat(\"结论：没有足够证据表明两种教学方法的平均效果存在显著差异（p ≥ 0.05）\\n\")\n}",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>统计学与R语言期末复习指南</span>"
    ]
  },
  {
    "objectID": "统计学与R语言期末复习指南.html#第四章方差分析",
    "href": "统计学与R语言期末复习指南.html#第四章方差分析",
    "title": "统计学与R语言期末复习指南",
    "section": "第四章：方差分析",
    "text": "第四章：方差分析\n\n4.1 核心知识点\n\n4.1.1 单因素方差分析（One-way ANOVA）\n适用场景： 比较三个或更多独立样本组的均值\n前提假设：\n\n各组样本相互独立\n各组数据来自正态分布\n各组方差相等（方差齐性）\n\nR语言实现：\n# 拟合ANOVA模型\nanova_model &lt;- aov(outcome ~ group, data = dataset)\n\n# 查看ANOVA表\nsummary(anova_model)\n\n# 模型诊断\nplot(anova_model)\n\n# 检查残差正态性\nshapiro.test(residuals(anova_model))\n\n\n4.1.2 事后检验（Post-hoc Tests）\n当ANOVA结果显著时，需要进行事后检验确定具体哪些组之间存在差异：\n# Tukey's HSD检验\nTukeyHSD(anova_model)\n\n# 或使用其他包\nlibrary(agricolae)\nHSD.test(anova_model, \"group\")\n\n\n\n4.2 练习题\n练习6： 单因素方差分析\n# 场景：比较三种促销活动对销售额的影响\n# 1. 进行方差分析\n# 2. 检查模型假设\n# 3. 如果结果显著，进行事后检验\n\n# 参考答案\n# 假设数据在 promotion_data 中，包含 sales 和 promotion_type 列\n\n# 1. 拟合ANOVA模型\nanova_model &lt;- aov(sales ~ promotion_type, data = promotion_data)\nanova_summary &lt;- summary(anova_model)\nprint(anova_summary)\n\n# 2. 模型诊断\npar(mfrow = c(2, 2))\nplot(anova_model)\n\n# 检查残差正态性\nshapiro_result &lt;- shapiro.test(residuals(anova_model))\ncat(\"Shapiro-Wilk正态性检验 p值:\", shapiro_result$p.value, \"\\n\")\n\n# 3. 如果ANOVA显著，进行事后检验\nif (anova_summary[[1]]$`Pr(&gt;F)`[1] &lt; 0.05) {\n  cat(\"ANOVA结果显著，进行Tukey's HSD事后检验：\\n\")\n  tukey_result &lt;- TukeyHSD(anova_model)\n  print(tukey_result)\n} else {\n  cat(\"ANOVA结果不显著，各组均值无显著差异\\n\")\n}",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>统计学与R语言期末复习指南</span>"
    ]
  },
  {
    "objectID": "统计学与R语言期末复习指南.html#第五章相关分析与回归分析",
    "href": "统计学与R语言期末复习指南.html#第五章相关分析与回归分析",
    "title": "统计学与R语言期末复习指南",
    "section": "第五章：相关分析与回归分析",
    "text": "第五章：相关分析与回归分析\n\n5.1 核心知识点\n\n5.1.1 相关分析\nPearson相关系数：\n\n衡量两个连续变量之间的线性关系强度和方向\n取值范围：-1 到 1\n|r| &gt; 0.7：强相关；0.3 &lt; |r| &lt; 0.7：中等相关；|r| &lt; 0.3：弱相关\n\n# 计算相关系数\ncor(x, y, use = \"complete.obs\")\n\n# 相关性检验\ncor.test(x, y)\n\n# 相关矩阵\ncor(data[, numeric_columns])\n\n# 相关性可视化\nlibrary(corrplot)\ncorrplot(cor_matrix, method = \"circle\")\n重要注意： 相关性不等于因果关系！\n\n\n5.1.2 简单线性回归\n模型形式： \\(Y = \\beta_0 + \\beta_1X + \\epsilon\\)\n其中：\n\n\\(\\beta_0\\)：截距，当X=0时Y的期望值\n\\(\\beta_1\\)：斜率，X每增加一个单位，Y的期望平均变化量\n\\(\\epsilon\\)：误差项\n\n# 拟合线性回归模型\nlm_model &lt;- lm(y ~ x, data = dataset)\n\n# 模型摘要\nsummary(lm_model)\n\n# 模型诊断图\nplot(lm_model)\n\n# 预测\npredict(lm_model, newdata = new_data)\n模型评价指标：\n\nR²（决定系数）：因变量总变异中能被自变量解释的比例\n调整R²：考虑自变量个数的R²调整版本\n残差标准误（RSE）：模型预测的平均误差\n\n\n\n5.1.3 多元线性回归\n模型形式： \\(Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_pX_p + \\epsilon\\)\n偏回归系数解释： \\(\\beta_i\\) 表示在控制了模型中其他所有自变量的影响后，\\(X_i\\) 每变化一个单位，Y的期望平均变化量。\n# 多元回归\nmulti_model &lt;- lm(y ~ x1 + x2 + x3, data = dataset)\n\n# 检测多重共线性\nlibrary(car)\nvif(multi_model)  # VIF &gt; 10 表示存在严重多重共线性\n\n\n5.1.4 回归模型假设与诊断\n线性回归的基本假设：\n\n线性关系\n残差独立性\n残差正态性\n残差方差齐性（同方差性）\n无多重共线性（多元回归）\n\n模型诊断：\n# 残差图\nplot(lm_model, which = 1)  # 残差 vs 拟合值\n\n# 正态Q-Q图\nplot(lm_model, which = 2)  # 检查残差正态性\n\n# 影响点图\nplot(lm_model, which = 4)  # Cook距离\n\n# 残差分布检验\nshapiro.test(residuals(lm_model))\n\n\n\n5.2 练习题\n练习7： 简单线性回归分析\n# 场景：分析广告投入与销售额的关系\n# 1. 创建散点图观察关系\n# 2. 拟合线性回归模型\n# 3. 模型诊断\n# 4. 解释结果\n\n# 参考答案\n# 假设数据在 advertising_data 中，包含 ad_spend 和 sales 列\n\n# 1. 探索性分析\nggplot(advertising_data, aes(x = ad_spend, y = sales)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  labs(title = \"广告投入与销售额关系\",\n       x = \"广告投入（万元）\",\n       y = \"销售额（万元）\")\n\n# 相关性分析\ncor_result &lt;- cor.test(advertising_data$ad_spend, advertising_data$sales)\ncat(\"相关系数:\", cor_result$estimate, \"\\n\")\ncat(\"相关性检验 p值:\", cor_result$p.value, \"\\n\")\n\n# 2. 拟合回归模型\nlm_model &lt;- lm(sales ~ ad_spend, data = advertising_data)\nmodel_summary &lt;- summary(lm_model)\nprint(model_summary)\n\n# 3. 模型诊断\npar(mfrow = c(2, 2))\nplot(lm_model)\n\n# 4. 结果解释\ncat(\"模型方程: 销售额 =\", round(coef(lm_model)[1], 2), \"+\", \n    round(coef(lm_model)[2], 2), \"× 广告投入\\n\")\ncat(\"R²:\", round(model_summary$r.squared, 3), \"\\n\")\ncat(\"解释：广告投入每增加1万元，销售额平均增加\", \n    round(coef(lm_model)[2], 2), \"万元\\n\")",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>统计学与R语言期末复习指南</span>"
    ]
  },
  {
    "objectID": "统计学与R语言期末复习指南.html#第六章logistic回归与分类",
    "href": "统计学与R语言期末复习指南.html#第六章logistic回归与分类",
    "title": "统计学与R语言期末复习指南",
    "section": "第六章：Logistic回归与分类",
    "text": "第六章：Logistic回归与分类\n\n6.1 核心知识点\n\n6.1.1 Logistic回归模型\n适用场景： 二分类或多分类问题\n模型形式： \\[\\log\\left(\\frac{p}{1-p}\\right) = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_pX_p\\]\n其中 \\(p\\) 是事件发生的概率。\n概率转换： \\[p = \\frac{e^{\\beta_0 + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_pX_p}}{1 + e^{\\beta_0 + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_pX_p}}\\]\n# 拟合Logistic回归\nlogit_model &lt;- glm(outcome ~ x1 + x2 + x3, \n                   data = dataset, \n                   family = binomial(link = \"logit\"))\n\n# 模型摘要\nsummary(logit_model)\n\n# 优势比计算\nexp(coef(logit_model))\n\n# 预测概率\npredicted_probs &lt;- predict(logit_model, type = \"response\")\n\n\n6.1.2 优势比（Odds Ratio）\n优势（Odds）：事件发生概率与不发生概率的比值 \\[Odds = \\frac{p}{1-p}\\]\n优势比（OR）：\\(e^{\\beta_i}\\)，表示该变量增加一个单位时，事件发生的优势变化倍数\n\nOR = 1：该变量对结果无影响\nOR &gt; 1：该变量增加时，事件发生的优势增加\nOR &lt; 1：该变量增加时，事件发生的优势减少\n\n\n\n6.1.3 模型评估\n分类性能指标：\n# 混淆矩阵\nlibrary(caret)\npredictions &lt;- ifelse(predicted_probs &gt; 0.5, 1, 0)\nconfusionMatrix(factor(predictions), factor(actual_outcomes))\n\n# 准确率、精确率、召回率、F1分数\naccuracy &lt;- sum(predictions == actual_outcomes) / length(actual_outcomes)\nprecision &lt;- sum(predictions == 1 & actual_outcomes == 1) / sum(predictions == 1)\nrecall &lt;- sum(predictions == 1 & actual_outcomes == 1) / sum(actual_outcomes == 1)\nf1_score &lt;- 2 * (precision * recall) / (precision + recall)\nROC曲线和AUC：\nlibrary(pROC)\nroc_curve &lt;- roc(actual_outcomes, predicted_probs)\nauc_value &lt;- auc(roc_curve)\nplot(roc_curve, main = paste(\"ROC Curve (AUC =\", round(auc_value, 3), \")\"))\n\n\n\n6.2 练习题\n练习8： Logistic回归分析\n# 场景：预测客户是否会购买产品\n# 变量：年龄、收入、是否有促销、购买历史\n# 结果：是否购买（1=购买，0=不购买）\n\n# 参考答案\n# 假设数据在 customer_data 中\n\n# 1. 数据预处理\ncustomer_data$promotion &lt;- as.factor(customer_data$promotion)\ncustomer_data$purchase &lt;- as.factor(customer_data$purchase)\n\n# 2. 拟合Logistic回归模型\nlogit_model &lt;- glm(purchase ~ age + income + promotion + purchase_history,\n                   data = customer_data,\n                   family = binomial(link = \"logit\"))\n\n# 3. 模型摘要\nsummary(logit_model)\n\n# 4. 优势比计算和解释\nor_values &lt;- exp(coef(logit_model))\nor_ci &lt;- exp(confint(logit_model))\ncbind(OR = or_values, or_ci)\n\n# 5. 模型预测\npredictions &lt;- predict(logit_model, type = \"response\")\n\n# 6. 性能评估\nlibrary(pROC)\nroc_result &lt;- roc(customer_data$purchase, predictions)\ncat(\"AUC:\", auc(roc_result), \"\\n\")\n\n# 7. 决策阈值分析\nthresholds &lt;- seq(0.1, 0.9, 0.1)\nperformance &lt;- data.frame(\n  threshold = thresholds,\n  accuracy = sapply(thresholds, function(t) {\n    pred_class &lt;- ifelse(predictions &gt; t, 1, 0)\n    sum(pred_class == as.numeric(customer_data$purchase) - 1) / length(pred_class)\n  })\n)\nprint(performance)",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>统计学与R语言期末复习指南</span>"
    ]
  },
  {
    "objectID": "统计学与R语言期末复习指南.html#第七章卡方检验与分类数据分析",
    "href": "统计学与R语言期末复习指南.html#第七章卡方检验与分类数据分析",
    "title": "统计学与R语言期末复习指南",
    "section": "第七章：卡方检验与分类数据分析",
    "text": "第七章：卡方检验与分类数据分析\n\n7.1 核心知识点\n\n7.1.1 卡方独立性检验\n适用场景： 检验两个分类变量之间是否存在关联\n前提假设：\n\n样本随机抽取\n期望频数 ≥ 5（至少80%的单元格）\n没有期望频数 &lt; 1\n\n# 创建列联表\ncontingency_table &lt;- table(variable1, variable2)\n\n# 卡方检验\nchi_square_result &lt;- chisq.test(contingency_table)\nprint(chi_square_result)\n\n# 期望频数检查\nchi_square_result$expected\n\n\n7.1.2 结果解释\n卡方统计量： \\(\\chi^2 = \\sum \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\\)\n其中 \\(O_{ij}\\) 是观察频数，\\(E_{ij}\\) 是期望频数。\np值解释：\n\np &lt; 0.05：拒绝原假设，认为两变量存在关联\np ≥ 0.05：不拒绝原假设，没有足够证据表明两变量存在关联\n\n\n\n\n7.2 练习题\n练习9： 卡方独立性检验\n# 场景：分析不同地区用户对产品满意度的差异\n# 变量：地区（东部、中部、西部）、满意度（满意、一般、不满意）\n\n# 参考答案\n# 1. 创建列联表\nsatisfaction_table &lt;- table(survey_data$region, survey_data$satisfaction)\nprint(satisfaction_table)\n\n# 2. 卡方检验\nchi_result &lt;- chisq.test(satisfaction_table)\nprint(chi_result)\n\n# 3. 检查期望频数\ncat(\"期望频数：\\n\")\nprint(chi_result$expected)\n\n# 检查是否满足假设\nmin_expected &lt;- min(chi_result$expected)\nprop_greater_5 &lt;- sum(chi_result$expected &gt;= 5) / length(chi_result$expected)\n\ncat(\"最小期望频数:\", min_expected, \"\\n\")\ncat(\"期望频数≥5的比例:\", prop_greater_5, \"\\n\")\n\n# 4. 结果解释\nif (chi_result$p.value &lt; 0.05) {\n  cat(\"结论：地区和满意度之间存在显著关联 (p =\", \n      round(chi_result$p.value, 4), \")\\n\")\n} else {\n  cat(\"结论：没有足够证据表明地区和满意度之间存在关联 (p =\", \n      round(chi_result$p.value, 4), \")\\n\")\n}\n\n# 5. 残差分析（如果结果显著）\nif (chi_result$p.value &lt; 0.05) {\n  standardized_residuals &lt;- chi_result$stdres\n  cat(\"标准化残差（绝对值&gt;2表示贡献较大）：\\n\")\n  print(round(standardized_residuals, 2))\n}",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>统计学与R语言期末复习指南</span>"
    ]
  },
  {
    "objectID": "统计学与R语言期末复习指南.html#第八章综合分析案例",
    "href": "统计学与R语言期末复习指南.html#第八章综合分析案例",
    "title": "统计学与R语言期末复习指南",
    "section": "第八章：综合分析案例",
    "text": "第八章：综合分析案例\n\n8.1 完整数据分析流程\n以下是一个完整的数据分析项目示例：\n# 完整数据分析流程示例\nlibrary(tidyverse)\nlibrary(corrplot)\nlibrary(car)\nlibrary(pROC)\n\n# 1. 数据导入和初步探索\ndata &lt;- read_csv(\"dataset.csv\")\nglimpse(data)\nsummary(data)\n\n# 2. 数据清理\ndata_clean &lt;- data %&gt;%\n  # 处理缺失值\n  drop_na(critical_variables) %&gt;%\n  # 数据类型转换\n  mutate(\n    categorical_var = as.factor(categorical_var),\n    date_var = as.Date(date_var)\n  ) %&gt;%\n  # 创建新变量\n  mutate(\n    new_var = ifelse(condition, value1, value2)\n  )\n\n# 3. 探索性数据分析\n# 描述性统计\nnumeric_vars &lt;- data_clean %&gt;% select_if(is.numeric) %&gt;% names()\ncategorical_vars &lt;- data_clean %&gt;% select_if(is.factor) %&gt;% names()\n\ndescriptive_stats &lt;- data_clean %&gt;%\n  select(all_of(numeric_vars)) %&gt;%\n  summary()\n\n# 相关性分析\ncorrelation_matrix &lt;- cor(data_clean[numeric_vars], use = \"complete.obs\")\ncorrplot(correlation_matrix, method = \"circle\")\n\n# 可视化\n# 分布图\ndata_clean %&gt;%\n  select(all_of(numeric_vars)) %&gt;%\n  pivot_longer(everything()) %&gt;%\n  ggplot(aes(x = value)) +\n  geom_histogram(bins = 30) +\n  facet_wrap(~name, scales = \"free\")\n\n# 分类变量分布\ndata_clean %&gt;%\n  select(all_of(categorical_vars)) %&gt;%\n  pivot_longer(everything()) %&gt;%\n  ggplot(aes(x = value)) +\n  geom_bar() +\n  facet_wrap(~name, scales = \"free\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n# 4. 假设检验分析\n# 示例：比较不同组别的均值\ngroup_comparison &lt;- data_clean %&gt;%\n  group_by(group_variable) %&gt;%\n  summarise(\n    mean_outcome = mean(outcome_variable, na.rm = TRUE),\n    sd_outcome = sd(outcome_variable, na.rm = TRUE),\n    n = n()\n  )\n\n# t检验或ANOVA\nif (length(unique(data_clean$group_variable)) == 2) {\n  test_result &lt;- t.test(outcome_variable ~ group_variable, data = data_clean)\n} else {\n  anova_model &lt;- aov(outcome_variable ~ group_variable, data = data_clean)\n  test_result &lt;- summary(anova_model)\n}\n\n# 5. 回归分析\n# 线性回归\nlm_model &lt;- lm(continuous_outcome ~ predictor1 + predictor2 + predictor3, \n               data = data_clean)\nsummary(lm_model)\n\n# 模型诊断\npar(mfrow = c(2, 2))\nplot(lm_model)\n\n# Logistic回归（如果是分类问题）\nlogit_model &lt;- glm(binary_outcome ~ predictor1 + predictor2 + predictor3,\n                   data = data_clean,\n                   family = binomial())\nsummary(logit_model)\n\n# 6. 模型评估和验证\n# 交叉验证\nlibrary(caret)\nset.seed(123)\ntrain_indices &lt;- createDataPartition(data_clean$outcome, p = 0.8, list = FALSE)\ntrain_data &lt;- data_clean[train_indices, ]\ntest_data &lt;- data_clean[-train_indices, ]\n\n# 重新拟合模型\nfinal_model &lt;- lm(outcome ~ ., data = train_data)\npredictions &lt;- predict(final_model, newdata = test_data)\n\n# 评估指标\nrmse &lt;- sqrt(mean((test_data$outcome - predictions)^2))\nmae &lt;- mean(abs(test_data$outcome - predictions))\nr_squared &lt;- cor(test_data$outcome, predictions)^2\n\n# 7. 结果可视化和报告\n# 残差图\nresiduals_df &lt;- data.frame(\n  fitted = fitted(final_model),\n  residuals = residuals(final_model)\n)\n\nggplot(residuals_df, aes(x = fitted, y = residuals)) +\n  geom_point() +\n  geom_hline(yintercept = 0, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"残差图\", x = \"拟合值\", y = \"残差\")\n\n# 预测 vs 实际值\nprediction_df &lt;- data.frame(\n  actual = test_data$outcome,\n  predicted = predictions\n)\n\nggplot(prediction_df, aes(x = actual, y = predicted)) +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"预测值 vs 实际值\", x = \"实际值\", y = \"预测值\")\n\n\n8.2 综合练习\n练习10： 完整数据分析项目\n# 场景：分析影响员工满意度的因素\n# 数据包含：员工ID、部门、工作年限、薪资、培训小时数、满意度评分\n\n# 任务：\n# 1. 数据探索和清理\n# 2. 描述性统计分析\n# 3. 相关性分析\n# 4. 比较不同部门的满意度（ANOVA）\n# 5. 建立预测满意度的回归模型\n# 6. 模型评估和解释\n\n# 提示代码结构：\nemployee_analysis &lt;- function(data) {\n  # 1. 数据清理\n  # 2. EDA\n  # 3. 统计检验\n  # 4. 建模\n  # 5. 评估\n  # 6. 可视化报告\n}",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>统计学与R语言期末复习指南</span>"
    ]
  },
  {
    "objectID": "统计学与R语言期末复习指南.html#第九章r-markdownquarto与可重复研究",
    "href": "统计学与R语言期末复习指南.html#第九章r-markdownquarto与可重复研究",
    "title": "统计学与R语言期末复习指南",
    "section": "第九章：R Markdown/Quarto与可重复研究",
    "text": "第九章：R Markdown/Quarto与可重复研究\n\n9.1 核心知识点\n\n9.1.1 R Markdown/Quarto基础\n代码块语法：\n\n# R代码块\n\n常用代码块选项：\n\necho = FALSE：不显示代码，只显示结果\ninclude = FALSE：不在输出中包含代码块\neval = FALSE：不执行代码\nwarning = FALSE：不显示警告信息\nmessage = FALSE：不显示消息\n\n\n\n9.1.2 可重复研究最佳实践\n\n清晰的文档结构\n完整的代码和注释\n版本控制\n数据和代码的分离\n环境管理",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>统计学与R语言期末复习指南</span>"
    ]
  },
  {
    "objectID": "统计学与R语言期末复习指南.html#第十章考试策略与复习建议",
    "href": "统计学与R语言期末复习指南.html#第十章考试策略与复习建议",
    "title": "统计学与R语言期末复习指南",
    "section": "第十章：考试策略与复习建议",
    "text": "第十章：考试策略与复习建议\n\n10.1 题型分析\n选择题（40分）：\n\n重点：基础概念、函数用法、统计原理\n策略：理解概念，记忆关键函数\n\n判断题（20分）：\n\n重点：常见误区、概念辨析\n策略：注意细节，避免绝对化表述\n\n简答题（40分）：\n\n重点：分析思路、方法选择、结果解释\n策略：条理清晰，步骤完整\n\n\n\n10.2 复习时间安排\n建议复习计划：\n\n第1-2天： R语言基础和数据处理\n第3-4天： 描述性统计和可视化\n第5-6天： 假设检验和方差分析\n第7-8天： 回归分析\n第9天： 分类数据分析和Logistic回归\n第10天： 综合练习和真题演练\n\n\n\n10.3 重点知识清单\n必须掌握的概念：\n\n整洁数据原则\ndplyr核心函数（select, filter, mutate, summarise, group_by）\nggplot2基本语法（aes, geom_*）\n描述性统计指标的适用场景\n假设检验的基本步骤和p值解释\nt检验的类型和适用条件\nANOVA的前提假设和事后检验\n线性回归的假设和诊断\nLogistic回归的原理和优势比解释\n卡方检验的适用场景\n模型评估指标（R²、AUC、精确率、召回率等）\n\n必须会用的函数：\n# 数据处理\nread_csv(), filter(), select(), mutate(), group_by(), summarise()\n\n# 统计检验\nt.test(), aov(), chisq.test(), cor.test()\n\n# 建模\nlm(), glm(), predict(), summary()\n\n# 可视化\nggplot(), aes(), geom_point(), geom_bar(), geom_histogram()",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>统计学与R语言期末复习指南</span>"
    ]
  },
  {
    "objectID": "统计学与R语言期末复习指南.html#附录常用函数速查表",
    "href": "统计学与R语言期末复习指南.html#附录常用函数速查表",
    "title": "统计学与R语言期末复习指南",
    "section": "附录：常用函数速查表",
    "text": "附录：常用函数速查表\n\nA.1 数据操作函数\n\n\n\n函数\n功能\n示例\n\n\n\n\nread_csv()\n读取CSV文件\nread_csv(\"data.csv\")\n\n\nfilter()\n筛选行\nfilter(data, x &gt; 10)\n\n\nselect()\n选择列\nselect(data, x, y, z)\n\n\nmutate()\n创建/修改列\nmutate(data, new_col = x + y)\n\n\ngroup_by()\n分组\ngroup_by(data, group_var)\n\n\nsummarise()\n汇总统计\nsummarise(data, mean_x = mean(x))\n\n\n\n\n\nA.2 统计检验函数\n\n\n\n函数\n功能\n示例\n\n\n\n\nt.test()\nt检验\nt.test(x ~ group, data = df)\n\n\naov()\n方差分析\naov(y ~ group, data = df)\n\n\nchisq.test()\n卡方检验\nchisq.test(table(x, y))\n\n\ncor.test()\n相关性检验\ncor.test(x, y)\n\n\n\n\n\nA.3 建模函数\n\n\n\n函数\n功能\n示例\n\n\n\n\nlm()\n线性回归\nlm(y ~ x1 + x2, data = df)\n\n\nglm()\n广义线性模型\nglm(y ~ x, family = binomial, data = df)\n\n\npredict()\n模型预测\npredict(model, newdata = new_df)",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>统计学与R语言期末复习指南</span>"
    ]
  },
  {
    "objectID": "统计学与R语言期末复习指南.html#结语",
    "href": "统计学与R语言期末复习指南.html#结语",
    "title": "统计学与R语言期末复习指南",
    "section": "结语",
    "text": "结语\n本复习指南涵盖了《统计学与R语言》课程的核心内容。建议结合课堂笔记、教材和实际练习进行复习。记住，统计学不仅仅是记忆公式和函数，更重要的是理解概念、掌握分析思路、能够正确解释结果。\n最后提醒：\n\n多做练习，熟悉R语言操作\n重视概念理解，不要死记硬背\n注意结果解释，培养批判性思维\n保持代码整洁，养成良好编程习惯\n\n祝您考试顺利！🎉",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>统计学与R语言期末复习指南</span>"
    ]
  },
  {
    "objectID": "week1_lab.html",
    "href": "week1_lab.html",
    "title": "第一周实验：R 环境与基础操作",
    "section": "",
    "text": "1. 目标\n本实验旨在帮助你熟悉 R 和 RStudio 环境，练习基本的 R 语法，并为后续的数据分析打下基础。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>第一周实验：R 环境与基础操作</span>"
    ]
  },
  {
    "objectID": "week1_lab.html#目标",
    "href": "week1_lab.html#目标",
    "title": "第一周实验：R 环境与基础操作",
    "section": "",
    "text": "熟悉 RStudio 界面。\n练习使用 R 作为计算器。\n掌握变量赋值。\n理解并创建不同类型的向量。\n安装并加载 tidyverse 包。\n(可选) 尝试使用 AI 助手查询简单问题。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>第一周实验：R 环境与基础操作</span>"
    ]
  },
  {
    "objectID": "week1_lab.html#rstudio-环境熟悉",
    "href": "week1_lab.html#rstudio-环境熟悉",
    "title": "第一周实验：R 环境与基础操作",
    "section": "2. RStudio 环境熟悉",
    "text": "2. RStudio 环境熟悉\n打开 RStudio，花几分钟熟悉以下几个主要窗口：\n\n脚本编辑器 (Script Editor / Source Pane): 左上角。用于编写和保存 R 代码脚本 (.R 文件) 或 Quarto/R Markdown 文档 (.qmd / .Rmd)。\n控制台 (Console): 左下角。用于直接输入和执行 R 命令，查看输出结果和错误信息。&gt; 符号是命令提示符。\n环境/历史记录 (Environment/History): 右上角。\n\nEnvironment: 显示当前工作空间中已创建的对象（变量、数据框、函数等）。\nHistory: 显示你之前在控制台中执行过的命令。\n\n文件/图形/包/帮助 (Files/Plots/Packages/Help/Viewer): 右下角。\n\nFiles: 浏览你的计算机文件系统。\nPlots: 显示生成的图形。\nPackages: 查看已安装的 R 包，加载或卸载包，安装新包。\nHelp: 查看 R 函数或数据集的帮助文档。\nViewer: 显示本地网页内容（例如 shiny 应用或 htmlwidgets）。\n\n\n尝试:\n\n在控制台中输入 1 + 1 并按 Enter。\n在脚本编辑器中输入 x &lt;- 5，然后选中这行代码，点击 “Run” 按钮（或使用快捷键 Cmd/Ctrl + Enter）。观察环境窗口中是否出现了变量 x。\n在控制台中输入 ?mean 查看 mean 函数的帮助文档，观察帮助窗口的变化。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>第一周实验：R 环境与基础操作</span>"
    ]
  },
  {
    "objectID": "week1_lab.html#r-作为计算器",
    "href": "week1_lab.html#r-作为计算器",
    "title": "第一周实验：R 环境与基础操作",
    "section": "3. R 作为计算器",
    "text": "3. R 作为计算器\n在控制台中尝试执行以下计算：\n# 加法\n5 + 12\n\n# 减法\n100 - 45\n\n# 乘法\n6 * 7\n\n# 除法\n50 / 4\n\n# 幂运算 (2 的 5 次方)\n2 ^ 5\n\n# 模运算 (取余数)\n17 %% 5\n\n# 整数除法\n17 %/% 5\n\n# 复杂表达式 (注意运算优先级)\n(5 + 3) * 2 / 4 - 1",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>第一周实验：R 环境与基础操作</span>"
    ]
  },
  {
    "objectID": "week1_lab.html#变量赋值与基本类型",
    "href": "week1_lab.html#变量赋值与基本类型",
    "title": "第一周实验：R 环境与基础操作",
    "section": "4. 变量赋值与基本类型",
    "text": "4. 变量赋值与基本类型\n\n使用 &lt;- 将计算结果赋值给变量。\n变量名可以包含字母、数字、点 (.) 和下划线 (_)，但必须以字母或点开头（如果以点开头，后面不能是数字）。区分大小写。\n\n# 将 10 赋值给变量 a\na &lt;- 10\n\n# 将 \"Hello\" 赋值给变量 message\nmessage &lt;- \"Hello, R learners!\"\n\n# 创建一个逻辑变量\nis_learning &lt;- TRUE\n\n# 查看变量的值\na\nmessage\nis_learning\n\n# 对变量进行运算\nb &lt;- a * 3\nb\n\n# 查看变量的数据类型\nclass(a)\nclass(message)\nclass(is_learning)\n练习:\n\n创建一个变量 my_age 并存储你的年龄。\n创建一个变量 course_name 并存储课程名称 “STAT & R”。\n计算 my_age 的 5 年后年龄，并将结果存储在 age_in_5_years 中。\n查看 age_in_5_years 的值和类型。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>第一周实验：R 环境与基础操作</span>"
    ]
  },
  {
    "objectID": "week1_lab.html#向量-vectors",
    "href": "week1_lab.html#向量-vectors",
    "title": "第一周实验：R 环境与基础操作",
    "section": "5. 向量 (Vectors)",
    "text": "5. 向量 (Vectors)\n向量是 R 中最基本的数据结构，用于存储相同类型的元素序列。使用 c() 函数创建。\n# 数值向量\nnumeric_vec &lt;- c(10.5, 5.2, 8.0, 1.5)\nnumeric_vec\nclass(numeric_vec)\nlength(numeric_vec) # 查看向量长度\n\n# 整数向量 (可以在数字后加 L)\ninteger_vec &lt;- c(1L, 5L, 10L, -2L)\ninteger_vec\nclass(integer_vec)\n\n# 字符向量\nchar_vec &lt;- c(\"apple\", \"banana\", \"cherry\", \"date\")\nchar_vec\nclass(char_vec)\n\n# 逻辑向量\nlogical_vec &lt;- c(TRUE, FALSE, FALSE, TRUE, TRUE)\nlogical_vec\nclass(logical_vec)\n\n# 访问向量元素 (索引从 1 开始)\nchar_vec[1]       # 第一个元素\nnumeric_vec[3]    # 第三个元素\nnumeric_vec[c(1, 4)] # 第一个和第四个元素\nnumeric_vec[2:4]    # 第二个到第四个元素\n\n# 向量运算 (通常是元素级别的)\nvec1 &lt;- c(1, 2, 3)\nvec2 &lt;- c(4, 5, 6)\nvec1 + vec2\nvec1 * 2\nvec1 &gt; 1\n\n# 向量类型强制转换\nmixed_vec &lt;- c(1, \"two\", TRUE)\nmixed_vec # 所有元素都变成了字符型\nclass(mixed_vec)\n练习:\n\n创建包含你最喜欢的 3 部电影名称的字符向量 favorite_movies。\n创建包含这 3 部电影大致评分（1-10）的数值向量 movie_ratings。\n访问 favorite_movies 中的第二部电影名称。\n访问 movie_ratings 中评分大于 8 的所有评分。 (提示: 可以使用逻辑索引 movie_ratings[movie_ratings &gt; 8])",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>第一周实验：R 环境与基础操作</span>"
    ]
  },
  {
    "objectID": "week1_lab.html#安装与加载-tidyverse",
    "href": "week1_lab.html#安装与加载-tidyverse",
    "title": "第一周实验：R 环境与基础操作",
    "section": "6. 安装与加载 tidyverse",
    "text": "6. 安装与加载 tidyverse\ntidyverse 是我们进行数据科学工作流的核心工具集。\n# 1. 安装 tidyverse (如果尚未安装)\n# 你只需要在你的 R 环境中执行一次这个命令。\n# 如果不确定是否安装过，可以先尝试加载，如果报错再安装。\n# install.packages(\"tidyverse\")\n\n# 2. 加载 tidyverse\n# 每次启动新的 R 会话 (Session) 时，如果需要使用 tidyverse 中的函数，\n# 都需要先加载它。\nlibrary(tidyverse)\n\n# 加载成功后，会显示 tidyverse 包含的核心包及其版本信息。\n检查: 加载 tidyverse 后，在控制台中输入 dplyr:: 并按 Tab 键，是否能看到 dplyr 包中的函数列表（如 filter, mutate 等）？",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>第一周实验：R 环境与基础操作</span>"
    ]
  },
  {
    "objectID": "week1_lab.html#可选-尝试-ai-助手",
    "href": "week1_lab.html#可选-尝试-ai-助手",
    "title": "第一周实验：R 环境与基础操作",
    "section": "7. (可选) 尝试 AI 助手",
    "text": "7. (可选) 尝试 AI 助手\n打开你选择的 AI 助手（如 ChatGPT 网页版，或 VS Code 中的 Copilot Chat）。\n尝试提问:\n\n“如何在 R 中创建从 1 到 10 的数字序列？” (提示: 答案可能是 1:10 或 seq(1, 10))\n“R 中的 length() 函数有什么作用？”\n“请举例说明如何在 R 中将计算结果赋值给变量。”\n\n思考:\n\nAI 的回答是否准确？\nAI 的解释是否清晰？\n与你自己查找帮助文档 (?length) 或讲义相比，AI 辅助的优缺点是什么？",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>第一周实验：R 环境与基础操作</span>"
    ]
  },
  {
    "objectID": "week1_lab.html#实验总结",
    "href": "week1_lab.html#实验总结",
    "title": "第一周实验：R 环境与基础操作",
    "section": "8. 实验总结",
    "text": "8. 实验总结\n在本实验中，我们熟悉了 RStudio 环境，练习了 R 的基本运算、变量赋值和向量操作，并成功安装和加载了 tidyverse。这些是后续进行更复杂数据分析的基础。确保你理解了向量的概念以及如何创建和访问它们。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>第一周实验：R 环境与基础操作</span>"
    ]
  },
  {
    "objectID": "week2_lab.html",
    "href": "week2_lab.html",
    "title": "第二周实验：数据导入与描述性统计",
    "section": "",
    "text": "1. 目标\n本实验旨在练习使用 readr 包导入数据，熟悉数据框 (Data Frame) 和 Tibble，处理因子类型，并计算和解释基本的描述性统计量，同时初步使用 dplyr 进行数据筛选。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>第二周实验：数据导入与描述性统计</span>"
    ]
  },
  {
    "objectID": "week2_lab.html#目标",
    "href": "week2_lab.html#目标",
    "title": "第二周实验：数据导入与描述性统计",
    "section": "",
    "text": "使用 read_csv() 导入数据文件。\n检查和理解导入数据的结构 (glimpse, str, summary)。\n创建和操作因子变量 (factor, levels)。\n计算集中趋势（均值、中位数）和离散趋势（标准差、IQR、分位数）统计量。\n使用 dplyr 的 select() 和 filter() 选择和筛选数据。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>第二周实验：数据导入与描述性统计</span>"
    ]
  },
  {
    "objectID": "week2_lab.html#数据导入-readr",
    "href": "week2_lab.html#数据导入-readr",
    "title": "第二周实验：数据导入与描述性统计",
    "section": "2. 数据导入 (readr)",
    "text": "2. 数据导入 (readr)\n我们将使用一个模拟的学生成绩数据集 grades.csv。\ngrades.csv 文件内容:\nStudentID,Name,Major,Exam1,Exam2,FinalProject,Attendance\nS001,Alice,Statistics,85,88,92,Present\nS002,Bob,CompSci,92,NA,85,Present\nS003,Charlie,Math,78,82,75,Absent\nS004,David,Statistics,88,90,95,Present\nS005,Eve,CompSci,75,80,NA,Absent\nS006,Frank,Statistics,95,98,96,Present\nS007,Grace,Math,NA,75,80,Present\nS008,Heidi,CompSci,81,84,88,Present\n任务:\n\n将上面的 CSV 内容复制到一个纯文本文件中，并将其命名为 grades.csv，保存在你的 R 项目工作目录下（或者你知道其路径的地方）。\n使用 readr::read_csv() 函数将 grades.csv 文件读入 R，并将结果存储在一个名为 grades_data 的 Tibble 中。\n打印 grades_data 查看内容。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>第二周实验：数据导入与描述性统计</span>"
    ]
  },
  {
    "objectID": "week2_lab.html#数据结构探索",
    "href": "week2_lab.html#数据结构探索",
    "title": "第二周实验：数据导入与描述性统计",
    "section": "3. 数据结构探索",
    "text": "3. 数据结构探索\n导入数据后，检查其结构非常重要。\n任务: 使用以下函数探索 grades_data 的结构：\n\nglimpse(): 快速查看数据结构，包括列名、类型和前几行数据。\nstr(): 显示对象的内部结构（更详细）。\nsummary(): 对每一列计算基本的描述性统计（对数值型计算最小值、Q1、中位数、均值、Q3、最大值、NA 数量；对字符型/因子型计算频数）。\nhead(): 查看前几行数据。\ntail(): 查看后几行数据。\n\n思考:\n\nread_csv 自动识别的列类型是否都正确？\n哪些列包含缺失值 (NA)？summary() 如何提示我们？\nMajor 和 Attendance 列目前是什么类型？你认为它们应该是什么类型更合适？",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>第二周实验：数据导入与描述性统计</span>"
    ]
  },
  {
    "objectID": "week2_lab.html#因子-factor",
    "href": "week2_lab.html#因子-factor",
    "title": "第二周实验：数据导入与描述性统计",
    "section": "4. 因子 (Factor)",
    "text": "4. 因子 (Factor)\nMajor 和 Attendance 列代表分类信息。将它们转换为因子类型通常更便于后续分析和绘图。\n任务:\n\n将 grades_data 中的 Major 列转换为因子类型。查看转换后的列和它的水平 (levels)。\n将 Attendance 列转换为因子类型。思考一下，Attendance 的水平是否有自然的顺序？（例如，“Present” 是否优于 “Absent”？在这个场景下可能没有）。\n(可选挑战) 如果我们认为专业 “Statistics” &gt; “Math” &gt; “CompSci”，如何创建一个有序因子？",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>第二周实验：数据导入与描述性统计</span>"
    ]
  },
  {
    "objectID": "week2_lab.html#描述性统计计算",
    "href": "week2_lab.html#描述性统计计算",
    "title": "第二周实验：数据导入与描述性统计",
    "section": "5. 描述性统计计算",
    "text": "5. 描述性统计计算\n现在我们来计算一些描述性统计量，以更好地理解数值型变量（如考试成绩）的分布。\n任务: 计算 Exam1, Exam2, 和 FinalProject 这三列的：\n\n均值 (Mean)\n中位数 (Median)\n标准差 (Standard Deviation)\n四分位距 (IQR)\n最小值 (Minimum) 和最大值 (Maximum)\n0.1 分位数和 0.9 分位数\n\n注意处理缺失值 (NA)！ 很多函数需要设置 na.rm = TRUE。\n思考:\n\n比较 Exam1 和 Exam2 的均值和中位数，哪个考试的平均表现似乎更好？哪个考试的成绩分布更受异常值影响（如果看均值和中位数的差异）？\n比较 Exam1 和 Exam2 的标准差和 IQR，哪个考试的成绩更分散？",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>第二周实验：数据导入与描述性统计</span>"
    ]
  },
  {
    "objectID": "week2_lab.html#dplyr-初步select-与-filter",
    "href": "week2_lab.html#dplyr-初步select-与-filter",
    "title": "第二周实验：数据导入与描述性统计",
    "section": "6. dplyr 初步：select() 与 filter()",
    "text": "6. dplyr 初步：select() 与 filter()\n练习使用 dplyr 选择特定的列和行。\n任务: 使用 grades_data Tibble 完成以下操作：\n\n选择 StudentID, Name, 和 FinalProject 这三列。\n选择除了 Attendance 之外的所有列。\n筛选出 Major 为 “Statistics” 的所有学生记录。\n筛选出 Exam1 成绩大于 85 分的学生记录。\n筛选出 Major 为 “CompSci” 且 Exam2 成绩大于 80 分的学生记录。\n筛选出 Attendance 为 “Absent” 或 FinalProject 成绩低于 80 分的学生记录。\n链式操作: 筛选出 Major 为 “Statistics” 的学生，然后只选择他们的 Name 和 FinalProject 成绩。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>第二周实验：数据导入与描述性统计</span>"
    ]
  },
  {
    "objectID": "week2_lab.html#实验总结",
    "href": "week2_lab.html#实验总结",
    "title": "第二周实验：数据导入与描述性统计",
    "section": "7. 实验总结",
    "text": "7. 实验总结\n在本实验中，我们练习了从 CSV 文件导入数据，使用多种函数检查了数据结构，将分类变量转换为因子，计算了关键的描述性统计量（注意处理 NA），并使用 dplyr 的 select 和 filter 对数据进行了基本的筛选和子集提取。这些是进行任何数据分析前必不可少的数据熟悉和准备步骤。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>第二周实验：数据导入与描述性统计</span>"
    ]
  },
  {
    "objectID": "week3_lab.html",
    "href": "week3_lab.html",
    "title": "第三周实验：dplyr 进阶与 tidyr 数据整形",
    "section": "",
    "text": "1. 目标\n本实验旨在熟练掌握 dplyr 包中更高级的数据转换函数，并使用 tidyr 包进行数据整形，同时练习处理缺失值和使用管道连接操作。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>第三周实验：`dplyr` 进阶与 `tidyr` 数据整形</span>"
    ]
  },
  {
    "objectID": "week3_lab.html#目标",
    "href": "week3_lab.html#目标",
    "title": "第三周实验：dplyr 进阶与 tidyr 数据整形",
    "section": "",
    "text": "熟练使用 dplyr::mutate() 创建和修改列。\n熟练使用 dplyr::arrange() 对数据进行排序。\n掌握 dplyr::group_by() 和 dplyr::summarise() 进行分组汇总计算。\n理解整洁数据 (Tidy Data) 的概念。\n使用 tidyr::pivot_longer() 将宽数据转换为长数据。\n使用 tidyr::pivot_wider() 将长数据转换为宽数据。\n练习识别和处理缺失值 (NA)。\n熟练运用管道 (%&gt;%) 串联多个数据处理步骤。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>第三周实验：`dplyr` 进阶与 `tidyr` 数据整形</span>"
    ]
  },
  {
    "objectID": "week3_lab.html#数据准备",
    "href": "week3_lab.html#数据准备",
    "title": "第三周实验：dplyr 进阶与 tidyr 数据整形",
    "section": "2. 数据准备",
    "text": "2. 数据准备\n我们将继续使用上周的 grades.csv 数据，并引入一个新的数据集 exam_attempts.csv 来练习 pivot_longer 和 pivot_wider。\ngrades.csv (回顾):\nStudentID,Name,Major,Exam1,Exam2,FinalProject,Attendance\nS001,Alice,Statistics,85,88,92,Present\nS002,Bob,CompSci,92,NA,85,Present\nS003,Charlie,Math,78,82,75,Absent\nS004,David,Statistics,88,90,95,Present\nS005,Eve,CompSci,75,80,NA,Absent\nS006,Frank,Statistics,95,98,96,Present\nS007,Grace,Math,NA,75,80,Present\nS008,Heidi,CompSci,81,84,88,Present\nexam_attempts.csv 文件内容:\nStudentID,Attempt1_Score,Attempt1_Time,Attempt2_Score,Attempt2_Time\nS001,85,50,88,45\nS002,92,60,NA,NA\nS003,78,55,82,50\nS004,88,48,90,42\n任务:\n\n确保 grades.csv 文件在你的工作目录中。\n创建 exam_attempts.csv 文件并保存在工作目录。\n加载 tidyverse 包。\n读入 grades.csv 到 grades_data。\n读入 exam_attempts.csv 到 attempts_data。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>第三周实验：`dplyr` 进阶与 `tidyr` 数据整形</span>"
    ]
  },
  {
    "objectID": "week3_lab.html#dplyr-进阶练习",
    "href": "week3_lab.html#dplyr-进阶练习",
    "title": "第三周实验：dplyr 进阶与 tidyr 数据整形",
    "section": "3. dplyr 进阶练习",
    "text": "3. dplyr 进阶练习\n\n3.1 mutate()\n任务: 使用 grades_data：\n\n计算 Exam1 和 Exam2 的平均分（忽略 NA），并将结果存储在新列 AvgExamScore 中。\n创建一个新列 FinalGrade，假设最终成绩计算方式为：Exam1 * 0.3 + Exam2 * 0.3 + FinalProject * 0.4。注意处理 NA 值（如果任一成绩为 NA，则 FinalGrade 也应为 NA）。\n创建一个逻辑列 PassedExam1，表示 Exam1 成绩是否大于等于 60 (假设 60 分及格)。\n\n\n\n3.2 arrange()\n任务: 使用 grades_data_mutated：\n\n按 FinalGrade 降序排列学生。\n先按 Major 字母顺序排列，然后在每个专业内按 Exam1 升序排列。\n\n\n\n3.3 group_by() 与 summarise()\n任务: 使用 grades_data：\n\n计算每个 Major 的学生人数。\n计算每个 Major 的 Exam1 平均分和 FinalProject 平均分（忽略 NA）。\n找出每个 Major 中 Exam1 的最高分。\n计算 Attendance 为 “Present” 和 “Absent” 的学生人数分别是多少。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>第三周实验：`dplyr` 进阶与 `tidyr` 数据整形</span>"
    ]
  },
  {
    "objectID": "week3_lab.html#tidyr-数据整形练习",
    "href": "week3_lab.html#tidyr-数据整形练习",
    "title": "第三周实验：dplyr 进阶与 tidyr 数据整形",
    "section": "4. tidyr 数据整形练习",
    "text": "4. tidyr 数据整形练习\n\n4.1 pivot_longer()\nattempts_data 目前是“宽”格式，每次尝试的成绩和时间分布在不同的列中。我们希望将其转换为“长”格式，每行代表一次尝试。\n任务: 将 attempts_data 转换为长格式，包含以下列：\n\nStudentID\nAttempt (值为 1 或 2)\nScore (对应尝试的得分)\nTime (对应尝试的时间)\n\n\n\n4.2 pivot_wider()\n任务: 将刚刚创建的长格式数据 attempts_long 转换回原来的宽格式。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>第三周实验：`dplyr` 进阶与 `tidyr` 数据整形</span>"
    ]
  },
  {
    "objectID": "week3_lab.html#处理缺失值-na",
    "href": "week3_lab.html#处理缺失值-na",
    "title": "第三周实验：dplyr 进阶与 tidyr 数据整形",
    "section": "5. 处理缺失值 (NA)",
    "text": "5. 处理缺失值 (NA)\n任务: 使用 grades_data：\n\n计算 Exam2 列有多少个缺失值。\n创建一个新数据框 grades_no_na_exam2，移除 Exam2 列包含 NA 的所有行。\n创建一个新数据框 grades_filled_project，将 FinalProject 列中的 NA 替换为该列的中位数。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>第三周实验：`dplyr` 进阶与 `tidyr` 数据整形</span>"
    ]
  },
  {
    "objectID": "week3_lab.html#综合链式操作",
    "href": "week3_lab.html#综合链式操作",
    "title": "第三周实验：dplyr 进阶与 tidyr 数据整形",
    "section": "6. 综合链式操作 (%>%)",
    "text": "6. 综合链式操作 (%&gt;%)\n任务: 使用 grades_data，通过一步链式操作完成以下任务：\n\n筛选出 Major 为 “Statistics” 或 “Math” 的学生。\n计算这些学生的 Exam1 和 Exam2 的平均分（忽略 NA），命名为 AvgExamScore。\n只保留 StudentID, Name, Major, 和 AvgExamScore 这几列。\n按 AvgExamScore 降序排列结果。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>第三周实验：`dplyr` 进阶与 `tidyr` 数据整形</span>"
    ]
  },
  {
    "objectID": "week3_lab.html#实验总结",
    "href": "week3_lab.html#实验总结",
    "title": "第三周实验：dplyr 进阶与 tidyr 数据整形",
    "section": "7. 实验总结",
    "text": "7. 实验总结\n在本实验中，我们深入练习了 dplyr 的核心数据转换函数 mutate, arrange, group_by, summarise，并掌握了使用 tidyr 的 pivot_longer 和 pivot_wider 在长宽数据格式间转换。我们还练习了处理缺失值的常用方法，并通过管道将这些操作流畅地组合起来。熟练掌握这些 tidyverse 技能对于高效地进行数据清理和准备至关重要。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>第三周实验：`dplyr` 进阶与 `tidyr` 数据整形</span>"
    ]
  },
  {
    "objectID": "week4_lab.html",
    "href": "week4_lab.html",
    "title": "第四周实验：ggplot2 可视化探索",
    "section": "",
    "text": "1. 目标\n本实验旨在通过实践 ggplot2 包，熟练掌握创建常用统计图形进行探索性数据分析 (EDA) 的技能，并练习基本的图形定制。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>第四周实验：`ggplot2` 可视化探索</span>"
    ]
  },
  {
    "objectID": "week4_lab.html#目标",
    "href": "week4_lab.html#目标",
    "title": "第四周实验：ggplot2 可视化探索",
    "section": "",
    "text": "回顾 ggplot2 的图层语法。\n练习绘制单变量图形：直方图、密度图、箱线图。\n练习绘制双变量图形：散点图、分组箱线图/小提琴图、条形图。\n使用 labs() 添加标题和标签。\n使用 theme_...() 应用不同的视觉主题。\n(可选) 结合 dplyr 进行数据汇总后再绘图。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>第四周实验：`ggplot2` 可视化探索</span>"
    ]
  },
  {
    "objectID": "week4_lab.html#数据准备",
    "href": "week4_lab.html#数据准备",
    "title": "第四周实验：ggplot2 可视化探索",
    "section": "2. 数据准备",
    "text": "2. 数据准备\n我们将主要使用 ggplot2 内置的 mpg 数据集。确保 tidyverse 已加载。\nlibrary(tidyverse)\nlibrary(ggplot2) # ggplot2 包含在 tidyverse 中，但显式加载有时有助于代码清晰\n\n# 查看 mpg 数据集结构\nglimpse(mpg)\n# ?mpg # 查看帮助文档",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>第四周实验：`ggplot2` 可视化探索</span>"
    ]
  },
  {
    "objectID": "week4_lab.html#单变量可视化练习",
    "href": "week4_lab.html#单变量可视化练习",
    "title": "第四周实验：ggplot2 可视化探索",
    "section": "3. 单变量可视化练习",
    "text": "3. 单变量可视化练习\n探索单个变量的分布特征。\n\n3.1 直方图 (geom_histogram)\n任务:\n\n绘制变量 cty (城市里程/加仑) 的直方图。\n尝试调整 binwidth 参数（例如 binwidth = 2 或 binwidth = 5），观察图形的变化。\n为直方图添加填充色 (fill) 和边框色 (color)。\n\n\n\n3.2 密度图 (geom_density)\n任务:\n\n绘制变量 hwy (高速公路里程/加仑) 的密度图。\n添加填充色，并使用 alpha 参数设置透明度。\n(可选挑战) 在同一张图上绘制不同 drv (驱动方式) 的 hwy 密度图，使用 fill 映射到 drv 并设置 alpha。\n\n\n\n3.3 箱线图 (geom_boxplot)\n任务:\n\n绘制变量 displ (发动机排量) 的箱线图。\n绘制按 class (车辆类别) 分组的 hwy (高速公路里程) 的箱线图。\n将上一步的箱线图翻转，使类别标签在 Y 轴上，更易阅读 (coord_flip())。\n(可选挑战) 在分组箱线图上叠加 geom_jitter()，显示原始数据点（设置 alpha 和 width）。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>第四周实验：`ggplot2` 可视化探索</span>"
    ]
  },
  {
    "objectID": "week4_lab.html#双变量可视化练习",
    "href": "week4_lab.html#双变量可视化练习",
    "title": "第四周实验：ggplot2 可视化探索",
    "section": "4. 双变量可视化练习",
    "text": "4. 双变量可视化练习\n探索两个变量之间的关系。\n\n4.1 散点图 (geom_point)\n任务:\n\n绘制 displ (发动机排量) 和 cty (城市里程) 的散点图。\n在散点图上，将点的颜色映射到 drv (驱动方式)。\n在散点图上，将点的大小映射到 cyl (气缸数)。\n(可选挑战) 添加一条线性拟合线 (geom_smooth(method = \"lm\"))。\n\n\n\n4.2 条形图 (geom_bar / geom_col)\n任务:\n\n使用 geom_bar() 统计 drv (驱动方式) 的频数并绘制条形图。\n(结合 dplyr) 先计算每个 manufacturer (制造商) 的平均 hwy (高速公路里程)，然后使用 geom_col() 绘制条形图展示结果，并按平均里程排序。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>第四周实验：`ggplot2` 可视化探索</span>"
    ]
  },
  {
    "objectID": "week4_lab.html#图形定制练习-labs-theme",
    "href": "week4_lab.html#图形定制练习-labs-theme",
    "title": "第四周实验：ggplot2 可视化探索",
    "section": "5. 图形定制练习 (labs & theme)",
    "text": "5. 图形定制练习 (labs & theme)\n任务: 选择你之前绘制的任意一个图形，进行以下定制：\n\n使用 labs() 添加一个有意义的 title, subtitle, x 轴标签, y 轴标签, 以及 caption。\n尝试应用不同的内置主题，如 theme_bw(), theme_minimal(), theme_classic(), theme_light()，观察效果。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>第四周实验：`ggplot2` 可视化探索</span>"
    ]
  },
  {
    "objectID": "week4_lab.html#实验总结",
    "href": "week4_lab.html#实验总结",
    "title": "第四周实验：ggplot2 可视化探索",
    "section": "6. 实验总结",
    "text": "6. 实验总结\n在本实验中，我们通过 mpg 数据集实践了 ggplot2 的核心功能。我们练习了绘制用于探索单变量分布的直方图、密度图和箱线图，以及用于探索双变量关系的散点图和条形图（包括分组比较）。我们还学习了如何使用 labs() 和 theme_...() 对图形进行基本定制，使其更具信息量和美观性。熟练掌握 ggplot2 是进行有效数据探索和结果沟通的关键技能。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>第四周实验：`ggplot2` 可视化探索</span>"
    ]
  },
  {
    "objectID": "week5_lab.html",
    "href": "week5_lab.html",
    "title": "第五周实验：假设检验实践 (t-检验与 ANOVA)",
    "section": "",
    "text": "1. 目标\n本实验旨在通过实践应用，熟练掌握单样本 t 检验、双独立样本 t 检验、配对样本 t 检验以及单因素方差分析 (ANOVA) 的 R 实现和结果解读。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>第五周实验：假设检验实践 (t-检验与 ANOVA)</span>"
    ]
  },
  {
    "objectID": "week5_lab.html#目标",
    "href": "week5_lab.html#目标",
    "title": "第五周实验：假设检验实践 (t-检验与 ANOVA)",
    "section": "",
    "text": "根据问题场景选择合适的假设检验方法。\n使用 t.test() 执行各种 t 检验，并解释 P 值和置信区间。\n理解并检查 t 检验和 ANOVA 的假设条件（特别是正态性和方差齐性）。\n使用 aov() 和 summary() 执行 ANOVA，并解读 ANOVA 表。\n在 ANOVA 结果显著后，使用 TukeyHSD() 进行事后检验，找出具体差异。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>第五周实验：假设检验实践 (t-检验与 ANOVA)</span>"
    ]
  },
  {
    "objectID": "week5_lab.html#数据准备",
    "href": "week5_lab.html#数据准备",
    "title": "第五周实验：假设检验实践 (t-检验与 ANOVA)",
    "section": "2. 数据准备",
    "text": "2. 数据准备\n我们将使用 R 内置数据集和一些模拟数据进行练习。\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(car) # 用于 Levene's Test\n\n# 查看内置数据集 sleep (比较两种安眠药的效果)\n# ?sleep\nglimpse(sleep)\nhead(sleep)\n\n# 模拟一些单样本数据 (例如，一批零件的长度，已知标准为 10cm)\nset.seed(123)\npart_lengths &lt;- rnorm(25, mean = 10.1, sd = 0.2) # 模拟 25 个零件，均值略偏离 10\n\n# 模拟 ANOVA 数据 (例如，三种不同教学方法 A, B, C 的学生得分)\nset.seed(456)\nscores_A &lt;- rnorm(20, mean = 75, sd = 5)\nscores_B &lt;- rnorm(20, mean = 80, sd = 5)\nscores_C &lt;- rnorm(20, mean = 78, sd = 5)\n\nanova_sim_data &lt;- tibble(\n  Score = c(scores_A, scores_B, scores_C),\n  Method = factor(rep(c(\"A\", \"B\", \"C\"), each = 20))\n)",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>第五周实验：假设检验实践 (t-检验与 ANOVA)</span>"
    ]
  },
  {
    "objectID": "week5_lab.html#单样本-t-检验-t.test",
    "href": "week5_lab.html#单样本-t-检验-t.test",
    "title": "第五周实验：假设检验实践 (t-检验与 ANOVA)",
    "section": "3. 单样本 t 检验 (t.test)",
    "text": "3. 单样本 t 检验 (t.test)\n场景: 假设已知零件的标准长度应为 10cm。我们抽取了 25 个零件样本 (part_lengths)，想要检验这批零件的平均长度是否显著不等于 10cm。\n任务:\n\n陈述原假设 (\\(H_0\\)) 和备择假设 (\\(H_1\\))。\n(可选) 检查数据的正态性假设（例如，使用 QQ 图或 Shapiro-Wilk 检验）。\n使用 t.test() 对 part_lengths 进行单样本 t 检验，检验均值是否等于 10。\n解读检验结果：t 值、自由度、P 值、置信区间、样本均值估计。\n根据 P 值和选择的显著性水平 \\(\\alpha = 0.05\\) 做出决策。\n用通俗语言解释结论。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>第五周实验：假设检验实践 (t-检验与 ANOVA)</span>"
    ]
  },
  {
    "objectID": "week5_lab.html#双独立样本-t-检验-t.test",
    "href": "week5_lab.html#双独立样本-t-检验-t.test",
    "title": "第五周实验：假设检验实践 (t-检验与 ANOVA)",
    "section": "4. 双独立样本 t 检验 (t.test)",
    "text": "4. 双独立样本 t 检验 (t.test)\n场景: 我们想比较两种不同的肥料（A 和 B）对作物产量 (yield) 的影响是否有显著差异。假设我们有两组独立的样本数据。\n模拟数据:\nset.seed(789)\nyield_fertA &lt;- rnorm(15, mean = 50, sd = 8)\nyield_fertB &lt;- rnorm(18, mean = 56, sd = 7)\n任务:\n\n陈述原假设 (\\(H_0\\)) 和备择假设 (\\(H_1\\))。\n(可选) 分别检查两组数据的正态性。\n检查方差齐性假设 (使用 Levene’s Test 或 var.test())。\n根据方差齐性检验结果，选择合适的 t.test() 参数 (var.equal = TRUE 或 FALSE，推荐默认 FALSE 即 Welch’s test)。执行双独立样本 t 检验。\n解读检验结果：t 值 (或 Welch’s t)、自由度、P 值、置信区间 (针对均值差)、样本均值估计。\n根据 P 值和 \\(\\alpha = 0.05\\) 做出决策。\n用通俗语言解释结论。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>第五周实验：假设检验实践 (t-检验与 ANOVA)</span>"
    ]
  },
  {
    "objectID": "week5_lab.html#配对样本-t-检验-t.test",
    "href": "week5_lab.html#配对样本-t-检验-t.test",
    "title": "第五周实验：假设检验实践 (t-检验与 ANOVA)",
    "section": "5. 配对样本 t 检验 (t.test)",
    "text": "5. 配对样本 t 检验 (t.test)\n场景: 使用 R 内置的 sleep 数据集。该数据集记录了 10 位病人在分别使用两种安眠药（group=1 和 group=2）后，相比未使用药物时额外睡眠时间的变化 (extra)。我们想检验这两种药物的效果是否有显著差异。这是一个典型的配对样本设计，因为每个病人都尝试了两种药物。\n任务:\n\n陈述原假设 (\\(H_0\\)) 和备择假设 (\\(H_1\\))。\n(可选) 检查配对差值的正态性。\n使用 t.test() 对 sleep 数据进行配对样本 t 检验 (比较 group 1 和 2 的 extra 值)。设置 paired = TRUE。\n解读检验结果：t 值、自由度、P 值、置信区间 (针对差值的均值)、差值的样本均值估计。\n根据 P 值和 \\(\\alpha = 0.05\\) 做出决策。\n用通俗语言解释结论。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>第五周实验：假设检验实践 (t-检验与 ANOVA)</span>"
    ]
  },
  {
    "objectID": "week5_lab.html#单因素-anova-与事后检验",
    "href": "week5_lab.html#单因素-anova-与事后检验",
    "title": "第五周实验：假设检验实践 (t-检验与 ANOVA)",
    "section": "6. 单因素 ANOVA 与事后检验",
    "text": "6. 单因素 ANOVA 与事后检验\n场景: 使用我们之前模拟的 anova_sim_data，比较三种不同教学方法 (A, B, C) 的学生平均得分 (Score) 是否存在显著差异。\n任务:\n\n陈述 ANOVA 的原假设 (\\(H_0\\)) 和备择假设 (\\(H_1\\))。\n(可选) 检查各组数据的正态性。\n检查方差齐性假设 (使用 Levene’s Test)。\n使用 aov() 拟合 ANOVA 模型。\n使用 summary() 查看 ANOVA 表，并解读 F 值和 P 值。\n根据 ANOVA 的 P 值和 \\(\\alpha = 0.05\\) 做出初步决策。\n如果 ANOVA 结果显著 (P &lt; 0.05)，则使用 TukeyHSD() 进行事后检验。\n解读 TukeyHSD 的结果（调整后的 P 值和置信区间），判断具体哪些组之间存在显著差异。\n用通俗语言总结最终结论。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>第五周实验：假设检验实践 (t-检验与 ANOVA)</span>"
    ]
  },
  {
    "objectID": "week5_lab.html#实验总结",
    "href": "week5_lab.html#实验总结",
    "title": "第五周实验：假设检验实践 (t-检验与 ANOVA)",
    "section": "7. 实验总结",
    "text": "7. 实验总结\n在本实验中，我们针对不同的研究场景，实践了四种核心的假设检验方法：单样本 t 检验、双独立样本 t 检验、配对样本 t 检验和单因素方差分析 (ANOVA) 及其事后检验。我们重点练习了如何在 R 中实现这些检验，并根据输出结果（特别是 P 值和置信区间）做出统计决策和解释结论。同时，我们也强调了在应用这些方法前检查相关假设条件（如正态性、方差齐性）的重要性。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>第五周实验：假设检验实践 (t-检验与 ANOVA)</span>"
    ]
  },
  {
    "objectID": "week6_lab.html",
    "href": "week6_lab.html",
    "title": "第六周实验：相关与简单线性回归实践",
    "section": "",
    "text": "1. 目标\n本实验旨在练习计算和解释相关系数，使用散点图可视化变量关系，并拟合和解释简单的线性回归模型。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>第六周实验：相关与简单线性回归实践</span>"
    ]
  },
  {
    "objectID": "week6_lab.html#目标",
    "href": "week6_lab.html#目标",
    "title": "第六周实验：相关与简单线性回归实践",
    "section": "",
    "text": "使用 cor() 计算 Pearson 和 Spearman 相关系数。\n使用 cor.test() 对相关性进行显著性检验并解释结果。\n使用 ggplot2::geom_point() 和 geom_smooth() 创建和解读散点图。\n理解相关不等于因果。\n使用 lm() 拟合简单线性回归模型。\n解读 summary(lm()) 的输出，特别是系数、P 值和 R²。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>第六周实验：相关与简单线性回归实践</span>"
    ]
  },
  {
    "objectID": "week6_lab.html#数据准备",
    "href": "week6_lab.html#数据准备",
    "title": "第六周实验：相关与简单线性回归实践",
    "section": "2. 数据准备",
    "text": "2. 数据准备\n我们将继续使用 mpg 数据集，并可能使用 mtcars 数据集。\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(GGally) # 用于绘制散点图矩阵\n\n# glimpse(mpg)\n# glimpse(mtcars)",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>第六周实验：相关与简单线性回归实践</span>"
    ]
  },
  {
    "objectID": "week6_lab.html#相关分析练习",
    "href": "week6_lab.html#相关分析练习",
    "title": "第六周实验：相关与简单线性回归实践",
    "section": "3. 相关分析练习",
    "text": "3. 相关分析练习\n\n3.1 计算与可视化\n场景: 我们想探索 mpg 数据集中几个连续变量之间的关系，例如 displ (排量), cty (城市里程), hwy (高速里程)。\n任务:\n\n绘制 displ 和 hwy 的散点图，并在图上添加一条线性拟合线 (method = \"lm\") 和一条非线性平滑曲线 (默认 geom_smooth)。观察它们的关系是线性的吗？\n计算 displ 和 hwy 之间的 Pearson 相关系数。\n计算 displ 和 hwy 之间的 Spearman 相关系数。比较两者的大小，思考为何可能有差异。\n(可选挑战) 使用 GGally::ggpairs() 函数创建一个散点图矩阵，可视化多个连续变量（如 displ, cty, hwy, cyl）之间的两两关系和各自的分布。 (需要先 install.packages(\"GGally\"))\n\n\n\n3.2 相关性检验 (cor.test)\n任务:\n\n使用 cor.test() 对 displ 和 hwy 之间的 Pearson 相关性进行显著性检验。\n解读检验结果：相关系数估计值、P 值、置信区间。根据 P 值和 \\(\\alpha = 0.05\\) 判断相关性是否显著。\n使用 cor.test() 对 displ 和 hwy 之间的 Spearman 相关性进行显著性检验。\n解读检验结果。\n\n\n\n3.3 相关不等于因果讨论\n思考题: 假设你发现一个城市中冰淇淋销量 (ice_cream_sales) 与犯罪率 (crime_rate) 之间存在强正相关 (\\(r \\approx 0.8, p &lt; 0.001\\))。\n\n这是否意味着吃冰淇淋会导致犯罪？为什么？\n你能想到一个可能的混淆变量来解释这种相关性吗？\n如果想研究冰淇淋是否真的影响犯罪率（虽然听起来很荒谬），相关分析足够吗？需要什么样的研究设计？",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>第六周实验：相关与简单线性回归实践</span>"
    ]
  },
  {
    "objectID": "week6_lab.html#简单线性回归-slr-练习",
    "href": "week6_lab.html#简单线性回归-slr-练习",
    "title": "第六周实验：相关与简单线性回归实践",
    "section": "4. 简单线性回归 (SLR) 练习",
    "text": "4. 简单线性回归 (SLR) 练习\n场景: 我们想建立一个模型，用汽车重量 wt (单位：1000 lbs) 来预测其每加仑英里数 mpg (使用 mtcars 数据集)。\n任务:\n\n绘制 wt (x 轴) 和 mpg (y 轴) 的散点图，并添加线性拟合线 (geom_smooth(method = \"lm\"))。初步判断两者是否存在线性关系。\n使用 lm() 函数拟合一个简单线性回归模型，用 wt 预测 mpg。将模型存储在 slr_mpg_wt 中。\n使用 summary() 查看模型 slr_mpg_wt 的详细结果。\n解读模型结果:\n\n写出回归方程 (\\(\\hat{mpg} = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\times wt\\))。\n解释截距\\(\\hat{\\beta}_0\\)的含义（在这个场景下是否有实际意义？）。\n解释斜率\\(\\hat{\\beta}_1\\)的含义。\nwt 对 mpg 的影响是否统计显著？依据是什么 (P 值)？\n模型解释了 mpg 变异的百分之多少 (R-squared)？这个模型的拟合优度如何？",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>第六周实验：相关与简单线性回归实践</span>"
    ]
  },
  {
    "objectID": "week6_lab.html#可选-预测",
    "href": "week6_lab.html#可选-预测",
    "title": "第六周实验：相关与简单线性回归实践",
    "section": "5. (可选) 预测",
    "text": "5. (可选) 预测\n使用我们拟合的模型 slr_mpg_wt 来进行预测。\n任务:\n\n预测一辆重量为 2500 lbs (即 wt = 2.5) 的汽车的 MPG。\n预测一辆重量为 4000 lbs (即 wt = 4.0) 的汽车的 MPG。\n使用 predict() 函数进行预测，并可以获取预测值的置信区间或预测区间。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>第六周实验：相关与简单线性回归实践</span>"
    ]
  },
  {
    "objectID": "week6_lab.html#实验总结",
    "href": "week6_lab.html#实验总结",
    "title": "第六周实验：相关与简单线性回归实践",
    "section": "6. 实验总结",
    "text": "6. 实验总结\n在本实验中，我们练习了相关分析和简单线性回归。我们计算并检验了 Pearson 和 Spearman 相关系数，强调了相关不等于因果。我们使用 ggplot2 可视化了变量间的关系。最重要的是，我们使用 lm() 拟合了简单线性回归模型，并详细解读了 summary() 输出中的系数、P 值和 R²，理解了它们在描述变量关系和模型拟合优度方面的含义。我们还初步尝试了使用拟合的模型进行预测。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>第六周实验：相关与简单线性回归实践</span>"
    ]
  },
  {
    "objectID": "week7_lab.html",
    "href": "week7_lab.html",
    "title": "第七周实验：卡方检验与统计方法选择",
    "section": "",
    "text": "1. 目标\n本实验旨在练习处理分类数据，特别是使用列联表和卡方检验来分析两个分类变量之间的关联性，并巩固根据研究问题选择合适统计方法的能力。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>第七周实验：卡方检验与统计方法选择</span>"
    ]
  },
  {
    "objectID": "week7_lab.html#目标",
    "href": "week7_lab.html#目标",
    "title": "第七周实验：卡方检验与统计方法选择",
    "section": "",
    "text": "使用 table() 创建列联表，并使用 prop.table() 计算百分比。\n使用 chisq.test() 执行卡方独立性检验。\n检查卡方检验的期望频数假设。\n解读卡方检验的结果（\\(\\chi^2\\) 值, df, P 值）。\n(可选) 了解并使用 fisher.test()。\n练习根据不同场景选择合适的统计检验方法（回顾阶段一内容）。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>第七周实验：卡方检验与统计方法选择</span>"
    ]
  },
  {
    "objectID": "week7_lab.html#数据准备",
    "href": "week7_lab.html#数据准备",
    "title": "第七周实验：卡方检验与统计方法选择",
    "section": "2. 数据准备",
    "text": "2. 数据准备\n我们将使用 ggplot2 内置的 diamonds 数据集，并可能创建一些模拟数据。\nlibrary(tidyverse)\n\n# 使用 diamonds 数据集\n# 为了避免样本量过大导致期望频数都很大，我们抽取一个子集\nset.seed(123)\ndiamonds_subset &lt;- diamonds %&gt;% sample_n(1000)\n\n# 查看数据结构和变量类型\nglimpse(diamonds_subset)\n# 我们将重点关注 cut (切割质量) 和 color (颜色) 这两个分类变量",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>第七周实验：卡方检验与统计方法选择</span>"
    ]
  },
  {
    "objectID": "week7_lab.html#列联表分析",
    "href": "week7_lab.html#列联表分析",
    "title": "第七周实验：卡方检验与统计方法选择",
    "section": "3. 列联表分析",
    "text": "3. 列联表分析\n任务:\n\n使用 table() 函数创建 diamonds_subset 数据集中 cut 和 color 变量的列联表，存储在 cut_color_table 中并打印。\n使用 prop.table() 计算该列联表的：\n\n单元格占总数的百分比。\n行百分比 (每行的和为 100%)。\n列百分比 (每列的和为 100%)。\n\n解读: 根据行百分比或列百分比，初步判断 cut 和 color 之间是否存在某种关联的迹象？（例如，某个切割等级是否更倾向于出现某种颜色？）",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>第七周实验：卡方检验与统计方法选择</span>"
    ]
  },
  {
    "objectID": "week7_lab.html#卡方独立性检验-chisq.test",
    "href": "week7_lab.html#卡方独立性检验-chisq.test",
    "title": "第七周实验：卡方检验与统计方法选择",
    "section": "4. 卡方独立性检验 (chisq.test)",
    "text": "4. 卡方独立性检验 (chisq.test)\n场景: 我们想正式检验钻石的切割质量 (cut) 与颜色 (color) 是否相互独立。\n任务:\n\n陈述卡方独立性检验的原假设 (\\(H_0\\)) 和备择假设 (\\(H_1\\))。\n使用 chisq.test() 对 cut_color_table 进行卡方检验。\n检查期望频数假设: 从检验结果中提取期望频数 ($expected)，检查是否有期望频数小于 5 的单元格？如果有很多，卡方检验的 P 值可能不准确。\n解读检验结果：\\(\\chi^2\\) 统计量值、自由度 (df)、P 值。\n根据 P 值和 \\(\\alpha = 0.05\\) 做出决策。\n用通俗语言解释结论。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>第七周实验：卡方检验与统计方法选择</span>"
    ]
  },
  {
    "objectID": "week7_lab.html#可选-fisher-精确检验-fisher.test",
    "href": "week7_lab.html#可选-fisher-精确检验-fisher.test",
    "title": "第七周实验：卡方检验与统计方法选择",
    "section": "5. (可选) Fisher 精确检验 (fisher.test)",
    "text": "5. (可选) Fisher 精确检验 (fisher.test)\n场景: 假设我们有一个 2x2 的列联表，或者卡方检验的期望频数假设不满足。\n模拟 2x2 数据: 假设我们调查了 30 人是否使用某 APP（UseApp: Yes/No）以及他们的性别（Gender: Male/Female）。\nset.seed(999)\n\ngender &lt;- sample(c(\"Male\", \"Female\"), 30, replace = TRUE)\nuse_app &lt;- sample(c(\"Yes\", \"No\"), 30, replace = TRUE, prob = c(0.6, 0.4))\n\napp_gender_table &lt;- table(Gender = gender, UseApp = use_app)\n\nprint(app_gender_table)\n任务:\n\n对 app_gender_table 执行 Fisher 精确检验。\n解读 P 值并做出结论。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>第七周实验：卡方检验与统计方法选择</span>"
    ]
  },
  {
    "objectID": "week7_lab.html#统计方法选择练习",
    "href": "week7_lab.html#统计方法选择练习",
    "title": "第七周实验：卡方检验与统计方法选择",
    "section": "6. 统计方法选择练习",
    "text": "6. 统计方法选择练习\n根据以下场景，选择最合适的统计检验或分析方法，并简要说明理由。\n\n场景一: 比较两种不同品牌（A 和 B）灯泡的平均使用寿命（单位：小时）。收集了两组独立样本数据。\n场景二: 调查某大学学生对新图书馆规章的满意度（分为：非常满意、满意、一般、不满意、非常不满意）是否与其所在学院（文学院、理学院、工学院、商学院）有关。\n场景三: 研究跑步距离（公里）与跑步者消耗的卡路里（大卡）之间的关系强度和方向。\n场景四: 一家公司想知道其新推出的广告（花费：万元）是否显著提升了产品月销量（件）。他们有广告投放前 12 个月和投放后 12 个月的月销量数据。\n场景五: 检验一个标准的六面骰子是否是公平的（即每个点数出现的概率是否都是 1/6）。进行了 600 次投掷。\n场景六: 想要预测一个客户是否会购买某产品（是/否），基于该客户的年龄、收入和历史购买次数。\n场景七: 比较三种不同施肥方案（方案 1、方案 2、对照组）对玉米平均产量的影响。\n场景八: 检验一批产品的实际重量（克）是否显著低于其标注重量 500 克。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>第七周实验：卡方检验与统计方法选择</span>"
    ]
  },
  {
    "objectID": "week7_lab.html#实验总结",
    "href": "week7_lab.html#实验总结",
    "title": "第七周实验：卡方检验与统计方法选择",
    "section": "7. 实验总结",
    "text": "7. 实验总结\n在本实验中，我们重点练习了处理分类变量关联性的主要工具——列联表和卡方独立性检验。我们学会了如何创建表格、计算百分比、执行检验、检查假设并解读结果。我们还了解了 Fisher 精确检验的适用场景。最后，通过场景分析，我们巩固了根据研究问题和数据类型选择合适统计方法的能力，这是整个第一阶段学习的核心技能之一。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>第七周实验：卡方检验与统计方法选择</span>"
    ]
  },
  {
    "objectID": "week8_lab.html",
    "href": "week8_lab.html",
    "title": "第八周实验：阶段回顾与多元回归实践",
    "section": "",
    "text": "1. 目标\n本实验旨在巩固第一阶段的核心知识，并通过实践加深对多元线性回归 (MLR) 的理解，特别是偏回归系数的解释和模型基本假设的回顾。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>第八周实验：阶段回顾与多元回归实践</span>"
    ]
  },
  {
    "objectID": "week8_lab.html#目标",
    "href": "week8_lab.html#目标",
    "title": "第八周实验：阶段回顾与多元回归实践",
    "section": "",
    "text": "快速回顾 tidyverse 数据处理、ggplot2 可视化和第一阶段的关键统计方法。\n使用 lm() 拟合包含多个自变量的 MLR 模型。\n重点练习解读 MLR 模型 summary() 输出，特别是偏回归系数的含义（控制其他变量）。\n解释分类自变量（因子）在 MLR 中的系数含义。\n区分 R-squared 和 Adjusted R-squared。\n理解模型整体 F 检验的意义。\n回顾 L.I.N.E. 假设在线性回归中的重要性。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>第八周实验：阶段回顾与多元回归实践</span>"
    ]
  },
  {
    "objectID": "week8_lab.html#阶段一快速回顾练习",
    "href": "week8_lab.html#阶段一快速回顾练习",
    "title": "第八周实验：阶段回顾与多元回归实践",
    "section": "2. 阶段一快速回顾练习",
    "text": "2. 阶段一快速回顾练习\n在深入 MLR 之前，快速完成以下练习以巩固基础。\n数据: 使用 mpg 数据集。\n\nlibrary(tidyverse)\nlibrary(car)  # 用于后续可能需要的方差膨胀因子(VIF)计算\n\n练习题:\n\ndplyr: 计算每个 class (车辆类别) 的平均 cty (城市里程)，并按平均里程降序排列。\nggplot2: 绘制 displ (排量) 与 cty 的散点图，并将点的颜色映射到 drv (驱动方式)，添加合适的标题和轴标签。\n假设检验选择: 你想比较 drv 为 ‘f’ (前驱) 和 ‘r’ (后驱) 的车辆的平均 hwy (高速里程) 是否有显著差异，你会选择哪种统计检验？(写出名称即可)\n相关性: 计算 cty 和 hwy 之间的 Pearson 相关系数。\nSLR 回顾: 拟合一个简单线性回归模型，用 cty 预测 hwy。写出回归方程，并解释斜率的含义。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>第八周实验：阶段回顾与多元回归实践</span>"
    ]
  },
  {
    "objectID": "week8_lab.html#多元线性回归-mlr-实践",
    "href": "week8_lab.html#多元线性回归-mlr-实践",
    "title": "第八周实验：阶段回顾与多元回归实践",
    "section": "3. 多元线性回归 (MLR) 实践",
    "text": "3. 多元线性回归 (MLR) 实践\n场景: 我们想建立一个更全面的模型来预测 mpg 数据集中的 hwy (高速公路里程)，同时考虑 cty (城市里程)、year (生产年份) 和 class (车辆类别) 的影响。\n任务:\n\n使用 lm() 拟合一个 MLR 模型，公式为 hwy ~ cty + as.factor(year) + class。将模型存储在 mlr_hwy 中。(注意：year 是二分类变量（1999 和 2008），使用 as.factor() 将其转换为因子变量)\n使用 summary() 查看模型 mlr_hwy 的详细结果。\n解读模型系数 (Coefficients):\n\n解释截距 (Intercept) 的含义（是否有实际意义？）。\n解释 cty 的偏回归系数的含义（强调“控制其他变量”）。\n解释 year 的偏回归系数的含义。(注意：year 的系数表示 2008 年相对于 1999 年（参照组）的 hwy 差异)\n解释 class 各水平的系数含义（它们是相对于哪个参照组的？）。\n判断每个系数的统计显著性（基于 P 值和 \\(\\alpha = 0.05\\)）。\n\n解读模型整体性能:\n\n解释 Adjusted R-squared 的值代表什么？\n解释 F-statistic 和对应的 p-value 的含义（检验模型的整体显著性）。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>第八周实验：阶段回顾与多元回归实践</span>"
    ]
  },
  {
    "objectID": "week8_lab.html#统计显著性-vs-实际重要性讨论",
    "href": "week8_lab.html#统计显著性-vs-实际重要性讨论",
    "title": "第八周实验：阶段回顾与多元回归实践",
    "section": "4. 统计显著性 vs 实际重要性讨论",
    "text": "4. 统计显著性 vs 实际重要性讨论\n思考:在上面的 mlr_hwy 模型中，year 的系数是统计显著的 (p ≈ 0.0036)，估计值为 0.46。\n\n这个结果的统计意义是什么？\n这个结果的实际重要性如何？增加约 0.46 MPG 对于购车者或汽车工程师来说，是一个值得关注的差异吗？（这取决于具体情境和比较基准）。\n如果样本量增大很多，一个估计值为 0.1 MPG 的系数也可能变得统计显著 (p &lt; 0.05)。在这种情况下，它的实际重要性又如何？",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>第八周实验：阶段回顾与多元回归实践</span>"
    ]
  },
  {
    "objectID": "week8_lab.html#回顾-l.i.n.e.-假设",
    "href": "week8_lab.html#回顾-l.i.n.e.-假设",
    "title": "第八周实验：阶段回顾与多元回归实践",
    "section": "5. 回顾 L.I.N.E. 假设",
    "text": "5. 回顾 L.I.N.E. 假设\n回顾线性回归的四个关键假设：\n\nLinearity (线性性): Y 与 X 之间的关系是线性的。\nIndependence (独立性): 误差项（残差）相互独立。\nNormality (正态性): 误差项（残差）服从正态分布。\nEqual Variance (等方差性 / Homoscedasticity): 误差项（残差）的方差在所有 X 水平上是恒定的。\n\n思考: 对于我们拟合的 mlr_hwy 模型： * 你认为哪个假设最有可能被违反？为什么？ * 如果这些假设被违反，会对我们的模型结果（系数估计、P 值、置信区间）产生什么影响？（回顾讲义内容）。\n（我们将在下周的实验中学习如何具体诊断这些假设。）",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>第八周实验：阶段回顾与多元回归实践</span>"
    ]
  },
  {
    "objectID": "week8_lab.html#实验总结",
    "href": "week8_lab.html#实验总结",
    "title": "第八周实验：阶段回顾与多元回归实践",
    "section": "6. 实验总结",
    "text": "6. 实验总结\n在本实验中，我们通过简短练习回顾了第一阶段的关键知识点。接着，我们重点实践了多元线性回归模型的拟合与解读，特别是深入理解了偏回归系数的含义——在控制其他变量影响下的独立效应。我们还练习了解读模型摘要中的 R² 和整体 F 检验，并讨论了统计显著性与实际重要性的区别。最后，我们回顾了 L.I.N.E. 假设，为下周的模型诊断做好铺垫。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>第八周实验：阶段回顾与多元回归实践</span>"
    ]
  },
  {
    "objectID": "week9_lab.html",
    "href": "week9_lab.html",
    "title": "第九周实验：回归模型诊断实践",
    "section": "",
    "text": "1. 目标\n本实验旨在通过实践操作，熟练掌握诊断线性回归模型（特别是多元线性回归）的常用方法，识别模型是否违反关键假设以及是否存在异常或强影响点。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>第九周实验：回归模型诊断实践</span>"
    ]
  },
  {
    "objectID": "week9_lab.html#目标",
    "href": "week9_lab.html#目标",
    "title": "第九周实验：回归模型诊断实践",
    "section": "",
    "text": "使用 plot() 函数生成默认的回归诊断图。\n解读残差图 (Residuals vs Fitted)，检查线性性和等方差性。\n解读正态 Q-Q 图 (Normal Q-Q Plot)，检查残差正态性。\n(可选) 解读标度-位置图 (Scale-Location Plot)，进一步检查等方差性。\n(可选) 解读残差与杠杆图 (Residuals vs Leverage Plot)，识别高杠杆点和强影响点。\n使用 shapiro.test() 对残差进行正态性检验。\n使用 car::vif() 计算方差膨胀因子，诊断多重共线性。\n使用 cooks.distance() 计算 Cook 距离，识别强影响点。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>第九周实验：回归模型诊断实践</span>"
    ]
  },
  {
    "objectID": "week9_lab.html#数据与模型准备",
    "href": "week9_lab.html#数据与模型准备",
    "title": "第九周实验：回归模型诊断实践",
    "section": "2. 数据与模型准备",
    "text": "2. 数据与模型准备\n我们将使用以下两个新模型进行诊断：\n\nmodel_diamonds: 基于 diamonds 数据集（抽样），price ~ carat + cut + color + clarity。\nmodel_complex_sim: 基于模拟的 complex_sim_data，y ~ x1 + x2 + x3，该模型拟合的数据包含非线性和异方差性，但模型本身是简单线性的，以便于诊断。\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(car)    # For vif() and leveneTest() if needed\nlibrary(broom)  # For augment()\n\n# --- 模型 1: diamonds 数据 ---\n# diamonds 数据集来自 ggplot2 (已通过 tidyverse 加载)\n# 选择价格作为因变量，克拉、切割、颜色、净度作为自变量\n# 注意: cut, color, clarity 是因子变量，lm() 会自动处理\n# 为了避免模型过于庞大和运行缓慢，可以考虑抽样一部分数据\nset.seed(123)\ndiamonds_sample &lt;- sample_n(diamonds, 5000) # 抽取 5000 个样本\nmodel_diamonds &lt;- lm(price ~ carat + cut + color + clarity, data = diamonds_sample)\n# summary(model_diamonds) # 回顾模型\n\n# --- 模型 2: 更复杂的模拟数据 ---\n# 目标: 创建包含非线性关系和异方差性的数据\nset.seed(123) # 使用不同的种子\nn_complex &lt;- 200 # 样本量增加到 200\nx1_complex &lt;- rnorm(n_complex)\nx2_complex &lt;- x1_complex * 0.5 + rnorm(n_complex, 0, 0.5) # 中等相关性\nx3_complex &lt;- runif(n_complex, -2, 2) # 均匀分布的变量\n\n# 真实模型包含非线性 (x1^2), 交互作用 (x1*x2), 和异方差性 (误差标准差随 |x1| 增加)\nerror_complex &lt;- rnorm(n_complex, 0, 1 + abs(x1_complex))\ny_complex &lt;- 5 + 2*x1_complex - 1*x1_complex^2 + 3*x2_complex + 1.5*x1_complex*x2_complex - 0.5*x3_complex + error_complex\n\n# 可以选择性地加入异常点或高杠杆点 (这里暂时不加，让问题更微妙)\n# y_complex[5] &lt;- y_complex[5] - 20 # y方向的异常点\n# x1_complex[10] &lt;- x1_complex[10] + 3 # x方向的高杠杆点\n\ncomplex_sim_data &lt;- tibble(y = y_complex, x1 = x1_complex, x2 = x2_complex, x3 = x3_complex)\n\n# 拟合一个 *错误设定* 的简单线性模型，以便诊断发现问题\nmodel_complex_sim &lt;- lm(y ~ x1 + x2 + x3, data = complex_sim_data)\n# summary(model_complex_sim) # 回顾模型",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>第九周实验：回归模型诊断实践</span>"
    ]
  },
  {
    "objectID": "week9_lab.html#使用-plotmodel-进行图形诊断",
    "href": "week9_lab.html#使用-plotmodel-进行图形诊断",
    "title": "第九周实验：回归模型诊断实践",
    "section": "3. 使用 plot(model) 进行图形诊断",
    "text": "3. 使用 plot(model) 进行图形诊断\nplot() 函数作用于 lm 对象时，会默认生成一系列有用的诊断图。\n任务:\n\n对 model_diamonds 模型使用 plot() 函数。观察生成的 4 个主要图形。\n解读第一个图 (Residuals vs Fitted):\n\n红线是否大致水平接近 0？\n点的散布是否随机，没有明显模式（如曲线、喇叭形）？\n这表明线性性和等方差性假设是否大致满足？\n\n解读第二个图 (Normal Q-Q):\n\n点是否大致落在虚线（对角线）上？\n尾部是否有系统性偏离？\n这表明残差正态性假设是否大致满足？\n\n解读第三个图 (Scale-Location):\n\n纵轴是标准化残差的平方根 (\\(\\sqrt{|Standardized Residuals|}\\))。\n红线是否大致水平？\n这进一步检查了等方差性假设。如果红线有明显上升或下降趋势，提示异方差。\n\n解读第四个图 (Residuals vs Leverage):\n\n横轴是杠杆值 (Leverage)，衡量 X 值的极端程度。\n纵轴是标准化残差。\n图中会用等高线标出 Cook’s distance 的阈值（如 0.5, 1）。\n观察是否有同时具有高杠杆值和高残差的点（通常在右上角或右下角）？这些点可能是强影响点。是否有 Cook’s D 很大的点？\n\n对 model_complex_sim 模型重复步骤 1-5，并比较其诊断图与 model_diamonds 的差异，观察模拟数据中引入的非线性和异方差性是如何在诊断图中体现的。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>第九周实验：回归模型诊断实践</span>"
    ]
  },
  {
    "objectID": "week9_lab.html#残差正态性检验-shapiro.test",
    "href": "week9_lab.html#残差正态性检验-shapiro.test",
    "title": "第九周实验：回归模型诊断实践",
    "section": "4. 残差正态性检验 (shapiro.test)",
    "text": "4. 残差正态性检验 (shapiro.test)\n任务:\n\n提取 model_diamonds 模型的残差。\n对这些残差进行 Shapiro-Wilk 正态性检验。\n根据 P 值和 \\(\\alpha = 0.05\\) 判断是否拒绝正态性假设。结合 Q-Q 图的观察，做出综合判断。\n对 model_complex_sim 的残差重复步骤 1-3。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>第九周实验：回归模型诊断实践</span>"
    ]
  },
  {
    "objectID": "week9_lab.html#多重共线性诊断-vif",
    "href": "week9_lab.html#多重共线性诊断-vif",
    "title": "第九周实验：回归模型诊断实践",
    "section": "5. 多重共线性诊断 (vif)",
    "text": "5. 多重共线性诊断 (vif)\n任务:\n\n使用 car::vif() 函数计算 model_diamonds 模型中数值型自变量（carat）和因子变量的广义方差膨胀因子 (GVIF)。注意：对于因子变量，需要关注 GVIF^(1/(2*Df)) 的值。\n解读 VIF 值。是否存在 VIF &gt; 5 或 &gt; 10 的情况？这说明了什么？\n对 model_complex_sim 模型重复步骤 1-2。比较结果。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>第九周实验：回归模型诊断实践</span>"
    ]
  },
  {
    "objectID": "week9_lab.html#强影响点诊断-cooks.distance",
    "href": "week9_lab.html#强影响点诊断-cooks.distance",
    "title": "第九周实验：回归模型诊断实践",
    "section": "6. 强影响点诊断 (cooks.distance)",
    "text": "6. 强影响点诊断 (cooks.distance)\n任务:\n\n使用 cooks.distance() 计算 model_diamonds 模型中每个观测点的 Cook 距离。\n确定一个阈值（如 \\(4/n\\)）。找出 Cook 距离大于该阈值的点的索引。这些点是潜在的强影响点吗？\n对 model_complex_sim 模型重复步骤 1-2。观察是否存在 Cook 距离较大的点。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>第九周实验：回归模型诊断实践</span>"
    ]
  },
  {
    "objectID": "week9_lab.html#实验总结",
    "href": "week9_lab.html#实验总结",
    "title": "第九周实验：回归模型诊断实践",
    "section": "7. 实验总结",
    "text": "7. 实验总结\n在本实验中，我们系统地实践了线性回归模型诊断的常用工具。通过解读 plot(model) 生成的诊断图，我们评估了模型的线性性、等方差性和残差正态性假设。我们还使用 shapiro.test() 对正态性进行了检验。利用 vif()，我们诊断了模型中是否存在多重共线性问题。最后，通过计算 cooks.distance()，我们识别了潜在的强影响点。掌握这些诊断技能对于评估模型可靠性、发现潜在问题并为下一步的模型改进奠定基础至关重要。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>第九周实验：回归模型诊断实践</span>"
    ]
  },
  {
    "objectID": "week10_lab.html",
    "href": "week10_lab.html",
    "title": "第十周实验：模型改进与选择实践",
    "section": "",
    "text": "1. 目标\n本实验旨在基于上周的模型诊断结果，实践模型改进的常用策略，并练习使用不同标准进行模型选择。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>第十周实验：模型改进与选择实践</span>"
    ]
  },
  {
    "objectID": "week10_lab.html#目标",
    "href": "week10_lab.html#目标",
    "title": "第十周实验：模型改进与选择实践",
    "section": "",
    "text": "应用变量变换（如对数变换）尝试解决非线性或异方差问题，并比较诊断结果。\n根据 VIF 结果，通过移除变量来处理多重共线性问题，并观察模型变化。\n通过移除强影响点（基于 Cook’s D）来评估其对模型的影响。\n在模型中添加交互项，并解释交互效应。\n使用 AIC 和 BIC 比较不同模型的相对优劣。\n了解 step() 函数的使用，并理解其局限性。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>第十周实验：模型改进与选择实践</span>"
    ]
  },
  {
    "objectID": "week10_lab.html#数据与模型准备",
    "href": "week10_lab.html#数据与模型准备",
    "title": "第十周实验：模型改进与选择实践",
    "section": "2. 数据与模型准备",
    "text": "2. 数据与模型准备\n我们将继续使用上周诊断过的模型：\n\nmlr_hwy: 基于 mpg 数据集，hwy ~ displ + cyl + drv。诊断显示可能存在轻微非线性/异方差，以及 displ 和 cyl 之间的共线性。\nprob_model: 基于模拟的 prob_data，y ~ x1 + x2 + x3。诊断显示存在严重共线性 (x1, x2) 和强影响点 (点 1)。\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(car)    # For vif()\nlibrary(broom)  # For augment()\nlibrary(interactions) # For interact_plot()\n\n# --- 模型 1: mpg 数据 ---\nmlr_hwy &lt;- lm(hwy ~ displ + cyl + drv, data = mpg)\n# summary(mlr_hwy)\n# vif(mlr_hwy)\n# par(mfrow=c(2,2)); plot(mlr_hwy); par(mfrow=c(1,1))\n\n\n# --- 模型 2: 问题数据 ---\nset.seed(42)\nn_prob &lt;- 100\nx1_prob &lt;- rnorm(n_prob)\nx2_prob &lt;- x1_prob * 0.8 + rnorm(n_prob, 0, 0.1) # 共线性\nx3_prob &lt;- rnorm(n_prob)\ny_prob &lt;- 2 + 3*x1_prob + 1*x2_prob - 2*x3_prob + rnorm(n_prob, 0, 2)\ny_prob[1] &lt;- y_prob[1] + 15 # 异常/强影响点\nx1_prob[2] &lt;- x1_prob[2] + 4 # 高杠杆点\nprob_data &lt;- tibble(y = y_prob, x1 = x1_prob, x2 = x2_prob, x3 = x3_prob)\nprob_model &lt;- lm(y ~ x1 + x2 + x3, data = prob_data)\n# summary(prob_model)\n# vif(prob_model)\n# plot(prob_model, which=4) # Cook's D",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>第十周实验：模型改进与选择实践</span>"
    ]
  },
  {
    "objectID": "week10_lab.html#变量变换实践",
    "href": "week10_lab.html#变量变换实践",
    "title": "第十周实验：模型改进与选择实践",
    "section": "3. 变量变换实践",
    "text": "3. 变量变换实践\n场景: mlr_hwy 模型的诊断图（特别是 Residuals vs Fitted 和 Scale-Location）提示可能存在轻微的异方差（方差随拟合值增大而增大）。燃油效率这类变量有时进行对数变换效果较好。\n任务:\n\n创建一个新模型 mlr_hwy_log，对因变量 hwy 进行自然对数变换 (log(hwy))，自变量保持不变。\n使用 plot() 函数对新模型 mlr_hwy_log 进行诊断。\n比较 mlr_hwy_log 和 mlr_hwy 的诊断图（特别是 Residuals vs Fitted 和 Scale-Location）。对数变换是否改善了异方差问题？对残差正态性是否有影响？\n(思考) 对数变换后，系数的解释发生了什么变化？",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>第十周实验：模型改进与选择实践</span>"
    ]
  },
  {
    "objectID": "week10_lab.html#处理多重共线性实践",
    "href": "week10_lab.html#处理多重共线性实践",
    "title": "第十周实验：模型改进与选择实践",
    "section": "4. 处理多重共线性实践",
    "text": "4. 处理多重共线性实践\n场景: prob_model 模型的 VIF 诊断显示 x1 和 x2 存在严重共线性。\n任务:\n\n回顾 prob_model 的 VIF 值。\n创建一个新模型 prob_model_nox2，从 prob_model 中移除共线性严重的变量之一（例如 x2）。\n查看新模型 prob_model_nox2 的摘要 (summary()) 和 VIF 值。\n比较 prob_model 和 prob_model_nox2 的结果：\n\nx1 的系数估计值和标准误有何变化？P 值呢？\n模型的 Adjusted R-squared 有何变化？\n移除 x2 是否解决了共线性问题？这样做是否合理（取决于 x1 和 x2 的理论重要性）？",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>第十周实验：模型改进与选择实践</span>"
    ]
  },
  {
    "objectID": "week10_lab.html#处理强影响点实践",
    "href": "week10_lab.html#处理强影响点实践",
    "title": "第十周实验：模型改进与选择实践",
    "section": "5. 处理强影响点实践",
    "text": "5. 处理强影响点实践\n场景: prob_model 的 Cook’s D 诊断显示第一个观测点是强影响点。\n任务:\n\n找出 prob_model 中 Cook’s D 大于某个阈值（例如 0.5 或 1）的点的索引。\n创建一个新模型 prob_model_noinf，从 prob_data 中移除这些强影响点后重新拟合模型 (y ~ x1 + x2 + x3)。\n比较 prob_model 和 prob_model_noinf 的模型摘要 (summary())。\n\n系数估计值（特别是截距和受影响变量的系数）是否有显著变化？\n标准误和 P 值是否有变化？\nR-squared 和 Adjusted R-squared 是否有变化？\n\n讨论: 移除这个点对模型结果产生了多大的影响？你认为应该移除它吗？（强调移除的谨慎性）。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>第十周实验：模型改进与选择实践</span>"
    ]
  },
  {
    "objectID": "week10_lab.html#交互项实践",
    "href": "week10_lab.html#交互项实践",
    "title": "第十周实验：模型改进与选择实践",
    "section": "6. 交互项实践",
    "text": "6. 交互项实践\n场景: 我们想探究 mpg 数据集中，发动机排量 (displ) 对高速公路里程 (hwy) 的影响是否会因为驱动方式 (drv) 的不同而不同。\n任务:\n\n拟合一个包含 displ 和 drv 主效应以及它们之间交互项的模型 hwy ~ displ * drv。将模型存储在 interaction_hwy 中。\n查看模型摘要 summary(interaction_hwy)。\n解读交互项系数:\n\n找到 displ:drv4 和 displ:drvr 的系数和 P 值。\n解释 displ:drv4 系数的含义（它如何调节 displ 的效应？）。\n这些交互项是否统计显著？这说明了什么？\n\n使用 interactions::interact_plot() 可视化交互效应。观察不同 drv 水平下 displ 对 hwy 的拟合线斜率是否不同。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>第十周实验：模型改进与选择实践</span>"
    ]
  },
  {
    "objectID": "week10_lab.html#模型比较实践-aicbic",
    "href": "week10_lab.html#模型比较实践-aicbic",
    "title": "第十周实验：模型改进与选择实践",
    "section": "7. 模型比较实践 (AIC/BIC)",
    "text": "7. 模型比较实践 (AIC/BIC)\n场景: 比较我们为 hwy 建立的几个模型：\n\nslr_hwy_displ &lt;- lm(hwy ~ displ, data = mpg) (仅排量)\nmlr_hwy (hwy ~ displ + cyl + drv) (排量+气缸+驱动)\nmlr_hwy_log (log(hwy) ~ displ + cyl + drv) (因变量对数变换) - 注意：AIC/BIC 不能直接比较因变量不同的模型！\ninteraction_hwy (hwy ~ displ * drv) (排量与驱动交互)\n\n任务:\n\n拟合 slr_hwy_displ 模型。\n使用 AIC() 和 BIC() 函数比较 因变量相同 的模型：slr_hwy_displ, mlr_hwy, interaction_hwy。\n哪个模型的 AIC/BIC 值最低？这表明哪个模型在拟合优度和复杂度之间取得了更好的平衡？",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>第十周实验：模型改进与选择实践</span>"
    ]
  },
  {
    "objectID": "week10_lab.html#实验总结",
    "href": "week10_lab.html#实验总结",
    "title": "第十周实验：模型改进与选择实践",
    "section": "8. 实验总结",
    "text": "8. 实验总结\n在本实验中，我们基于模型诊断的结果，实践了多种模型改进策略，包括变量变换、处理多重共线性和强影响点。我们还学习了如何添加和解释交互项，以捕捉更复杂的变量关系。最后，我们使用 AIC 和 BIC 作为参考指标，比较了不同模型的相对优劣。模型构建是一个迭代的过程，需要结合诊断、改进和选择，才能得到一个相对可靠和有效的模型。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>第十周实验：模型改进与选择实践</span>"
    ]
  },
  {
    "objectID": "week11_lab.html",
    "href": "week11_lab.html",
    "title": "第十一周实验：Logistic 回归拟合与解释",
    "section": "",
    "text": "1. 目标\n本实验旨在练习使用 R 拟合二元 Logistic 回归模型，并重点掌握其系数（特别是优势比 Odds Ratio）的解释。同时，开始构思综合实践项目。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>第十一周实验：Logistic 回归拟合与解释</span>"
    ]
  },
  {
    "objectID": "week11_lab.html#目标",
    "href": "week11_lab.html#目标",
    "title": "第十一周实验：Logistic 回归拟合与解释",
    "section": "",
    "text": "理解 Logistic 回归的应用场景（预测二元分类结果）。\n准备用于 Logistic 回归的数据（确保因变量是因子或 0/1）。\n使用 glm() 函数拟合 Logistic 回归模型 (family = binomial)。\n解读 summary(glm()) 的输出，特别是系数、z 值和 P 值。\n计算并解释优势比 (OR = exp(coef)) 及其置信区间。\n开始思考并初步确定综合实践项目的选题和研究问题。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>第十一周实验：Logistic 回归拟合与解释</span>"
    ]
  },
  {
    "objectID": "week11_lab.html#数据准备",
    "href": "week11_lab.html#数据准备",
    "title": "第十一周实验：Logistic 回归拟合与解释",
    "section": "2. 数据准备",
    "text": "2. 数据准备\n我们将使用 ISLR 包中的 Default 数据集（需要先安装 ISLR 包）。该数据集包含了关于信用卡客户是否违约 (default) 的信息，以及他们的收入 (income)、余额 (balance) 和是否是学生 (student) 等变量。\n\nlibrary(tidyverse)\n# install.packages(\"ISLR\") # 如果尚未安装\nlibrary(ISLR)     # 包含 Default 数据集\nlibrary(broom)    # 用于 tidy() 函数提取模型结果\n\n# 加载并查看 Default 数据集\ndata(\"Default\")\nglimpse(Default)\n\n#&gt; Rows: 10,000\n#&gt; Columns: 4\n#&gt; $ default &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, No, No, No, No, No…\n#&gt; $ student &lt;fct&gt; No, Yes, No, No, No, Yes, No, Yes, No, No, Yes, Yes, No, No, N…\n#&gt; $ balance &lt;dbl&gt; 729.5265, 817.1804, 1073.5492, 529.2506, 785.6559, 919.5885, 8…\n#&gt; $ income  &lt;dbl&gt; 44361.625, 12106.135, 31767.139, 35704.494, 38463.496, 7491.55…\n\nsummary(Default)\n\n#&gt;  default    student       balance           income     \n#&gt;  No :9667   No :7056   Min.   :   0.0   Min.   :  772  \n#&gt;  Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  \n#&gt;                        Median : 823.6   Median :34553  \n#&gt;                        Mean   : 835.4   Mean   :33517  \n#&gt;                        3rd Qu.:1166.3   3rd Qu.:43808  \n#&gt;                        Max.   :2654.3   Max.   :73554\n\n# 我们的目标是预测客户是否会违约 (default = Yes)\n# 检查因变量 default 的类型和水平\nclass(Default$default)\n\n#&gt; [1] \"factor\"\n\nlevels(Default$default) # No 是第一个水平 (参照组, 0), Yes 是第二个水平 (目标事件, 1)\n\n#&gt; [1] \"No\"  \"Yes\"",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>第十一周实验：Logistic 回归拟合与解释</span>"
    ]
  },
  {
    "objectID": "week11_lab.html#拟合简单-logistic-回归模型",
    "href": "week11_lab.html#拟合简单-logistic-回归模型",
    "title": "第十一周实验：Logistic 回归拟合与解释",
    "section": "3. 拟合简单 Logistic 回归模型",
    "text": "3. 拟合简单 Logistic 回归模型\n场景: 我们首先尝试只用信用卡余额 (balance) 来预测客户是否会违约 (default)。\n任务:\n\n使用 glm() 拟合一个简单 Logistic 回归模型，公式为 default ~ balance，family 设置为 binomial。将模型存储在 logistic_simple 中。\n使用 summary() 查看模型结果。\n解读系数:\n\n解释截距 (Intercept) 的对数优势 (log-odds) 含义。\n解释 balance 系数的对数优势 (log-odds) 含义。\nbalance 对违约的影响是否统计显著？\n\n计算并解释优势比 (OR):\n\n计算 balance 系数的优势比 (exp(coef))。\n解释该 OR 的含义（信用卡余额每增加一个单位，违约的优势变为原来的多少倍？）。\n计算 OR 的置信区间 (exp(confint(model)))。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>第十一周实验：Logistic 回归拟合与解释</span>"
    ]
  },
  {
    "objectID": "week11_lab.html#拟合多元-logistic-回归模型",
    "href": "week11_lab.html#拟合多元-logistic-回归模型",
    "title": "第十一周实验：Logistic 回归拟合与解释",
    "section": "4. 拟合多元 Logistic 回归模型",
    "text": "4. 拟合多元 Logistic 回归模型\n场景: 现在我们加入更多预测变量：student (是否是学生) 和 income (收入)，来构建一个更全面的违约预测模型。\n任务:\n\n使用 glm() 拟合一个多元 Logistic 回归模型，公式为 default ~ balance + income + student。将模型存储在 logistic_multi 中。\n使用 summary() 查看模型结果。\n解读系数:\n\n解释 balance 的偏系数的对数优势含义（强调控制其他变量）。\n解释 income 的偏系数的对数优势含义。\n解释 studentYes 系数的对数优势含义（它是相对于哪个参照组的？）。\n判断每个变量的统计显著性。\n\n计算并解释优势比 (OR):\n\n计算所有系数的 OR。\n解释 balance 的 OR（控制收入和学生身份后）。\n解释 income 的 OR。\n解释 studentYes 的 OR（学生相对于非学生的违约优势比是多少？）。\n\n\n思考:\n\n比较简单模型和多元模型中 balance 的系数和 OR，它们有变化吗？为什么？（因为加入了控制变量 income 和 student）。\nincome 变量在多元模型中变得统计显著了（虽然效应量很小），这可能是什么原因？（可能是由于控制了其他变量后，income 的微小独立效应显现出来，或者与样本量有关）。\nstudentYes 的系数是负的，OR 小于 1，这说明学生身份是违约的“保护”因素吗？（注意：这只是在控制了 balance 和 income 之后的结果。单独看学生身份和违约的关系可能会不同，可能存在混淆）。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>第十一周实验：Logistic 回归拟合与解释</span>"
    ]
  },
  {
    "objectID": "week11_lab.html#综合实践项目构思",
    "href": "week11_lab.html#综合实践项目构思",
    "title": "第十一周实验：Logistic 回归拟合与解释",
    "section": "5. 综合实践项目构思",
    "text": "5. 综合实践项目构思\n任务:\n\n初步选题: 确定 1-2 个你感兴趣的综合实践项目主题或方向。\n寻找数据: 尝试寻找与你选题相关的公开数据集，或者思考你已有的数据。评估数据的可获取性和大致质量。\n明确研究问题: 针对你的选题和数据，提出 1-2 个具体、可衡量、可通过数据分析回答的研究问题。\n\n例如：“哪些因素（如年龄、性别、浏览时长）显著影响用户是否会点击广告？” (Logistic 回归)\n例如：“不同促销策略（A, B, C）对产品周销量的平均影响是否存在显著差异？” (ANOVA)\n例如：“空气质量指数 (AQI) 与城市交通流量之间是否存在线性关系？能否用交通流量预测 AQI？” (相关/回归)\n\n初步计划: 简要思考你可能需要进行哪些数据处理步骤？可能用到哪些主要的统计方法？\n\n准备在下周课堂上简要分享和讨论你的初步想法。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>第十一周实验：Logistic 回归拟合与解释</span>"
    ]
  },
  {
    "objectID": "week11_lab.html#实验总结",
    "href": "week11_lab.html#实验总结",
    "title": "第十一周实验：Logistic 回归拟合与解释",
    "section": "6. 实验总结",
    "text": "6. 实验总结\n在本实验中，我们使用 ISLR::Default 数据集实践了拟合简单和多元 Logistic 回归模型。我们重点练习了使用 glm(family = binomial) 函数，并深入解读了模型系数，特别是计算和解释了优势比 (Odds Ratio) 及其含义。理解 OR 是掌握 Logistic 回归的关键。同时，我们也正式启动了综合实践项目的构思阶段。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>第十一周实验：Logistic 回归拟合与解释</span>"
    ]
  },
  {
    "objectID": "week12_lab.html",
    "href": "week12_lab.html",
    "title": "第十二周实验：Logistic 回归评估与模型比较",
    "section": "",
    "text": "1. 目标\n本实验旨在练习评估 Logistic 回归模型的性能，理解各种评估指标的含义和计算方法，并初步实践模型比较。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>第十二周实验：Logistic 回归评估与模型比较</span>"
    ]
  },
  {
    "objectID": "week12_lab.html#目标",
    "href": "week12_lab.html#目标",
    "title": "第十二周实验：Logistic 回归评估与模型比较",
    "section": "",
    "text": "从拟合的 Logistic 回归模型生成预测概率和预测类别。\n使用 table() 或 yardstick::conf_mat() 创建和解读混淆矩阵。\n使用 yardstick 包计算并解释 Accuracy, Precision, Recall, Specificity, F1-Score。\n理解不同评估指标的侧重点和适用场景。\n使用 yardstick 包绘制 ROC 曲线并计算 AUC 值，评估模型的整体区分能力。\n使用 AIC() 和 BIC() 比较不同 Logistic 回归模型的相对优劣。\n讨论综合实践项目选题和初步 EDA。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>第十二周实验：Logistic 回归评估与模型比较</span>"
    ]
  },
  {
    "objectID": "week12_lab.html#数据与模型准备",
    "href": "week12_lab.html#数据与模型准备",
    "title": "第十二周实验：Logistic 回归评估与模型比较",
    "section": "2. 数据与模型准备",
    "text": "2. 数据与模型准备\n我们将继续使用上周的 ISLR::Default 数据集和拟合的多元 Logistic 回归模型 logistic_multi。\n\nlibrary(tidyverse)\n# install.packages(\"ISLR\") # 如果尚未安装\nlibrary(ISLR)\nlibrary(broom)\n# install.packages(\"yardstick\") # 如果尚未安装\nlibrary(yardstick) # For metrics: conf_mat, accuracy, precision, recall, f_meas, spec\n\n# 加载数据并回顾模型\ndata(\"Default\")\nlogistic_multi &lt;- glm(default ~ balance + income + student, data = Default, family = binomial)",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>第十二周实验：Logistic 回归评估与模型比较</span>"
    ]
  },
  {
    "objectID": "week12_lab.html#混淆矩阵与基础指标",
    "href": "week12_lab.html#混淆矩阵与基础指标",
    "title": "第十二周实验：Logistic 回归评估与模型比较",
    "section": "3. 混淆矩阵与基础指标",
    "text": "3. 混淆矩阵与基础指标\n任务:\n\n使用 yardstick::conf_mat() 创建混淆矩阵。\n手动识别混淆矩阵中的 TP, FN, FP, TN (假设 “Yes” 是 Positive 类)。\n使用 yardstick 函数计算以下指标，并解释其含义：\n\n\nAccuracy\nPrecision\nRecall\nSpecificity\nF1-Score\n\n思考:\n\n在这个 Default 数据集中，类别是否平衡？（提示：查看 summary(Default$default) 或 table(Default$default)）。如果不平衡，Accuracy 是一个好的评估指标吗？为什么？\n对于信用卡违约预测，你认为 Precision 和 Recall 哪个更重要？或者说，误报 (FP - 将未违约者预测为违约) 和漏报 (FN - 将违约者预测为未违约) 哪个代价更大？这会如何影响你对模型的评估侧重？",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>第十二周实验：Logistic 回归评估与模型比较</span>"
    ]
  },
  {
    "objectID": "week12_lab.html#roc-曲线与-auc",
    "href": "week12_lab.html#roc-曲线与-auc",
    "title": "第十二周实验：Logistic 回归评估与模型比较",
    "section": "4. ROC 曲线与 AUC",
    "text": "4. ROC 曲线与 AUC\n任务:\n\n使用 yardstick::roc_curve() 函数，根据真实观测值和预测概率创建 ROC 对象。确保正确指定 levels 参数。\n使用 yardstick::roc_auc() 计算 AUC 值。\n解读 AUC 值的含义（模型的整体区分能力如何？）。\n使用 yardstick::autoplot() 绘制 ROC 曲线，并添加对角线和 AUC 值标注。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>第十二周实验：Logistic 回归评估与模型比较</span>"
    ]
  },
  {
    "objectID": "week12_lab.html#模型比较-aicbic",
    "href": "week12_lab.html#模型比较-aicbic",
    "title": "第十二周实验：Logistic 回归评估与模型比较",
    "section": "5. 模型比较 (AIC/BIC)",
    "text": "5. 模型比较 (AIC/BIC)\n场景: 比较上周拟合的两个 Logistic 回归模型：\n\nlogistic_simple: default ~ balance + student\nlogistic_multi: default ~ balance + income + student\n\n任务:\n\n重新拟合 logistic_simple 模型（如果需要）。\n使用 AIC() 和 BIC() 比较这两个模型。\n哪个模型的 AIC 和 BIC 更低？根据这些信息准则，哪个模型相对更优？这是否符合你对模型复杂度和拟合效果的直观感受？",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>第十二周实验：Logistic 回归评估与模型比较</span>"
    ]
  },
  {
    "objectID": "week12_lab.html#综合实践项目进展讨论",
    "href": "week12_lab.html#综合实践项目进展讨论",
    "title": "第十二周实验：Logistic 回归评估与模型比较",
    "section": "6. 综合实践项目进展讨论",
    "text": "6. 综合实践项目进展讨论\n任务:\n\n分享你的选题: 向小组或全班简要介绍你选择的综合实践项目主题、研究问题和数据来源。\n展示初步 EDA: 展示你使用 ggplot2 等工具进行的初步数据探索结果（关键变量分布、变量关系图等）。\n讨论遇到的问题: 分享你在数据获取、清理或初步探索中遇到的困难或疑问。\n接受反馈: 听取老师、助教和同学的建议。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>第十二周实验：Logistic 回归评估与模型比较</span>"
    ]
  },
  {
    "objectID": "week12_lab.html#实验总结",
    "href": "week12_lab.html#实验总结",
    "title": "第十二周实验：Logistic 回归评估与模型比较",
    "section": "7. 实验总结",
    "text": "7. 实验总结\n在本实验中，我们深入实践了 Logistic 回归模型的评估。我们学会了如何生成预测、构建混淆矩阵，并计算和解释了 Accuracy, Precision, Recall, Specificity, F1-Score 等关键指标。我们还掌握了使用 ROC 曲线和 AUC 值来评估模型整体区分能力的方法。最后，我们练习了使用 AIC/BIC 来比较不同 Logistic 回归模型。这些评估技能对于理解和选择合适的分类模型至关重要。同时，我们也推进了综合实践项目的选题和初步探索。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>第十二周实验：Logistic 回归评估与模型比较</span>"
    ]
  },
  {
    "objectID": "week13_lab.html",
    "href": "week13_lab.html",
    "title": "第13周实验：深入探索nycflights13 - AI与Quarto实战",
    "section": "",
    "text": "实验导览：深入探索 nycflights13\n欢迎来到第13周的进阶实验！本次实验我们将使用著名的 nycflights13 数据集，它包含了2013年从纽约市三大机场出发的所有航班的详细信息。这个数据集的复杂性和丰富性为我们提供了绝佳的机会，来实践并深化本周学习的AI辅助分析和Quarto可重复报告技能。\n实验目标：\n准备工作：",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>第13周实验：深入探索nycflights13 - AI与Quarto实战</span>"
    ]
  },
  {
    "objectID": "week13_lab.html#任务1.1-ai辅助理解数据结构与提出探索性问题",
    "href": "week13_lab.html#任务1.1-ai辅助理解数据结构与提出探索性问题",
    "title": "第13周实验：深入探索nycflights13 - AI与Quarto实战",
    "section": "任务1.1: AI辅助理解数据结构与提出探索性问题",
    "text": "任务1.1: AI辅助理解数据结构与提出探索性问题\nflights 数据集包含很多列。\n\n向AI提问以理解关键变量：\n\nPrompt示例： “我正在使用R中的nycflights13::flights数据集。请解释以下几个关键列的含义：dep_delay, arr_delay, carrier, origin, dest, air_time, distance。特别是，dep_delay 和 arr_delay 是如何计算的？正值和负值分别代表什么？”\n\n# 记录你向AI提问关于变量含义的Prompt和AI的回答要点：\n# Prompt:\n#\n# AI回答要点:\n#\nAI辅助生成探索性问题：\n\nPrompt示例： “基于nycflights13::flights数据集的主要变量（如起飞/到达延误、航空公司、出发地/目的地、飞行时间、距离、月份、星期几等），请帮我提出至少5个有趣的、可以通过数据分析来探索的问题。这些问题应该能帮助我们了解航班延误的模式、航空公司的表现或航线的特点。”\n\n# 记录AI为你生成的探索性问题：\n# 1.\n# 2.\n# 3.\n# 4.\n# 5.\n# (选择你认为最有趣的2-3个问题进行后续分析)",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>第13周实验：深入探索nycflights13 - AI与Quarto实战</span>"
    ]
  },
  {
    "objectID": "week13_lab.html#任务1.2-ai辅助数据清洗与转换-针对你选择的问题",
    "href": "week13_lab.html#任务1.2-ai辅助数据清洗与转换-针对你选择的问题",
    "title": "第13周实验：深入探索nycflights13 - AI与Quarto实战",
    "section": "任务1.2: AI辅助数据清洗与转换 (针对你选择的问题)",
    "text": "任务1.2: AI辅助数据清洗与转换 (针对你选择的问题)\n根据你在任务1.1中选择的探索性问题，你可能需要对数据进行一些清洗或转换。\n示例场景： 假设你选择的一个问题是“哪个航空公司的平均出发延误时间最长？”\n\n思考需要的数据和潜在问题：\n\n我们需要 carrier 和 dep_delay 列。\ndep_delay 可能包含NA值（例如，航班取消）。在计算平均延误时，我们应该如何处理这些NA？\n\n构建Prompt请求数据处理代码：\n\nPrompt示例： “我正在使用nycflights13::flights数据集，想找出每个航空公司 (carrier) 的平均出发延误时间 (dep_delay)。请帮我写一段dplyr代码完成以下步骤：\n\n移除dep_delay为NA的行。\n按carrier分组。\n计算每个carrier的平均dep_delay和航班数量。\n按平均延误时间降序排列结果。\n我还想将航空公司的代码 (carrier) 替换为完整的航空公司名称，你能告诉我如何通过nycflights13::airlines数据框来实现这个合并吗？”\n\n\n# 记录你的Prompt和AI生成的代码：\n# Prompt:\n#\n# AI生成代码 (粘贴并测试):\n# library(nycflights13)\n# data(airlines) # 需要加载airlines数据\n#\n# carrier_delay_summary &lt;- flights %&gt;%\n#   filter(!is.na(dep_delay)) %&gt;%\n#   group_by(carrier) %&gt;%\n#   summarise(\n#     avg_dep_delay = mean(dep_delay),\n#     num_flights = n()\n#   ) %&gt;%\n#   left_join(airlines, by = \"carrier\") %&gt;% # 合并航空公司名称\n#   arrange(desc(avg_dep_delay)) %&gt;%\n#   select(name, carrier, avg_dep_delay, num_flights) # 选择并重排序列\n#\n# print(carrier_delay_summary)\n\n评估AI代码的正确性和效率。AI是否正确处理了NA和合并操作？\n\n\n练习： 针对你自己选择的另一个探索性问题，思考需要的数据清理/转换步骤，并尝试让AI生成相应的代码。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>第13周实验：深入探索nycflights13 - AI与Quarto实战</span>"
    ]
  },
  {
    "objectID": "week13_lab.html#任务1.3-ai辅助复杂可视化",
    "href": "week13_lab.html#任务1.3-ai辅助复杂可视化",
    "title": "第13周实验：深入探索nycflights13 - AI与Quarto实战",
    "section": "任务1.3: AI辅助复杂可视化",
    "text": "任务1.3: AI辅助复杂可视化\n示例场景： 探索一天中不同时段的航班出发延误情况。\n\n数据准备 (可能需要AI辅助)：\n\n我们可能需要从 dep_time (格式如517代表5:17 AM) 中提取小时。\nPrompt示例： “在nycflights13::flights数据集中，dep_time列表示计划起飞时间（例如517代表5:17 AM）。我想创建一个新的列 dep_hour 来表示起飞的小时。请注意处理NA值。另外，dep_delay是出发延误时间。我想计算每个出发小时的平均出发延误，并统计每个小时的航班数量。请给出dplyr代码。”\n\n构建可视化Prompt：\n\nPrompt示例： “基于上一步按小时汇总的平均出发延误数据（包含dep_hour, avg_hourly_delay, hourly_flight_count列），请帮我用ggplot2创建一个组合图：\n\n用条形图展示每个小时的航班数量 (hourly_flight_count)。\n在同一张图上（可能使用双Y轴，或者将条形图作为背景），用折线图展示每个小时的平均出发延误 (avg_hourly_delay)。\n确保图形有清晰的标题和轴标签。”\n\n\n# 记录你的Prompt和AI生成的ggplot2代码 (可能需要多次迭代调整才能得到理想效果)：\n# Prompt for data prep:\n#\n# AI code for data prep (test and modify):\n# flights_with_hour &lt;- flights %&gt;%\n#   filter(!is.na(dep_time), !is.na(dep_delay)) %&gt;%\n#   mutate(dep_hour = dep_time %/% 100) # 简单提取小时\n#\n# hourly_delay_summary &lt;- flights_with_hour %&gt;%\n#   group_by(dep_hour) %&gt;%\n#   summarise(\n#     avg_hourly_delay = mean(dep_delay),\n#     hourly_flight_count = n()\n#   ) %&gt;%\n#   filter(hourly_flight_count &gt; 100) # 过滤掉航班过少的小时，使图形更稳定\n#\n# Prompt for visualization:\n#\n# AI code for visualization (test and modify):\n# # 简单的双Y轴实现可能比较复杂，AI或许会建议分面或颜色映射\n# # 例如，一个可能的简化版是：\n# ggplot(hourly_delay_summary, aes(x = dep_hour)) +\n#   geom_col(aes(y = hourly_flight_count), fill = \"lightblue\", alpha = 0.7) +\n#   geom_line(aes(y = avg_hourly_delay * 10), color = \"red\", size = 1) + # 乘以一个因子以便在同一尺度上显示\n#   scale_y_continuous(\n#     name = \"Hourly Flight Count\",\n#     sec.axis = sec_axis(~./10, name = \"Average Departure Delay (min)\") # 创建第二个Y轴\n#   ) +\n#   labs(title = \"Hourly Flight Departures and Average Delays from NYC\",\n#        x = \"Hour of Departure\",\n#        caption = \"Note: Delay axis scaled by factor of 10 for visualization\") +\n#   theme_minimal()\n\n挑战： 双Y轴图有时难以解读。和AI讨论是否有其他更好的可视化方式来展示这两个变量的关系（例如，将延误时间用颜色深浅映射到条形图上，或者使用分面图）。\n\n\n练习： 针对你自己选择的探索性问题，尝试让AI辅助你创建一个有洞察力的、可能比较复杂的可视化。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>第13周实验：深入探索nycflights13 - AI与Quarto实战</span>"
    ]
  },
  {
    "objectID": "week13_lab.html#任务2.1-创建并配置-nycflights13-项目的quarto文档",
    "href": "week13_lab.html#任务2.1-创建并配置-nycflights13-项目的quarto文档",
    "title": "第13周实验：深入探索nycflights13 - AI与Quarto实战",
    "section": "任务2.1: 创建并配置 nycflights13 项目的Quarto文档",
    "text": "任务2.1: 创建并配置 nycflights13 项目的Quarto文档\n\n新建Quarto文档：\n\nTitle: “NYC Flights 2013: 延误模式与航空公司表现分析” (或根据你的分析焦点命名)\nAuthor: 你的名字\n保存为 nycflights_analysis.qmd。\n\n配置YAML头部：\n---\ntitle: \"NYC Flights 2013: 延误模式与航空公司表现分析\"\nauthor: \"你的名字\"\ndate: \"today\"\nformat:\n  html:\n    toc: true\n    toc-depth: 3\n    number-sections: true # 给章节编号\n    code-fold: true\n    code-tools: true\n    theme: lumen # 或其他你喜欢的主题\neditor: source\nexecute:\n  echo: true\n  warning: false\n  message: false\n  error: true # 在报告中显示错误，方便调试\nbibliography: references.bib # 如果有参考文献，可以添加\ncsl: apa.csl #参考文献格式\n---\n(注意：bibliography 和 csl 是可选的，用于更正式的报告。)",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>第13周实验：深入探索nycflights13 - AI与Quarto实战</span>"
    ]
  },
  {
    "objectID": "week13_lab.html#任务2.2-规划报告结构与填充内容",
    "href": "week13_lab.html#任务2.2-规划报告结构与填充内容",
    "title": "第13周实验：深入探索nycflights13 - AI与Quarto实战",
    "section": "任务2.2: 规划报告结构与填充内容",
    "text": "任务2.2: 规划报告结构与填充内容\n根据你的分析焦点，规划报告的章节。以下是一个示例结构，你可以根据自己的分析进行调整：\n# 1. 引言\n\n*   项目背景：简要介绍`nycflights13`数据集。\n*   研究问题/分析目标：明确你本报告要探索的核心问题 (例如，哪些因素影响航班延误？不同航空公司的准点率如何？特定航线有何特点？)。\n\n# 2. 数据准备与概览\n\n## 2.1 加载所需R包与数据\n```{r setup-data, echo=TRUE}\n# library(tidyverse)\n# library(nycflights13)\n# library(skimr)\n# library(lubridate)\n# library(knitr)\n# library(ggrepel)\n# data(flights)\n# data(airports)\n# data(airlines)\n# data(weather)\n# data(planes)\n```\n*简要说明加载的数据集。*\n\n## 2.2 数据初步探查\n```{r initial-glimpse, echo=TRUE}\n# glimpse(flights)\n# kable(head(flights, 5), caption = \"Flights数据集前5行预览\")\n```\n*对`flights`数据集的关键变量进行初步说明 (可结合AI在任务1.1的回答)。*\n\n# 3. 航班延误分析 (示例章节，根据你的焦点调整)\n\n## 3.1 延误的整体情况\n```{r overall-delay-stats, echo=TRUE}\n# # 计算总体延误统计，例如平均延误、延误百分比等\n# flights %&gt;%\n#   summarise(\n#     avg_dep_delay = mean(dep_delay, na.rm = TRUE),\n#     avg_arr_delay = mean(arr_delay, na.rm = TRUE),\n#     prop_dep_delayed = mean(dep_delay &gt; 0, na.rm = TRUE),\n#     prop_arr_delayed = mean(arr_delay &gt; 0, na.rm = TRUE)\n#   ) %&gt;%\n#   kable(caption = \"航班总体延误情况\", digits = 2)\n```\n*解读总体延误情况。*\n\n## 3.2 不同因素对出发延误的影响\n\n### 3.2.1 按月份/季节分析延误\n```{r delay-by-month, echo=TRUE, fig.cap=\"每月平均出发延误与航班量\"}\n# # 创建 month 列\n# flights_with_month &lt;- flights %&gt;% \n#   filter(!is.na(dep_delay)) %&gt;%\n#   mutate(month = factor(month, levels = 1:12, labels = month.abb))\n# \n# monthly_delay_summary &lt;- flights_with_month %&gt;%\n#   group_by(month) %&gt;%\n#   summarise(\n#     avg_dep_delay = mean(dep_delay),\n#     num_flights = n()\n#   )\n# \n# # 可视化 (例如，条形图显示航班量，折线图显示平均延误)\n# ggplot(monthly_delay_summary, aes(x = month)) +\n#   geom_col(aes(y = num_flights, group = 1), fill = \"skyblue\", alpha = 0.7) + # group=1 for month factor\n#   geom_line(aes(y = avg_dep_delay * (max(monthly_delay_summary$num_flights)/max(monthly_delay_summary$avg_dep_delay, na.rm=TRUE))/2 , group = 1), color = \"red\", size = 1.2) + # 调整缩放因子\n#   scale_y_continuous(\n#     name = \"月航班数量\",\n#     sec.axis = sec_axis(~. * (max(monthly_delay_summary$avg_dep_delay, na.rm=TRUE) / (max(monthly_delay_summary$num_flights)/2)), name = \"平均出发延误 (分钟)\")\n#   ) +\n#   labs(title = \"每月航班量与平均出发延误 (NYC, 2013)\", x = \"月份\")\n```\n*解读月份/季节对延误的影响。*\n\n### 3.2.2 按航空公司分析延误\n```{r delay-by-carrier, echo=TRUE, fig.cap=\"各航空公司平均出发延误（至少飞行1000次）\"}\n# # 使用任务1.2中生成的 carrier_delay_summary (或重新生成)\n# # 确保 airlines 数据框已加载并合并\n# carrier_delay_plot_data &lt;- flights %&gt;%\n#   filter(!is.na(dep_delay), dep_delay &gt; -60) %&gt;% # 过滤掉一些极端提前起飞的情况\n#   group_by(carrier) %&gt;%\n#   summarise(\n#     avg_dep_delay = mean(dep_delay),\n#     num_flights = n()\n#   ) %&gt;%\n#   left_join(airlines, by = \"carrier\") %&gt;%\n#   filter(num_flights &gt; 1000) %&gt;% # 筛选航班较多的航空公司\n#   mutate(name = reorder(name, avg_dep_delay)) # 按平均延误排序\n# \n# ggplot(carrier_delay_plot_data, aes(x = name, y = avg_dep_delay, fill = avg_dep_delay)) +\n#   geom_col() +\n#   geom_text(aes(label = round(avg_dep_delay, 1)), hjust = -0.2, size = 3) +\n#   coord_flip() + # 水平条形图更易读\n#   scale_fill_gradient(low = \"green\", high = \"red\") +\n#   labs(title = \"各航空公司平均出发延误 (NYC, 2013)\",\n#        x = \"航空公司\", y = \"平均出发延误 (分钟)\", fill = \"平均延误\") +\n#   theme_minimal() +\n#   theme(legend.position = \"none\")\n```\n*解读不同航空公司的延误表现。*\n\n*(继续添加其他你感兴趣的分析，例如按出发机场、目的地、一天中的时段、星期几等分析延误。每个分析点都应该包含：*\n*   *简要的文字说明你的分析目的。*\n*   *执行数据处理和可视化的R代码块 (确保`echo=TRUE`，并为图表添加`fig.cap`)。*\n*   *对图表或结果的文字解读，阐述你的发现。*\n*   *在这个过程中，遇到R代码难题或需要可视化灵感时，积极使用AI辅助。*)*\n\n# 4. (可选) 深入探索：特定航线或飞机型号分析\n\n*   例如，选择一条热门航线 (如 NYC 到 LAX)，分析其延误特点。\n*   或者，分析不同飞机型号 (`planes`数据) 与飞行表现 (如速度、延误) 的关系。这需要连接 `flights` 和 `planes` 数据框。\n    ```{r join-planes-example, eval=FALSE}\n    # # 连接 flights 和 planes (需要处理 tailnum 的NA)\n    # flights_with_plane_data &lt;- flights %&gt;%\n    #   filter(!is.na(tailnum)) %&gt;%\n    #   left_join(select(planes, tailnum, type, manufacturer, model, year), by = \"tailnum\")\n    # \n    # # 然后可以按飞机制造商或型号进行分析...\n    ```\n\n# 5. 结论与展望\n\n*   总结你本报告中的主要发现。\n*   提出基于分析的可能结论或建议。\n*   指出未来可以进一步探索的方向。\n\n---",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>第13周实验：深入探索nycflights13 - AI与Quarto实战</span>"
    ]
  },
  {
    "objectID": "week13_lab.html#任务2.3-填充渲染与迭代",
    "href": "week13_lab.html#任务2.3-填充渲染与迭代",
    "title": "第13周实验：深入探索nycflights13 - AI与Quarto实战",
    "section": "任务2.3: 填充、渲染与迭代",
    "text": "任务2.3: 填充、渲染与迭代\n\n逐步填充内容：\n\n将你在Part 1中进行的AI辅助探索（或你自己独立完成的分析）的代码和发现，系统地组织到你的Quarto报告的相应章节中。\n对于每个分析点，确保有清晰的目标说明、R代码块 (带注释和合适的选项)、以及结果解读。\n遇到编码或分析难题时，使用AI辅助。 例如，如果你想计算特定条件下航班准点率，但不确定如何用dplyr实现，可以向AI提问。\n\nAI辅助撰写报告文本：\n\n描述复杂图表： “我绘制了一个显示不同航空公司每月平均延误时间的热力图。请帮我写一段文字，描述如何解读这个热力图，以及它可能揭示的模式。”\n总结分析发现： “基于对纽约航班数据的分析，我发现月份和航空公司是影响出发延误的两个重要因素。具体来说，[总结你的关键发现]。请帮我将这些发现组织成一段流畅的总结性文字，用于报告的结论部分。”\n润色语言： 如果你已经写了草稿，可以让AI帮你检查语法、改进表达，使其更专业。\n\n频繁渲染与迭代：\n\n在写作过程中，经常点击 “Render” 按钮生成HTML报告。\n检查报告的结构、代码的运行、图表的显示、文本的流畅性。\n根据渲染结果，不断修改和完善你的 .qmd 文件。这是一个迭代的过程。\n\n\n挑战与思考：\n\nnycflights13 数据集中还有 weather 数据。你能否将其与 flights 数据结合，探索天气对航班延误的影响？这可能需要你向AI咨询如何按日期和机场合并这两个数据集，并进行相应的分析和可视化。\n尝试使用 DT 包 (DT::datatable()) 来创建交互式的HTML表格，以更好地展示某些摘要数据。",
    "crumbs": [
      "实验",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>第13周实验：深入探索nycflights13 - AI与Quarto实战</span>"
    ]
  },
  {
    "objectID": "统计学与R语言复习练习题集.html",
    "href": "统计学与R语言复习练习题集.html",
    "title": "统计学与R语言复习练习题集",
    "section": "",
    "text": "使用说明\n本练习题集基于《统计学与R语言》期末试题内容设计，包含：\n建议按题型分别练习，注意时间控制。每道题目都是原创设计，与真题相似但不重复。",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>统计学与R语言复习练习题集</span>"
    ]
  },
  {
    "objectID": "统计学与R语言复习练习题集.html#使用说明",
    "href": "统计学与R语言复习练习题集.html#使用说明",
    "title": "统计学与R语言复习练习题集",
    "section": "",
    "text": "选择题 100 道：涵盖R语言基础、统计概念、数据分析方法\n判断题 50 道：重点考查概念理解和常见误区\n简答题 20 道：综合应用和分析解释能力",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>统计学与R语言复习练习题集</span>"
    ]
  },
  {
    "objectID": "统计学与R语言复习练习题集.html#第一部分选择题共100题",
    "href": "统计学与R语言复习练习题集.html#第一部分选择题共100题",
    "title": "统计学与R语言复习练习题集",
    "section": "第一部分：选择题（共100题）",
    "text": "第一部分：选择题（共100题）\n\n题目 1-50\n1. 在R中，以下哪个包不属于 tidyverse 核心包集合？ A. dplyr\nB. ggplot2\nC. lattice\nD. tidyr\n2. 使用 readr 包读取CSV文件时，哪个函数可以自动推断列的数据类型？ A. read.csv()\nB. read_csv()\nC. import_csv()\nD. load_csv()\n3. 在 dplyr 中，如果要根据多个条件筛选数据，正确的语法是？ A. filter(data, condition1, condition2)\nB. filter(data, condition1 & condition2)\nC. filter(data, condition1 AND condition2)\nD. 以上都正确\n4. 以下哪个描述最准确地概括了”整洁数据”的特征？ A. 数据越复杂越整洁\nB. 每个变量一列，每个观测一行，每个值一个单元格\nC. 所有数据都放在一个表格中\nD. 数据必须是数值型\n5. 在ggplot2中，要创建一个按分组变量着色的散点图，应该使用以下哪种语法？ A. ggplot(data, aes(x, y)) + geom_point(color = group_var)\nB. ggplot(data, aes(x, y, color = group_var)) + geom_point()\nC. ggplot(data, aes(x, y)) + geom_point() + color(group_var)\nD. ggplot(data) + geom_point(aes(x, y), color = group_var)\n6. 在数据中心趋势的衡量中，以下哪个指标最不容易受到极端值影响？ A. 算术平均数\nB. 几何平均数\nC. 中位数\nD. 众数\n7. 标准差的平方被称为？ A. 标准误\nB. 方差\nC. 极差\nD. 四分位距\n8. 在 ggplot2 中，geom_histogram() 和 geom_density() 的主要区别是？ A. 前者显示频数，后者显示密度\nB. 前者适合连续变量，后者适合分类变量\nC. 前者是柱状图，后者是条形图\nD. 没有本质区别\n9. 在假设检验中，显著性水平 α 通常设定为？ A. 0.01\nB. 0.05\nC. 0.10\nD. 根据具体情况确定\n10. 在独立样本t检验中，如果两组的方差不相等，应该使用？ A. 配对t检验\nB. Welch’s t检验\nC. 单样本t检验\nD. 非参数检验\n11. 当比较四个或更多独立组的均值时，最适合的统计方法是？ A. 多重t检验\nB. 配对t检验\nC. 单因素方差分析\nD. 卡方检验\n12. 在进行ANOVA之前，不需要检验的假设是？ A. 各组方差齐性\nB. 各组数据正态性\nC. 各组样本独立性\nD. 各组样本量相等\n13. Pearson相关系数的取值范围是？ A. 0到1\nB. -1到1\nC. 0到无穷大\nD. 负无穷大到正无穷大\n14. 在简单线性回归 \\(Y = \\beta_0 + \\beta_1X + \\epsilon\\) 中，\\(\\beta_0\\) 表示？ A. 斜率\nB. 截距\nC. 误差项\nD. 相关系数\n15. 决定系数 \\(R^2\\) 衡量的是？ A. 回归系数的显著性\nB. 自变量解释因变量变异的比例\nC. 残差的大小\nD. 样本量的充足性\n16. 在多元线性回归中，方差膨胀因子(VIF)用于检测？ A. 异方差性\nB. 多重共线性\nC. 残差正态性\nD. 自相关性\n17. Logistic回归适用于哪种类型的因变量？ A. 连续型变量\nB. 分类变量\nC. 有序变量\nD. 以上都可以\n18. 在Logistic回归中，如果某变量的优势比(OR)为1.5，意味着？ A. 该变量增加1个单位，发生比增加50%\nB. 该变量增加1个单位，概率增加1.5倍\nC. 该变量增加1个单位，优势变为原来的1.5倍\nD. 该变量对结果无影响\n19. ROC曲线下面积(AUC)的取值范围是？ A. 0到1\nB. -1到1\nC. 0.5到1\nD. 0到无穷大\n20. 卡方独立性检验主要用于分析？ A. 两个连续变量的关系\nB. 两个分类变量的关系\nC. 一个连续变量和一个分类变量的关系\nD. 多个连续变量的关系\n21. 在卡方检验中，期望频数的最低要求通常是？ A. 至少为1，80%的单元格大于5\nB. 所有单元格都大于10\nC. 所有单元格都大于5\nD. 没有具体要求\n22. 在R中，mutate() 函数的主要功能是？ A. 筛选行\nB. 选择列\nC. 创建或修改变量\nD. 数据排序\n23. 中心极限定理的核心内容是？ A. 所有数据都服从正态分布\nB. 样本均值的抽样分布趋近正态分布\nC. 样本量越大，数据越接近正态分布\nD. 总体必须服从正态分布\n24. 置信区间的正确解释是？ A. 总体参数落在该区间内的概率\nB. 样本统计量落在该区间内的概率\nC. 重复抽样时，该比例的区间包含总体参数\nD. 估计的精确度\n25. 在 tidyr 包中，将宽格式数据转换为长格式的函数是？ A. pivot_wider()\nB. pivot_longer()\nC. spread()\nD. separate()\n26. 在 dplyr 中，group_by() 函数通常与哪个函数配合使用？ A. filter()\nB. select()\nC. summarise()\nD. arrange()\n27. 箱线图中的中线代表？ A. 均值\nB. 中位数\nC. 众数\nD. 第一四分位数\n28. 在假设检验中，第二类错误是指？ A. 拒绝了真的原假设\nB. 接受了假的原假设\nC. 接受了真的原假设\nD. 拒绝了假的原假设\n29. 当进行多重比较时，为了控制整体错误率，通常采用？ A. Bonferroni校正\nB. 增大样本量\nC. 降低显著性水平\nD. 以上都可以\n30. 在线性回归的残差分析中，如果残差图呈现漏斗状，说明违反了？ A. 线性关系假设\nB. 残差正态性假设\nC. 同方差性假设\nD. 残差独立性假设\n31. 在R中，检验数据正态性的函数是？ A. norm.test()\nB. shapiro.test()\nC. normal.test()\nD. qqnorm()\n32. ggplot2 中添加图例标题的函数是？ A. ggtitle()\nB. labs()\nC. theme()\nD. scale_color_manual()\n33. 在多元回归中，调整R²相对于R²的优势是？ A. 考虑了自变量的个数\nB. 计算更简单\nC. 数值更大\nD. 解释更直观\n34. 以下哪种情况下不适合使用Pearson相关系数？ A. 两个连续变量\nB. 变量间存在非线性关系\nC. 样本量较大\nD. 数据满足正态分布\n35. 在Logistic回归中，logit变换的作用是？ A. 使概率线性化\nB. 简化计算\nC. 提高精度\nD. 消除异常值\n36. 在R中，生成随机数种子的函数是？ A. random.seed()\nB. set.seed()\nC. seed.set()\nD. random()\n37. 交叉验证的主要目的是？ A. 增加数据量\nB. 评估模型泛化能力\nC. 简化模型\nD. 降低计算复杂度\n38. 在假设检验中，p值小于0.01通常被认为是？ A. 不显著\nB. 边缘显著\nC. 高度显著\nD. 极高度显著\n39. dplyr 中的 arrange() 函数用于？ A. 数据分组\nB. 数据排序\nC. 数据汇总\nD. 数据筛选\n40. 在进行回归分析时，Cook’s距离用于检测？ A. 多重共线性\nB. 异方差性\nC. 强影响点\nD. 残差正态性\n41. 在 ggplot2 中，要在同一图中显示多个几何对象，应该？ A. 使用多个 ggplot() 调用\nB. 使用 + 连接多个 geom_*() 函数\nC. 分别创建多个图形\nD. 无法实现\n42. 在统计推断中，样本量的大小主要影响？ A. 总体参数\nB. 估计的精度\nC. 变量的类型\nD. 数据的分布\n43. 以下哪个不是探索性数据分析(EDA)的目标？ A. 发现数据模式\nB. 检测异常值\nC. 验证特定假设\nD. 了解变量分布\n44. 在R中，计算描述性统计的函数 summary() 不包括？ A. 均值\nB. 中位数\nC. 标准差\nD. 四分位数\n45. 在双侧检验中，p值等于0.04，在α=0.05水平下应该？ A. 接受原假设\nB. 拒绝原假设\nC. 重新收集数据\nD. 改变显著性水平\n46. 方差分析中的F统计量是基于？ A. 组间变异和组内变异的比值\nB. 各组均值的差异\nC. 样本方差的大小\nD. 样本量的多少\n47. 在Quarto文档中，R代码块的正确语法是？ A. r   B.{r}\nC. ```R\nD. 以上都可以\n48. 在数据清洗过程中，处理缺失值的 na.omit() 函数会？ A. 只删除包含缺失值的列\nB. 删除包含缺失值的行\nC. 用均值替换缺失值\nD. 用中位数替换缺失值\n49. 在统计学习中，过拟合通常指？ A. 模型在训练数据上表现很好，但在新数据上表现差\nB. 模型过于简单\nC. 数据量不足\nD. 特征过少\n50. 在R中，向量元素访问使用的符号是？ A. ()\nB. []\nC. {}\nD. &lt;&gt;\n\n\n题目 51-100\n51. 在 ggplot2 中，要修改坐标轴标签，应该使用？ A. axis.title()\nB. labs()\nC. scale_x_continuous()\nD. B和C都可以\n52. 回归模型中残差的期望值应该是？ A. 大于0\nB. 小于0\nC. 等于0\nD. 不确定\n53. 在进行单样本t检验时，原假设通常是？ A. 样本均值等于总体均值\nB. 样本均值等于某个特定值\nC. 总体均值等于某个特定值\nD. 样本方差等于总体方差\n54. dplyr 包中的 slice() 函数用于？ A. 按条件筛选行\nB. 按位置选择行\nC. 选择特定列\nD. 数据排序\n55. 在相关分析中，如果两个变量完全不相关，相关系数应该是？ A. 1\nB. -1\nC. 0\nD. 不确定\n56. 以下哪种图形最适合显示分类变量的分布？ A. 散点图\nB. 条形图\nC. 箱线图\nD. 密度图\n57. 在线性回归中，如果所有观测点都完全落在回归线上，R²等于？ A. 0\nB. 0.5\nC. 1\nD. -1\n58. Bootstrap方法的核心思想是？ A. 增加样本量\nB. 有放回的重复抽样\nC. 无放回的重复抽样\nD. 改变抽样方法\n59. 在R中，创建因子变量的函数是？ A. factor()\nB. as.factor()\nC. to.factor()\nD. A和B都可以\n60. 在假设检验中，功效(Power)是指？ A. 正确拒绝假的原假设的概率\nB. 正确接受真的原假设的概率\nC. 犯第一类错误的概率\nD. 犯第二类错误的概率\n61. 在多元回归中，偏相关系数衡量的是？ A. 两个变量的简单相关\nB. 控制其他变量后两个变量的相关\nC. 所有变量的平均相关\nD. 变量的重要性\n62. ggplot2 中的 facet_wrap() 函数用于？ A. 创建子图\nB. 调整图形大小\nC. 设置颜色\nD. 添加标题\n63. 在统计学中，抽样分布是指？ A. 样本数据的分布\nB. 总体数据的分布\nC. 统计量的分布\nD. 误差的分布\n64. 在R中，管道操作符 %&gt;% 来自哪个包？ A. dplyr\nB. magrittr\nC. tidyr\nD. ggplot2\n65. 在进行配对t检验时，分析的实际上是？ A. 两组数据的均值\nB. 两组数据的方差\nC. 配对差值的均值\nD. 配对差值的方差\n66. 以下哪个不是回归模型的基本假设？ A. 线性关系\nB. 残差正态性\nC. 变量独立性\nD. 样本量足够大\n67. 在Logistic回归中，预测概率的范围是？ A. 负无穷到正无穷\nB. -1到1\nC. 0到1\nD. 0到无穷大\n68. tidyr 包中的 separate() 函数用于？ A. 分离数据框\nB. 将一列分成多列\nC. 删除重复行\nD. 数据排序\n69. 在方差分析中，如果F值很大，说明？ A. 组间差异相对较小\nB. 组间差异相对较大\nC. 数据不满足正态分布\nD. 方差不齐\n70. 在R中，查看数据框结构的函数是？ A. structure()\nB. str()\nC. view()\nD. info()\n71. 置信水平为95%意味着置信区间的错误概率是？ A. 5%\nB. 0.5%\nC. 2.5%\nD. 不确定\n72. 在 ggplot2 中，geom_smooth() 的默认方法是？ A. 线性回归\nB. 局部回归(loess)\nC. 多项式回归\nD. 无方法\n73. 在卡方检验中，自由度的计算公式是？ A. (行数-1) × (列数-1)\nB. 行数 × 列数\nC. 行数 + 列数 - 2\nD. 总样本量 - 1\n74. dplyr 中的 count() 函数相当于？ A. group_by() + summarise(n = n())\nB. filter() + select()\nC. arrange() + slice()\nD. mutate() + select()\n75. 在线性回归诊断中，杠杆值(leverage)衡量的是？ A. 残差的大小\nB. 观测点在自变量空间的极端程度\nC. 因变量的变异\nD. 模型的拟合度\n76. 标准误(Standard Error)衡量的是？ A. 数据的离散程度\nB. 估计量的精确性\nC. 样本的代表性\nD. 模型的复杂度\n77. 在R中，合并数据框的函数是？ A. combine()\nB. merge()\nC. join()\nD. bind()\n78. 在假设检验中，如果p值非常接近显著性水平，应该？ A. 坚决拒绝原假设\nB. 坚决接受原假设\nC. 谨慎解释结果\nD. 重新设定显著性水平\n79. ggplot2 中的图层语法基于的理论是？ A. 数据可视化语法\nB. 图形语法\nC. 统计语法\nD. 编程语法\n80. 在多重线性回归中，当自变量之间高度相关时会出现？ A. 异方差性\nB. 多重共线性\nC. 自相关性\nD. 非线性关系\n81. 在R中，字符串处理主要使用哪个包？ A. stringr\nB. textminer\nC. wordcloud\nD. text\n82. 在统计推断中，点估计是指？ A. 用单个数值估计总体参数\nB. 用区间估计总体参数\nC. 估计样本参数\nD. 估计误差范围\n83. ggplot2 中要创建分组的箱线图，正确的方法是？ A. geom_boxplot(aes(x = group, y = value))\nB. geom_boxplot(aes(y = value), group = group)\nC. geom_boxplot(value ~ group)\nD. A是正确的\n84. 在回归分析中，当残差存在自相关时，可能的原因是？ A. 数据按时间顺序排列且相邻观测相关\nB. 数据量不足\nC. 变量选择不当\nD. 模型过于复杂\n85. 在R中，计算分位数的函数是？ A. quartile()\nB. quantile()\nC. percentile()\nD. decile()\n86. 双侧检验与单侧检验的主要区别在于？ A. 样本量要求\nB. 备择假设的形式\nC. 显著性水平\nD. 检验统计量\n87. 在 dplyr 中，distinct() 函数用于？ A. 数据排序\nB. 去除重复行\nC. 数据分组\nD. 变量选择\n88. 在线性模型中，哑变量(dummy variable)通常用于？ A. 处理缺失值\nB. 表示分类变量\nC. 减少变量数量\nD. 提高模型精度\n89. 在统计学中，“无偏估计”意味着？ A. 估计值等于真实值\nB. 估计值的期望等于真实值\nC. 估计值的方差最小\nD. 估计值没有误差\n90. ggplot2 中的 coord_flip() 函数用于？ A. 翻转图形颜色\nB. 交换x轴和y轴\nC. 旋转图形\nD. 镜像显示\n91. 在假设检验中，效应量(effect size)的作用是？ A. 决定是否显著\nB. 衡量效应的实际重要性\nC. 计算p值\nD. 确定样本量\n92. 在R中，检查对象类型的函数是？ A. type()\nB. class()\nC. kind()\nD. typeof()\n93. 在回归分析中，拟合优度检验通常使用？ A. t检验\nB. F检验\nC. 卡方检验\nD. z检验\n94. tidyverse 中读取Excel文件的包是？ A. readxl\nB. xlsx\nC. excel\nD. readr\n95. 在正态分布中，约68%的数据落在均值的几个标准差范围内？ A. 1个标准差\nB. 2个标准差\nC. 3个标准差\nD. 1.96个标准差\n96. 在 ggplot2 中，设置图形主题使用的函数前缀是？ A. set_\nB. theme_\nC. style_\nD. format_\n97. 在多元回归中，逐步回归的目的是？ A. 提高计算速度\nB. 选择最优变量组合\nC. 减少多重共线性\nD. 简化模型解释\n98. 在R中，向数据框添加新行使用的函数是？ A. add_row()\nB. rbind()\nC. append_row()\nD. A和B都可以\n99. 在统计学中，第一四分位数Q1对应的百分位数是？ A. 25%\nB. 50%\nC. 75%\nD. 100%\n100. 在机器学习中，训练集和测试集的典型比例是？ A. 50:50\nB. 60:40\nC. 70:30\nD. 80:20",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>统计学与R语言复习练习题集</span>"
    ]
  },
  {
    "objectID": "统计学与R语言复习练习题集.html#第二部分判断题共50题",
    "href": "统计学与R语言复习练习题集.html#第二部分判断题共50题",
    "title": "统计学与R语言复习练习题集",
    "section": "第二部分：判断题（共50题）",
    "text": "第二部分：判断题（共50题）\n说明： 请判断以下陈述是否正确，正确的打”√“，错误的打”×“。\n1. R语言是大小写敏感的编程语言。（ ）\n2. 在 tidyverse 中，geom_bar() 和 geom_col() 的功能完全相同。（ ）\n3. 方差越大，数据的离散程度越小。（ ）\n4. 在假设检验中，α水平（显著性水平）是我们预先设定的犯第一类错误的概率上限。（ ）\n5. 如果两个变量的Pearson相关系数接近于-1，我们可以断定它们之间存在负向因果关系。（ ）\n6. 线性回归要求因变量必须服从正态分布。（ ）\n7. 在R中，lm() 函数的返回对象可以直接用 plot() 函数生成模型诊断图。（ ）\n8. 进行卡方独立性检验时，所有单元格的期望频数都必须大于5。（ ）\n9. Logistic回归的回归系数可以直接解释为自变量每变化一个单位时，事件发生概率的变化量。（ ）\n10. 在 dplyr 中，管道操作符 %&gt;% 可以将前一个函数的结果作为后一个函数的第一个参数传递。（ ）\n11. 在 ggplot2 中，必须在每个 geom_*() 函数中重复指定 aes() 映射。（ ）\n12. 样本均值总是等于总体均值。（ ）\n13. 在进行双独立样本t检验前，必须先检验两总体方差是否相等。（ ）\n14. 配对样本t检验要求两个样本必须来自相同的总体。（ ）\n15. ANOVA检验的原假设是所有组的均值都相等。（ ）\n16. 如果ANOVA的F检验结果显著，说明所有组的均值都互不相同。（ ）\n17. 相关系数为0意味着两个变量之间不存在任何类型的关系。（ ）\n18. 在简单线性回归中，R²的值越大，模型的预测能力越强。（ ）\n19. 多元线性回归中的偏回归系数考虑了其他自变量的影响。（ ）\n20. 当VIF值大于10时，通常认为存在严重的多重共线性问题。（ ）\n21. 在Logistic回归中，优势比等于1表示该变量对结果没有影响。（ ）\n22. ROC曲线下面积(AUC)的最大值是2。（ ）\n23. 精确率(Precision)和召回率(Recall)总是同时增加或减少。（ ）\n24. 卡方检验只能用于2×2的列联表。（ ）\n25. tidyr 包的 pivot_longer() 函数用于将宽格式数据转换为长格式。（ ）\n26. 在R中，向量只能存储相同数据类型的元素。（ ）\n27. dplyr 的 select() 函数可以同时选择列和筛选行。（ ）\n28. 箱线图中的中线代表数据的均值。（ ）\n29. 中心极限定理要求总体必须服从正态分布。（ ）\n30. 置信区间的宽度与样本量成正比。（ ）\n31. 在假设检验中，p值越小，原假设越不可能为真。（ ）\n32. 统计显著性等同于实际重要性。（ ）\n33. Bootstrap方法可以在不知道总体分布的情况下估计统计量的抽样分布。（ ）\n34. 在线性回归中，残差的方差应该保持恒定（同方差性）。（ ）\n35. Cook距离用于识别对回归结果有强影响的观测点。（ ）\n36. 在R中，因子变量的水平是有顺序的。（ ）\n37. ggplot2 中的 facet_wrap() 和 facet_grid() 功能完全相同。（ ）\n38. 标准误(Standard Error)衡量的是估计量的变异性。（ ）\n39. 在进行多重比较时，不需要调整显著性水平。（ ）\n40. 第一类错误的概率等于1减去第二类错误的概率。（ ）\n41. 在R中，NA 和 NULL 表示相同的含义。（ ）\n42. 逐步回归能够保证找到最优的变量组合。（ ）\n43. 在正态分布中，约95%的数据落在均值的两个标准差范围内。（ ）\n44. 交叉验证的主要目的是增加训练数据的数量。（ ）\n45. 在Quarto文档中，代码块的选项 echo = FALSE 表示不执行代码。（ ）\n46. 哑变量只能取0和1两个值。（ ）\n47. 在假设检验中，拒绝原假设意味着备择假设绝对正确。（ ）\n48. 样本量越大，估计的精确度越高。（ ）\n49. 在R中，tibble 和 data.frame 是完全等价的数据结构。（ ）\n50. 机器学习中的过拟合问题可以通过增加模型复杂度来解决。（ ）",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>统计学与R语言复习练习题集</span>"
    ]
  },
  {
    "objectID": "统计学与R语言复习练习题集.html#第三部分简答题共20题",
    "href": "统计学与R语言复习练习题集.html#第三部分简答题共20题",
    "title": "统计学与R语言复习练习题集",
    "section": "第三部分：简答题（共20题）",
    "text": "第三部分：简答题（共20题）\n\n基础概念与R语言（题目1-5）\n1. （场景：数据导入与清理） 某研究人员收到一个包含销售数据的CSV文件，发现数据中存在缺失值、重复记录，且部分列的数据类型不正确。 请回答： a) 在R中，你会使用哪些函数来检查数据的基本信息和结构？（3分） b) 列举三种处理缺失值的方法，并说明各自的适用情况。（4分） c) 如何使用 dplyr 包去除重复记录？（3分）\n2. （概念：整洁数据与数据变换） 假设你有一个”宽格式”的数据，包含学生ID、语文成绩、数学成绩、英语成绩四列。 请回答： a) 什么是”整洁数据”？请简述其三个基本原则。（4分） b) 如果要将这个宽格式数据转换为长格式（学生ID、科目、成绩），应该使用 tidyr 包的哪个函数？请写出基本语法。（3分） c) 转换后的长格式数据相比宽格式有什么优势？（3分）\n3. （实践：ggplot2绘图） 某电商公司想分析不同商品类别在各个月份的销售额变化趋势。 请回答： a) 你会选择哪种类型的图形来展示这种数据？说明理由。（3分） b) 在 ggplot2 中，如果要在同一图中显示多个商品类别的趋势线，应该如何设置美学映射？（4分） c) 如何为图形添加标题、坐标轴标签和图例？（3分）\n4. （概念：描述性统计） 某班级期末考试成绩的描述性统计结果显示：均值75分，中位数78分，标准差12分。 请回答： a) 根据均值和中位数的关系，你认为该班级成绩分布呈现什么特征？说明理由。（4分） b) 如果要比较两个班级成绩的离散程度，除了标准差外，还可以使用什么指标？为什么？（3分） c) 在R中，计算这些描述性统计量的函数分别是什么？（3分）\n5. （实践：数据操作） 有一个包含员工信息的数据框，包括姓名、部门、薪资、工作年限等字段。 请回答： a) 如何使用 dplyr 找出每个部门薪资最高的员工？请写出代码思路。（4分） b) 如何计算每个部门的平均薪资和员工数量？（3分） c) 如何筛选出工作年限大于5年且薪资高于平均薪资的员工？（3分）\n\n\n假设检验与方差分析（题目6-10）\n6. （场景：独立样本比较） 某医学研究想比较新药和对照药物的治疗效果，随机分配患者到两组，记录治疗后的恢复天数。 请回答： a) 这个研究设计适合使用哪种统计检验方法？该方法有什么前提假设？（4分） b) 如果检验结果p值为0.02，在α=0.05水平下应该得出什么结论？（3分） c) 除了p值外，你还会关注哪些信息来全面评估治疗效果？（3分）\n7. （场景：多组比较） 某农业试验比较四种不同肥料对作物产量的影响，每种肥料处理了10块试验田。 请回答： a) 为什么不能用多次t检验来比较这四组？应该使用什么方法？（4分） b) 如果ANOVA检验结果显著，接下来应该进行什么分析？目的是什么？（3分） c) 在R中进行ANOVA分析的基本函数是什么？如何查看详细结果？（3分）\n8. （场景：配对比较） 某培训机构想评估其培训课程的效果，对20名学员进行培训前后的能力测试。 请回答： a) 这种研究设计与独立样本比较有什么区别？为什么要采用这种设计？（4分） b) 应该使用哪种统计检验方法？该方法实际分析的是什么？（3分） c) 如果培训前后的测试分数呈现出显著差异，可以得出什么结论？有什么局限性？（3分）\n9. （概念：检验力与样本量） 某研究者在设计实验时需要确定适当的样本量。 请回答： a) 什么是统计检验力（Power）？它与哪些因素有关？（4分） b) 第一类错误和第二类错误分别指什么？两者之间有什么关系？（3分） c) 如果研究预算有限，样本量较小，对检验结果有什么影响？（3分）\n10. （实践：非参数检验） 某市场调研收集了消费者对产品的满意度评分（1-5分），数据明显偏态分布。 请回答： a) 为什么偏态分布不适合使用t检验？应该考虑什么替代方法？（4分） b) 如果要比较两组消费者的满意度，可以使用哪种非参数检验？（3分） c) 非参数检验相比参数检验有什么优缺点？（3分）\n\n\n回归分析与建模（题目11-15）\n11. （场景：简单线性回归） 某房地产公司想研究房屋面积与售价的关系，收集了100套房屋的数据。 请回答： a) 在进行回归分析之前，你会创建什么图形来初步探索两个变量的关系？（3分） b) 如果回归方程为：售价 = 50 + 0.8×面积，请解释截距和斜率的含义。（4分） c) 如果R² = 0.65，这个数值说明了什么？模型的拟合效果如何？（3分）\n12. （场景：多元回归） 某公司想预测员工绩效，考虑年龄、工作经验、教育水平等多个因素。 请回答： a) 多元回归中的偏回归系数与简单回归中的回归系数有什么区别？（4分） b) 在解释多元回归结果时，应该重点关注哪些指标？（3分） c) 如果发现某个自变量的p值很大（如0.8），应该如何处理？（3分）\n13. （概念：回归诊断） 某研究者拟合了一个线性回归模型，需要检验模型假设是否成立。 请回答： a) 线性回归的主要假设有哪些？（4分） b) 如果残差图显示出喇叭状模式，这违反了哪个假设？可能的解决方法是什么？（3分） c) 在R中，plot(lm_model) 会生成哪些诊断图？各自的作用是什么？（3分）\n14. （场景：模型选择） 某研究有10个候选自变量，需要构建最优的回归模型。 请回答： a) 什么是多重共线性？如何检测？对模型有什么影响？（4分） b) 向前选择、向后消除、逐步回归的区别是什么？（3分） c) 除了统计显著性外，选择变量时还应考虑什么因素？（3分）\n15. （实践：Logistic回归） 某银行想预测客户是否会违约，基于收入、年龄、信用历史等信息。 请回答： a) 为什么这个问题适合使用Logistic回归而不是线性回归？（4分） b) 如果某变量的优势比(OR)为2.5，如何解释这个结果？（3分） c) 在评估Logistic回归模型时，除了准确率外，还有哪些重要指标？（3分）\n\n\n高级主题与应用（题目16-20）\n16. （场景：分类变量分析） 某调查研究了性别、教育水平、收入层次与消费行为的关系。 请回答： a) 如果要检验性别与消费行为（高、中、低消费）是否有关，应该使用什么统计方法？（3分） b) 卡方检验的前提假设是什么？如果违反了这些假设应该怎么办？（4分） c) 如何解释卡方检验的结果？显著结果意味着什么？（3分）\n17. （概念：统计推断） 某质量控制工程师需要对生产线进行监控。 请回答： a) 置信区间和预测区间的区别是什么？各自的应用场景是什么？（4分） b) 95%置信区间的正确解释是什么？常见的误解有哪些？（3分） c) 在质量控制中，如何选择合适的显著性水平？需要考虑什么因素？（3分）\n18. （实践：模型评估） 某数据科学团队构建了一个分类模型，需要评估模型性能。 请回答： a) 训练集、验证集、测试集的作用分别是什么？为什么要进行这样的划分？（4分） b) 什么是过拟合？如何检测和预防过拟合？（3分） c) 交叉验证的基本思想是什么？有什么优势？（3分）\n19. （应用：数据科学流程） 某公司要开展一个数据分析项目，从业务问题到最终报告。 请回答： a) 完整的数据分析流程包括哪些主要步骤？每个步骤的关键任务是什么？（4分） b) 在数据探索阶段，应该重点关注哪些方面？为什么？（3分） c) 如何确保分析结果的可重复性？Quarto/R Markdown在其中发挥什么作用？（3分）\n20. （综合：案例分析） 某电商平台想分析影响用户购买行为的因素，数据包括用户属性、浏览行为、历史购买记录等。 请回答： a) 这是一个什么类型的分析问题？需要什么样的建模方法？（3分） b) 在特征工程阶段，你会如何处理分类变量和数值变量？（4分） c) 如何评估和解释最终模型？向业务部门汇报时应该重点强调什么？（3分）",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>统计学与R语言复习练习题集</span>"
    ]
  },
  {
    "objectID": "统计学与R语言复习练习题集.html#参考答案",
    "href": "统计学与R语言复习练习题集.html#参考答案",
    "title": "统计学与R语言复习练习题集",
    "section": "参考答案",
    "text": "参考答案\n\n选择题答案（1-100）\n1-25题答案： 1.C 2.B 3.D 4.B 5.B 6.C 7.B 8.A 9.B 10.B\n11.C 12.D 13.B 14.B 15.B 16.B 17.B 18.C 19.A 20.B\n21.A 22.C 23.B 24.C 25.B\n26-50题答案： 26.C 27.B 28.B 29.A 30.C 31.B 32.B 33.A 34.B 35.A\n36.B 37.B 38.A 39.B 40.C 41.B 42.B 43.C 44.C 45.B\n46.A 47.B 48.B 49.A 50.B\n51-75题答案： 51.D 52.C 53.C 54.B 55.C 56.B 57.C 58.B 59.D 60.A\n61.B 62.A 63.C 64.B 65.C 66.D 67.C 68.B 69.B 70.B\n71.A 72.B 73.A 74.A 75.B\n76-100题答案： 76.B 77.B 78.C 79.B 80.B 81.A 82.A 83.D 84.A 85.B\n86.B 87.B 88.B 89.B 90.B 91.B 92.B 93.B 94.A 95.A\n96.B 97.B 98.D 99.A 100.D\n\n\n判断题答案（1-50）\n1-25题答案： 1.√ 2.× 3.× 4.√ 5.× 6.× 7.√ 8.× 9.× 10.√\n11.× 12.× 13.√ 14.× 15.√ 16.× 17.× 18.√ 19.√ 20.√\n21.√ 22.× 23.× 24.× 25.√\n26-50题答案： 26.√ 27.× 28.× 29.× 30.× 31.√ 32.× 33.√ 34.√ 35.√\n36.× 37.× 38.√ 39.× 40.× 41.× 42.× 43.√ 44.× 45.×\n46.√ 47.× 48.√ 49.× 50.×\n\n\n简答题要点提示\n说明： 以下仅为答题要点提示，完整答案应结合具体分析和说明。\n题目1-5（基础概念与R语言）要点： - 数据检查函数：str(), summary(), head(), dim() 等 - 缺失值处理：删除、均值/中位数填充、插值法 - 整洁数据原则：变量成列、观测成行、值为单元格 - ggplot2语法结构和图层逻辑 - dplyr核心函数的组合使用\n题目6-10（假设检验与方差分析）要点： - 独立样本t检验的假设和应用 - ANOVA vs多重t检验的问题 - 配对设计的优势和分析思路 - 统计检验力和错误类型 - 参数vs非参数检验的选择\n题目11-15（回归分析与建模）要点： - 简单vs多元回归的系数解释 - 回归诊断的方法和图形 - 多重共线性检测和处理 - Logistic回归的特点和应用 - 模型选择的统计和实际考虑\n题目16-20（高级主题与应用）要点： - 卡方检验的应用和解释 - 置信区间vs预测区间 - 模型评估和验证策略 - 数据科学完整流程 - 业务问题的建模思路",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>统计学与R语言复习练习题集</span>"
    ]
  },
  {
    "objectID": "统计学与R语言复习练习题集.html#复习建议",
    "href": "统计学与R语言复习练习题集.html#复习建议",
    "title": "统计学与R语言复习练习题集",
    "section": "复习建议",
    "text": "复习建议\n\n📋 重点知识清单\n\nR语言基础：tidyverse生态、数据操作、管道操作\n统计概念：描述性统计、抽样分布、中心极限定理\n假设检验：t检验、ANOVA、卡方检验的应用场景\n回归分析：线性回归、Logistic回归、模型诊断\n数据可视化：ggplot2语法、探索性数据分析\n模型评估：交叉验证、性能指标、过拟合问题\n\n\n\n⏰ 复习时间建议\n\n选择题：建议用时90分钟（约1分钟/题）\n判断题：建议用时25分钟（约30秒/题）\n\n简答题：建议用时100分钟（约5分钟/题）\n\n\n\n💡 答题策略\n\n选择题：注意审题，排除明显错误选项\n判断题：注意绝对化表述，通常为错误\n简答题：条理清晰，结合代码和理论\n时间控制：先易后难，留时间检查\n\n希望这份练习题集能够帮助您系统复习《统计学与R语言》的核心内容！",
    "crumbs": [
      "讲义",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>统计学与R语言复习练习题集</span>"
    ]
  }
]