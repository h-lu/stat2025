---
title: "数据科学全流程实战：从统计分析到预测建模的AI辅助实践"
subtitle: "《统计学与R语言》课程设计 - 一周综合项目"
author: "[学生姓名]"
date: "2024年春季学期"
format:
  html:
    toc: true
    toc-depth: 3
    number-sections: true
    code-fold: show
    code-tools: true
    theme: cosmo
    css: styles.css
  pdf:
    toc: true
    number-sections: true
editor: visual
execute:
  echo: true
  warning: false
  message: false
  error: true
bibliography: references.bib
---

# 项目概述 {#overview}

## 项目背景与意义

本课程设计是《统计学与R语言》课程的综合实践项目，旨在：

1. **巩固统计学基础**：运用描述统计、推断统计、回归分析等核心概念
2. **深化R语言技能**：熟练使用tidyverse生态系统进行数据科学工作流
3. **引入机器学习思想**：为后续《机器学习Python》课程建立概念桥梁
4. **掌握AI辅助分析**：系统性学习如何在数据科学项目中有效运用AI工具
5. **培养项目思维**：从问题定义到解决方案的完整数据科学项目经验

## 项目选题：房价预测的多维度分析

**核心研究问题**：如何基于房屋特征、地理位置、经济环境等多维度信息，构建有效的房价预测模型？

**数据来源**：
- 主数据集：Boston Housing或California Housing数据
- 辅助数据：人口统计、经济指标、地理信息等
- 实时数据：通过API获取的房地产市场数据

**项目特色**：
- 结合传统统计方法与现代机器学习思想
- 全程AI辅助的数据科学工作流
- 可重复、可扩展的分析框架

# 第一天：项目规划与数据获取 {#day1}

## 项目规划与AI辅助需求分析

### 业务理解与问题定义

```{r setup, message=FALSE}
library(tidyverse)
library(corrplot)
library(GGally)
library(plotly)
library(DT)
library(knitr)
library(broom)
library(modelr)

# 设置全局选项
options(scipen = 999)  # 避免科学计数法
theme_set(theme_minimal())  # 设置ggplot默认主题
```

**AI辅助任务规划**：
> **Prompt示例**："我正在进行一个房价预测的数据科学项目，需要结合统计分析和机器学习方法。请帮我：
> 1. 梳理房价影响因素的理论框架
> 2. 设计从数据探索到模型建立的完整分析流程
> 3. 推荐适合初学者的统计和机器学习方法组合"

### 数据获取策略

```{r data-loading}
# 加载主要数据集
# 这里使用MASS包中的Boston数据作为示例
library(MASS)
data(Boston)

# 查看数据基本信息
cat("数据集维度：", dim(Boston), "\n")
cat("变量名称：", names(Boston), "\n")

# 数据预览
Boston %>% 
  head(10) %>% 
  kable(caption = "Boston房价数据集预览")
```

**数据字典构建**：
```{r data-dictionary}
# AI辅助生成数据字典
variable_descriptions <- tibble(
  Variable = names(Boston),
  Description = c(
    "人均犯罪率",
    "超过25000平方英尺的住宅用地比例", 
    "非零售商业用地比例",
    "是否邻近Charles河（1=是，0=否）",
    "氮氧化物浓度",
    "平均房间数",
    "1940年前建造的房屋比例",
    "到波士顿5个就业中心的加权距离",
    "辐射状公路可达性指数",
    "每万美元财产税率",
    "师生比例",
    "黑人比例统计量",
    "低收入人口比例",
    "房价中位数（千美元）"
  ),
  Type = c(
    "连续型", "连续型", "连续型", "二分类",
    "连续型", "连续型", "连续型", "连续型",
    "连续型", "连续型", "连续型", "连续型",
    "连续型", "连续型"
  )
)

variable_descriptions %>% 
  kable(caption = "变量说明表")
```

## 数据质量评估

```{r data-quality}
# 基本数据质量检查
data_quality <- Boston %>% 
  summarise_all(list(
    missing = ~sum(is.na(.)),
    min = ~min(., na.rm = TRUE),
    max = ~max(., na.rm = TRUE),
    mean = ~mean(., na.rm = TRUE),
    sd = ~sd(., na.rm = TRUE)
  )) %>% 
  pivot_longer(everything(), names_to = c("variable", "metric"), names_sep = "_") %>% 
  pivot_wider(names_from = metric, values_from = value)

data_quality %>% 
  kable(digits = 2, caption = "数据质量评估")
```

# 第二天：探索性数据分析与统计建模 {#day2}

## 描述性统计分析

### 目标变量分析

```{r target-analysis}
# 房价分布分析
p1 <- Boston %>% 
  ggplot(aes(x = medv)) +
  geom_histogram(bins = 30, fill = "steelblue", alpha = 0.7) +
  geom_vline(aes(xintercept = mean(medv)), color = "red", linetype = "dashed") +
  labs(title = "房价分布", x = "房价中位数（千美元）", y = "频数")

p2 <- Boston %>% 
  ggplot(aes(x = medv)) +
  geom_boxplot(fill = "lightblue", alpha = 0.7) +
  labs(title = "房价箱线图", x = "房价中位数（千美元）")

# 使用plotly创建交互式图表
ggplotly(p1)
```

### 特征变量探索

```{r feature-exploration}
# 相关性矩阵
correlation_matrix <- Boston %>% 
  select_if(is.numeric) %>% 
  cor()

# 绘制相关性热图
corrplot(correlation_matrix, method = "color", type = "upper", 
         order = "hclust", tl.cex = 0.8, tl.col = "black")
```

## 统计推断实践

### 假设检验应用

```{r hypothesis-testing}
# 示例：检验邻近Charles河是否影响房价
t_test_result <- t.test(medv ~ chas, data = Boston)

# AI辅助解释结果
cat("t检验结果解释：\n")
cat("t统计量：", round(t_test_result$statistic, 3), "\n")
cat("p值：", round(t_test_result$p.value, 3), "\n")
cat("95%置信区间：[", round(t_test_result$conf.int[1], 2), ",", 
    round(t_test_result$conf.int[2], 2), "]\n")

# 可视化比较
Boston %>% 
  mutate(chas_label = ifelse(chas == 1, "邻近Charles河", "不邻近Charles河")) %>% 
  ggplot(aes(x = chas_label, y = medv, fill = chas_label)) +
  geom_boxplot(alpha = 0.7) +
  geom_jitter(width = 0.2, alpha = 0.5) +
  labs(title = "是否邻近Charles河对房价的影响",
       x = "", y = "房价中位数（千美元）") +
  theme(legend.position = "none")
```

### ANOVA分析示例

```{r anova-analysis}
# 将rad变量分组进行ANOVA分析
Boston_grouped <- Boston %>% 
  mutate(rad_group = cut(rad, breaks = 3, labels = c("低", "中", "高")))

anova_result <- aov(medv ~ rad_group, data = Boston_grouped)
summary(anova_result)

# 事后检验
TukeyHSD(anova_result)
```

## 回归分析建模

### 简单线性回归

```{r simple-regression}
# 房间数与房价的关系
simple_model <- lm(medv ~ rm, data = Boston)

# 模型摘要
summary(simple_model)

# 可视化
Boston %>% 
  ggplot(aes(x = rm, y = medv)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = TRUE, color = "red") +
  labs(title = "房间数与房价关系", 
       x = "平均房间数", y = "房价中位数（千美元）")
```

### 多元线性回归

```{r multiple-regression}
# 构建多元回归模型
multiple_model <- lm(medv ~ crim + zn + indus + chas + nox + rm + age + dis + rad + tax + ptratio + black + lstat, 
                     data = Boston)

# 模型摘要
summary(multiple_model)

# 系数可视化
multiple_model %>% 
  tidy() %>% 
  filter(term != "(Intercept)") %>% 
  ggplot(aes(x = reorder(term, estimate), y = estimate)) +
  geom_col(fill = "steelblue", alpha = 0.7) +
  geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error), 
                width = 0.2) +
  coord_flip() +
  labs(title = "多元回归系数", x = "变量", y = "回归系数")
```

# 第三天：模型诊断与改进 {#day3}

## 回归假设检验

### 线性性检验

```{r linearity-check}
# 残差图检验线性性
Boston %>% 
  add_predictions(multiple_model) %>% 
  add_residuals(multiple_model) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.6) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  geom_smooth(se = FALSE, color = "blue") +
  labs(title = "残差 vs 拟合值图", x = "拟合值", y = "残差")
```

### 正态性检验

```{r normality-check}
# Q-Q图
Boston %>% 
  add_residuals(multiple_model) %>% 
  ggplot(aes(sample = resid)) +
  stat_qq() +
  stat_qq_line(color = "red") +
  labs(title = "残差Q-Q图")

# Shapiro-Wilk检验
shapiro.test(residuals(multiple_model))
```

### 同方差性检验

```{r homoscedasticity-check}
# 残差的绝对值与拟合值
Boston %>% 
  add_predictions(multiple_model) %>% 
  add_residuals(multiple_model) %>% 
  ggplot(aes(x = pred, y = abs(resid))) +
  geom_point(alpha = 0.6) +
  geom_smooth(se = FALSE, color = "red") +
  labs(title = "残差绝对值 vs 拟合值", x = "拟合值", y = "|残差|")
```

### 多重共线性检验

```{r multicollinearity-check}
# VIF计算
library(car)
vif_values <- vif(multiple_model)
vif_values

# VIF可视化
tibble(
  Variable = names(vif_values),
  VIF = vif_values
) %>% 
  ggplot(aes(x = reorder(Variable, VIF), y = VIF)) +
  geom_col(fill = "orange", alpha = 0.7) +
  geom_hline(yintercept = 5, color = "red", linetype = "dashed") +
  geom_hline(yintercept = 10, color = "red") +
  coord_flip() +
  labs(title = "方差膨胀因子(VIF)", x = "变量", y = "VIF值")
```

## 模型改进策略

### 变量选择

```{r model-selection}
# 逐步回归
library(MASS)
step_model <- stepAIC(multiple_model, direction = "both", trace = FALSE)
summary(step_model)

# 比较模型
AIC(multiple_model, step_model)
BIC(multiple_model, step_model)
```

### 变量变换

```{r variable-transformation}
# 对部分变量进行对数变换
Boston_transformed <- Boston %>% 
  mutate(
    log_crim = log(crim + 1),
    log_dis = log(dis),
    log_lstat = log(lstat)
  )

# 重新拟合模型
transformed_model <- lm(medv ~ log_crim + zn + indus + chas + nox + rm + age + log_dis + rad + tax + ptratio + black + log_lstat, 
                        data = Boston_transformed)

summary(transformed_model)
```

# 第四天：机器学习方法初探 {#day4}

## 数据预处理

### 数据分割

```{r data-splitting}
library(caret)
set.seed(123)

# 分割训练集和测试集
train_index <- createDataPartition(Boston$medv, p = 0.8, list = FALSE)
train_data <- Boston[train_index, ]
test_data <- Boston[-train_index, ]

cat("训练集大小：", nrow(train_data), "\n")
cat("测试集大小：", nrow(test_data), "\n")
```

### 特征标准化

```{r feature-scaling}
# 标准化数值特征
preprocess_params <- preProcess(train_data[, -14], method = c("center", "scale"))
train_scaled <- predict(preprocess_params, train_data)
test_scaled <- predict(preprocess_params, test_data)

# 查看标准化效果
train_scaled %>% 
  select(crim, rm, lstat, medv) %>% 
  summary()
```

## 多种建模方法比较

### 线性模型族

```{r linear-models}
# 多元线性回归
lm_model <- train(medv ~ ., data = train_scaled, method = "lm")

# 岭回归
ridge_model <- train(medv ~ ., data = train_scaled, method = "ridge")

# LASSO回归
lasso_model <- train(medv ~ ., data = train_scaled, method = "lasso")

# 弹性网络
elastic_model <- train(medv ~ ., data = train_scaled, method = "enet")
```

### 非线性模型

```{r nonlinear-models}
# 随机森林
library(randomForest)
rf_model <- train(medv ~ ., data = train_scaled, method = "rf", ntree = 100)

# 支持向量机
svm_model <- train(medv ~ ., data = train_scaled, method = "svmRadial")
```

### 模型性能比较

```{r model-comparison}
# 收集所有模型
models <- list(
  "Linear Regression" = lm_model,
  "Ridge Regression" = ridge_model,
  "LASSO Regression" = lasso_model,
  "Elastic Net" = elastic_model,
  "Random Forest" = rf_model,
  "SVM" = svm_model
)

# 在测试集上预测
predictions <- map(models, ~predict(., test_scaled))

# 计算性能指标
performance <- map_dfr(predictions, ~{
  tibble(
    RMSE = sqrt(mean((test_scaled$medv - .)^2)),
    MAE = mean(abs(test_scaled$medv - .)),
    R2 = cor(test_scaled$medv, .)^2
  )
}, .id = "Model")

performance %>% 
  kable(digits = 3, caption = "模型性能比较")
```

## 模型解释与特征重要性

```{r feature-importance}
# 随机森林特征重要性
rf_importance <- varImp(rf_model)
plot(rf_importance, main = "随机森林特征重要性")

# LASSO系数路径
plot(lasso_model$finalModel, xvar = "lambda", label = TRUE)
```

# 第五天：综合应用与成果展示 {#day5}

## 最优模型选择与解释

### 模型集成

```{r model-ensemble}
# 简单平均集成
ensemble_pred <- (predictions$`Random Forest` + predictions$`LASSO Regression`) / 2

# 集成模型性能
ensemble_performance <- tibble(
  RMSE = sqrt(mean((test_scaled$medv - ensemble_pred)^2)),
  MAE = mean(abs(test_scaled$medv - ensemble_pred)),
  R2 = cor(test_scaled$medv, ensemble_pred)^2
)

cat("集成模型性能：\n")
print(ensemble_performance)
```

### 预测结果可视化

```{r prediction-visualization}
# 实际值 vs 预测值
results_df <- tibble(
  Actual = test_scaled$medv,
  Linear = predictions$`Linear Regression`,
  LASSO = predictions$`LASSO Regression`,
  RandomForest = predictions$`Random Forest`,
  Ensemble = ensemble_pred
)

results_df %>% 
  pivot_longer(-Actual, names_to = "Model", values_to = "Predicted") %>% 
  ggplot(aes(x = Actual, y = Predicted)) +
  geom_point(alpha = 0.6) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  facet_wrap(~Model, scales = "free") +
  labs(title = "实际值 vs 预测值", x = "实际房价", y = "预测房价")
```

## AI辅助洞察挖掘

### 业务洞察总结

**基于AI辅助分析，我们发现：**

1. **关键影响因素**：房间数（rm）、低收入人口比例（lstat）、犯罪率（crim）是房价的主要决定因素
2. **非线性关系**：某些特征与房价存在非线性关系，机器学习模型能更好地捕捉这些模式
3. **地理因素**：辐射状公路可达性（rad）和到就业中心距离（dis）反映了地理位置的重要性
4. **社会经济指标**：师生比例（ptratio）等教育指标也显著影响房价

### 模型推荐

```{r final-recommendation}
# 最终推荐模型的详细评估
best_model <- rf_model  # 假设随机森林表现最佳

# 详细性能报告
cat("=== 最终推荐模型：随机森林 ===\n")
cat("交叉验证RMSE：", round(min(best_model$results$RMSE), 3), "\n")
cat("测试集RMSE：", round(sqrt(mean((test_scaled$medv - predictions$`Random Forest`)^2)), 3), "\n")
cat("测试集R²：", round(cor(test_scaled$medv, predictions$`Random Forest`)^2, 3), "\n")
```

## 项目文档与可重复性

### 环境信息

```{r session-info}
sessionInfo()
```

### 代码组织

本项目采用以下代码组织结构：
- `data/`：原始数据和处理后数据
- `scripts/`：分析脚本
- `outputs/`：图表和结果
- `docs/`：项目文档

### 后续改进方向

1. **数据扩展**：整合更多外部数据源（如学区信息、交通数据等）
2. **模型优化**：超参数调优、特征工程
3. **部署应用**：构建Shiny应用进行交互式预测
4. **Python过渡**：将分析流程迁移到Python，为机器学习课程做准备

# 项目总结与反思 {#conclusion}

## 技能掌握清单

通过本项目，我掌握了：

- [ ] 完整的数据科学项目流程
- [ ] 统计学理论在实际问题中的应用
- [ ] R语言高级数据操作和建模技能
- [ ] AI工具在数据分析中的有效运用
- [ ] 模型诊断和改进的系统方法
- [ ] 机器学习基础概念和方法
- [ ] 可重复研究的最佳实践

## AI使用总结

### 成功的AI辅助场景
1. **概念理解**：统计概念的深入解释
2. **代码生成**：复杂可视化和建模代码
3. **结果解释**：模型输出的业务含义解读
4. **文档撰写**：技术文档的优化和润色

### AI使用注意事项
1. **验证准确性**：始终验证AI生成的代码和解释
2. **理解逻辑**：不盲目使用，要理解背后的统计原理
3. **创新思考**：AI辅助而非替代独立思考

## 为机器学习Python课程的准备

本项目为后续Python机器学习课程奠定了基础：
- 理解了机器学习的基本概念和工作流程
- 熟悉了模型评估和选择的方法
- 建立了数据科学项目的系统思维
- 掌握了AI辅助学习的有效方法

---

**项目完成时间**：[填写实际完成日期]  
**总用时**：约40小时（一周集中时间）  
**代码行数**：约500行R代码  
**生成图表**：15+个可视化图表  
**AI交互次数**：50+次有效对话 