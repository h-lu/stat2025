---
title: "第十一周：预测分类结果：Logistic 回归（一）"
---

## 1. 从线性回归到分类预测

到目前为止，我们学习的回归模型（SLR, MLR）都是用于预测**连续型**因变量 Y。但很多时候，我们感兴趣的预测目标是**分类变量**，特别是**二元分类 (Binary Classification)** 变量，其结果只有两种可能（例如：是/否、成功/失败、购买/不购买、患病/未患病）。

-   **线性回归的局限性:**
    -   如果直接用线性回归预测一个 0/1 的二元变量，预测值 $\hat{y}$ 可能会超出 \[0, 1\] 的合理范围。
    -   误差项不满足正态性和等方差性假设。
    -   因变量和自变量之间的关系通常不是线性的，而是 S 形的。
-   **Logistic 回归 (Logistic Regression):**
    -   一种广泛用于处理**二元或多元分类**问题的**广义线性模型 (Generalized Linear Model, GLM)**。
    -   它不直接预测类别 (0 或 1)，而是预测属于某个类别（通常是 "成功" 或 "事件发生"，编码为 1）的**概率 (Probability)** $P(Y=1|X)$。
    -   然后可以设定一个阈值（如 0.5），将预测概率转换为类别预测。

::: {.callout-note title="本周目标"}
-   理解为何线性回归不适用于分类结果。
-   掌握 Logistic 回归的基本原理：Sigmoid 函数和 Logit 变换。
-   理解 Logistic 回归的模型形式。
-   **重点掌握** Logistic 回归系数的解释，特别是**优势比 (Odds Ratio, OR)**。
-   能够使用 R 的 `glm()` 函数拟合二元 Logistic 回归模型。
-   **了解 Capstone 综合项目的要求、选题方向、时间节点和评分标准。**
:::

## 2. Logistic 回归原理

Logistic 回归通过两个关键步骤将线性预测值与概率联系起来：

1.  **线性预测器 (Linear Predictor):** 与线性回归类似，计算自变量的线性组合： $$ z = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_k X_k $$ 这个 $z$ 的取值范围是 $(-\infty, +\infty)$。

2.  **连接函数 (Link Function) 的逆转换 / Sigmoid 函数:** 为了将 $z$ 映射到 (0, 1) 的概率区间，Logistic 回归使用了 **Sigmoid 函数** (也称为 Logistic 函数)： $$ P(Y=1|X) = p = \frac{e^z}{1 + e^z} = \frac{1}{1 + e^{-z}} $$

    -   Sigmoid 函数的图形呈 S 形，可以将任何实数 $z$ 转换为 (0, 1) 之间的值。
    -   当 $z \to +\infty$ 时，$p \to 1$。
    -   当 $z \to -\infty$ 时，$p \to 0$。
    -   当 $z = 0$ 时，$p = 0.5$。

3.  **Logit 变换 (Logit Transformation) / 连接函数:** 反过来，如果我们想将概率 $p$ 转换回线性预测器 $z$，需要用到 Sigmoid 函数的反函数，即 **Logit 变换**：

    -   **优势 (Odds):** 事件发生的概率与不发生的概率之比。$Odds = \frac{p}{1-p}$。取值范围是 $(0, +\infty)$。
    -   **对数优势 (Log-odds) / Logit:** 对优势取自然对数。$Logit(p) = \log(\frac{p}{1-p})$。取值范围是 $(-\infty, +\infty)$。
    -   在 Logistic 回归中，**Logit(p) 被假定为自变量的线性组合**: $$ \log\left(\frac{p}{1-p}\right) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_k X_k $$ 这里的 Logit 函数就是 Logistic 回归的**连接函数**，它将非线性的概率关系转换为了线性的对数优势关系。

## 3. Logistic 回归模型形式

核心模型是： $$ \log\left(\frac{P(Y=1|X)}{1-P(Y=1|X)}\right) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_k X_k $$

或者等价地写成概率形式： $$ P(Y=1|X) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 X_1 + ... + \beta_k X_k)}} $$

-   模型参数 $\beta_0, \beta_1, ..., \beta_k$ 通常使用**最大似然估计 (Maximum Likelihood Estimation, MLE)** 来获得，而不是 OLS。

## 4. 系数解释：优势比 (Odds Ratio, OR) - 核心！

直接解释 Logistic 回归的系数 $\beta_j$ 比较困难，因为它表示自变量 $X_j$ 每增加一个单位，**对数优势 (Log-odds)** 的变化量。为了更直观地理解，我们通常解释**优势比 (Odds Ratio, OR)**。

-   **优势比 (OR):** 指自变量 $X_j$ **增加一个单位**时，事件发生的**优势 (Odds)** 变为原来的**多少倍**。 $$ OR_j = \frac{Odds(X_j+1)}{Odds(X_j)} = \frac{e^{\beta_0 + \beta_1 X_1 + ... + \beta_j(X_j+1) + ...}}{e^{\beta_0 + \beta_1 X_1 + ... + \beta_j X_j + ...}} = e^{\beta_j} $$
    -   **计算:** $OR_j = \exp(\beta_j)$。
-   **解读 OR:**
    -   \*\*$OR_j > 1$ (\$ \beta\_j \> 0 \$):\*\* $X_j$ 增加一个单位，事件发生的**优势增加** (变为原来的 $OR_j$ 倍)。$X_j$ 是风险因素/促进因素。
    -   \*\*$OR_j < 1$ (\$ \beta\_j \< 0 \$):\*\* $X_j$ 增加一个单位，事件发生的**优势减少** (变为原来的 $OR_j$ 倍)。$X_j$ 是保护因素。
    -   \*\*$OR_j = 1$ (\$ \beta\_j = 0 \$):\*\* $X_j$ 变化对事件发生的优势**没有影响**。
-   **示例解释:**
    -   假设研究吸烟 (X=1 表示吸烟, X=0 表示不吸烟) 对患肺癌 (Y=1) 的影响，得到 $\hat{\beta}_{smoke} = 1.609$。
    -   计算 $OR_{smoke} = \exp(1.609) \approx 5.0$。
    -   **解释:** 吸烟者的患肺癌**优势**是**不吸烟者**的\*\* 5 倍\*\* (在控制其他变量后)。
    -   假设研究年龄 (X，连续变量) 对购买某产品 (Y=1) 的影响，得到 $\hat{\beta}_{age} = -0.05$。
    -   计算 $OR_{age} = \exp(-0.05) \approx 0.95$。
    -   **解释:** 年龄**每增加 1 岁**，购买该产品的**优势**变为原来的\*\* 0.95 倍\*\* (即降低了约 5%) (在控制其他变量后)。
-   **分类自变量的 OR:** 如果 $X_j$ 是一个分类变量（如用虚拟编码表示），$e^{\beta_j}$ 表示该类别相对于**参照类别**的优势比。

::: {.callout-warning title="OR vs RR"}
优势比 (OR) **不等于** 相对风险 (Relative Risk, RR = $P(Y=1|X_j+1) / P(Y=1|X_j)$)。只有当事件发生率很低时，OR 才近似等于 RR。解释时要用“优势”而非“风险”或“概率”。
:::

## 5. R 实现: `glm()` (Generalized Linear Model)

使用 `glm()` 函数拟合 Logistic 回归模型。

-   **关键参数:**

    -   `formula`: 与 `lm()` 类似，`Y ~ X1 + X2 + ...`。Y 应该是 0/1 编码或因子（R 会自动处理第一个水平为 0，第二个为 1）。
    -   `family`: 指定模型的分布族和连接函数。对于 Logistic 回归，使用 `family = binomial(link = "logit")` 或简写 `family = binomial`。
    -   `data`: 数据框。

-   **示例:** 使用 `mtcars` 数据集，预测汽车是自动挡 (am=0) 还是手动挡 (am=1)，基于马力 (hp) 和重量 (wt)。

    ``` r
    # 准备数据，确保 am 是因子或 0/1
    mtcars_data <- mtcars %>%
      mutate(am = factor(am, levels = c(0, 1), labels = c("Automatic", "Manual"))) # 将 am 转为因子

    # glimpse(mtcars_data)

    # 拟合 Logistic 回归模型
    # 预测 am 为 Manual (1) 的概率
    logistic_model <- glm(am ~ hp + wt, data = mtcars_data, family = binomial)

    # 查看模型摘要
    summary(logistic_model)
    ```

-   **解读 `summary(logistic_model)`:**

    ```         
    Call:
    glm(formula = am ~ hp + wt, family = binomial, data = mtcars_data)

    Deviance Residuals: # 残差，解释较复杂，后续评估会用到
        Min        1Q    Median        3Q       Max
    -1.90693  -0.41426  -0.15149   0.34966   1.74990

    Coefficients:
                 Estimate Std. Error z value Pr(>|z|) # 注意是 z value
    (Intercept) 12.20400    5.53743   2.204   0.0275 *
    hp           0.03560    0.01961   1.815   0.0695 . # hp 的 beta_hat
    wt          -6.11890    2.42060  -2.528   0.0115 * # wt 的 beta_hat
    ---
    Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

    (Dispersion parameter for binomial family taken to be 1)

    Null deviance: 43.860  on 31  degrees of freedom
    Residual deviance: 25.568  on 29  degrees of freedom # 偏差，用于模型比较
    AIC: 31.568 # AIC

    Number of Fisher Scoring iterations: 6
    ```

    -   **`Coefficients` 表:**

        -   `Estimate`: 系数 $\hat{\beta}_j$ 的估计值。
        -   `Std. Error`: 标准误。
        -   `z value`: Wald z 统计量，用于检验 $H_0: \beta_j = 0$。
        -   `Pr(>|z|)`: 对应的 P 值。

    -   **系数解释 (计算 OR):**

        ``` r
        # 计算系数的 OR
        exp(coef(logistic_model))
        # (Intercept)          hp          wt
        # 199087.1037      1.0362      0.0022

        # 计算系数的置信区间 (对数优势尺度)
        confint(logistic_model)
        # 计算 OR 的置信区间
        exp(confint(logistic_model))
        #                    2.5 %      97.5 %
        # (Intercept) 3.900118e+00 1.616111e+07
        # hp          9.974981e-01 1.077501e+00
        # wt          1.760519e-04 2.203618e-01
        ```

        -   **hp:** $\hat{\beta}_{hp} \approx 0.036$ (P ≈ 0.07)。$OR_{hp} = \exp(0.036) \approx 1.036$。
            -   解释：在保持重量 (wt) 不变的情况下，马力 (hp) 每增加 1 单位，汽车为**手动挡 (Manual)** 的**优势**是原来的 **1.036 倍** (约增加 3.6%)。但这个效应在 $\alpha=0.05$ 水平下不显著 (P \> 0.05)。95% CI for OR: \[0.997, 1.078\]，包含 1。
        -   **wt:** $\hat{\beta}_{wt} \approx -6.119$ (P \< 0.05)。$OR_{wt} = \exp(-6.119) \approx 0.0022$。
            -   解释：在保持马力 (hp) 不变的情况下，重量 (wt) 每增加 1000 磅，汽车为**手动挡 (Manual)** 的**优势**变为原来的 **0.0022 倍** (即优势显著降低)。效应显著。95% CI for OR: \[0.00018, 0.22\]，不包含 1。

## 6. Capstone 综合项目启动

本周，我们将正式启动课程的 **Capstone 综合项目**！

-   **目标:** 应用本课程（主要是第一阶段，后续会补充第二阶段知识）所学的数据处理、可视化和统计推断/建模技能，选择一个你感兴趣的数据集和研究问题，完成一次相对完整的数据分析过程，并撰写报告或进行展示。
-   **选题方向:**
    -   可以使用课程提供的示例数据集。
    -   可以寻找公开数据集（如 Kaggle, UCI Machine Learning Repository, 政府公开数据平台等）。
    -   可以使用与你专业领域相关的数据（需确保可获取性）。
    -   **关键:** 选择一个\*\* manageable\*\* (可管理的) 范围，问题要明确，数据要相对规整或可通过 `tidyverse` 清理。
-   **时间节点 (暂定，以老师最终通知为准):**
    -   **第 11-12 周:** 确定选题、研究问题、获取数据、初步数据探索 (EDA)。
    -   **第 13-14 周:** 数据清理、模型构建（选择合适的统计方法）、模型诊断与改进。
    -   **第 15 周:** 结果解释、报告撰写、展示准备、预演与反馈。
    -   **第 16 周:** 最终项目展示与答辩 / 报告提交。
-   **评分标准 (大致方向):**
    -   问题定义的清晰性与合理性。
    -   数据处理与准备的恰当性。
    -   探索性数据分析 (可视化) 的有效性。
    -   统计方法选择与应用的正确性。
    -   模型诊断与评估的完整性 (如适用)。
    -   结果解释的准确性与深入性。
    -   报告/展示的清晰度与专业性。

**本周任务:** 开始思考你的 Capstone 项目选题！寻找可能的数据集，明确你想要通过数据分析回答什么问题。下周我们将讨论选题并进行初步的数据探索。

## 7. 本周总结与预告

本周我们开启了分类预测的大门，学习了 Logistic 回归的基本原理，包括 Sigmoid 函数、Logit 变换以及最重要的优势比 (Odds Ratio) 解释。我们还掌握了使用 `glm()` 函数在 R 中拟合模型的方法。同时，Capstone 项目正式启动，请大家积极思考选题。

**下周预告:** 拟合了 Logistic 回归模型，如何评估它的表现？下周我们将学习 Logistic 回归的**评估指标**，如混淆矩阵、准确率、精确率、召回率、F1 分数以及 ROC 曲线和 AUC 值，并探讨如何在不同模型间进行比较。